<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/Blog">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

  <title>Machine Learning, Week 3</title>
  <meta name="description" content="" />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Machine Learning, Week 3">
  <meta name="twitter:description" content="지난 시간엔 Regression 을 해결하기 위해 graident descent 알고리즘을 도입했었다. learning rate, vectorization 등에 대해서 알아 보기도 했고. 이번시간엔 classification 과 regulrzation 에 대해서 배워 본다.  이 수업이 재밌는 이유는 수식을 증명하는 것보다 수식속에 숨겨진 내용들을 직관적으로 이해할 수 있게 설명하기 때문이다. 그러나 교수님 과제는 제발 그만 Classification regression 이">
  <meta name="twitter:creator" content="@yourTwitterUsername">
  <meta name="twitter:image" content="">
  <meta name="twitter:url" content="http://1ambda.github.io/machine-learning-week-3/">
  <meta name="twitter:domain" content="http://1ambda.github.io">

  

  <link rel="author" href="https://plus.google.com/101105410053351451441?rel=author" />

  <link rel="shortcut icon" href="../favicon.ico">

  <link rel="stylesheet" type="text/css" href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" />
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Droid+Serif" />
  <link rel='stylesheet' type='text/css' href="http://fonts.googleapis.com/css?family=Open+Sans:600,300" />
  <link rel="stylesheet" type="text/css" href="../assets/stylesheets/xpressio.css" />
  <link rel="stylesheet" type="text/css" href="../assets/1ambda/1ambda.css" />
  <script type="text/javascript" src="../assets/1ambda/modernizr.js">
  </script>
  <script type="text/javascript" src="../assets/1ambda/detectizr.min.js">
  </script>

  <!--load css if windows -->
  <script type="text/javascript">
    if (Modernizr.windows) {
      file = location.pathname.split( "/" ).pop();
      link = document.createElement( "link" );
      link.href = "/assets/1ambda/1ambda_windows.css";
      link.type = "text/css";
      link.rel = "stylesheet";
      link.media = "screen,print";
      document.getElementsByTagName("head")[0].appendChild( link );
    }
  </script>


  
  <link rel="stylesheet" href="../assets/highlight/styles/github.css">
<script src="../assets/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


  <meta name="generator" content="Ghost 0.5" />
<link rel="alternate" type="application/rss+xml" title="Old Lisper" href="../rss">
<link rel="canonical" href="http://1ambda.github.io/machine-learning-week-3/" />

  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52181619-1', '1ambda.github.io');
  ga('send', 'pageview');
</script>

  
</head>
<body>

  
  <script src="../public/jquery.js?v=3ee5474a99"></script>

  

<header class="site_width text center padding_top_big margin_bottom_big">
  
  <h1 class="blog_title margin_bottom_small"><a href="http://1ambda.github.io">Old Lisper</a></h1>
  <h4 class="text book">Lisp, Emacs, Scala</h4>
  
  <div class="social border solid top_small bottom_small padding_medium">
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="/about-me"><i class="fa fa-user"></i> <span class="margin_left_small desktop">About me</span></a></h6>
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="http://kr.linkedin.com/in/1ambda" target="_blank"><i class="fa fa-linkedin-square"></i> <span class="margin_left_small desktop">Linkedin</span></a></h6>
  <h6 class="text book color c_black_medium without_margin"><a href="http://github.com/1ambda" target="_blank"><i class="fa fa-github"></i> <span class="margin_left_small desktop">GitHub</span></a></h6>
</div>

</header>

<main class="site_width" role="main">
  <article class="post tag-coursera tag-machine-lerning tag-regularization tag-classification">

    

    <header class="text center margin_bottom_medium">
      <h5 class="text book small uppercase color c_black_light margin_bottom_small">Posted in <a href="../tag/coursera">coursera</a>, <a href="../tag/machine-lerning">machine lerning</a>, <a href="../tag/regularization">regularization</a>, <a href="../tag/classification">classification</a></h5>
      <h1 class="margin_bottom_medium">Machine Learning, Week 3</h1>
      <h5 class="text book small uppercase color c_black_light margin_bottom_small"><time datetime="2014-10-15">Wednesday, October 15, 2014</time>
      <br/><br/>
       <a href="http://1ambda.github.io/machine-learning-week-3/#disqus_thread">Comment</a>
      </h5>
    </header>

    <section>
      <p>지난 시간엔 <em>Regression</em> 을 해결하기 위해 <em>graident descent</em> 알고리즘을 도입했었다. <em>learning rate</em>, <em>vectorization</em> 등에 대해서 알아 보기도 했고. 이번시간엔 <em>classification</em> 과 <em>regulrzation</em> 에 대해서 배워 본다. </p>

<p>이 수업이 재밌는 이유는 수식을 증명하는 것보다 수식속에 숨겨진 내용들을 직관적으로 이해할 수 있게 설명하기 때문이다. <del>그러나 교수님 과제는 제발 그만</del></p>

<h3 id="classification">Classification</h3>

<p><em>regression</em> 이 <em>continuous value</em> 를 다룬다면 <strong>Classification</strong> 은 <strong>discrete value</strong> 를 다룬다. 따라서 <em>Classification (분류)</em> 의 예는,</p>

<ul>
<li>이메일이 스팸인지 / 아닌지  </li>
<li>온라인 거래가 사기인지 / 아닌지 (Online Transaction: Fraudulent)  </li>
<li>악성 종양인지 / 아닌지  </li>
</ul>

<p><img src="http://i.stack.imgur.com/VVtRW.png" align="center" />  </p>

<p align="center">(<a href='http://stats.stackexchange.com'>http://stats.stackexchange.com</a>)</p>

<p>위와 같은 경우, <em>Regression</em> 으로 문제를 풀면 당장은 맞아 보이나, 종양이 이상한 위치에 생겼을 경우 아래와 같이 직선이 크게 변한다.</p>

<p><img src="http://i.stack.imgur.com/nEC4H.png" align="center" />  </p>

<p align="center">(<a href='http://stats.stackexchange.com'>http://stats.stackexchange.com</a>)</p>

<p>따라서 이렇게 <em>discrete value</em> 에 대해서는 <em>Regression</em> 보다는 <em>Threshold</em> 에 기반을 두어, <code>h(x)</code> 가 일정 값 이상이면 <code>y=1</code> 로 예측하는 편이 더 정확도가 높아진다. 게다가 <em>regression</em> 은 직선이기 때문에, <code>0 &lt;= y &lt;= 1</code> 인 <code>y</code> 에 대해서 0보다 작거나, 1보다 더 큰 <code>y</code> 를 만들어낼 수 있다.</p>

<p>이런 이유 때문에 <em>Classification</em> 문제에 <em>Regression</em> 을 잘 사용하지 않는다. 그러나 <code>y</code> 의 범위가 <code>0 &lt;= h(x) &lt;= 1</code> 을 가지는 <em>Logistic Regression</em> 도 있다. 이건 <em>Classification</em> 에 사용되기도 한다.</p>

<h3 id="logisticregression">Logistic Regression</h3>

<p>이전에 언급했듯이 <em>classification</em> 에선 예측된 값, 즉 <code>h(x)</code> 값이 0 과 1사이에 있길 바란다. 이를 위해 <em>logistic function</em>, 혹은 <strong>sigmoid function</strong> 이라 불리는 아래 식을 <em>hypothesis</em> <code>h(x)</code> 에 적용하면 아래와 같은 그림이 나온다.</p>

<p><img src="http://www.saedsayad.com/images/ANN_Sigmoid.png" align="center" />  </p>

<p align="center">(<a href='http://www.saedsayad.com'>http://www.saedsayad.com</a>)</p>

<p>이 때 <em>sigmoid function</em> 이 적용된 <code>h(x)</code> 는 최대값이 1이므로, 이건 입력값 <code>x</code> 에 대해서 <code>y</code> 가 1이 나올 확률이라 보아도 된다. 따라서</p>

<p><code>h(x) = P(y = 1 | x ; 0)</code></p>

<blockquote>
  <p>Probability that <code>y = 1</code>, given <code>x</code>, parameterized by <code>0(theta)</code></p>
</blockquote>

<p>이 때 <em>sigmoid function</em> 을 보면, X 축이 0보다 큰 점에선 <code>y</code> 값이 0.5 보다 크므로, 이 점 이후부터는 <code>y</code> 를 1 이라 <em>예측 (predict)</em> 하고, 반대로 X 축 값이 0보다 작은 지점에선 <code>y</code> 를 0이라 예측할 수 있다.</p>

<p>그런데 <code>h(x) = g(0^T * x)</code> 이므로, 본래의 <em>hypothesis</em> <code>0^T * x</code> 가 0이 되는 지점을 찾으면 된다.</p>

<p><img src="http://my.csdn.net/uploads/201207/04/1341403634_5914.jpg" align="center" />  </p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer/'>http://blog.csdn.net/abcjennifer/</a>)</p>

<h3 id="decisionboundary">Decision Boundary</h3>

<p>이제 실제로 문제에 적용해 보자. 다음과 같이 두개의 집단이 있을때, 이 두 집단을 가르는 식을 찾기 위한 <code>h(x) = g(01 + 01x1 + 02x2)</code> 가 있다고 해 보자. </p>

<p><img src="http://my.csdn.net/uploads/201207/05/1341470683_7505.jpg" align="center" />  </p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer/'>http://blog.csdn.net/abcjennifer/</a>)</p>

<p>이때 <code>0(theta)</code> 를 <code>[-3; 1; 1]</code> 로 잡으면 <code>y</code> 가 <code>1</code> 이 되는 지점은 <code>0^T * x &gt;= 0</code> 인 지점, 즉 <code>-3 + x1 + x2 &gt;= 0</code> 인지점을 찾으면 된다. 이 식을 풀어서 쓰면</p>

<p><code>x1 + x2 =&gt; 3</code> 이므로, 위 그림에서 분홍색 선을 찾을 수 있다. 이 선을 <strong>Decision Boundary</strong> 라 부른다. 그리고 이 <em>Decision Boundary</em> 는 <code>g(z) = 0</code> 즉,  <code>h(x) = 0.5</code> 인 지점이다.</p>

<p><em>Non-linear dicision boundary</em> 는 어떨까?</p>

<p><img src="http://my.csdn.net/uploads/201207/05/1341471338_7289.jpg" align="center" />  </p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer/'>http://blog.csdn.net/abcjennifer/</a>)</p>

<p>이 경우  <code>x1^2</code>, <code>x2^2</code> 이라는 새로운 <em>feature</em> 를 도입하고, <em>parameter</em> 인 <code>theta</code> 를 <code>[-1; 0; 0; 1; 1;]</code> 로 잡았다. 식을 풀면, 위와 같은 원 형태의 <em>Decision Boundary</em> 가 나온다.</p>

<p><em>feature</em> 만 잘 조합하면, 즉 <em>polynomial</em> 만 잘 만들면 땅콩이나 하트모양 등의 <em>Decision boundary</em> 도 만들 수 있다.</p>

<h3 id="costfunction">Cost Function</h3>

<p>이제 문제는 <code>theta</code> 를 어떻게 고르느냐 하는건데, 식을 좀 다시 살펴보자.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[9].png" align="center" /> <br />
<img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[11].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p><em>Linear regression</em> 에서 사용하는 <em>cost function</em> 에 지금의 <code>h(x)</code>, 즉 <em>sigmoid function</em> 이 적용된 <code>h(x)</code> 를 제곱한 <code>J(0)</code> 는 <em>non-convex</em> 형태가 된다. 따라서 <em>global optimum</em> 보다는 <em>local optimum</em> 을 찾게 된다. </p>

<p>이를 방지하기 위해서, <em>convex</em> 형태의 <em>cost function</em> 을 사용해야 하는데, </p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[12].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>이 <em>cost function</em> 을 사용하면, <code>y = 1</code> 일때 다음과 같은 그래프를 얻게 된다. <code>0 &lt;= h(x) &lt;= 1</code> 임을 참고하자. <code>y = 1</code> 일때, <code>h(x) = 0</code> 으로 가면, <em>cost function</em> 의 값, 즉 <em>cost</em> 자체가 높아지므로, <em>Cost</em> 를 낮추는 반대 방향으로 움직이게 된다. </p>

<p>직관적으로 보면, <code>h(x)</code> 자체는 <code>y = 1</code> 일 확률인데, <code>y = 1</code> 일때, <code>h(x) = 0</code> 이라는 것은 말이 안 되므로 비용이 무한대로 증가하는 것이 말이 된다.  </p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[13].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>반대로 <code>y = 0</code> 일때의 그래프를 보면 <code>h(x) = 0</code> 즉, <code>y = 0</code> 일 확률이 <code>0</code> 으로 갈때 <em>cost</em> 가 감소한다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[14].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>결국 아래의 새로운 <em>logistric regression cost function</em> 을 이용하면, <code>J(0)</code> 를 <em>convex function</em> 으로 만들 수 있다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[12].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<h3 id="simplifiedcostfunctionandgradientdescent">Simplified Cost Function and Gradient Descent</h3>

<p>이제 <code>y = 0</code>, <code>y = 1</code> 로 나누어져 있던 <em>cost function</em> 을 좀 더 간단히 표현해 보자.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[15].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>다음과 동일하다. <code>y = 0</code>, <code>y = 1</code> 을 직접 넣어보면 금방 알 수 있다.</p>

<p><code>cost(hθ(x),y) = -y * log(hθ(x)) - (1-y) * log(1 - hθ(x))</code></p>

<p><br/> <br />
자 이제 다시 본론으로 돌아와서, 우리는 처음에 <code>theta</code> 를 찾길 원했고, 그래서 <em>gradient descent</em> 를 쓰려고 했는데, 마침 보니 <code>h(x)</code> 가 <em>sigmoid function</em> 이 적용된 형태라서 <em>non-convex function</em> 이므로, <code>h(x)</code> 를 포함한 <em>cost-function</em> 이 <em>convex function</em> 이 되는 식을 찾아냈다. 이제 그 식을 <em>gradient descent</em> 에 적용하면,</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[16].png" align="center" /></p>

<p>이고, 이제 이걸 <em>batch gradient descent</em> 에 적용하면 아래와 같은데, 여기에 <em>partial derivative</em> 를 적용하면</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[20].png" align="center" /></p>

<p>놀랍게도 <em>linear regression</em> 과 같은 식이 나온다. <del>오오 머신러닝 오오</del></p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[18].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>다만 다른점은 <em>hypothesis</em> 가 <em>sigmoid function</em> 을 적용한 형태라는 것,</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[17].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<h3 id="advancedoptimization">Advanced Optimization</h3>

<p>위에서 보았겠지만, <code>J(0)</code> 의 최소값을 찾기 위해서는 아래 두개의 값을 구해야 한다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[19].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>이 값들을 이용해서 <em>gradient descent</em> 대신 다음의 알고리즘을 사용할 수 있다.</p>

<p>(1) Conjugate gradient <br />
(2) BFGS <br />
(3) L-BFGS  </p>

<p>이 알고리즘들의 장점은, <em>leanring rate</em> 를 고를 필요가 없고, 대부분 <em>gradient decsent</em> 보다 빠르다. </p>

<p>그러나 더 복잡하고, 라이브러리마다 구현이 다를 수 있으며, 디버깅이 힘들수 있다. 자 이제 <em>advanced optimization</em> 을 이용해 보자.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[21].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>위와 같은 식에 대해서 <em>cost function</em> 을 <code>octave</code> 에서 이렇게 만들 수 있다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[22].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>  

<p><br/></p>

<p>이제, <code>octave</code> 에서 제공해 주는 <code>fminunc</code> 에 우리가 만든 <code>costFunction</code> 과 초기 <code>theta</code> 값, 그리고 옵션을 집어 넣으면</p>

<pre><code class="matlab">% define the options data structure
options= optimset('GradObj', 'on', 'MaxIter', '100'); 

% set the initial dimensions for theta % initialize the theta values
initialTheta= zeros(2,1); 

% run the algorithm
[optTheta, funtionVal, exitFlag]= fminunc(@costFunction, initialTheta, options); 
</code></pre>

<p><code>optTheta</code> 는 우리 찾길 원했던 <code>theta</code> 값이고, <code>functionVal</code> 은 최종 <em>cost</em> 를 돌려준다. <code>exstFlag</code> 는 알고리즘이 수렴했는지, 아닌지 알려준다.</p>

<p>만약 <em>logistic regression</em> 에 대한 <code>theta</code> 값을 찾고 싶으면, <em>cost function</em> 을 <em>logistic regression</em> 에 맞게 작성하면 된다.</p>

<h3 id="multiclassclassification">Multiclass Classification</h3>

<p>이제 단순히 <code>y = 0 or 1</code>(<em>binary classification</em>) 이 아닌, 다양한 <em>class</em> 가 있는 <em>classification</em> 을 고려해보자, 예를 들면 날씨는 <code>sunny</code>, <code>cloudy</code>, <code>hot</code>, <code>cold</code> 등으로 분류될 수 있다.</p>

<h4 id="onevsallonevsrest">one-vs-all (One-vs-rest)</h4>

<p><em>multi class</em> 를 분류할 수 있는 한가지 방법은, 하나를 정하고, 그 나머지와 분류하는것이다. 이걸 <em>class</em> 갯수만큼 진행하면,</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[23].png" align="center" /> <br />
<img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[24].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>위 그림과 같은 경우, <em>class</em> 가 3개기 때문에 <code>(i = 1, 2, 3)</code> 으로 놓으면 <code>i</code> 마다 각각의 <code>hθ^(i)(x)</code> 값, 즉 예측 값을 얻을 수 있다. 따라서 새로운 무언가가 input 으로 들어왔을때, <code>hθ^(i)(x)</code> 값을 최대로 해주는 <code>i</code> 을 선택하면 분류가 된다. <del>참 쉽죠?</del></p>

<h3 id="overfitting">Overfitting</h3>

<p><strong>Overfitting</strong> 은 너무나 많은 <em>feature</em> 가 있을 때는 <em>cost function</em> 이 트레이닝 셋에 잘 맞아 <code>0</code> 에 수렴 하지만, 새로운 데이터가 들어왔을때는 예측을 잘 하지 못하는 경우를 말한다. 다시 말해 <em>hypothesis</em> 가 너무 고차원의 다항식이어서 그렇다. <em>(too many parameters)</em> 즉 아래 그림에서 좌측은 경향을 나타내긴 하지만 모든 트레이닝셋을 경유하는 직선은 만들어내지 못했다. (<em>under fit</em>) 반면 가장 우측은, 트레이닝셋을 모두 경유하는 <em>hypothesis</em> 를 만들어 냈지만, 다항식의 차수가 너무 높아 새로운 데이터가 들어왔을 때 예측하지 못할 수가 있다. <em>can't apply, unable to generalize</em> 교수님은 다음과 같이 슬라이드에 적으셨다.</p>

<blockquote>
  <p>It makes accurate predictions for examples in the training set, but it does not generalize well to make accurate prediction on new, previously unseen examples</p>
</blockquote>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image.png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p><em>logistic regression</em> 에서도 <em>Overfitting</em> 이 발생할 수 있다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[1].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>주로 <em>training set</em> 이 부족하고 <em>feature</em> 가 많을때 발생하는데 해결책은</p>

<p>(1) <em>feature</em> 를 줄일 수 있다. 수동으로 사용할 <em>feature</em> 를 선택하는 방법과 <em>Model selection algorithm</em> 을 사용할 수도 있다. <br />
(2)  <em>regularization</em> 을 이용한다. 모든 <em>feature</em> 를 유지하지만, 얼마나 각 <em>feature</em> 가 <em>prediction</em> 에 기여할지를 변경한다.</p>

<h3 id="regularizationcostfunction">Regularization, Cost function</h3>

<p><em>Regularization</em> 은 원하는 파라미터가 <em>hypothesis</em> 에 기여하는 바를 조절하는 것이다. 우리가 만약에 <code>0_3</code> 과 <code>0_4</code> 를 최소화 하고 싶다고 하자.  그럼 다음과 같은 식을 만들면 된다. 전체 식의 최소값을 찾는 것이기 때문에, 상수가 <code>1000</code> 인 <code>0_3</code>, <code>0_4</code> 는 <em>0(zero)</em> 에 가까운 수가 나온다. 다시 말해서 이들 두 파라미터가 기여하는 바를 줄인 것이다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[2].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p><em>parameters</em> 가 작은 값을 가질수록 간단한 <em>hypothesis</em> 가 나오고, <em>overfitting</em> 하지 않는다. 이를 위해 <code>λ</code> 라는 <em>regularization parameter</em> 를 가진 식을 <em>cost function</em> 에 더 붙여 <em>parameter</em> 가 기여하는 바를 조절하면, 아래와 같은 식을 구할 수 있다. 참고로 뒷 부분의 식은  <em>regularization term</em> 이라 부르는데, <code>j</code> 가 1부터 시작하는 것에 주목하자. 이는 <code>0_0</code> 은 <em>regularization</em> 하지 않는다는 의미이다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[5].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p><code>λ</code> 가 매우 크면 어떻게 될까? <code>0_0</code> 이외의 다른 파라미터는 0에 수렴 하므로, <em>hypothesis</em> 는 상수가 되어 트레이닝 셋에 <em>under fit</em> 할 것이다.</p>

<h3 id="regularizedlinearregression">Regularized Linear Regression</h3>

<p><em>regularization term</em> 으 <code>j</code> 가 1부터 시작하므로, <em>cost function</em> 을 쉽게 계산하기 위해 분리하면 <em>gradient descent</em> 식은 다음과 같이 적을 수 있다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[6].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<p>이제 위 두 식에서 아래 식을 정리하면, 다음과 같고</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[8].png" align="center" /> <br />
&lt;면 된다. 이때 이 매트릭스의 <code>(0, 0)</code> <br />
위 식에서 앞부분은 아래와 같다. 보통 <code>m</code> 이 매우 크고, <code>a</code> 가 매우 작으므로 위 값은 1보다 작다. 예를 들면 <code>0.99 * 0_j</code> 처럼. </p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[9].png" align="center" /></p>

<p>이제 <em>Normal equation</em> 에 어떻게 적용할지 고려해 보자, 본래 <em>normal equation</em> 식은 아래와 같은데, </p>

<p><img src="http://www.holehouse.org/mlclass/04_Linear_Regression_with_multiple_variables_files/Image%20[13].png" align="center" /></p>

<p><code>X^T * X</code> 부분에 <code>λ</code> 가 곱해지는 <code>n+1 * n+1</code> 의 <em>matrix</em> 를 곱하면 된다. 이때 이 매트릭스의 <code>(0, 0)</code> 부분이 <code>0</code> 인 것은 <code>0_0</code> 에 <em>regularization</em> 을 적용하지 않기 위한 것.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[10].png" align="center" /></p>

<p>그럼 만약에 <code>X^T * X</code> 가 <em>non-invertible</em> 이라면 어떻게 될까? 이건 지난 시간에 언급했듯이 <em>redundant feature</em> 가 너무 많거나, <code>m &lt;= n</code>, 즉 트레이닝 셋에 비해 <em>feature</em> 가 너무 많을 때 발생한다고 말했다.</p>

<p>놀랍게도, <code>λ &gt; 0</code> 이면, 아래 식에서 <code>X^T * X + λ</code> (λ's (0, 0) = 0) 은 제대로 <em>invertible</em> 함을 증명할 수 있다. 다시 말해서 <em>regularzation</em> 을 통해서 <em>non-invertible</em> 문제도 해결할 수 있다는 것.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[10].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>

<h3 id="regularizedlogisticregression">Regularized Logistic Regression</h3>

<p><em>linear regression</em> 과 마찬가지로 <code>0(theta)</code> 를 0과 1로 분리해 <em>regularization term</em> 을 추가하면 된다. 다른점은 <code>h(x)</code> 가 <em>sigmoid function</em> 의 형태라는 것.</p>

<p>그리고 <em>gradient descent</em> 를 풀기 위해 <em>octave</em> 에서 제공하는 알고리즘들을(<em>conjugate</em>, <em>BFGS</em>, <em>L-BFGS</em> 등) 을 <code>fminunc</code> 이용해서 사용할 수 있다. 이를 위해 언급 했듯이 <code>jval</code> 과 <code>0(theta)</code> 에 대한 <code>graident</code> 를 돌려주는 <em>cost function</em> 을 만들어야 하는데, <em>regularzation term</em> 이 추가되었으므로 해당하는 값을 더해서 각 <code>0</code> 에 대한 <em>gradient</em> 를 계산하는 식을 만들어주면 된다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[16].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/'>http://www.holehouse.org/</a>)</p>  

<p><br/></p>

<h3 id="summary">Summary</h3>

<p>3주째에는 <em>Classification</em> 과 <em>Regularization</em> 에 대해서 배웠다. 수업은 어렵지 않다. 과제가 문제지 ㅠㅠ 교수님. 파이썬으로 과제를 내주셨으면 좀 더 배우는 맛이 있었을텐데요!</p>

<h3 id="references">References</h3>

<p>(1) <a href="http://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression">why-not-approach-classification-through-regression</a> <br />
(2) <a href="http://www.saedsayad.com/artificial_neural_network.htm">http://www.saedsayad.com</a> <br />
(3) <a href="http://blog.csdn.net/abcjennifer/">http://blog.csdn.net/abcjennifer/</a> <br />
(4) <a href="http://www.holehouse.org/">http://www.holehouse.org/</a>  </p>

<p><strong>Machine Learning</strong> by Andrew Ng, <em>Coursera</em></p>
    </section>

    <footer>
      
      <section class="author_info margin_top_big">
        <div class="alignleft border rad_circle" style="height: 87px; width: 87px; background-image: url(http://www.gravatar.com/avatar/aa2032ba2302419e3c2ede54f1fbf687?d=404&amp;s=250); background-size: cover;"></div>
        <p class="margin_left_medium text small">Author</p>
        <p class="margin_left_medium text bold"><a href="http://language.is">1ambda</a></p>
        <p class="margin_left_medium text small">Lisp, Emacs, FP</p>
      </section>
      
    </footer>

    

    
    <div id="disqus_thread" class="margin_top_big"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = '1ambda'; // required: replace example with your forum shortname
  var disqus_identifier = '46';
  var disqus_url = 'http://1ambda.github.io/machine-learning-week-3/';

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

    </article>
</main>


  
  <script src="../assets/fitvids/jquery.fitvids.js"></script>
<script>
$(document).ready(function(){
  // Target your .container, .wrapper, .post, etc.
  $("section").fitVids();
});
</script>


  <footer class="blog_info margin_top_big padding_medium text center">
    <h5 class="text book small">&copy; 2014 <a href="..">Old Lisper</a>. All rights reserved.</h5>
    <h5 class="text book small"><a href="https://github.com/dreyacosta/velox" target="_blank" class="text bold">Velox theme</a> by <a href="http://dreyacosta.com/">David Rey</a></h5>
    <h5 class="text book small">Proudly published with <a href="http://ghost.org"><span>Ghost</span></a></h5>

  </footer>

  
  <script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = '1ambda'; // required: replace example with your forum shortname

/* * * DON'T EDIT BELOW THIS LINE * * */
(function () {
 var s = document.createElement('script'); s.async = true;
 s.type = 'text/javascript';
 s.src = '//' + disqus_shortname + '.disqus.com/count.js';
 (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
 }());
</script>



  </body>
  </html>
