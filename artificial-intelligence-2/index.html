
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <title>Artificial Intelligence 2, Search</title>
  <meta name="description" content="">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Artificial Intelligence 2, Search">
  <meta name="twitter:description" content="Agents agent 가 good decision 을 내릴려면 planning 을 해야합니다. 그러기 위해선 어떤 action 이 좋을지 search (탐색) 해 보아야 하고 결국 풀어야 할 문제는 search problem 이 됩니다. (1) reflex agent Choose action based on current percept (and maybe memory) May have memory or a model of the world's">
  <meta name="twitter:creator" content="@yourTwitterUsername">
  <meta name="twitter:image" content="">
  <meta name="twitter:url" content="http://1ambda.github.io/artificial-intelligence-2/">
  <meta name="twitter:domain" content="http://1ambda.github.io">


  <link rel="author" href="https://plus.google.com/101105410053351451441?rel=author">

  <link rel="shortcut icon" href="../favicon.ico">

  <link rel="stylesheet" type="text/css" href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Droid+Serif">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open+Sans:600,300">
  <link rel="stylesheet" type="text/css" href="../assets/stylesheets/xpressio.css">
  <link rel="stylesheet" type="text/css" href="../assets/1ambda/1ambda.css">
  <script type="text/javascript" src="../assets/1ambda/modernizr.js">
  </script>
  <script type="text/javascript" src="../assets/1ambda/detectizr.min.js">
  </script>

  <!--load css if windows -->
  <script type="text/javascript">
    if (Modernizr.windows) {
      file = location.pathname.split( "/" ).pop();
      link = document.createElement( "link" );
      link.href = "/assets/1ambda/1ambda_windows.css";
      link.type = "text/css";
      link.rel = "stylesheet";
      link.media = "screen,print";
      document.getElementsByTagName("head")[0].appendChild( link );
    }
  </script>


  <link rel="stylesheet" href="../assets/highlight/styles/github.css">
<script src="../assets/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

  <link rel="canonical" href="http://1ambda.github.io/artificial-intelligence-2/">
    <meta name="referrer" content="origin">
    
    <meta property="og:site_name" content="Old Lisper">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Artificial Intelligence 2, Search">
    <meta property="og:description" content="Agents agent 가 good decision 을 내릴려면 planning 을 해야합니다. 그러기 위해선 어떤 action 이 좋을지 search (탐색) 해 보아야 하고 결국 풀어야 할 문제는 search problem 이 됩니다. (1) reflex agent Choose action based on current percept (and maybe...">
    <meta property="og:url" content="http://1ambda.github.io/artificial-intelligence-2/">
    <meta property="article:published_time" content="2015-02-19T06:59:46.300Z">
    <meta property="article:modified_time" content="2015-02-19T15:18:49.777Z">
    <meta property="article:tag" content="edx">
    <meta property="article:tag" content="artificial intelligence">
    <meta property="article:tag" content="CS188">
    <meta property="article:tag" content="search">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Artificial Intelligence 2, Search">
    <meta name="twitter:description" content="Agents agent 가 good decision 을 내릴려면 planning 을 해야합니다. 그러기 위해선 어떤 action 이 좋을지 search (탐색) 해 보아야 하고 결국 풀어야 할 문제는 search problem 이 됩니다. (1) reflex agent Choose action based on current percept (and maybe...">
    <meta name="twitter:url" content="http://1ambda.github.io/artificial-intelligence-2/">
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "Old Lisper",
    "author": {
        "@type": "Person",
        "name": "1ambda",
        "image": "//www.gravatar.com/avatar/aa2032ba2302419e3c2ede54f1fbf687?d=404&s=250",
        "url": "http://1ambda.github.io/author/1ambda",
        "sameAs": "http://1ambda.github.io",
        "description": "Functional, Scala, Akka, Rx and Haskell"
    },
    "headline": "Artificial Intelligence 2, Search",
    "url": "http://1ambda.github.io/artificial-intelligence-2/",
    "datePublished": "2015-02-19T06:59:46.300Z",
    "dateModified": "2015-02-19T15:18:49.777Z",
    "keywords": "edx, artificial intelligence, CS188, search",
    "description": "Agents agent 가 good decision 을 내릴려면 planning 을 해야합니다. 그러기 위해선 어떤 action 이 좋을지 search (탐색) 해 보아야 하고 결국 풀어야 할 문제는 search problem 이 됩니다. (1) reflex agent Choose action based on current percept (and maybe..."
}
    </script>

    <meta name="generator" content="Ghost 0.6">
    <link rel="alternate" type="application/rss+xml" title="Old Lisper" href="http://1ambda.github.io/rss/">

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52181619-1', '1ambda.github.io');
  ga('send', 'pageview');
</script>
  
</head>
<body>

  <script src="../public/jquery.js?v=1e25303174"></script>

  
<header class="site_width text center padding_top_big margin_bottom_big">
  
  <h1 class="blog_title margin_bottom_small"><a href="http://1ambda.github.io">Old Lisper</a></h1>
  <h4 class="text book">Functional Programming World</h4>
  <div class="social border solid top_small bottom_small padding_medium">
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="../articles.1"><i class="fa fa-columns"></i> <span class="margin_left_small desktop">Article</span></a></h6>
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="http://kr.linkedin.com/in/1ambda" target="_blank"><i class="fa fa-linkedin-square"></i> <span class="margin_left_small desktop">Linkedin</span></a></h6>
  <h6 class="text book color c_black_medium without_margin"><a href="http://github.com/1ambda" target="_blank"><i class="fa fa-github"></i> <span class="margin_left_small desktop">GitHub</span></a></h6>
</div>
</header>

<main class="site_width" role="main">
  <article class="post tag-edx tag-artificial-intelligence tag-cs188 tag-search">


    <header class="text center margin_bottom_medium">
      <h5 class="text book small uppercase color c_black_light margin_bottom_small">Posted in <a href="../tag/edx/">edx</a>, <a href="../tag/artificial-intelligence/">artificial intelligence</a>, <a href="../tag/cs188/">CS188</a>, <a href="../tag/search/">search</a></h5>
      <h1 class="margin_bottom_medium">Artificial Intelligence 2, Search</h1>
      <h5 class="text book small uppercase color c_black_light margin_bottom_small"><time datetime="2015-02-19">Thursday, February 19, 2015</time>
      <br><br>
       <a href="http://1ambda.github.io/artificial-intelligence-2/#disqus_thread">Comment</a>
      </h5>
    </header>

    <section>
      <p><img src="http://picm.yourswallpaper.com/other/box-robot_18407.jpg" alt=""></p>

<p><br></p>

<h3 id="agents">Agents</h3>

<p><em>agent</em> 가 <em>good decision</em> 을 내릴려면 <em>planning</em> 을 해야합니다. 그러기 위해선 어떤 <em>action</em> 이 좋을지 <em>search (탐색)</em> 해 보아야 하고 결국 풀어야 할 문제는 <em>search problem</em> 이 됩니다.</p>

<p>(1) <strong>reflex agent</strong></p>

<ul>
<li>Choose action based on current percept (and maybe memory)</li>
<li>May have memory or a model of the world's current state</li>
<li>Do not consider the future consequences of their action</li>
<li>Consider how the world <strong>IS</strong></li>
</ul>

<p>자신이 인지하는 <em>environment</em> 에 기반하여 어떤 <em>action</em> 을 취할지 결정하나, <em>action</em> 의 결과를 고려하지 않고 결정을 내리기에 문제가 생길 수 있습니다. <em>reflext agent</em> 가 <em>rational</em> 할 수 있을까요?</p>

<blockquote>
  <p>Of course. Rationality is a function of the actions you take, not the computation. So if you had a big enough, good enough lookup table, and you're taking the right actions. <strong>Rationality doesn't care what process led to them.</strong> Reflex is a comment on the thought process</p>
</blockquote>

<p>(2) <strong>planning agents</strong></p>

<p><em>planning agent</em> 는 <em>reflex agent</em> 와는 다르게 <strong>what if</strong> 를 질문합니다. 따라서</p>

<ul>
<li>Decisions based on (hypothesized) consequences of actions</li>
<li>Must have a model of how the world evolves in response to actinos</li>
<li>Must formulate a goal(test)</li>
<li>Consider how the world <strong>WOULD BE</strong></li>
</ul>

<p><em>planning agent</em> 는 <em>action</em> 을 선택할때 <em>real world</em> 에서 실제로 실행해보진 않습니다. 대신 <em>model</em> 을 이용해 <em>simulation</em> 을 해봅니다. 따라서 <em>planning agent</em> 에서는 <em>real world</em> 를 반드시 모델링 해야 합니다.</p>

<blockquote>
  <p>In order to have a planning agent, you must have <strong>a model of the world</strong></p>
</blockquote>

<p>그렇기 때문에 모델상에서 <em>goal</em> 인지 테스트 할 수 있는 방법도 필요합니다. </p>

<p><em>planning</em> 과 관련해서 <em>complete planning</em> 과 <em>optimal planning</em> 이 있습니다. <em>complete planning</em> 은 <em>solution</em> 을 찾아내고, <em>optimal planning</em> 은 <em>best solution</em> 을 찾아냅니다.</p>

<p>또한 <em>planning agent</em> 는 한번에 <em>plan</em> 을 세워 실행할 수도 있지만, 매 실행 후 다시 <em>re-planning</em> 할 수도 있습니다. </p>

<p><br></p>

<h3 id="searchproblem">Search Problem</h3>

<p><em>search problem</em> 은 다음처럼 구성됩니다.</p>

<ul>
<li><strong>A state space:</strong> models how the world is</li>
<li><strong>A successor function (with actions, costs):</strong> models how it evolves in response to your actions</li>
<li><strong>A start state</strong> and <strong>a goal test</strong></li>
</ul>

<p>그리고 <em>solution</em> 은 <em>start state</em> 를 <em>goal state</em> 로 변환하는 <em>a sequence of actions (a plan)</em> 입니다.</p>

<p>다시 정리하자면, <em>state</em> 는 <em>world</em> 를 어떻게 모델링 하는지를 나타내고, <em>successor function</em> 은 <em>action</em> 에 <em>world</em> 가 어떻게 반응할지를 나타냅니다.</p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/searchprbs_are_models.jpg" alt=""></p>

<blockquote>
  <p>Search problems are just models</p>
</blockquote>

<p>실제로 현실세계를 그대로 시뮬레이션하기엔 복잡하기때문에, 이를 계산하기 위해 <em>rough</em> 한 모델이 필요합니다. 이 <em>model</em> 적절하다면 <em>search problem</em> 의 결과도 정확합니다.</p>

<p>모델을 너무 추상화 해서 만들면 (<em>abstract too much</em>) 문제를 풀 수 없고, 그 반대라면 현실세계의 복잡함을 모두 다뤄야 하기 때문에 계산이 어려울 수 있습니다. 따라서 적절한 정도의 <em>abstraction</em> 이 필요합니다.</p>

<p>예를 들어 모든 <em>dot</em> 을 먹는 팩맨 에이전트를 만든다고 할때, <em>state</em> 에 문제를 풀기에 필요 이상의 정보를 넣으면 <em>search space</em> 가 너무 커져 계산이 어렵고, 너무 추상화해서 문제를 풀기에 필요한 정보가 부족하면 <em>solution</em> 을 찾는다 해도 올바른 <em>solution</em> 이 아닐 수 있습니다.</p>

<p><br></p>

<h3 id="searchstategraph">Search State Graph</h3>

<p><em>state space graph</em> 는 <em>search problem</em> 의 <em>mathematical representation</em> 입니다.</p>

<ul>
<li>Nodes are (abstracted) world configurations</li>
<li>Arcs represent successors (action results)</li>
<li>The goal test is a set of goal nodes (maybe only one)</li>
<li>In a search graph, each state occurs only once</li>
</ul>

<h3 id="searchstatetree">Search State Tree</h3>

<p><em>search tree</em> 는 <em>plan</em> 이 어떠할지를 나타내는 일종의 <em>what if tree</em> 입니다. </p>

<ul>
<li>The start state is the root node</li>
<li>Children correspond to successors</li>
<li>Nodes show states, but correspond to <strong>PLANS</strong> that achieve those states</li>
<li>For most problems, we can never actually build the whole tree</li>
</ul>

<p><em>general tree search</em> 알고리즘은</p>

<pre><code>function TREE-SEARCH(problem, strategy) returns a solution, or failure

  initialize the search tree using the initial state of problem

  loop do
    if there are no candidates for expansion 
      then return failure

    choose a leaf node for expansion according to strategy

    if the node contains a goal state
      then return the corresponding solution
      else expand the node and 
           add the resulting nodes to the search tree

  end
</code></pre>

<p>여기서 중요한 요소는 <em>fringe (현재 고려중인 nodes)</em>, <em>expansion</em>, <em>exploration strategy</em> 다. 특히 어떤 <em>fringe nodes</em> 를 선택할 것인가가 중요한 질문이 됩니다.</p>

<p>널리 알려진 방법으로 <em>Depth-First Serach</em>, <em>Breadth-First Search</em> 등이 있습니다. 이들 <em>search algorithm</em> 의 성능을 평가하기 위해 다음 요소를 고려할 수 있습니다. </p>

<ul>
<li><strong>complete:</strong> guaranteed to find a solution if one exists</li>
<li><strong>optimal:</strong> guaranteed to find the least cost path</li>
<li>time complexity</li>
<li>space complexity</li>
</ul>

<p>그리고 <em>DFS</em> 은 <em>branching factor</em> <code>b</code>, <em>depth</em> <code>m</code> 이라 했을때 </p>

<ul>
<li>At any given time during the search, the number of nodes on the fringe can be no larger than <code>b*m</code></li>
<li>The number of nodes expanded throughout the entire search can be as large as <code>b^m</code></li>
</ul>

<p><em>BFS</em> 알고리즘에서 <em>branching factor</em> <code>b</code>, <em>depth</em> <code>s</code> 라 했을때 </p>

<ul>
<li>At any given time during the search, the number of nodes on the fringe can be large as <code>b^s</code></li>
<li>The number of nodes expanded throughout the entire search can be as large as <code>b^s</code></li>
</ul>

<p>두 방법을 섞은 <em>iterative deepening</em> 이란 알고리즘도 있습니다. <em>limit 1</em> 까지는 <em>DFS</em> 를 돌려보고, 실패하면 <em>limit2</em> 까지 <em>DFS</em> 를 돌려보는 방식입니다. </p>

<p><em>Uniform Cost Search (UCS)</em> 란 것도 있는데 <em>priority queue</em> 를 이용해서 더 낮은 <em>cost</em> 부터 탐색하는 방식입니다. <em>UCS</em> 는 <em>complete</em>, <em>optimal search</em> 입니다. 단점으로는 </p>

<ul>
<li>Explores options in every direction</li>
<li>No information about goal location</li>
</ul>

<p><br></p>

<p>지금까지 배운 <em>search algorithm</em> 은 모두 <em>uninformed search</em> 입니다. 간단히 정리하면</p>

<ul>
<li>search operates <strong>over models of the world</strong></li>
<li>the agent doesn't actually try all the plans out in the real world</li>
<li>planning in all <strong>"in simulation"</strong></li>
<li><strong>your search is only as good as your models</strong></li>
</ul>

<p>위에서 본 <em>search algorithm</em> 은 <em>fringe strategies</em> 만 다르고 모두 동일합니다. 개념상으로는 모든 <em>fringes</em> 는 <em>priority queue</em>  입니다. <em>DFS</em> 와 <em>BFS</em> 의 경우에는 각각 <em>stack</em>, <em>queue</em> 를 이용해서 <em>priority queue</em> 의 <em>log(n)</em> 오버헤드를 피할 수 있습니다.</p>

<p><br></p>

<h3 id="informedsearch">Informed Search</h3>

<p>이번시간에는 <em>state</em> 의 정보를 이용하는 <em>informed search</em> 와 <em>graph search</em> 를 배웁니다. <em>informed search</em> 의 기본적인 아이디어는 <em>direction</em> 을 결정할때, <em>goal</em> 에 가까운 방향인지를 알 수 있는 정보를 이용하는 것입니다.</p>

<p>(1) <strong>informed search</strong></p>

<ul>
<li>heuristics</li>
<li>greedy search</li>
<li>A* search</li>
</ul>

<p>(2) <strong>Graph Search</strong></p>

<p><br></p>

<h3 id="searchheuristics">Search Heuristics</h3>

<p><em>A heuristic is:</em></p>

<ul>
<li>A function that <strong>estimatees</strong> how close a state is to a goal</li>
<li>Designed for a particular search problem</li>
</ul>

<p>문제에 따라 <em>heuristics</em> 는 다릅니다. 루마니아 투어 문제의 경우 <em>직선거리</em> 가 될 수 있고, 팬케잌 문제(하노이탑) 의 경우 잘못 올려진 팬케잌의 수가 <em>heuristic function</em> 이 될 수 있습니다.</p>

<p>이런 <em>heuristics</em> 을 어떻게 알고리즘에 적용할까요? 하나는 <em>DFS</em> 처럼 같은 <em>sibling</em> 사이에서 더 낮은 <em>heuristics</em> 값을 가지는 <em>fringe</em> 를 선택하는 방법이 있습니다. 이걸 <em>greedy search</em> 라 부릅니다.</p>

<p>반면 <em>BFS</em> 처럼 같은 <em>heuristics</em> 값을 가지는 모든 <em>fringe</em> 를 탐색할 수도 있습니다. 이걸 <em>A* search</em> 라 부릅니다.</p>

<p><br></p>

<h3 id="greedysearch">Greedy Search</h3>

<p><em>greedy search</em> 는 <em>heuristic</em> <em>(estimate of distance to nearest goal for each state)</em> 을 이용해서 <em>fringe</em> 를 선택하지만, <em>DFS</em> 처럼 <em>badly-guided</em> 될 수 있습니다. 항상 <em>optimal</em> 한 솔루션을 찾아주진 않는다는 이야기입니다.</p>

<p></p>

<h3 id="asearch">A* Search</h3>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/ucs_plus_greedy.jpg" alt=""></p>

<p><em>A* Search</em> 는 <code>f(n) = g(n) + h(n)</code> 을 이용합니다. 즉, 지금까지 온 거리 <code>g(n)</code> 과 앞으로 남은 (예측) 거리 <code>h(n)</code> 을 더한 값을 이용해서 어떤 <em>fringe</em> 를 선택할지 결정합니다. </p>

<p><em>A*</em> 와 관련해서 생각해 볼 한가지는 <em>goal fringe</em> 를 <em>enqueue</em> 할 때가 아니라 <em>dequeue</em> 할때 <em>stop</em> 해야한다는 것 입니다. 이는 현재 <em>queue</em> 에 있는 것중 <em>goal</em> 까지 더 작은 <code>g(n)</code> 을 가진 <em>fringe</em> 가 존재할 수 있기 때문이죠.</p>

<p><em>A* search</em> 는 <em>admissible</em> 하면 <em>optimal</em> 입니다. 여기서 <em>admissible (optimistic)</em> 하다는 뜻은 <em>heuristics</em> 값 <code>h(n)</code>이 절대로 실제 <em>cost</em> <code>h*(n)</code> 보다 높지 않다는 뜻입니다. (always underestimate)</p>

<p><code>0 &lt;= h(n) &lt;= h*(n)</code></p>

<ul>
<li><strong>Inadmissible (pessimistic)</strong> heuristics <strong>break</strong> optimality by trapping good plans on the fringe</li>
<li><strong>Admissible (optimistic)</strong> heuristics slow down bad plans but never outweigh true costs</li>
</ul>

<p><br></p>

<p><em>uniform-cost search</em> 와 <em>A* search</em> 를 기하학적으로 비교해보면, <em>UCS</em> 는 정원의 등고선을 그리며 <em>goal</em> 을 탐색하지만 <em>A*</em> 는 <em>goal</em> 쪽으로 기운 타원형태의 등고선이 만들어집니다.</p>

<p>정리하자면</p>

<ul>
<li><strong>DFS, BFS:</strong> uninformed search, don't consider cost</li>
<li><strong>UCS:</strong> uninformed search, only consider cost</li>
<li><strong>Greedy search:</strong> informed search, only consider heuristic</li>
<li><strong>A* search:</strong> informed search which uses both cost and heuristic</li>
</ul>

<p><br></p>

<h3 id="admissibleheuristics">Admissible Heuristics</h3>

<p>어려운 <em>search problem</em> 을 최적으로 풀어내려면 <em>admissible heuristics</em> 를 만들어야 하는데, 이 <em>admissible heuristics</em> 은  본래 문제에서 <em>constaints</em> 가 조금 줄어들어 새로운 <em>action</em> 을 사용할 수 있는 <em>relaxed problem</em> 의 솔루션이 될 수 있습니다. </p>

<p>그리고 <em>inadmissible heuristic</em> 도 때로는 유용할 수 있습니다. <em>optimal solution</em> 이 꼭 필요하지 않다면요. </p>

<p>그러나 이번에는 <em>admissible heuristics</em> 을 만드는 연습을 해보겠습니다. <em>8 puzzle</em> 을 <em>search problem</em> 으로 해서요. 먼저 해야 할 질문은</p>

<ul>
<li>What are the states?</li>
<li>How many states?</li>
<li>What are actions?</li>
<li>How many successor from the start state?</li>
<li>What should the costs be?</li>
</ul>

<p>(1) 만약 <em>heuristic</em> 을 <em>number of tiles misplaced</em> 로 한다면, 이건 <em>admissible</em> 일까요? </p>

<p>당연히 <em>admissible heuristic</em> 입니다. 왜냐하면 어느 <em>action</em> 도 한번에 <code>1</code> 개 이상의 타일을 옮길 수 없으니까요. 그런데 이건 <em>relaxed problem heuristic</em> 입니다. 최대 <code>8</code> 번만에 문제를 풀려면 타일을 직접 정확한 위치에 붙여야 합니다. 부직포 붙이듯이요.</p>

<p>(2) 만약 타일을 직접 목적지로 한번에 움직이진 않지만, 다른 타일을 무시하고 움직일 수 있다면 어떨까요? 아까보단 <em>less relaxed</em> 하다고 생각해봅시다. 이 경우 <em>manhattan distance</em> 를 이용할 수 있습니다.   이것도 마찬가지로 <em>relaxed heuristic</em> 이지만 아까보단 좀 덜 루즈합니다. </p>

<p>아까보다는 <em>heuristic</em> <code>h</code> 값이 더 커졌으니까, 가장 정확한 <em>heuristic</em> (actual cost) 값은 이것보다는 적어도 크다고 생각할 수 있습니다. 일종의 <em>lower bound</em> 라고 보면 쉽습니다. </p>

<p>그리고 <em>heuristic</em> 이 더 정확해졌기 때문에, <em>expanded nodes</em> 수도 이전보다 훨씬 줄어들게 됩니다.</p>

<p>(3) <em>actual cost</em> 를 <em>heuristic</em> 으로 사용하면 어떨까요? 이 값은 당연히 <em>admissible</em> 합니다. <code>h(n) = h*(n)</code> 이니까요. 게다가 <em>expanded nodes</em> 수도 가장 적습니다. </p>

<p>다만 문제는, 가장 정확한 <em>heuristic</em> 이기 때문에 매 턴마다 이 값을 계산하기 위한 연산 비용이 비쌉니다. 이것이 <em>A*</em> 알고리즘이 가진 <em>trade-off</em> 입니다. <em>quality of estimate</em> 와 <em>work per node</em>  를 적절히 조절해서 <em>heuristic</em> 을 만들어야 합니다.</p>

<blockquote>
  <p>As heuristics get closer to the true cost, you will expand fewer nodes but usually do more work per node to compute the heuristic itself</p>
</blockquote>

<p>나침반을 보고 길을 찾을때, <em>loose heuristic</em> 은 좀 더 넓은 범위에서 맞다고 알려주어 이용하기 쉽다면, <em>actual cost</em> 의 경우에는 나침반이 제시하는 올바른 방향이 너무나 작기때문에 자세히 보고, 여러번봐야 하는것과 비슷합니다.</p>

<p>정리하자면 <em>heuristic</em> 이 <em>actual cost</em> 에 가깝다고 해서 반드시 좋은건 아닙니다. 연산시간을 고려하면 적정 수준의 <em>loose heuristic</em> 을 사용할 필요가 있습니다.</p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/heuristic_dominance.jpg" alt=""></p>

<p>모든 <em>heuristic</em> 값이 더 크면 <em>dominance</em> 라고 말합니다. 다시 말해 더 정확한, <em>actual cost</em> 에 가깝다는 뜻입니다. 그리고 <em>admissible</em> 한 두 <em>heuristics</em> 에 대해 그 <em>max</em> 값도 당연히 <em>admissible</em> 합니다.</p>

<p><em>bottom lattice</em> 를 <em>zero heuristic</em>, <em>top</em> 을 <em>exact</em> 라 부릅니다. 만약 <em>zero heuristic</em> 을 이용하면 <em>uniform-cost search</em> 와 동일합니다.</p>

<h3 id="graphsearch">Graph Search</h3>

<p><em>tree search</em> 는 중복되는 부분에 대해 다시 탐색하므로 비효율적입니다. 이 부분을 개선하기 위해 <strong>모든 state 를 단 한번만</strong> <em>expand</em> 할 수 있습니다. <em>set of expanded states</em> 를 유지하고, <em>state</em> 를 탐색하기 전에 이미 <em>expanded</em> 되었는지 검사하면 됩니다.</p>

<p><em>graph search</em> 는 <em>completeness</em> 엔 문제가 없으나 <em>not-optimal</em> 일 수 있습니다. 아래 예제를 보면 <em>sub-optimal solution</em> 을 리턴합니다. <em>admissible heuristic</em> 임에도 불구하고요.</p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/a_star_graph_suboptimal.jpg" alt=""></p>

<p><br></p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/consistency.jpg" alt=""></p>

<p>이건 <em>consistency</em> 속성이 만족되지 않아서 그렇습니다. <em>goal</em> 까지의 <em>admissibility</em> 뿐만 아니라, 각 <em>arc</em> 마다도 <code>h &lt;= actual cost</code> 를 만족하면 <em>consistent</em> 하다고 말합니다. 만약 <em>heuristic</em> 이 <em>consistent</em> 하면 <em>f value</em> 가 절대로 줄지 않기 때문에 결과적으로 <em>graph search</em> 를 통한 결과도 <em>optimal</em> 이 됩니다.</p>

<ul>
<li><em>Fact 1:</em> In tree search, A* expands nodes in increasing total <em>f value</em> (<strong>f-contours</strong>)</li>
<li><em>Fact 2:</em> For every state <code>s</code>, nodes that reach <code>s</code> optimally are expanded before nodes that reach <code>s</code> suboptimally</li>
</ul>

<p><br></p>

<h3 id="optimality">Optimality</h3>

<p>(1) Tree Search</p>

<ul>
<li>만약 <em>heuristic</em> 이 <em>admissible</em> 이면 A* 는 <em>optimal</em> 입니다</li>
<li><em>UCS</em> 는 <code>h = 0</code> 인 <em>special case</em> 입니다</li>
</ul>

<p>(2) Graph Search</p>

<ul>
<li>만약 <em>heuristic</em> 이 <em>consistent</em> 이면, A* 는 <em>optimal</em> 입니다.</li>
<li><em>UCS</em> 도 <code>h = 0</code> 이어서 <em>consistent heuristic</em> 이므로 <em>optimal</em></li>
</ul>

<blockquote>
  <p>Consistency implies admissibility</p>
</blockquote>

<p>일반적으로 대부분의 <em>natural admissible heuristic</em> 는 <em>consistent</em> 합니다. 특히 <em>relaxed problems</em> 에서 나왔다면 더더욱요</p>

<p><br></p>

<h3 id="refs">Refs</h3>

<p>(1) <strong>Artificial Integelligence (CS 188)</strong> by <em>Dan Klein, Pieter Abbeel</em> <br>
(2) <a href="http://imgkid.com/cute-box-robot-tumblr.shtml">Title Image</a>  </p>
    </section>

    <footer>
      <section class="author_info margin_top_big">
        <div class="alignleft border rad_circle" style="height: 87px; width: 87px; background-image: url(http://www.gravatar.com/avatar/aa2032ba2302419e3c2ede54f1fbf687?d=404&amp;s=250); background-size: cover;"></div>
        <p class="margin_left_medium text small">Author</p>
        <p class="margin_left_medium text bold"><a href="http://1ambda.github.io">1ambda</a></p>
        <p class="margin_left_medium text small">Functional, Scala, Akka, Rx and Haskell</p>
      </section>
    </footer>


    <div id="disqus_thread" class="margin_top_big"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = '1ambda'; // required: replace example with your forum shortname
  var disqus_identifier = '104';
  var disqus_url = 'http://1ambda.github.io/artificial-intelligence-2/';

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
    </article>
</main>


  <script src="../assets/fitvids/jquery.fitvids.js"></script>
<script>
$(document).ready(function(){
  // Target your .container, .wrapper, .post, etc.
  $("section").fitVids();
});
</script>

  <footer class="blog_info margin_top_big padding_medium text center">
    <h5 class="text book small">© 2015 <a href="../">Old Lisper</a>. All rights reserved.</h5>
    <h5 class="text book small"><a href="https://github.com/dreyacosta/velox" target="_blank" class="text bold">Velox theme</a> by <a href="http://dreyacosta.com/">David Rey</a></h5>
    <h5 class="text book small">Proudly published with <a href="http://ghost.org"><span>Ghost</span></a></h5>

  </footer>

  <script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = '1ambda'; // required: replace example with your forum shortname

/* * * DON'T EDIT BELOW THIS LINE * * */
(function () {
 var s = document.createElement('script'); s.async = true;
 s.type = 'text/javascript';
 s.src = '//' + disqus_shortname + '.disqus.com/count.js';
 (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
 }());
</script>


  </body>
  