<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Old Lisper]]></title><description><![CDATA[Functional Programming]]></description><link>http://1ambda.github.io/</link><generator>Ghost 0.5</generator><lastBuildDate>Sat, 28 Feb 2015 16:54:38 GMT</lastBuildDate><atom:link href="http://1ambda.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Articles]]></title><description><![CDATA[<h3 id="scala">Scala</h3>

<p><strong>Functional Programming in Scala</strong> by <em>Martin Odersky</em></p>

<p><a href='http://1ambda.github.io/functional-programming-in-scala-chapter-1/' >Chapter 1</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-2/' >Chapter 2</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-3/' >Chapter 3</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-4/' >Chapter 4</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-5/' >Chapter 5</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-6/' >Chapter 6</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-7/' >Chapter 7</a>  </p>

<p><strong>Reactive Programming</strong> by <em>Martin Odersky</em></p>

<p><a href='http://1ambda.github.io/reactive-programming-1/' >Chapter 1</a> - Monads, Random Generators <br />
<a href='http://1ambda.github.io/reactive-programming-2/' >Chapter 2</a> - Stateful Object <br />
<a href='http://1ambda.github.io/reactive-programming-3/' >Chapter 3</a> - Try, Future, Promise <br />
<a href='http://1ambda.github.io/reactive-programming-4/' >Chapter 4</a> - Observable, Rx, Scheduler <br />
<a href='http://1ambda.github.io/reactive-programming-5/' >Chapter 5</a> - Actor   </p>

<p><strong>Articles</strong></p>

<p><a href='http://1ambda.github.io/new-to-play-framework-2/' >new to Play Framework2</a> <br />
<a href='http://1ambda.github.io/partial-functions-scala/' >Partial Functions, Scala</a>  </p>

<h3 id="haskell">Haskell</h3>

<p><strong>Introduction to Functional Programming using Haskell</strong></p>

<p><a href='http://1ambda.github.io/haskell-intro1' >Chapter 1</a> - Basics <br />
<a href='http://1ambda.github.io/haskell-intro2' >Chapter 2</a> - List Comprehension <br />
<a href='http://1ambda.github.io/haskell-intro3' >Chapter 3</a> - Recursion, Higher Order Function <br />
<a href='http://1ambda.github.io/haskell-intro4' >Chapter 4</a> - Monad <br />
<a href='http://1ambda.github.io/haskell-intro5' >Chapter 5</a> - IO Monad <br />
<a href='http://1ambda.github.io/haskell-intro6' >Chapter 6</a> - Type and Class <br />
<a href='http://1ambda.github.io/haskell-intro7' >Chapter 7</a> - The Countdown Problem <br />
<a href='http://1ambda.github.io/haskell-intro8' >Chapter 8</a> - Lazy Evaluation, Strict <br />
<a href='http://1ambda.github.io/haskell-intro9' >Chapter 9</a> - Induction <br />
<a href='http://1ambda.github.io/a-poor-mans-concurrency-monad' >Poor Man's Concurrency Monad</a></p>

<h3 id="machinelearning">Machine Learning</h3>

<p><strong>Machine Learning</strong> by <em>Andrew Ng</em>, Coursera</p>

<p><a href='http://1ambda.github.io/machine-learning-week-1/' >Chapter 1</a> - Linear Regression <br />
<a href='http://1ambda.github.io/machine-learning-week-2/' >Chapter 2</a> - Gradient Descent <br />
<a href='http://1ambda.github.io/machine-learning-week-3/' >Chapter 3</a> - Logistic Regression <br />
<a href='http://1ambda.github.io/machine-learning-week-4/' >Chapter 4</a> - Neural Network <br />
<a href='http://1ambda.github.io/machine-learning-week-5/' >Chapter 5</a> - Back Propagation <br />
<a href='http://1ambda.github.io/machine-learning-week-6/' >Chapter 6</a> - Practical Advices <br />
<a href='http://1ambda.github.io/machine-learning-week-7/' >Chapter 7</a> - Support Vector Machine <br />
<a href='http://1ambda.github.io/machine-learning-week-8/' >Chapter 8</a> - K-means, PCA Details <br />
<a href='http://1ambda.github.io/machine-learning-week-9/' >Chapter 9</a> - Anomaly Detection, Recommender System <br />
<a href='http://1ambda.github.io/machine-learning-week-10/' >Chapter 10</a> - Stochastic Gradient, Synthetic Data, Ceiling Analysis  </p>

<h3 id="algorithm">Algorithm</h3>

<p><strong>Algorithm: Design and Analysis Part 1</strong> by <em>Tim Roughgarden</em></p>

<p>(1) <a href='http://1ambda.github.io/divide-and-conquer/' >Divide and Conquer</a> <br />
(2) <a href='http://1ambda.github.io/randomized-selection/' >Randomized Selection</a> <br />
(3) <a href='http://1ambda.github.io/graphs-the-contraction-algorithm/' >Graphs, The Contraction Algorithm</a> <br />
(4) <a href='http://1ambda.github.io/graph-search-and-connectivity/' >Graph Search and Connectivity</a> <br />
(5) <a href='http://1ambda.github.io/dijkstra-heap-balanced-tree/' >Dijkstra, Heap, Red-Black Tree</a> <br />
(6) <a href='http://1ambda.github.io/hash-table-universal-hashing-bloom-filters/' >Hash Table, Universal Hashing, Bloom filters</a>  </p>

<p><strong>Algorithms, Part 1</strong> by <em>Robert Sedgewick</em></p>

<p>(1) <a href='http://1ambda.github.io/union-find-algorithms-week-1/' >Union Find</a> <br />
(2) <a href='http://1ambda.github.io/analysis-of-algorithms/' >Analysis of Algorithms</a> </p>

<p><strong>Algorithms, Part 2</strong> by <em>Robert Sedgewick</em></p>

<p>(1) <a href='http://1ambda.github.io/graph-challenges-minimum-spanning-trees' >Spanning Tree, Shortest Paths</a> <br />
(2) <a href='http://1ambda.github.io/radix-sort-suffix-sort' >Radix Sort, Suffix Sort</a> <br />
(3) <a href='http://1ambda.github.io/r-way-ternary-search-tries/' >R-way, Ternary Tries</a> <br />
(4) <a href='http://1ambda.github.io/substring-search/' >KMP, Boyer-Moore, Rabin-Karp</a> <br />
(5) <a href='http://1ambda.github.io/maximum-flow/' >Maximum Flow (Ford-Fulkerson)</a> <br />
(6) <a href='http://1ambda.github.io/algorithm-data-compression/' >Data Compression, Huffman, LZW</a>   </p>

<h3 id="artificialintelligence">Artificial Intelligence</h3>

<p><strong>Artificial Intelligence (CS188)</strong> by <em>Dan Klein, Pieter Abbeel</em></p>

<p>(1) <a href='http://1ambda.github.io/artificial-intelligence-1' >Intro</a> <br />
(2) <a href='http://1ambda.github.io/artificial-intelligence-2' >Search</a>  </p>

<p><strong>Artificial Intelligence Planning</strong> by <em>Dr.Gerhard Wickler</em>, <em>Prof. Austin Tate</em></p>

<p>(1) <a href='http://1ambda.github.io/ai-planning-1' >Intro</a> <br />
(2) <a href='http://1ambda.github.io/ai-planning-2' >A*, STRIPS, forward and backward search</a> <br />
(3) <a href='http://1ambda.github.io/ai-planning-3' >PSP, PoP</a> <br />
(4) <a href='http://1ambda.github.io/ai-planning-4' >STN, HTN</a>  </p>

<h3 id="cloudcomputing">Cloud Computing</h3>

<p><strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera</p>

<p>(1) <a href='http://1ambda.github.io/cloud-computing-1-1/' >MapReduce</a> <br />
(2) <a href='http://1ambda.github.io/cloud-computing-gossip-protocol/' >Gossip Protocol</a> <br />
(3) <a href='http://1ambda.github.io/cloud-computing-membership-protocol/' >Membership Protocol</a> <br />
(4) <a href='http://1ambda.github.io/cloud-computing-p2p-systems/' >P2P Systems</a>  </p>

<h3 id="dataanalysis">Data Analysis</h3>

<p><strong>Pattern Discovery</strong> by <em>Jiawei Han</em>, Coursera</p>

<p><a href='http://1ambda.github.io/pattern-discovery-1/' >Chapter 1</a> - Apriori, FP Growth <br />
<a href='http://1ambda.github.io/pattern-discovery-2/' >Chapter 2</a> - Null-invariant, Pattern-Fusion, Constaint   </p>

<p><strong>Intro to Computational Thinking and Data Science</strong>, edx</p>

<p><a href='http://1ambda.github.io/edx-600-2x-1/' >Chapter 1</a> - Modeling <br />
<a href='http://1ambda.github.io/edx-600-2x-2/' >Chapter 2</a> - Monte Carlo Simulation <br />
<a href='http://1ambda.github.io/edx-600-2x-3/' >Chapter 3</a> - Optimization Problem <br />
<a href='http://1ambda.github.io/edx-600-2x-4/' >Chapter 4</a> - State Modeling, Hierarchical Clustering   </p>

<p><strong>Coding The Matrix</strong> by <em>Philip Klein</em>, Coursera</p>

<p><a href='http://1ambda.github.io/coding-the-matrix-1/' >Chapter 1</a> - Function, Field, Vector</p>

<h3 id="processmining">Process Mining</h3>

<p><strong>Process Mining</strong> by <em>Wil Van der Alast</em>, Coursera</p>

<p><a href='http://1ambda.github.io/process-mining-week1/' >Week 1</a> - Process Mining Intro <br />
<a href='http://1ambda.github.io/process-mining-week2/' >Week 2</a> - Alpha Algorithm <br />
<a href='http://1ambda.github.io/process-mining-week3/' >Week 3</a> - Metric, C-nets <br />
<a href='http://1ambda.github.io/process-mining-week4/' >Week 4</a> - Conformance Checking, Dotted Chart <br />
<a href='http://1ambda.github.io/process-mining-week5/' >Week 5</a> - Decision, Social, Organization Mining  </p>

<h3 id="java">Java</h3>

<p><strong>Articles</strong></p>

<p><a href='http://1ambda.github.io/java-interview-questions-collection-framework/' >Java Interview Questions - Collection Framework</a>  </p>]]></description><link>http://1ambda.github.io/articles/</link><guid isPermaLink="false">9666f26e-e434-403f-95b1-8e667199693c</guid><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 28 Feb 2015 16:50:51 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, P2P Systems]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<p>P2P 시스템의 기술들은 <em>cloud computing</em> 의 많은 분야에서 활용됩니다. 뒤에서 배울 <em>Chord P2P hashing</em> 같은 경우는 <em>Cassandra</em>, <em>Voldmort</em> 등의 <em>key-value store</em> 에서 쓰이고 있습니다. </p>

<p><br/></p>

<h3 id="napster">Napster</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/napster.png'  alt="" /></p>

<p>최초에 <em>peer</em> 는 서버에게 메세지를 보내 P2P 시스템에 가입했다는 사실을 알립니다.</p>

<p><em>Napster</em> 에서는 중앙에 서버를 두어, 파일이 저장된 <em>peer</em> 를 기록합니다. 각 <em>peer</em> 는 파일이 어디있는지 검색하기 위해 중앙 서버에 질의해야 합니다. 그림에서 볼 수 있듯이, 각 파일은 서버가 아니라 <strong>클라이언트</strong> 에 저장되어 있습니다. 파일이 어느 클라이언트(<em>peer</em>) 에 저장되어있는지 알게되면, <em>ping</em> 을 날려 살아있는지 확인 후 파일을 다운 받습니다. </p>

<p><em>Napster</em> 의 문제점은</p>

<ul>
<li>중앙 서버로의 요청이 너무나 많습니다.</li>
<li><p>서버가 다운되면, 시스템이 멈춥니다.</p>

<p><br/></p></li>
</ul>

<h3 id="gnutella">Gnutella</h3>

<p><em>Gnutella</em> 는 <em>Napster</em> 시스템에서 <strong>서버</strong>를 제거했습니다. 각 클라이언트 (<em>peer</em>) 는 파일이 어디 저장되어있는지 파악하기 위해 서로 통신하지요. 이처럼 클라이언트가 서버처럼 행동하기때문에 <em>servent</em> 라 부르기도 합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella.png'  alt="" /></p>

<p>위 슬라이드에서 알 수 있듯이, 각 피어는 근처에 있는 피어로의 링크를 가지고 있습니다. 이 링크는 <em>overlay graph</em> 라 부르기도 합니다.</p>

<p><em>gnutella</em> 에서 피어간 통신에 사용되는 주요 메세지 타입은</p>

<ul>
<li><strong>Query:</strong> search</li>
<li><strong>QueryHit:</strong> reponse to query</li>
<li><strong>Ping:</strong> to probe network for other peers</li>
<li><strong>Pong:</strong> reply to ping, contains address of another peer</li>
<li><strong>Push:</strong> used to initiate file transfer</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella_header.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella_search_ttl.png'  alt="" /></p>

<p>위 그림에서 <code>TTL = 2</code> 이기 때문에 <em>query</em> 메세지는 <em>2-hop</em> 까지만 전파됩니다. 그리고 <em>gnutella</em> 에서는 각 피어가 최근에 퍼트린 <em>query</em> 메세지 리스트를 유지하고 있기 때문에 같은 메세지를 다시 전파하지 않습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella_queryhit_msg.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella_queryhit_msg_ex.png'  alt="" /></p>

<p>피어가 보낸 <em>query</em> 에 대해 해당하는 파일을 가지고 있다는 응답은 <em>query hit</em> 메세지를 통해 전달됩니다.</p>

<p><em>gnutella</em> 에서는 과도한 트래픽을 방지하기 위해 다음의 방법을 사용합니다.</p>

<ul>
<li>to avoid duplicate transmissions, each peer maintains a list of recently received messages</li>
<li>query forwarded to all neighbors except peer from which received</li>
<li>each query (identified by <code>DescriptorID</code>) forwarded only once</li>
<li><em>QueryHit</em> routed back only to peer from which <em>Query</em> received with same <code>DescriptorID</code></li>
<li>for flooded messages, duplicates with same <code>DescriptorID</code> and <em>Payload descriptor</em> are dropped</li>
<li><em>QueryHit</em> with <code>DescriptorID</code> for which <em>Query</em> not seen is dropped</li>
</ul>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/after_receiving_queryhit.png'  alt="" /></p>

<p><em>QueryHit</em> 메세지를 <em>requestor</em> 가 받으면 최적의 <em>responder</em> 를 고르고,  <strong>HTTP</strong> 를 이용해서 몇번의 통신을 한 뒤 파일을 전송받습니다. 여기서 <em>gnutella</em> 가 <em>HTTP</em> 를 이용하는 이유는, HTTP 가 <em>standard</em>, <em>well-debugged</em>, <em>widely used</em> 이기 때문입니다.</p>

<p>그런데 만약, <em>responder</em> 가 방화벽(<em>firewall</em>) 뒤에 있으면 어떻게 될까요? 일반적으로 방화벽은 <em>incomming message</em> 를 필터링 합니다. <em>gnutella</em> 는 이럴 경우 대비해 <em>push</em> 를 만들어 놓았습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/dealing_with_firewalls.png'  alt="" /></p>

<p><em>query hit</em> 메세지를 받은 후에 <em>requestor</em> 가 보내는 <em>HTTP</em> 메세지에 <em>responder</em> 가 응답하지 않으면 <em>overlay link</em> (이미 연결되어있는) 을 통해서 <em>push</em> 메세지를 <em>requestor</em> 가 보냅니다. <em>responder</em> 는 방화벽 뒤에 있어도, <em>overlay link</em> 를 통해 받은 <em>push</em> 메세지를 확인하고 파일 전송을 시작합니다.</p>

<p>만약 <em>requestor</em> 가 방화벽 뒤에 있다면, <em>gnutella</em> 프로토콜로는 파일을 전송 받을 수 없습니다.</p>

<p><br/></p>

<p><em>gnutella</em> 에서 생기는 문제점은 </p>

<ul>
<li><em>ping/pong</em> constituted 50% traffic: use multiplex, cache and reduce freq of <em>ping/pong</em></li>
<li>modem-conncted hosts do not have enough bandwidth for passing gnutella traffic: use a central server to act as proxy for such peers. or use <strong>FastTrack System</strong></li>
<li>large number of <em>free loaders</em></li>
<li>flooding causes excessive traffic: use <strong>Structured P2P system</strong> e.g <strong>Chord System</strong></li>
</ul>

<p><br/></p>

<h3 id="fasttrac">FastTrac</h3>

<p><em>FastTrac</em> 은 <em>Kazza</em>, <em>KazzaLite</em>, <em>Grokster</em> 라는 기술을 기반으로 한 <em>Napster</em> <em>Gnutella</em> 의 하이브리드입니다. </p>

<p><em>healthier participants</em> 를 이용하겠다는 기본적인 아이디어로부터 출발했습니다. <em>gnutella</em> 와 비슷하지만 노드중 일부가 <em>supernode</em> 가 되어, 특별한 역할을 수행합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/fast_trac.jpg'  alt="" /></p>

<ul>
<li><em>supernode</em>는 <em>Napster server</em> 와 비슷하게 근처에 있는 노드의 <code>&lt;file name, peer point&gt;</code> 리스트를 저장합니다</li>
<li><em>supernode</em> 의 멤버십은 시간이 지나면서 변합니다</li>
<li>어떤 노드도 <em>supernode</em> 가 될 수 있습니다. 그러기 위해서는 <em>reputation</em> 을 얻어야 합니다</li>
<li>각 노드는 데이터를 탐색하기 위해 <em>supernode</em> 에 질의합니다</li>
</ul>

<p>이 <em>reputation system</em> 은 <em>Kazaalite</em> 처럼 <em>upload</em> 한 파일의 양으로 결정할 수도 있고, 경제학적인 원리를 적용한 방법도 있습니다</p>

<p><br/></p>

<h3 id="bittorrent">BitTorrent</h3>

<p>이전에 언급했듯이 <strong>다운만 받는 peer</strong> 도 존재할 수 있습니다. <em>BitTorrent</em> 는 업로드 하는 <em>peer</em> 에게 보상을 해 주어, <em>peer</em> 들의 업로드를 더 이끌어 낼 수 있습니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/bit_torrent_network.jpg'  alt="" /></p>

<p><em>BitTorrent</em> 네트워크 구성은 위 슬라이드와 같습니다.</p>

<ul>
<li><strong>Tracker:</strong> 파일당 하나씩 존재하며 <em>heartbeat</em> 를 받아 <em>peer</em> 의 <em>join</em>, <em>leave</em> 를 관리합니다.</li>
<li><strong>Seed:</strong> 전체 파일을 가지고 있는 <em>peer</em> </li>
<li><strong>Leecher:</strong> 파일의 일부분을 가지고 있는 <em>peer</em> </li>
</ul>

<p><em>BitTorrent</em> 에서는 블럭단위로 파일을 전송하는데, 이 때 사용하는 몇 가지 규칙이 있습니다.</p>

<ul>
<li><em>Local Rarest First:</em> 파일을 다운받을때, 귀한 블럭부터 먼저 받습니다</li>
<li><em>Tit for tat:</em> 업로드 하는 만큼, 다운로드 <em>bandwidth</em> 를 할당받습니다. 다시 말해서 업로드를 많이해야 빠르게 받을 수 있습니다</li>
<li><em>Choking:</em> 동시에 업로드하는 <em>neighbor</em> 수를 제한해서 <em>bandwidth</em> 가 너무 많이 사용되지 않도록 합니다. <em>best neighbor</em> 를 선택하여 <em>unchoked set</em> 을 유지하고, 주기적으로 이 집합을 재평가합니다. 이외의 다른 <em>peer</em> 는 <em>choked set</em> 입니다. </li>
</ul>

<p><em>optimistic unchoke</em> 기법은 주기적으로 랜덤한 <em>neighbor</em> 를 <em>unchoke</em> 해서, <em>unchoked set</em> 을 <em>fresh</em> 하게 유지합니다. 여기서 <em>random choice choking</em> 을 쓰는 이유는</p>

<ul>
<li>To avoid the sysem from getting stuck where only a few peers receive service</li>
</ul>

<p><br/></p>

<h3 id="dht">DHT</h3>

<p>지금까지 본 <em>Napster</em>, <em>Gnutella</em>, <em>FastTrac</em> 은 일종의 <em>DHT, Distribute Hash Table</em> 입니다.</p>

<p><em>DHT</em> 에서의 <em>performance concerns</em> 는</p>

<ul>
<li>load balancing</li>
<li>fault-tolerance</li>
<li>efficiency of lookup and inserts</li>
<li>locality</li>
</ul>

<p>우리가 배울 <em>Chord</em> 는 이런 구조가 적용된 <em>structured peer to peer system</em> 입니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/performance_comparison_nap_gnu.jpg'  alt="" /></p>

<p><em>Napster</em> 는 <em>peer</em> 의 경우 파일을 저장하지 않기 때문에 메모리가 많이 들지 않지만, <em>server</em> 에서 많은 메모리를 요구합니다. 서버로 질의가 가기때문에 <em>lookup latency</em> 나 <em>lookup</em> 을 위한 메세지 수 자체는 많지 않지만, 서버의 부하가 상당히 심할 수 있습니다.</p>

<p>반면 <em>Gnutella</em> 에서는 서버가 없습니다. 그렇기 때문에 피어는 파일이 저장되어있는 주변 피어의 목록을 가지고 있어야 하는데, <code>N</code> 만큼의 이웃이 주변에 있을 수 있습니다. 따라서 한 피어에서 필요한 메모리 양은 <code>O(N)</code> 입니다.</p>

<p>그리고 네트워크가 직선으로 구성되어 있다고 할때, <em>lookup latency</em> 는 <code>O(N)</code> (<code>N-1</code>) 이고 룩업을 위한 메세지 수도 <code>O(N)</code> (<code>2(N-1)</code>) 입니다.</p>

<p>반면 <em>Chord</em> 는 모두 <code>O(log N)</code> 입니다. 이론적으로 <em>constant</em> 는 아니지만, <em>real world</em> 에서는 상당히 낮은 수가 될 수 있습니다.</p>

<p><br/></p>

<h3 id="chord">Chord</h3>

<p><em>Chord</em> 는 <em>Berkeley</em> 와 <em>MIT</em> 에서 개발된 <em>P2P</em> 프로토콜입니다.<em>latency</em> 와 <em>message cost of routing</em> (<em>lookups</em>/<em>inserts</em>) 를 줄이기 위해 지능적으로 <em>neighbor</em> 를 선택하고 <em>Consistent Hashing</em> 기법을 사용합니다.</p>

<p><em>Consistent Hasing</em> 값은 <em>peer</em> 에 부여되는 주소값으로</p>

<ul>
<li>IP 와 Port로 <em>SHA1</em> 로 해싱해서 160 비트 스트링을 만들고 </li>
<li><code>m</code> 비트로 절단해서 사용합니다</li>
<li><em>peer</em> 의 <em>ID</em> 라 불리기도 하는데, 이 값은 당연히 최대 <code>2^m - 1</code> 입니다</li>
<li>해싱값이므로 <em>unique</em> 하진 않지만 충돌이 일어날 확률은 굉장히 적습니다</li>
<li>그리고 이 값이 <code>2^m</code> 개의 점이 되어 하나의 원을 구성합니다</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/ring_of_peers.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_finger_table.png'  alt="" /></p>

<p>각 노드는 (반) 시계방향으로의 <em>successor</em> 를 가지고 있고, 다른 노드를 가리키기 위한 <em>finger table</em> 을 가지고 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_file_saving.png'  alt="" /></p>

<p>파일도 마찬가지로 <em>SHA-1</em> 으로 해싱해서, 160 비트로 짜른 뒤 <code>mod 2^m</code> 연산해서, 같은 값이거나 그보다 큰 값을 가지는 <em>peer</em> 에 저장합니다.</p>

<p>만약 균일하게 해싱된다면 <code>K</code> 개의 키, <code>N</code> 개의 피어에서 파일은 각 피어당 <code>K/N</code> 개씩 저장되므로 피어당 걸리는 부하는 <code>O(K/N)</code> 입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_search_process.png'  alt="" /></p>

<p>위 그림에서 <code>N80</code> 피어가 <code>K42</code> 파일을 찾을때, </p>

<ul>
<li><em>finger table</em> 에 <code>42</code> 가 없으므로 최대한 먼 <code>N16</code> 에 질의하고, </li>
<li><code>N16</code> 은 <code>N32</code> 와 <code>N80</code> 밖에 모르므로 <code>N32</code> 를 거쳐 <code>N45</code> 로 질의합니다.</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_search_analysis.png'  alt="" /></p>

<p><em>chrod search</em> 는 <code>O(log N)</code> 의 시간이 듭니다. 증명에 대한 <em>intuition</em> 은 쉽습니다.</p>

<p>만약 현재 <code>Here</code> 에서 <code>Key</code> 를 모른다고 합시다. 그러면 그 거리의 <code>1/2</code> 만큼은 점프를 해야합니다. 그것보다 더 적게 점프하면 거리를 <code>d</code> 라 합시다. <em>finger table entry</em> 값은 2배씩 증가하기 때문에, <code>2d</code> 만큼 점프할 수 있는 엔트리가 있어야 하고, 그럼 애초부터 <code>2d</code> 만큼 점프했어야 했기 때문에 모순입니다.</p>

<p><code>log(N)</code> 만큼의 점프 뒤에는 <em>key</em> 까지의 거리는 아무리 멀어봐야 <code>2^m / N</code> 입니다. 균일하게 분포되는 해싱을 쓴다 가정하면, 이 사이에는 적은 수의 노드만 있습니다. 따라서 <code>O(logN)</code> 만큼만 더 점프한다면 높은 확률로 <em>key</em> 를 찾을 수 있습니다. <code>O(logN) + O(logN) = O(logN)</code> 이므로, <em>search</em> 는 <code>O(logN)</code> 입니다.</p>

<p><em>insertion</em> 도 <em>searching</em> 과 마찬가지로 <code>O(logN)</code> 입니다. 그러나 이 성능은 <em>finger table</em> 과 <em>successor</em> 가 잘못되지 않았을 경우에만 참입니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_multiple_successor.png'  alt="" /></p>

<p><em>chrod</em> 는 <em>successor</em> 한개만 가질땐 <em>failure</em> 에 취약하기 때문에, 위 그림처럼 다수개의 <em>successor</em> 를 가질 수 있습니다. 이 경우 성능은 어떻게될까요?</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/multiple_successor_analysis.png'  alt="" /></p>

<p><code>2log(N)</code> 개의 <em>successor</em> 를 유지할 경우를 한번 생각해 봅시다. <code>50%</code> 씩 <em>failure</em> 가 발생하면</p>

<ul>
<li>하나의 노드에서 유지하는 <em>successor</em> 중, 적어도 하나의 <em>successor</em> 가 살아있을 확률은</li>
</ul>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%28%7B1%20%5Cover%202%7D%29%5E%7B2logN%7D%20%3D%201%20-%20%7B1%20%5Cover%20N%5E2%7D'  alt="" /></p>

<ul>
<li>위 확률은 모든 살아있는 노드(<code>50%</code>) 에서 참일때, 다시 말해서 모든 노드에서 적어도 하나의 <em>successor</em> 가 존재할 확률은 <code>N</code> 이 매우 클때</li>
</ul>

<p><img src='http://latex.codecogs.com/gif.latex?%281%20-%20%7B1%20%5Cover%20N%5E2%7D%29%5E%7BN/2%7D%20%3D%20e%5E%7B-%7B1%5Cover%202N%7D%7D%20%5Capprox%201'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_joining.png'  alt="" /></p>

<ul>
<li>a new peer affects <code>O(logN)</code> other finger entires in the system, on average</li>
<li>number of messages per peer join <code>O(logN * logN)</code></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_stabilization_protocol.png'  alt="" /></p>

<p><em>join</em>, <em>leave</em>, <em>failure</em> 등 <em>churn</em> 이 자주 일어나므로 <em>loop</em> 가 있는지 없는지 검사하기 위해 주기적으로 <em>stabilization protocol</em> 를 사용합니다.</p>

<p><br/></p>

<h3 id="pastry">Pastry</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/pastry_routing.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/pastry_locality.png'  alt="" /></p>

<p><em>Pastry</em> 는 <em>chord</em> 처럼 <em>node</em> 에 <em>id</em> 를 부여합니다. <em>routing table</em> 은 <em>prefix matching</em> 에 기반하기 때문에 <code>log(N)</code> 의 성능을 보여줍니다. 그리고 짧은 <em>prefix</em> 일 수록 가까이에 있을 확률이 높습니다.</p>

<p><br/></p>

<h3 id="kelips">Kelips</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/kelips.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/kelips2.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/kelips3.png'  alt="" /></p>

<p><em>Kelips</em> 는 <em>1-hop lookup</em> 을 보여줍니다. 이럴 수 있는 이유는 위 그림에서 보듯이 <em>affinity group</em> 이란걸 사용하기 때문입니다. 루트 <code>N</code> 에 가까운 숫자 <code>k</code> 를 정하고, 이 수로 <code>mod</code> 연산을 해, 그룹을 만듭니다. 각각의 그룹은 내에 있는 모든 노드는 서로 어떤 파일을 저장하는지 알고 있습니다. 그리고 각 노드는 다른 그룹으로의 링크를 하나씩 가지고 있습니다. 따라서 어딜가든 거의 1번 혹은 2번 내에 <em>lookup</em> 이 가능합니다.</p>

<p><em>chord</em> 에 비해 메모리를 더 잡아먹긴 합니다. <code>O(logN)</code> 보단 많은 양이지만, 그렇게 많지도 않습니다. 메모리가 귀하다면 <em>chord</em> 나 <em>pastry</em> 를, 그렇지 않고 <em>lookup</em> 속도가 중요하다면 <em>kelips</em> 를 사용하면 됩니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/kelips4.png'  alt="" /></p>

<p><em>membership</em> 은 <em>gossip-based</em> 프로토콜로 관리할 수 있습니다. </p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-p2p-systems/</link><guid isPermaLink="false">6e527ab7-0598-4177-b199-dd4ef466f537</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[P2P]]></category><category><![CDATA[Napster]]></category><category><![CDATA[Gnutella]]></category><category><![CDATA[BitTorrent]]></category><category><![CDATA[FastTrack]]></category><category><![CDATA[Chord]]></category><category><![CDATA[Pastry]]></category><category><![CDATA[Kelips]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 28 Feb 2015 16:18:25 GMT</pubDate></item><item><title><![CDATA[Java Interview Questions, Collection Framework]]></title><description><![CDATA[<p><img src='http://4.bp.blogspot.com/_b6abT-2H2yE/TSTixbyU8GI/AAAAAAAAAUU/LcqDidb_liw/s1600/screen-capture-1.png'  alt="" /></p>

<p><br/></p>

<h3 id="general">General</h3>

<p>(1) <strong>Explain Collections Hierarchy?</strong></p>

<p><img src='http://2.bp.blogspot.com/-M0M8nv5s2lQ/U3BcbRQcRvI/AAAAAAAAAec/oBBmQCPDm9Y/s1600/Collection-Classes.tif'  alt="" /></p>

<p><img src='http://4.bp.blogspot.com/-o9Jk4Z4Tohs/U3Be46CxGTI/AAAAAAAAAeo/Wq8-hhZ8dCA/s1600/Collection-Classes_Map.tif'  alt="" /></p>

<p align="center">(<a href='http://www.java-redefined.com/' >http://www.java-redefined.com</a>)</p>

<p>크게 보면 <em>Collection</em> 과 <em>Map</em> 인터페이스로 구분되어 있습니다. </p>

<ul>
<li><code>Map</code> 은 <em>key-value pair</em> 컨테이너이기 때문에 단일 원소에 대한 컨테이너인 <code>Collection</code> 과 호환되지 않습니다.</li>
<li><code>Set</code> 은 중복된 원소를 허용하지 않습니다.</li>
<li><code>Set</code> 과 <code>Map</code> 에 정렬 기능이 필요하면 <code>SortedSet</code>,  <code>SortedMap</code> 인터페이스 구현체인 <code>TreeMap</code>, <code>TreeSet</code> 등을 이용할 수 있습니다.</li>
</ul>

<p>(2) How do you remove an entry from a collection? and subsequently what is difference between <code>Collection.remove()</code> and <code>Iterator.remove()</code>, which one you will use, while removing elements during iteration?</p>

<p>아래에서 언급하겠지만 <em>fail-fast</em> 와 관련된 문제입니다. 만약 순회하고 있지 않다면 <code>Collection.remove()</code> 를 사용해도 상관 없지만</p>

<p><em>iterator</em> 를 이용해서 순회하는 동안 컬렉션의 <code>remove()</code> 메소드를 이용하면 <code>ConcurrentModificationException</code> 예외가 발생합니다.  따라서 <code>Iterator.remove()</code> 를 이용해야 합니다. <a href='http://stackoverflow.com/questions/14200489/collection-iterator-remove-vs-collection-remove' >SO 답변</a>에서도 그 이유를 찾을 수 있습니다.</p>

<pre><code class="java">// invalid
List&lt;Integer&gt; l = new ArrayList&lt;Integer&gt;(Arrays.asList(1, 2, 3, 4));  
for (int el : l) {  
  if (el &lt; 3) {
      l.remove(el);
  }
}

// correct way
Iterator&lt;Integer&gt; it = l.iterator();  
while (it.hasNext()) {  
  int el = it.next();
  if (el &lt; 3) {
      it.remove();
  }
}
</code></pre>

<p><br/></p>

<h3 id="listinterfacerelated">List interface related</h3>

<ul>
<li><code>List</code> 는 중복된 원소를 허용하며 <em>ordered elements</em> 를 담는 컨테이너입니다. 때때로 <em>Sequence</em> 라 불리기도 합니다. </li>
</ul>

<p>(1) <code>Vector</code> vs <code>ArrayList</code> vs <code>LinkedList</code></p>

<ul>
<li><code>Vector</code> 의 모든 메소드는 <em>동기화 (synchronized)</em> 됩니다. <code>ArrayList</code> 는 <em>thread-unsafe</em> 합니다.</li>
<li><code>Vector</code> 는 <em>JDK</em> 첫 릴리즈부터 포함되어있던 레거시 클래스고, <code>ArrayList</code> 는 <em>JDK 1.2</em> 에서 컬렉션 프레임워크 도입과 함께 추가되었습니다.</li>
<li><em>default</em> 로 <code>Vector</code> 는 두배씩 사이즈가 커지는 반면, <code>ArrayList</code> 는 <em>50%</em> 씩 증가합니다.</li>
<li><code>LinkedList</code> 도 <em>thread-unsafe</em> 하기 때문에 대신 <a href='http://docs.oracle.com/javase/6/docs/api/java/util/concurrent/ConcurrentLinkedQueue.html' >ConcurrentLinkedQueue</a> 나 <a href='http://docs.oracle.com/javase/6/docs/api/java/util/concurrent/LinkedBlockingDeque.html' >LinkedBlockingDeque</a> 를 이용할 수 있습니다.</li>
</ul>

<p>(2) What is different between <code>Iterator</code> and <code>ListIterator</code></p>

<ul>
<li><code>Iterator</code> 를 이용해 <code>Set</code> 등 컬렉션을 순회할 수 있지만 <code>ListIterator</code> 는 <code>List</code> 밖에 못 합니다</li>
<li><code>Iterator</code> 는 <em>forward-only</em> 지만, <code>ListIterator</code> 는 양방향 순회가 가능합니다</li>
<li><code>ListIterator</code> 는 <em>add</em>, <em>replace</em>, <em>getting index position</em> 등의 기능이 더 있습니다. </li>
</ul>

<p>참고로 <em>iterator</em> 를 이용해 리스트를 순회하는 방법은</p>

<pre><code class="java">List&lt;String&gt; strList = new ArrayList&lt;&gt;();  
Iterator&lt;String&gt; it = strList.iterator();

while(it.hasNext()){  
  String obj = it.next();
  System.out.println(obj);
}
</code></pre>

<p><br/></p>

<h3 id="setinterfacerelated">Set interface related</h3>

<p><code>Set</code> 은 <em>uniqueness of elements</em> 를 보장합니다. 따라서 중복된 원소를 허용하지 않습니다. 만약 <em>ordering</em> 이 있는 <code>Set</code> 을 사용하고 싶다면 구현체로 <code>TreeSet</code> 을 선택하면 됩니다.</p>

<p>(1) <strong>How HashSet store elements?</strong></p>

<p><code>HashSet</code> 은 <em>uniqueness</em> 를 보장하기 위해 내부적으로 <code>Map</code> 을 이용합니다. <em>key-value</em> 를 저장하나, 모든 <em>value</em> 를 같게끔 하죠.</p>

<pre><code class="java">private transient HashMap&lt;E, Object&gt; map;  
// This is added as value for each key
private static final Object PRESENT = new Object();

public boolean add(E e) {  
  return map.put(e, PRESENT) == null;
}
</code></pre>

<p>(2) Can a null element added to a <code>TreeSet</code> or <code>HashSet</code>?</p>

<p><code>HashMap</code>, <code>HashSet</code> 은 하나의 <em>null-key</em> 를 허용하지만, <code>TreeSet</code>, <code>TreeMap</code> 은 <em>null-key</em> 를 허용하지 않습니다. </p>

<p><code>TreeMap</code> 은 <code>NavigableMap</code> 의 구현이고, <code>TreeSet</code> 은 내부적으로 <code>NavigableMap</code> 을 사용합니다. 그런데 <code>NavigableMap</code> 이 <em>null-key</em> 를 허용하지 않기 때문에, <code>TreeSet</code>, <code>TreeMap</code> 도 그렇습니다.</p>

<p><br/></p>

<h3 id="mapinterfacerelated">Map interface related</h3>

<p><code>Map</code> 은 <em>key-value pair</em> 를 저장하기 위해 사용합니다. <code>Map</code> 인터페이스 구현체로 <code>HashMap</code>, <code>LinkedHashMap</code>, <code>HashTable</code>, <code>EnumMap</code>, <code>IdentityHashMap</code>, <code>Properties</code> 가 있습니다.</p>

<p>(1) Difference between <code>HashMap</code> and <code>HashTable</code></p>

<ul>
<li><code>HashTable</code> 은 <em>동기화 (synchronized)</em> 되지만, <code>HashMap</code> 은 그렇지 않습니다.</li>
<li><code>HashTable</code> 은 <em>null-key</em> 나 <em>null-value</em> 를 허용하지 않습니다.</li>
<li><code>HashMap</code> 의 <em>iterator</em> 는 <strong>fail-fast</strong> 인 반면 <code>HashTable</code> 의 <em>enumerator</em> 는 그렇지 않습니다.</li>
</ul>

<p>참고로, <em>iterator</em> 는 <em>iteration</em> 동안 <em>caller</em> 가 <code>remove</code> 메소드를 이용해서 원소를 제거할 수 있지만, <em>enumerator</em> 를 이용할때는 원소를 추가하거나 제거할 수 없습니다. 이런 기능 차이 때문에 <em>enumerator</em> 가 기본적인 기능만 가지고 있고 더 빠릅니다. 또 다른 차이점은 <em>enumerator</em> 는 <code>Stack</code>, <code>Vector</code> 처럼 레거시 클래스에 대해 사용합니다.</p>

<p>(2) What are <code>IdentityHashMap</code> and <code>WeakHashMap</code>?</p>

<p>이부분은 <a href='http://howtodoinjava.com/2013/07/09/useful-java-collection-interview-questions/' #identityHashMap_weakHashMap_differences">원문</a>을 첨부합니다.</p>

<blockquote>
  <p><strong>IdentityHashMap</strong> is similar to HashMap except that <strong>it uses reference equality when comparing elements</strong>. IdentityHashMap class is not a widely used Map implementation. While this class implements the Map interface, it intentionally violates Map’s general contract, which mandates the use of the equals() method when comparing objects. IdentityHashMap is designed for use only in the rare cases wherein reference-equality semantics are required.</p>
  
  <p><strong>WeakHashMap</strong> is an implementation of the Map interface that <strong>stores only weak references to its keys</strong>. Storing only weak references allows a key-value pair to be garbage collected when its key is no longer referenced outside of the WeakHashMap. This class is intended primarily for use with key objects whose equals methods test for object identity using the == operator. Once such a key is discarded it can never be recreated, so it is impossible to do a look-up of that key in a WeakHashMap at some later time and be surprised that its entry has been removed.</p>
</blockquote>

<p><br/></p>

<h3 id="morequestions">More Questions</h3>

<p>(1) What do you understand by iterator <strong>fail-fast</strong> property?</p>

<p><strong>fail-fast iterator</strong> 는 <em>iteration</em> 이 시작된 이후로 <em>collection</em> 이 변경되는걸 알아채는 순간 <code>ConcurrentModificationException</code> 을 던지면서 멈춥니다. 여기서 <em>변경</em> 이란 한 스레드가 컬렉션을 순회하는 동안, 컬렉션에 있는 원소의 삭제, 변경 혹은 추가가 일어나는 것을 말합니다.</p>

<p><em>fail-fast</em> 는 <em>modification count</em> 란 것을 유지하고 있다가, <em>iteration thread</em> 가 <em>modification count</em> 의 변경을 알아채면 예외를 던지는 방식으로 구현됩니다.</p>

<p>(2) What is difference between <strong>fail-fast</strong> and <strong>fail-safe</strong></p>

<p><strong>fail-safe iterator</strong> 는 복사본에 대해 컬렉션 순회를 진행하기 때문에 원본에 변경이 일어나도 멈추지 않습니다. 일반적으로 <code>java.util.concurrent</code> 에 있는 클래스들의 (e.g <code>ConcurrentHashMap</code> 이나 <code>CopyOnWriteArrayList</code>) <em>iterator</em> 가 <em>fail-safe</em> 입니다.</p>

<p>(3) How to avoid <code>ConcurrentModificationException</code> while iterating a collection?</p>

<ul>
<li>먼저 <em>fail-safe iterator</em> 를 사용할 수 있는지 확인합니다 <em>JDK 1.5</em> 이상을 사용한다면, <code>ConcurrentHashMap</code> 이나 <code>CopyOnWriteArrayList</code> 를 사용할 수 있습니다.</li>
</ul>

<p>위 방법이 불가능하면 다음을 고려할 수 있으나, 퍼포먼스가 떨어질 수 있다는 점을 유의해야 합니다. </p>

<ul>
<li><em>list</em> 를 <em>array</em> 로 바꾸어, 순회합니다</li>
<li><em>list</em> 를 순회하는 동안 <em>synchronized block</em> 을 이용해 <em>lock</em> 을 겁니다.</li>
</ul>

<p>(4) What is difference between Synchronized Collection and Concurrent Collection?</p>

<p><em>Java 5</em> 와 함께 <code>ConcurrentHashMap</code>, <code>CopyOnWriteArrayList</code>, <code>BlockingQueue</code> 등의 <em>concurrent collection</em> 클래스들이 추가 되었습니다. 이 클래스들은 <em>synchronized collection</em> 보다 성능이 더 나은데, 이는 일부분에만 <em>lock</em> 을 걸기 때문입니다. 더 자세한 내용은 <a href='http://javarevisited.blogspot.kr/2011/04/difference-between-concurrenthashmap.html' >여기로</a></p>

<p>(5) What is <code>Comparable</code> and <code>Comparator</code>?</p>

<p>자바에서 <code>TreeSet</code> 이나 <code>TreeMap</code> 처럼 <em>automatic sorting</em> 기능이 있는 모든 컬렉션은 <code>compare</code> 메소드를 사용합니다. </p>

<p>이 때 <em>element class</em> 는 정렬을 위해 <code>Comparator</code> <strong>또는</strong> <code>Comparable</code> 인터페이스를 반드시 구현해야 합니다. <em>wrapper class</em> 인 <code>Integer</code>, <code>Double</code> 등이 <code>Comparable</code> 인터페이스를 구현하는 이유가 바로 이것입니다.</p>

<p><code>Comparable</code> 은 원소가 컬렉션에 추가될때 자동적으로 정렬되도록 (<em>natural sorting</em>) 하기 위해 사용하고, <code>Comparator</code> 는 추가적인 정렬방법을 이용하기 위해 정의할 수 있습니다. <a href='http://www.java2blog.com/2013/02/difference-between-comparator-and.html' >여기</a>서 가져온 예제를 보면</p>

<pre><code class="java">// Comparable
public class Country implements Comparable&lt;Country&gt;{  
       @Override
    public int compareTo(Country country) {
        return (this.countryId &lt; country.countryId ) ? -1: (this.countryId &gt; country.countryId ) ? 1:0 ;
}} 

// Comparator

Country indiaCountry=new Country(1, "India");  
Country chinaCountry=new Country(4, "China");  
Country nepalCountry=new Country(3, "Nepal");  
Country bhutanCountry=new Country(2, "Bhutan");  
        
List&lt;Country&gt; listOfCountries = new ArrayList&lt;Country&gt;();  
listOfCountries.add(indiaCountry);  
listOfCountries.add(chinaCountry);  
listOfCountries.add(nepalCountry);  
listOfCountries.add(bhutanCountry); 

Collections.sort(listOfCountries,new Comparator&lt;Country&gt;() {  
  @Override
  public int compare(Country o1, Country o2) {
    return o1.getCountryName().compareTo(o2.getCountryName());
  }
});
</code></pre>

<p><br/></p>

<h3 id="references">References</h3>

<p>(1) <a href='http://howtodoinjava.com/2013/07/09/useful-java-collection-interview-questions/' #why_map_not_extend_collection">Useful Java Collection Interview Questions</a> <br />
(2) <a href='http://websphereemerge.blogspot.kr/' >Title Image</a> <br />
(3) <a href='http://www.java-redefined.com/2014/05/java-collection-interview-questions.html' >http://www.java-redefined.com</a> <br />
(4) <a href='http://www.java2blog.com/2013/02/difference-between-comparator-and.html' >http://www.java2blog.com/</a> <br />
(5) <a href='http://www.javatpoint.com/java-collections-interview-questions' >http://www.javatpoint.com</a> <br />
(6) <a href='http://stackoverflow.com/questions/14200489/collection-iterator-remove-vs-collection-remove' >SO:  Iterator.remove() vs Collection.remove()</a></p>]]></description><link>http://1ambda.github.io/java-interview-questions-collection-framework/</link><guid isPermaLink="false">617c586a-498c-458f-aad2-67156cb56b52</guid><category><![CDATA[collection]]></category><category><![CDATA[java]]></category><category><![CDATA[interview]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 22 Feb 2015 16:27:11 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, Membership Protocol]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<p>왜 <em>membership</em> 이란 개념이 클라우드 컴퓨팅에 필요할까요? </p>

<p>한 노드가 <em>OS</em>, <em>Disk</em>, <em>Network</em> 등 때문에 10년 (120개월) 마다 한 번씩 고장난다고 합시다. 그러면 120개의 노드를 가지고 있다면 1개월마다  한 번씩입니다. 이정도는 참을만하죠? 그런데, 12,000 개의 서버를 가지고 있다면 <em>MTTF (mean time to failure)</em> 는 7.2 시간마다 한번씩입니다. 이건 큰 문제입니다. </p>

<p>따라서 머신이 멀쩡한지 아닌지를 수동이 아니라 자동으로 판단하고 보고해줄 시스템이 필요합니다. <em>membership</em> 이 필요한 것이죠. 이 대상은</p>

<p>(1) Process <em>group</em>-based systems</p>

<ul>
<li>Clouds / Datacenters</li>
<li>Replicated servers</li>
<li>Distributed databases</li>
</ul>

<p>(2) Cash-stop / Fail stop process failures</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/membership1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/membership2.jpg'  alt="" /></p>

<p>멤버십 프로토콜은 다음처럼 구성되어 있습니다.</p>

<ul>
<li>멤버쉽 리스트 (<em>complete</em>, <em>almost-complete</em>, <em>partial-random</em>)</li>
<li><em>dissemination</em> mechanism to inform about joins, leavs, and failures of processes</li>
<li><em>failure detector</em></li>
</ul>

<p><br/></p>

<h3 id="failuredetector">Failure Detector</h3>

<p><em>distributed failure detector</em> 를 평가할 수 있는 지표는</p>

<ul>
<li><strong>Completeness:</strong> each failure is detected</li>
<li><strong>Accuracy:</strong> there is no mistaken detection</li>
<li><strong>Speed:</strong> time to first detection of a failure</li>
<li><strong>Scale:</strong> equal load on each member. network message load</li>
</ul>

<p>안타깝게도 <em>completeness</em> 와 <em>accuracy</em> 를 <em>lossy network</em> 에서 동시에 추구할 수 없다는 사실이 밝혀졌습니다. (<em>Chandra and Toueg</em>) </p>

<p>현실적으로는</p>

<ul>
<li><em>completeness:</em> 100% guaranteed</li>
<li><em>accuracy:</em> partial / probabilistic guarantee</li>
</ul>

<p><br></p>

<p>(1) Centralized Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/centralized_heartbeating.jpg'  alt="" /></p>

<p>중앙 집중형이기 때문에 <em>load</em> 가 한쪽으로만 쏠린다는 단점이 있습니다.</p>

<p>(2) Ring Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/ring_heartbeating.jpg'  alt="" /></p>

<p>링 형태로 구성되었기때문에 동시에 발생하는 다수개의 <em>failure</em> 를 탐지하지 못합니다.</p>

<p>(3) All To All Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/all2all_heartbeating.jpg'  alt="" /></p>

<p>우선 <em>equal load</em> 라는 장점이 있습니다. 개별 노드당 오버헤드가 큰 것처럼 보이는데, 뒤에서 다시 한번 보겠지만 사실 그렇게 크지 않습니다. </p>

<p>(4) Gossip-Style Membership</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_heartbeating1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_heartbeating2.jpg'  alt="" /></p>

<p><em>accuracy</em> 가 높다는 장점이 있습니다.</p>

<p>동작 방식은 이렇습니다. <em>hearbeat</em> 가 <code>T_fail</code> 초 후에도 증가하지 않으면, 해당 멤버는 <em>failure</em> 를 일으킨 것으로 판별됩니다. 그리고 멤버 리스트에서는 <code>T_cleanup</code> 초 후에 제거됩니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/why_cleanup_time1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/why_cleanup_time2.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/why_cleanup_time3.jpg'  alt="" /></p>

<p>왜 바로 제거하지 않고, <code>T_cleanup</code> 초 후에 제거할까요? 이는 위 슬라이드에서 볼 수 있듯이 <code>3</code> 번 노드가 <em>failure</em> 를 일으켰을때, <code>2</code> 번 노드의 멤버 리스트에서 바로 제거한다면 <code>1</code> 번 노드로부터 업데이트를 받아 멤버 리스트에 <em>failure</em> 가 발생하지 않은것처럼 추가될 수 있기 때문입니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_membership_analysis.jpg'  alt="" /></p>

<p><code>T_gossip</code> 이 줄면, <em>bandwidth</em> 를 많이 잡아먹는 대신, <em>detection time</em> 이 줄어듭니다. <em>trade-off</em> 라 보면 되겠습니다.</p>

<p>그리고 <code>T_fail, T_cleanup</code> 이 증가하면 <em>false positive rate</em> 는 줄어드는 대신, 당연히 <em>detection time</em> 이 늘어납니다.</p>

<p><br/></p>

<p>그러면 위에 나온 것 중 어느것이 가장 좋은 <em>failure detector</em> 일까요? 앞서 언급했던 기준들을 이용해서 살펴보겠습니다.</p>

<ul>
<li><em>Completeness:</em> guarantee always</li>
<li><em>Accuracy:</em> a prob of mstake in time T <code>PM(T)</code></li>
<li><em>Speed:</em> <code>T</code> time units</li>
<li><em>Scale:</em> <code>N*L</code> Compare this across protocols</li>
</ul>

<p>(1) All-To-All Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/performance_all2all.jpg'  alt="" /></p>

<p><em>work load</em> 가 <code>N</code> 에 비례합니다.</p>

<p>(2) Gossip-Style Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/performance_gossip.jpg'  alt="" /></p>

<p><code>tg</code> 를 <code>O(n)</code> 의 <em>gossip message</em> 를 보내는데 걸리는 <em>gossip period</em> 라 했을때, 한 <em>round</em> 에서의 전파 시간인 <code>logN</code> 을 곱해 <code>T = logN * tg</code> 입니다. 이때 오버헤드 <code>L = N/tg</code> 이므로, <code>L = N * logN / T</code> 입니다. </p>

<p>오버헤드가 <em>all-to-all heartbeating</em> 보다 훨씬 높죠? 이는 <em>accuracy</em> 가 더 높기 때문입니다. 앞에서 <em>all-to-all</em> 가 더 비용이 많이 들것 같지만 실제로는 그렇지 않다고 했었는데, 이런 이유에서입니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/suboptimal_worstcase.jpg'  alt="" /></p>

<ul>
<li><em>worst case load per member</em> <code>L*</code> 라 하고</li>
<li><code>P_ml</code> 을 독립적인 메시지 손실양 이라고 했을때, </li>
</ul>

<p><code>L*</code> 을 <code>T, PM(T), P_ml</code> 의 함수로 표시하면 </p>

<p><img src='http://latex.numberempire.com/render?L%2A%20%3D%20%7B%20log%28PM%28T%29%29%20%5Cover%20log%28P_ml%29%20%7D%20%2A%20%7B1%20%5Cover%20T%20%7D&amp;sig=b21744720873bd544c3b394bd827b158'  alt="" /></p>

<p>메시지 손실 <code>P_ml</code> 이 높을수록, 오버헤드 <code>L*</code> 는 당연히 작아져야 하고, <code>PM(T)</code> 가 높을수록 <em>false-positive</em> 가 많으므로 오버헤드가 높습니다. 수식을 보면 변수 <code>N</code> 이 없는데, 이는 <em>scale-free</em> 함을 보여줍니다.</p>

<p>그리고 <em>all-to-all</em> 이나 <em>gossip-based</em> 는 <strong>suboptimal</strong> 입니다. 왜냐하면 </p>

<ul>
<li><code>L = O(N/T)</code></li>
<li>try to achieve simultaneous detection at all processes</li>
<li>fail to distinguish <strong>failure detection</strong> and <strong>dissemination components</strong></li>
</ul>

<p>따라서 두개의 컴포넌트를 분리하고, <em>non heatbeat-based failure detection</em> 을 이용하면 됩니다.</p>

<p><br/></p>

<h3 id="swimfailuredetector">SWIM Failure Detector</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_intro.jpg'  alt="" /></p>

<p><em>SWIM</em> 은 <em>probabilistic failure detector protocol</em> 입니다. </p>

<p><em>period</em> <code>T</code> 동안 프로세스(노드) <code>pi</code> 는 <code>pj</code> 를 랜덤하게 골라 <em>ping</em> 을 보냅니다. <em>ack</em> 가 오면, 남은 <em>period</em> 동안 아무것도 하지 않습니다. 그러나 위 슬라이드에서 볼 수 있듯이 <code>pj</code> 가 응답하지 않으면 랜덤하게 <code>K</code> 개의 프로세스를 선택해서, <em>ping</em> 을 날리고, 이를 통해 <em>indirect</em> 한 방법으로 <code>pj</code> 의 응답을 검사합니다.</p>

<p><em>SWIM</em> 의 퍼포먼스는 <em>heartbeat</em> 와 비교했을때 어떨까요?</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_vs_heartbeating.jpg'  alt="" /></p>

<p><code>X</code> 축은 <strong>process load</strong>, <code>Y</code> 축은 <em>first detection time</em> 입니다. <em>false-positive rate</em> 와 <em>message loss rate</em> 는 고정되어있다고 가정합니다.</p>

<p><em>heartbeat</em> 의 경우에는 앞서 봤듯이 <em>detection time</em> 읖 높이면 <em>work load</em> 가 낮아지고 (= <em>low bound on the bandwidth</em>), 반대로 <em>detection time</em> 을 낮추면, <em>work load</em> 가 높아집니다. 반면 <em>SWIM</em> 은 둘다 적죠.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_parameters.jpg'  alt="" /></p>

<p>슬라이드에서 볼 수있듯이 <em>first detection time</em>, <em>process load</em> 는 <em>constant</em> 입니다. <em>process load</em> 의 경우에는 <em>15% packet loss</em> 가 있을때 <em>optimal</em> 의 8배인 <code>8L*</code> 보다 적습니다.</p>

<p><em>false positive rate</em> 는 <code>K</code> 를 증가시켜서 줄일 수 있습니다. <code>K</code> 가 증가함에 따라 <em>false positive rate</em> 는 지수적으로 감소합니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_accuracy_load.jpg'  alt="" /></p>

<p><del>쿨하게 페이퍼를 보시라는 교수님</del></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_detection_time.jpg'  alt="" /></p>

<p>어째서 <em>expected detection time</em> 이 <code>1 / e-1</code> 일까요? 하나의 프로세스가 죽었을때, 핑 되려면 다른 프로세스의 멤버쉽 리스트에 있어야 하고, 랜덤하게 선택되야 합니다. </p>

<p>랜덤하게 선택될 확률은 <code>1/N</code> 이고, 선택되지 않을 확률은 <code>1 - 1/N</code> 입니다. 다른 <code>N-1</code> 개의 프로세스에 의해 모두 선택되지 않을 확률은 <code>(1-1/N)^N-1</code> 이고, <code>1</code> 에서 이 값을 빼면 선택될 확률입니다. 그리고 익히 알려진 바대로 <del>응?</del> <code>N</code> 이 매우 커지면 이 값은 <code>1-e^-1</code> 과 같습니다.</p>

<p>그리고 확률론을 잘 안다면 <del>응?</del> 이 값에 기대값을 취하면 <code>e / e-1</code> 이 됩니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/time_bounded_completeness.jpg'  alt="" /></p>

<p>여기에 간단한 트릭을 이용하면 <em>worst case</em> 로 <code>O(N)</code>, 정확히는 <code>2N-1</code> <em>period</em> 내에 <em>failure</em> 가 발견되도록 할 수 있습니다. <em>membership list</em> 를 순회하다가, 마지막에 도달하면 랜덤하게 재배열 하는 것입니다. </p>

<p>그러면 최악의 경우 2번째 멤버에 대해 <em>ping</em> 을 날릴때 첫번째 멤버에 <em>failure</em> 가 발생하고, 재 배열했을때 첫번째 멤버가 마지막에 있다면 <code>(N-1) + (N)</code> 의 <em>period</em> 가 걸립니다. 그리고 이것은 <em>accuracy</em> 등 다른 <em>failure detector</em> 의 속성들을 그대로 유지한채 <em>worst case</em> 시간을 줄이는 결과를 만듭니다.</p>

<p><br/></p>

<h4 id="disseminationandsuspicion">Dissemination and Suspicion</h4>

<p><em>dissemiantion</em> 방법으로</p>

<p>(1) <strong>Multicast</strong> (Hardware / IP)</p>

<ul>
<li>unreliable</li>
<li>multiple simultaneous multicasts</li>
</ul>

<p>(2) <strong>Point-To-Point</strong> (TCP / UDP)</p>

<ul>
<li>expensive</li>
</ul>

<p>(3) <strong>Zero extra message:</strong> Piggyback on Failure Detector messages</p>

<ul>
<li>Infection-style Dissemination (like <em>SWIM</em>)</li>
</ul>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/infection_style_dissemination.jpg'  alt="" /></p>

<p>슬라이드에서 볼 수 있듯이 <em>infection style dissemination</em> 은 <code>λ log(N)</code> <em>protocol periods</em> 후에 <code>N^-(2λ-2)</code> 개의 프로세스만 업데이트되지 않습니다. 바꿔말하면 <code>O(logN)</code> 후에 대부분의 프로세스는 발견돈 <em>failure</em> 정보를 업데이트 한다는 뜻입니다. </p>

<p>여기서 <code>λ</code> 는 <em>consistency level</em> 을 결정하는 상수입니다. 어떤 경우에도 <em>SWIM detector</em> 는 <em>failure</em> 를 <code>2N-1</code> 내에 발견하기 때문에 <em>completeness</em> 100% 가 보장됩니다.</p>

<p><br/></p>

<h3 id="suspicionmechanism">Suspicion Mechanism</h3>

<p><em>false positive</em> 가 발생하는 이유는</p>

<ul>
<li>perturbed processes</li>
<li>package losses (e.g from congestion)</li>
</ul>

<p><em>SWIM</em> 에서 사용했던 <em>indirect pinging</em> 도 이 문제를 해결하지 못할 수 있습니다. (e.g <em>correlated message losses near pinged host</em>)</p>

<p>먼저 <em>failure</em> 가 발견되었을때 다른 노드들에게 알리기 전에 먼저 <em>suspect</em> 한다면 <em>false positive</em> 비율을 줄일 수 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/suspicon_mechanism_state_machine.jpg'  alt="" /></p>

<p>그림이 좀 복잡한데, 프로세스(노드) <code>pi</code> 기준으로 <em>state</em> 가 어떻게 변하는지를 나타낸 그림이라고 보면 됩니다. <code>pj</code> 에게 핑을 날려 응답하지 않으면 <em>suspected</em> 상태로 변하고, 여기서 <em>timeout</em> 되면 <em>failed</em> 되어 <code>pj</code> 가 <em>failure</em> 라고 <em>dissemination</em> 하는 상태가 됩니다.</p>

<p>한 가지 발생할 수 있는 문제점은 <em>suspected</em> 상태에서 <em>alive</em> 상태로 반복적으로 전환될 수 있다는 점입니다. 이러한 혼란을 피하기 위해 <em>incarnation number</em> 를 사용할 수 있습니다.</p>

<p>프로세스 <code>pj</code> 가 <em>suspected</em> 메세지를 받았을때, <em>incarnation number</em> 를 증가시킬 수 있는 것은 <code>pj</code> 만 가능합니다. 그리고 <em>increase incarnation number</em> 메시지를 받은 다른 프로세스들은 <em>alive</em> <code>pj</code> 메시지를 전달합니다.</p>

<p>높은 숫자의 <em>incarnation number</em> 가 더 우선합니다. 그리고 <em>suspect</em> 와 <em>alive</em> 같은 값이라면 <em>suspect</em> 메시지로 처리됩니다. 그리고 <em>failed</em> 메시지는 다른 어떤 메시지보다 더 높은 우선순위를 가지고 있습니다.</p>

<p><br/></p>

<h3 id="summary">Summary</h3>

<ul>
<li>failures the norm, not the exception in datacenters</li>
<li>every distributed system uses a failure detector</li>
<li>many distributed systems use a membership service</li>
<li>ring failure detection underlies <em>IBM SP2</em> and many other similar clusters</li>
<li>Gossip-style failure detection underlies AWS EC2/S3 (rumored)</li>
</ul>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-membership-protocol/</link><guid isPermaLink="false">146da27a-1df0-44d0-a8e1-3020c05f0d22</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[membership]]></category><category><![CDATA[SWIM]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 22 Feb 2015 07:02:52 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, Gossip Protocol]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<h3 id="multicast">Multicast</h3>

<p>이번시간에 배울 내용은 <em>Gossip Protocol</em> (혹은 <em>Epidemic Protocol</em>) 입니다.</p>

<p>기존에는 특정 그룹에게 메세지를 보내기 위해 <em>multicast</em> 를 이용했지만, 클라우드 컴퓨티 환경에서는</p>

<ul>
<li>프로세스가 죽어 노드가 크래쉬를 일으킬수도</li>
<li>네트워크 문제때문에 패킷이 딜레이되거나, 드랍될 수 있고</li>
<li>노드가 빠르게 증가합니다.</li>
</ul>

<p>그러나 멀티캐스트는 <em>fault-tolerance</em> 와 <em>scalability</em> 측면에서 부족한 부분이 많았습니다. 이런 문제를 해결하기 위해 다양한 방법이 도입되었는데</p>

<p>(1) <strong>Centralized:</strong> 중앙 서버에서 <em>TCP, UDP</em> 패킷을 날립니다. 간단한 구현이지만 중앙서버의 오버헤드가 높고, 수천개의 노드가 있을때 <em>latency</em> 가 생깁니다. 노드의 수를 <code>N</code> 이라 했을때, 모든 노드에 메시지가 전달되는데 <code>O(N)</code> 시간이 걸리지요.</p>

<p>(2) <strong>Tree-Based:</strong> 전달 받은 노드에서, 다시 패킷을 전달하여 경로가 <em>tree</em> 형태로 구성됩니다. <em>balanced tree</em> 라면 어떤 그룹에 패킷이 전달되는데 <code>O(logN)</code> 의 시간이 걸립니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/tree_based_multicast.jpg'  alt="" /></p>

<p>이 방법의 단점은 </p>

<ul>
<li><em>tree</em> 를 구성하고 유지하는데 필요한 오버헤드</li>
<li><em>root</em> 에 가까운 곳에서 <em>failure</em> 가 발생했을때의 파급력</li>
</ul>

<p>일반적으로 <em>tree-based multicast</em> 프로토콜에서는 <em>spanning tree</em> 를 구성해서 최단비용으로 패킷을 전달합니다. 그리고 메시지가 올바르게 전달되었는지 <em>ACK</em> 또는 <em>NAK</em> 를 이용하는데 <em>SRM</em> 이던 <em>RMTP</em> 던 여전히 <code>O(N)</code> 만큼의 <em>ACK/NAK</em> 오버헤드가 발생합니다.</p>

<p><br/></p>

<h3 id="gossip">Gossip</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_example1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_example2.jpg'  alt="" /></p>

<p>가십 프로토콜은 위 그림처럼 작동합니다.</p>

<ul>
<li>주기적으로 랜덤한 타겟을 골라 <em>gossip message</em> 를 전송합니다</li>
<li>그리고 이것을 받아 <em>infected</em> 상태가 된 노드도 똑같이 행동합니다.</li>
</ul>

<p>이걸 <em>Push gossip</em> 이라 부릅니다. <em>multiple message</em> 를 가십하기 위해 랜덤 서브셋을 선택하거나, <em>recently-received</em> 메시지를 를 선택하거나, <em>higher priority one</em> 을 고를 수 있습니다.</p>

<p>어떤 가십 메시지에 대해 대부분의 노드가 <em>infected</em> 되었을때 <em>push gossip</em> 은 비효율적입니다. 이때는 <em>uninfected</em> 노드가, 새로운 가십메시지가 있는지 주변 노드에게 물어보는 <strong>pull gossip</strong> 이 오버헤드가 더 적습니다.</p>

<ul>
<li><strong>Pull gossip:</strong> Periodically poll a few random selected processes for new multicast meesages that you haven't received</li>
</ul>

<p><br/></p>

<h3 id="gossipanalysis">Gossip Analysis</h3>

<p>가십프로토콜은 다음의 특징을 가집니다.</p>

<ul>
<li><strong>lightweight</strong> in large groups</li>
<li>spreads a multicast quickly</li>
<li>highly <em>fault-tolerant</em></li>
</ul>

<p>이를 위해 간단한 증명을 해보도록 하겠습니다.</p>

<ul>
<li>전체 <code>n+1</code> 의 <em>population</em> 에 대해 </li>
<li><em>uninfected individuals</em> 의 수를 <code>x</code></li>
<li><em>infected individuals</em> 의 수를 <code>y</code> </li>
<li><em>individual pair</em> 간의 <em>contract rate</em> 를 <code>β</code> 라 하면</li>
</ul>

<p>항상 <code>x + y = n + 1</code> 이고, 시작상태에서는 <code>x_0 = n, y_0 = 1</code> 입니다. 그리고 시간이 지날때마다 <em>uninfected</em> <code>y</code> 는 다음처럼 감소합니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cmathrm%7Bd%7D%20x%7D%7B%5Cmathrm%7Bd%7D%20t%7D%20%3D%20-%5Cbeta%20xy'  alt="" /></p>

<p>그러면 이 수식으로부터 다음을 이끌어 낼 수 있습니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?x%20%3D%20%7B%20n%28n&plus;1%29%20%5Cover%20%7Bn%20&plus;%20e%5E%7B%5Cbeta%28n&plus;1%29t%7D%7D%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?y%20%3D%20%7B%20%28n&plus;1%29%20%5Cover%20%7B1%20&plus;%20ne%5E%7B-%5Cbeta%28n&plus;1%29t%7D%7D%7D'  alt="" /></p>

<p>그리고 <em>infected node</em> 가 랜덤하게 <code>b</code> 개의 노드를 고른다 하면 <code>β</code> 는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cbeta%20%3D%20%7Bb%20%5Cover%20b%7D'  alt="" /></p>

<p>그리고 시간 <code>t</code> 를 가십이 진행되는 <em>round</em> 라 보고 <code>t = clog(n)</code> 이라 치환하겠습니다. 다음을 이끌어낼 수 있습니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?y%20%5Capprox%20%28n&plus;1%29%20-%20%7B1%20%5Cover%20n%5E%7Bcb-2%7D%7D'  alt="" /></p>

<p>이 식으로부터 <em>gossip protocol</em> 이 <em>low latency</em>, <em>reliability</em>, <em>lightweight</em> 하다는 것을 알 수 있습니다.</p>

<p>(1) <strong>low latency</strong></p>

<p><code>c, b</code> 를 <code>n</code> 과 독립적으로 아주 작은 숫자로 세팅하면 <code>clog(n)</code> <em>round</em> 이므로 적은 시간 내에 메시지가 전파됩니다.</p>

<p>(2) <strong>reliability</strong></p>

<p><code>n</code> 이 매우 크면 <code>1 / n^{cb-2}</code> 가 <code>0</code> 에 가까워지므로, <code>1 / n^{cb-2}</code> 만큼의 노드를 제외한 모든 노드가 <em>infected</em> 된다는 것을 알 수 있습니다.</p>

<p>(3) <strong>lightweight</strong></p>

<p>각 노드는 <code>cb log(n)</code> 만큼의 <em>gossip message</em> 만 전파합니다. 이론적으로는 <code>log(N)</code> 은 상수가 아니지만, 실제로는 아주 천천히 증가하는 숫자기에 작은 숫자처럼 생각할 수 있습니다.</p>

<p><br/></p>

<h3 id="faulttolerance">Fault-Tolerance</h3>

<p><em>50% packet loss</em> 를 생각해 봅시다. <code>b</code> 를 <code>2/b</code> 로 치환하면 됩니다. 그러면 이전과 같은 <em>reliability</em> <em>0% packet loss</em> 를 위하 두배의 <em>round</em> 만큼만 더 진행하면 됩니다.</p>

<p><em>node failure</em> 는 어떨까요? 50% 노드에서 <em>failure</em> 가 발생한다면 <code>n, b</code> 을 <code>2/n, 2/b</code> 으로 치환하면 됩니다. 이는 <em>contract rate</em> 에서 가십 메시지를 전달하는 <code>n</code> 중 <code>2/n</code> 의 노드만 살아있고, 선택되는 <code>b</code> 중 <code>b/2</code> 노드만 살아있기 때문입니다. 이 경우에도 상수만 곱하면 이전과 같은 <em>reliability</em> 를 얻을 수 있습니다.</p>

<p><em>failure</em> 와 관련해서 한 가지 생각해 볼 문제가 있습니다. 모든 노드가 죽는것이 가능할까요? 물론 가능합니다 초기에 모든 노드가 죽으면요. 그러나 <em>improbable</em> 입니다. 일단 몇개의 노드가 <em>infected</em> 되면, 이후에는 퍼지는 속도가 훨씬 더 빠르기 때문입니다. 루머나 바이러스가 퍼질 수 있는 이유를 생각하면 이해하기 쉽습니다.</p>

<p><br/></p>

<h3 id="pullgossip">Pull Gossip</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/pull_gossip_analysis.jpg'  alt="" /></p>

<p>그림에서 볼 수 있듯이, 어떤 형태의 가십 프로토콜이던 <code>2/N</code> 까지 전달할때는 <code>O(logN)</code> 만큼의 시간이 걸립니다. 그 이후에는 <em>pull gossip</em> 이 훨씬 빠르죠.</p>

<p><code>i</code> <em>round</em> 후에 남아있는 <em>uninfected node</em> 의 수를 <code>p_i</code> 라 합시다. <em>pull gossip</em> 을 이용할때 다음 단계에서도 <em>uninfected</em> 일 확률은 </p>

<p><img src='http://latex.codecogs.com/gif.latex?p_%7Bi&plus;1%7D%20%3D%20p_i%5E%7Bk&plus;1%7D'  alt="" /></p>

<p>이는 <code>p_i</code> 자체가 <em>uninfected</em> 여야 하고, 이 노드가 선택하는 <code>k = b</code> 만큼의 노드도 <em>uninfected</em> 여야 하는데, 이 확률은 극히 낮습니다. 슬라이드에서 보듯이 <em>super-exponential</em> 하고, 그렇기 때문에 <em>second half</em> 부터는 <em>pull gossip</em> 이 <code>O(log(logN))</code> 입니다.</p>

<p><br/></p>

<h3 id="topologyawaregossip">Topology-Aware Gossip</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/topology_aware_gossip.jpg'  alt="" /></p>

<p>만약 <em>uninfected node</em> 를 <em>uniformly random</em> 하게 고른다면 위 그림에서 라우터의 오버헤드는 <code>O(N)</code> 이 됩니다. 더 정확하게는 <em>round</em> 마다 <code>b * (2/n)</code> 이 될겁니다. </p>

<p>이를 해결하기 위해, 서브넷에 <code>n_i</code> 개의 노드가 있을때 자신이 속한 서브넷에 있는 <em>uninfected node</em> 를 더 자주 고르게, 확률을 <code>1 - (1/n_i)</code> 가 되도록 합니다. 그러면, 현재 서브넷에 있는 노드를 선택할 확률이 1 에 가까우므로 <code>O(logN)</code> 시간 내에 전파되고, 라우터의 오버헤드는 <code>(n_i) / (n_i)</code> 가 되어, <code>O(1)</code> 이 됩니다. </p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-gossip-protocol/</link><guid isPermaLink="false">791b3276-2b13-469d-96ff-21b0b279bfd2</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[gossip]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 21 Feb 2015 05:41:54 GMT</pubDate></item><item><title><![CDATA[Pattern Discovery 2]]></title><description><![CDATA[<p><img src='https://m1.behance.net/rendition/modules/7116731/disp/d18c13cd5b49bf40b41e6ef0610b26d3.png'  alt="" /></p>

<p>패턴 마이닝을 통해 만들어지는 수많은 <em>pattern</em>, <em>rule</em> 이 모두 유용한 것은 아닙니다. 따라서 <em>interestingness measure</em> 을 위해 객관적이거나, 주관적인 평가방법을 이용할 수 있습니다.</p>

<p>(1) <strong>Objective interestingness measures</strong></p>

<ul>
<li>support, confidence, correlation</li>
</ul>

<p>(2) <strong>Subjective interestingness measures</strong></p>

<ul>
<li><em>Query-based:</em> relevant to a user's particular request</li>
<li><em>Against one's knowledge-base:</em> unexpected, freshness, timeliness</li>
<li><em>Visualization tools:</em> Multi-dimensional, interactive examination</li>
</ul>

<p>이 방법중, 먼저 객관적인 방법에 대해 좀 더 알아보겠습니다.</p>

<p><br/></p>

<h3 id="liftchisquared">Lift, χ²(Chi-squared)</h3>

<p><em>confidence</em> 는 두 변수가 관련있는지 말해주지만, <em>positive</em> 혹은 <em>negative</em> 관계인지 말해주지 않습니다. 이를 판별하기 위해 <em>lift</em> 를 이용할 수 있죠</p>

<p><img src='http://latex.codecogs.com/gif.latex?lift%28B%2C%20C%29%20%5C%5C%20%5C%5C%20%3D%20%7Bc%28B%20-%3E%20C%29%20%5Cover%20s%28C%29%7D%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20%7Bs%28B%20%5Ccup%20C%29%20%5Cover%20%7Bs%28B%29%20%5Ctimes%20s%28C%29%7D%7D'  alt="" /></p>

<p><code>Lift(B, C)</code> 는 <code>B</code> 와 <code>C</code> 가 얼마나 관련있는지를 말해줍니다. 수식을 보면 알겠지만</p>

<ul>
<li><code>Lift(B, C) = 1</code> 이면 <code>B</code> 와 <code>C</code> 는 <em>independent</em></li>
<li><code>&gt; 1</code> 이면 <em>positive correlated</em></li>
<li><code>&lt; 1</code> 이면 <em>negative correlated</em></li>
</ul>

<p><br/></p>

<p><em>correlated events</em> 를 판별하는 다른 방법은 <code>χ²</code> 를 이용하는 것입니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cchi%5E2%20%3D%20%5Csum%20%7B%28observed%20-%20expected%29%5E2%20%5Cover%20expected%7D'  alt="" /></p>

<ul>
<li><code>χ² = 0</code> 이면 <em>independent</em></li>
<li><code>χ² &gt; 1</code> 이면 <em>correlated</em> 이며 <em>positive</em> 인지 <em>negative</em> 인지는 <em>expected</em> 값과 비교하면 알 수 있습니다.</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/null_transaction.jpg'  alt="" /></p>

<p>그러나 <em>lift</em> 와 <em>chi-squared</em> 가 항상 좋은 평가지표는 아닙니다. 위 테이블을 보면 <code>Lift(B, C) = 8.44</code> 입니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?lift%28B%2C%20C%29%20%5C%5C%20%5C%5C%20%3D%20%7B%28100/102100%29%20%5Cover%20%7B%281100/102100%29%20' *%20%281100/102100%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%208.4380" alt="" /></p>

<p>이는 <code>~B and ~C</code> 부분의 숫자가 <code>B, C</code> 보다 월등히 높아서 그런데, 이런 영역을 <em>null transaction</em> 이라 부릅니다. </p>

<p><code>B, C</code> 는 같이 일어날 확률이 상당히 낮지만, <em>null transaction</em> 때문에 높은것처럼 보입니다.</p>

<p><br/></p>

<h3 id="nullinvariantmeasures">Null Invariant Measures</h3>

<p><em>lift</em> 와 <em>chi-squared</em> 는 많은 수의 <em>null transaction</em> 이 있을 때 좋은 평가 지표가 될 수 없습니다. </p>

<p>이를 해결하기 위해 <em>null transaction</em> 에 영향을 받지 않는 <em>null-invaraint measures</em> 를 사람들이 만들어 두었습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/null_invariant_measures.jpg'  alt="" /></p>

<p><em>null invariance</em> 는 <em>massive transaction data</em> 를 마이닝할때 아주 중요합니다. <em>null transaction</em> 이 아주 많을 수 있기 때문이죠. </p>

<p>그러면 이 많은 <em>measures</em> 중 어떤것이 가장 나을까요? 예제 데이터로 한번 비교해 봅시다. <code>m</code> 은 <em>milk</em>, <code>c</code> 는 <em>coffee</em> 입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/comparison_of_measures.jpg'  alt="" /></p>

<blockquote>
  <p>Kulc holds firm and is in balance of both directional implications</p>
</blockquote>

<p>여기에 <em>imbalance ratio</em> 라는 개념을 도입할 수 있습니다.</p>

<ul>
<li><strong>imbalance ratio:</strong> measure the imbalance of two itemsets <code>A</code> and <code>B</code> in rule implications</li>
</ul>

<p><img src='http://latex.codecogs.com/gif.latex?IR%28A%2C%20B%29%20%5C%5C%20%5C%5C%20%3D%20%7B%7B%7Cs%28A%29%20-%20s%28B%29%7D%20%5Cover%20s%28A%29%20&plus;%20s%28B%29%20-%20s%28A%5Ccup%20B%29%7D'  alt="" /></p>

<p><em>Kulc</em> 와 <em>IR</em> 을 이용하면 조금 더 데이터를 자세히 살펴볼 수 있죠.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/IR.jpg'  alt="" /></p>

<ul>
<li>D4 is <em>neutral</em>, <em>balanced</em></li>
<li>D5 is <em>neutral</em>, but <em>imbalanced</em></li>
<li>D6 is <em>neutral</em>, but very <em>imbalanced</em></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/DBLP_example.jpg'  alt="" /></p>

<p><code>ID 5</code> 를 보면, <em>Kulc</em> 는 아이템 <code>A, B</code> 가 상당한 연관성이 있지만, <em>imbalance</em> 하므로 <code>0.562</code> 의 값을 돌려주는 것을 볼 수 있습니다.</p>

<p><br/></p>

<h2 id="5miningdiversepatterns">5. Mining Diverse Patterns</h2>

<p>이번 시간에 배울 주제들은 다음과 같습니다.</p>

<ul>
<li>Mining Multiple-Level Associations</li>
<li>Mining Multi-Dimensional Associations</li>
<li>Mining Quantitative Associations</li>
<li>Mining Negative Correlations</li>
<li>Mining Compressed and Redundancy-Aware Patterns</li>
<li>Mining Long/Colossal Patterns</li>
</ul>

<p><br/></p>

<h3 id="multilevelassociations">Multi-Level Associations</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/multi_level_items.jpg'  alt="" /></p>

<p><em>item</em> 은 하위 계층으로 다시 분류될 수 있습니다. 이럴때는 단순히 <em>uniform min support</em> 를 이용하는 것보다, 아래 계층으로 내려갈수록 <em>reduced min support</em> 를 이용하는 편이 더 낫습니다.</p>

<p>그리고 한번의 여러 단계(<em>multi-level</em>) 을 마이닝하기 위해 <em>shared multi-level mining</em> 이란 기법을 이용할 수 있습니다.  이건 뒷부분에서 더 살펴보겠습니다.</p>

<p><em>multi-level association</em> 마이닝의 문제점은 <em>redundant rules</em> 을 만들 수 있다는 점입니다. 따라서 필터링 기법이 필요합니다. <code>level 1</code> 에서 발견된 룰을, <code>level 2</code> 에서 다시 검사하지 않는것 처럼요</p>

<ul>
<li><code>milk -&gt; wheat bread [s=8%, c=70%]</code></li>
<li><code>2% milk -&gt; wheat breadk [s=2%, c=72%]</code></li>
</ul>

<p>아이템에 따라서 <em>customized min support</em> 가 필요한 경우도 있습니다. 우유나 빵은 그렇지 않아도 상관 없지만, <em>diamond</em>, <em>watch</em> 등은 커스터마이징이 꼭 필요합니다. 고가의 아이템이니까요. 이 경우 <em>group-based individualized min-support</em> 를 이용하면 됩니다.</p>

<ul>
<li><code>{diamon, watch}: 0.05%; {bread, milk}: 5%;, ...</code></li>
</ul>

<p><br/></p>

<h3 id="multidimensionalassociations">Multi-Dimensional Associations</h3>

<p><em>multi-dimensional</em> 의 예는</p>

<p>(1) <strong>inter-dimension association rules</strong> (no repeated pred)</p>

<p><code>age(X, "18-25") ∩ occupation(X, "student") =&gt; buys(X, "coke")</code></p>

<p>(2) <strong>hybrid-dimension association rules</strong> (repeated pred)</p>

<p><code>age(X, "18-25") ∩ buys(X, "popcorn") =&gt; buys(X, "coke")</code></p>

<p><em>attribute</em> 는 <em>categorical</em> 이거나 <em>quantitative</em> 일 수 있습니다. </p>

<p><br/></p>

<h3 id="quantitativeassociations">Quantitative Associations</h3>

<p><em>numerical attribute</em> (e.g <em>age, salary</em>) 를 마이닝 하기 위해 다양한 <em>method</em> 를 사용할 수 있습니다.</p>

<p>(1) static discretization based on prefefined concept hierarchies. data cube-based aggregation</p>

<p>(2) dynamic discretization based on data distribution</p>

<p>(3) clustering: distance-based association. first one-dimensional clustering, then association</p>

<p>(4) deviation analysis</p>

<p><br/></p>

<h3 id="negativecorrelations">Negative Correlations</h3>

<p><em>rare pattern</em> 과 <em>negative pattern</em> 은 다릅니다.</p>

<p>(1) <strong>Rare patterns</strong></p>

<ul>
<li>아주 낮은 <em>support</em> 지만, 롤렉스 시계를 사는 행위처럼 중요할 수 있습니다</li>
<li><em>individualized</em>, <em>group-based min support</em> 를 다양한 아이템 그룹에 설정해서 마이닝합니다.</li>
</ul>

<p>(2) <strong>Negative patterns</strong></p>

<ul>
<li>자동차를 동시에 2개 사는것처럼, 같이 일어나는 경우가 드뭅니다 (<em>unlikely to happen together</em>)</li>
</ul>

<p><br/></p>

<p><em>negative pattern</em> 은 어떻게 마이닝할까요? 한가지 방법은 <em>lift</em> 에서 사용했던 <em>support-based definition</em> 을 이용하는 것입니다.</p>

<ul>
<li><code>s(A ∪ B) &lt;&lt; s(A) X s(B)</code></li>
</ul>

<p>이 정의는 작은 <em>transaction dataset</em> 에서는 통하지만, 데이터 크기가 커지면 적용되지 않습니다.</p>

<p>(1) 전체 200개의 트랜잭션에 대해</p>

<ul>
<li><code>s(A∪B) = 0.005, s(A) x s(B) = 0.25, s(A∪B) &lt;&lt; s(A) X s(B)</code></li>
</ul>

<p>(2) 전체 10^5 개의 트랜잭션에 대해</p>

<ul>
<li><code>s(A∪B) = 1/10^5, s(A) x s(B) = 1/10^3 X 1/10^3, s(A∪B) &gt;&gt; s(A) X s(B)</code></li>
</ul>

<p>이전에 봤었던 <em>null transaction</em> 때문입니다. <em>support-based definition</em> 은 <em>not null-invariant</em> 입니다.</p>

<p>이를 해결하기 위해 <em>Kulczynski measure-based definition</em> 을 이용하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%28P%28A%7CB%29%20&plus;%20P%28B%7CA%29%29%20/%202%20%3C%20%5Cepsilon'  alt="" /></p>

<p>여기서 <code>ɛ</code> 는 <em>negative pattern threshold</em> 를 의미합니다. 만약 위 수식이 <code>ɛ</code> 보다 작으면 <em>negatively correlated</em> 란 뜻이지요. </p>

<p><br/></p>

<h3 id="compressedpatterns">Compressed Patterns</h3>

<p>때로는 너무 많아 의미가 없는 <em>scattered pattern</em> 때문에 <em>compressed pattern</em> 을 마이닝 할 필요가 있습니다. </p>

<p><em>compressed pattern</em> 인 <em>closed pattern</em> 과 <em>max pattern</em> 의 정의를 복습해보면</p>

<ul>
<li><strong>closed pattern:</strong> A pattern <code>x</code> is <strong>closed</strong> if <code>x</code> is frequent, and there exists no super pattern <code>Y ⊃ X</code> with the same support as <code>X</code></li>
<li><strong>max pattern:</strong> A pattern <code>X</code> is a <strong>max pattern</strong>. if <code>X</code> is frequent and there exists no frequent super-pattern <code>Y ⊃ X</code></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/compressed_pattern.jpg'  alt="" /></p>

<p>예를 들어 위 그림에서 <code>P1, 2, 3, 4, 5</code>는 모두 <em>closed</em> 고, <code>P3</code> 는 <em>max pattern</em> 입니다. <em>P3</em> 만 남기자니 <em>information loss</em> 가 너무 많고, 다 남기자니 엣지가 없습니다. <code>P2, P3, P4</code> 정도면 적당할 것 같습니다.</p>

<p>이 적당한 정도를 결정하기 위해 <em>pattern distance measure</em> 을 사용할 수 있습니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?Dist%28P_1%2C%20P_2%29%20%3D%201%20-%20%7B%7CT%28P_1%29%20%5Ccap%20T%28P_2%29%7C%20%5Cover%20%7CT%28P_1%29%20%5Ccup%20T%28P_2%29%7C%7D'  alt="" /></p>

<p>그리고 이 <em>distance</em> 값을 이용해 <em>δ-cluserting</em> 을 합니다. </p>

<ul>
<li><strong>δ-clustering:</strong> For each pattern <code>P</code>, find all patterns which can be expressed by <code>P</code> and whose distance to within <code>δ</code> (<em>δ-cover</em>)</li>
</ul>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/redundancy_aware_top_k.jpg'  alt="" /></p>

<p><em>Redundancy-Aware Top-k pattern</em> 이란 기법도 있습니다.</p>

<p><code>(a)</code> 가 본래 패턴이고, <em>traditional top-k</em> 기법으로는 가장 컴팩트한(진한) 3개의 패턴만 남깁니다. 따라서 우측 클러스터는 버려지죠.</p>

<p>이를 막기 위해 클러스터별로 하나씩 남기는 <code>(d)</code> <em>summarization</em> 을 이용할 수도 있으나, 이건 중요한 것만을 돌려주지 않습니다. </p>

<p>따라서 두 방법을 조합한 <code>(b)</code>, 중복을 허용하는 <em>redundancy-aware top-k</em> 를 이용하면 적절한 패턴을 남기고, 나머지는 버릴 수 있습니다.</p>

<p>이를 위해 <em>MMS (Maximal Marginal Significance)</em> 메소드를 사용할 수 있습니다.</p>

<p><br/></p>

<h3 id="colossalpatterns">Colossal Patterns</h3>

<p><em>long pattern mining</em> 은 소셜 네트워크 분석이나, 바이오인포메틱스, 소프트웨어 엔지니어링등 다양한 분야에서 필요로 합니다. 그러나, 지금까지 우리가 본건 길이가 10 보다 적은 패턴을 마이닝하는 기법들이었습니다.</p>

<p><em>long pattern</em> 을 분석하기 어려운 이유는 지난시간에 봤듯이 <em>downward closure property</em> 때문입니다. <em>frequent pattern</em> 의 <em>sub-pattern</em> 은 적어도 그만큼은 빈번하기 때문에, 패턴의 길이가 길고 <em>frequent</em> 하다면, 그 수많은 서브패턴을 분석해야 하는 것이지요.</p>

<p><em>BFS (e.g Apriori)</em>, <em>DFS (e.g FPgrowth)</em> 등 무엇을 이용하든 수 많은 패턴을 검색해야 하고, <em>combinatorial explosion</em> 과 마주할 수 밖에 없습니다.</p>

<p><code>40C20</code> 컴비네이션의 경우 기존에 존재하는 가장 빠른 마이닝 알고리즘들(e.g FP-Close, LCM)도 계산을 완료하지 못하는 경우가 많습니다. 그러나 놀랍게도 <em>pattern-fusion</em> 알고리즘은 1초만에 결과를 돌려줍니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/pattern_fusion1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/pattern_fusion2.jpg'  alt="" /></p>

<p>즉, 작은 <em>core pattern</em> 을 모아 <em>colossal pattern</em> 을 만들어 낸다는 것이지요.</p>

<ul>
<li><strong>core patterns</strong> of a colossal pattern <code>α</code>: A set of subpatterns of <code>α</code> that cluster around <code>α</code> by sharing a similar support</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/robustness_of_colossal_pattern.jpg'  alt="" /></p>

<p><em>core pattern</em> 에 대한 더 엄밀한 정의는 위와 같습니다.</p>

<p><em>frequent pattern</em> <code>α</code> 에 대해, <em>sub-pattern</em> 인 <code>β</code> 는  다음을 만족하면 <em>τ-core pattern</em> 입니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B%7CD_%5Calpha%7C%20%5Cover%20%7CD_%5Cbeta%7C%7D%20%5Cgeq%20%5Ctau%5C%20%28where%5C%20%5Ctau%5C%20is%5C%20core%5C%20ratio%29'  alt="" /></p>

<p>그리고 패턴 <code>α</code> 에서 <code>d</code> 만큼의 아이템을 제거해도, 여전히 <em>τ-core pattern of α</em> 이면 <code>α</code> 를 <em>(d, τ)-robust</em> 라 부릅니다. 따라서 <code>d</code> 만큼의 아이템이 있거나 없어도, 코어패턴이므로 전체 숫자는 <code>2^d</code> 만큼의 코어패턴을 만들 수 있습니다.</p>

<p>그러므로 <em>colossal pattern</em> 이라면, 정말 많은 수의 <em>core pattern</em> 을 만들 수 있습니다. 그리고 이런 <em>core pattern</em> 은  <em>distance</em> 가 충분히 작으므로 <em>dense ball</em> 형태로 뭉칩니다. 결과적으로 <em>random pattern space</em> 에서 패턴을 뽑으면, <em>dense ball</em> 내의 패턴일 확률이 굉장히 높습니다.</p>

<p>이를 기반으로한 <em>Pattern-Fusion Algorithm</em> 은</p>

<ol>
<li><p><strong>Initialize (creating initial pool)</strong>: </p></li>
<li><p>Use an existing algorithm to min all frequent patterns up to a small size (e.g 3)</p></li>
<li><p><strong>Iteration (iterative pattern fusion):</strong> </p></li>
<li><p>At each iteration, <code>K</code> seed patterns are randomly picked from the current pattern pool</p></li>
<li>For each seed pattern thus picked, we find all the patterns within a bounding ball centered at the seed pattern</li>
<li>All these patterns found are fused tohether to generate a set of super-patterns</li>
<li><p>All the super-patterns thus generated form a new pool for the next iteration</p></li>
<li><p><strong>Termination:</strong></p></li>
<li><p>when the current poll contains no more than <code>K</code> patterns at the beginning of an iteration</p></li>
</ol>

<p><br/></p>

<h2 id="6constraintbasedmining">6. Constraint-Based Mining</h2>

<p>이번시간에 배울 내용은 다음과 같습니다.</p>

<ul>
<li>Different Pruning Strategies</li>
<li>Constrainted Mining with Pattern Anti-Monotonicity</li>
<li>Constrainted Mining with Pattern Monotonicity</li>
<li>Constrainted Mining with Data Anti-Monotonicity</li>
<li>Constrainted Mining with Succinct Constraints</li>
<li>Constrainted Mining with Convertible Constraints</li>
<li>Hanlding Multiple Constraints</li>
</ul>

<p>왜 <em>Constraint-Based Mining</em> 이 필요할까요? 데이터셋에 있는 <strong>all</strong> 패턴을 <strong>autonomously</strong> 하게 찾는것은 불가능합니다. 이는 <em>compressed pattern mining</em> 에서 언급했듯이, 너무 많은 패턴이 있기 때문이지요. 특히 데이터셋이 커지면 사용자가 관심 없는 데이터가 기하급수적으로 늘어납니다.</p>

<p>따라서 패턴 마이닝은 사용자가 무엇을 원하는지 <em>data mining query language</em> 나 <em>GUI</em> 를 통해서 직접 명령을 내리는 <em>interactive</em> 한 과정이 되야 합니다.</p>

<p><em>constraints</em> 를 이용하면 다음과 같은 장점이 있습니다.</p>

<ul>
<li><strong>user flexibility:</strong> provides <strong>constraints</strong> on what to be mined</li>
<li><strong>optimization:</strong> explores such constraints for efficient mining</li>
</ul>

<p><br/></p>

<h3 id="differentpruning">Different Pruning</h3>

<p><em>constraints</em> 에 따라 <em>pruning strategy</em> 달라집니다.</p>

<p>(1) <strong>pattern space pruning constraints</strong></p>

<ul>
<li><em>anti-monotonic:</em> if constraint <code>c</code> is violated, its further mining can be terminated</li>
<li><em>monotonic:</em> if <code>c</code> is satisfied, no need to check <code>c</code> agina</li>
<li><em>succinct:</em> <code>c</code> can be enforced by directly manipulating the data</li>
<li><em>convertible:</em> <code>c</code> can be converted to monotonic or anti-monotonic if items can be propery ordered in processing</li>
</ul>

<p>(2) <strong>data space pruning constraints</strong></p>

<ul>
<li><em>data succinct:</em> data space can be pruned at the initial pattern mining process</li>
<li><em>data anti-monotonic:</em> if a transaction <code>t</code> doesn't satisfy <code>c</code>, then <code>t</code> can be pruned to reduce data processing effort</li>
</ul>

<p><br/></p>

<h3 id="antimonotonicity">Anti-Monotonicity</h3>

<p><em>constaint</em> <code>C</code> 는 다음의 경우에 <em>anti-monotone</em> 이라고 말합니다.</p>

<ul>
<li>If an itemset <code>S</code> <strong>violates</strong> constraint <code>C</code>, so does any of its superset</li>
<li>That is, mining on itemset <code>S</code> can be terminated</li>
</ul>

<p>예를 들어서 다음의 제약조건은 <em>anti-monotone</em> 입니다</p>

<ul>
<li><code>sum(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &lt;= 15</code> </li>
<li><code>support(S) &gt;= k</code></li>
</ul>

<p>따라서 <em>Apriori pruning</em> 은 본질적으론 <em>anti-monotonic constaint</em> 에 기반합니다.</p>

<p>반대로 <code>sum(S.price) &gt;= v</code> 는 <em>not anti-monotone</em> 입니다.</p>

<p><br/></p>

<h3 id="monotonicity">Monotonicity</h3>

<p><em>itemset</em> <code>S</code> 가 <em>constaint</em> <code>c</code> 를 만족할때, <code>S</code> 의 <em>superset</em> 도 그러하다면 <code>c</code> 는 <em>monotone</em> 이라 부릅니다. 다음은 모두 <em>monotone</em> 입니다.</p>

<ul>
<li><code>sum(S.price) &gt;= v</code></li>
<li><code>min(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &gt;= 15</code></li>
</ul>

<p><br/></p>

<h3 id="dataantimonotonicity">Data Anti-Monotonicity</h3>

<p><em>data anti-monotone</em> 는 <em>transaction</em> 기반으로 <em>pruning</em> 을 진행해 나아갑니다. 정의는 이렇습니다.</p>

<ul>
<li>In the mining process, if a data entry <code>t</code> cannot satisfy a pattern <code>p</code> under <code>c</code>, <code>t</code> cannot satisfy <code>p</code>'s superset either</li>
</ul>

<p>다음은 모두 <em>data anti-monotone</em> 입니다.</p>

<ul>
<li><code>sum(S.price) &gt;= v</code> </li>
<li><code>min(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &gt;= 25</code></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/data_anti_monotone.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="succinctconstaints">Succinct Constaints</h3>

<p><em>succintness</em> 는 <em>data space</em> 와 <em>pattern space</em> 를 모두 <em>pruning</em> 합니다.</p>

<blockquote>
  <p>if the constaint <code>c</code> can be enforced by directly manipulating the data</p>
</blockquote>

<p>(1) To find those patterns without item <code>i</code></p>

<p><em>pattern space pruning</em> 처럼 <code>i</code> 을 DB 에서 제거합니다.</p>

<p>(2) To find those patterns containing item <code>i</code></p>

<p><em>data space pruning</em> 처럼 <em>i-projected</em> DB 만 마이닝 합니다.</p>

<p>(3) <code>min(S.price) &lt;= v</code> is succinct</p>

<p><code>price &lt;= v</code> 에서 시작해서, <em>high-price item</em> 을 제거해 나가기 때문에 <em>pattern + data space pruning</em> 입니다.</p>

<p>(4) <code>sum(S.price) &gt;= v</code> is not succinct</p>

<p><em>itemset</em> <code>S</code> 의 <em>sum</em> 이 점점 크기때문에, 미리 제거할 수 없습니다.</p>

<p><br/></p>

<h3 id="convertibleconstaints">Convertible Constaints</h3>

<blockquote>
  <p>Convert tough constaints into (anti-) monotone by proper ordering of items in transactions</p>
</blockquote>

<p><code>avg(S.profit) &gt; 20</code> 같은 경우는 <em>anti-monotone</em> 도 <em>monotone</em> 도 아닙니다. </p>

<ul>
<li>만약 현재 만족한다고 했을때, 아주 작은 <code>profit*</code> 을 가지는 아이템을 추가하면 <em>violation</em> 이고,</li>
<li>만약 현재 위반한다고 했을때, 아주 큰 값을 추가하면 <em>satisfaction</em> 이기 때문입니다.</li>
</ul>

<p>이런 <em>constaint</em> 에 대해서도 <em>pruning advantage</em> 를 얻고자 하는것이 바로 <em>convertible constaints</em> 의 목적입니다. 가능하면 <em>anti-monotone</em> 이 더 선호되는데, 이는 <em>monotone</em> 일 경우 검사만 하지 않고, <em>anti-monotone</em> 일 경우 <em>super-pattern</em> 을 날려버릴 수 있기 때문입니다.</p>

<ul>
<li>만약 <code>c: avg(S.profit &gt; 20)</code> 에 대해서 </li>
<li><em>itemset</em> 을 내림차순으로 <code>S: {a, g, f, b, h, d, c, e}</code> 정렬하고 </li>
<li><code>avg(ab) = 20</code>, <code>g = 20</code> 이면</li>
</ul>

<p><em>constaint</em> <code>C</code> 는 <em>anti-monotone</em> 이라 할 수 있습니다. 왜냐하면 패턴 내부가 <code>profit</code> 을 기준으로 내림차순으로 되어서, 어떤 <em>item entry</em> 를 뽑아도 <code>c</code> 를 만족할 수 없기 때문입니다.</p>

<p>아쉽게도 이 방법은 <em>level-wise candidate generation</em> 을 하는 <em>Apriori</em> 알고리즘엔 적용되지 않습니다.</p>

<p><br/></p>

<h3 id="hanldingmultipleconstaints">Hanlding Multiple Constaints</h3>

<p>다수개의 <em>constaints</em> 를 사용하는것은 좋으나, <em>item ordering</em> 에서 충돌이 생길 수 있습니다. 이럴땐 먼저 하나의 <em>constaint</em> 기준으로 정렬하고, 나머지는 <em>projected databases</em> 를 마이닝할때 하면 좋습니다.</p>

<p>예를 들어 다음 두개의 <em>constaints</em> 가 있을때</p>

<ul>
<li><code>c1: avg(S.profit) &gt; 20</code></li>
<li><code>c2: avg(S.price) &lt; 50</code></li>
</ul>

<p><code>c1</code> 이 더 강력한 <em>pruning power</em> 가 있다고 생각하고, <code>c1</code> 먼저  <em>anti-monotone</em> 으로 변경 한 후, 각 <em>projected-DB</em> 에서 트랜잭션을 오름차순으로 정렬해 <code>c2</code> 를 마이닝에 이용합니다.    </p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='https://www.behance.net/gallery/625042/Icon-and-pattern-with-a-marketing-theme' >Title image</a> <br />
(2) <strong>Pattern Discovery</strong> by <em>Jiawei Han</em> </p>]]></description><link>http://1ambda.github.io/pattern-discovery-2/</link><guid isPermaLink="false">eae33e61-9556-4292-99f1-9b45d93ceb62</guid><category><![CDATA[coursera]]></category><category><![CDATA[pattern discovery]]></category><category><![CDATA[data mining]]></category><category><![CDATA[lift]]></category><category><![CDATA[pattern-fusion]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 20 Feb 2015 02:49:15 GMT</pubDate></item><item><title><![CDATA[Artificial Intelligence 2, Search]]></title><description><![CDATA[<p><img src='http://picm.yourswallpaper.com/other/box-robot_18407.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="agents">Agents</h3>

<p><em>agent</em> 가 <em>good decision</em> 을 내릴려면 <em>planning</em> 을 해야합니다. 그러기 위해선 어떤 <em>action</em> 이 좋을지 <em>search (탐색)</em> 해 보아야 하고 결국 풀어야 할 문제는 <em>search problem</em> 이 됩니다.</p>

<p>(1) <strong>reflex agent</strong></p>

<ul>
<li>Choose action based on current percept (and maybe memory)</li>
<li>May have memory or a model of the world's current state</li>
<li>Do not consider the future consequences of their action</li>
<li>Consider how the world <strong>IS</strong></li>
</ul>

<p>자신이 인지하는 <em>environment</em> 에 기반하여 어떤 <em>action</em> 을 취할지 결정하나, <em>action</em> 의 결과를 고려하지 않고 결정을 내리기에 문제가 생길 수 있습니다. <em>reflext agent</em> 가 <em>rational</em> 할 수 있을까요?</p>

<blockquote>
  <p>Of course. Rationality is a function of the actions you take, not the computation. So if you had a big enough, good enough lookup table, and you're taking the right actions. <strong>Rationality doesn't care what process led to them.</strong> Reflex is a comment on the thought process</p>
</blockquote>

<p>(2) <strong>planning agents</strong></p>

<p><em>planning agent</em> 는 <em>reflex agent</em> 와는 다르게 <strong>what if</strong> 를 질문합니다. 따라서</p>

<ul>
<li>Decisions based on (hypothesized) consequences of actions</li>
<li>Must have a model of how the world evolves in response to actinos</li>
<li>Must formulate a goal(test)</li>
<li>Consider how the world <strong>WOULD BE</strong></li>
</ul>

<p><em>planning agent</em> 는 <em>action</em> 을 선택할때 <em>real world</em> 에서 실제로 실행해보진 않습니다. 대신 <em>model</em> 을 이용해 <em>simulation</em> 을 해봅니다. 따라서 <em>planning agent</em> 에서는 <em>real world</em> 를 반드시 모델링 해야 합니다.</p>

<blockquote>
  <p>In order to have a planning agent, you must have <strong>a model of the world</strong></p>
</blockquote>

<p>그렇기 때문에 모델상에서 <em>goal</em> 인지 테스트 할 수 있는 방법도 필요합니다. </p>

<p><em>planning</em> 과 관련해서 <em>complete planning</em> 과 <em>optimal planning</em> 이 있습니다. <em>complete planning</em> 은 <em>solution</em> 을 찾아내고, <em>optimal planning</em> 은 <em>best solution</em> 을 찾아냅니다.</p>

<p>또한 <em>planning agent</em> 는 한번에 <em>plan</em> 을 세워 실행할 수도 있지만, 매 실행 후 다시 <em>re-planning</em> 할 수도 있습니다. </p>

<p><br/></p>

<h3 id="searchproblem">Search Problem</h3>

<p><em>search problem</em> 은 다음처럼 구성됩니다.</p>

<ul>
<li><strong>A state space:</strong> models how the world is</li>
<li><strong>A successor function (with actions, costs):</strong> models how it evolves in response to your actions</li>
<li><strong>A start state</strong> and <strong>a goal test</strong></li>
</ul>

<p>그리고 <em>solution</em> 은 <em>start state</em> 를 <em>goal state</em> 로 변환하는 <em>a sequence of actions (a plan)</em> 입니다.</p>

<p>다시 정리하자면, <em>state</em> 는 <em>world</em> 를 어떻게 모델링 하는지를 나타내고, <em>successor function</em> 은 <em>action</em> 에 <em>world</em> 가 어떻게 반응할지를 나타냅니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/searchprbs_are_models.jpg'  alt="" /></p>

<blockquote>
  <p>Search problems are just models</p>
</blockquote>

<p>실제로 현실세계를 그대로 시뮬레이션하기엔 복잡하기때문에, 이를 계산하기 위해 <em>rough</em> 한 모델이 필요합니다. 이 <em>model</em> 적절하다면 <em>search problem</em> 의 결과도 정확합니다.</p>

<p>모델을 너무 추상화 해서 만들면 (<em>abstract too much</em>) 문제를 풀 수 없고, 그 반대라면 현실세계의 복잡함을 모두 다뤄야 하기 때문에 계산이 어려울 수 있습니다. 따라서 적절한 정도의 <em>abstraction</em> 이 필요합니다.</p>

<p>예를 들어 모든 <em>dot</em> 을 먹는 팩맨 에이전트를 만든다고 할때, <em>state</em> 에 문제를 풀기에 필요 이상의 정보를 넣으면 <em>search space</em> 가 너무 커져 계산이 어렵고, 너무 추상화해서 문제를 풀기에 필요한 정보가 부족하면 <em>solution</em> 을 찾는다 해도 올바른 <em>solution</em> 이 아닐 수 있습니다.</p>

<p><br/></p>

<h3 id="searchstategraph">Search State Graph</h3>

<p><em>state space graph</em> 는 <em>search problem</em> 의 <em>mathematical representation</em> 입니다.</p>

<ul>
<li>Nodes are (abstracted) world configurations</li>
<li>Arcs represent successors (action results)</li>
<li>The goal test is a set of goal nodes (maybe only one)</li>
<li>In a search graph, each state occurs only once</li>
</ul>

<h3 id="searchstatetree">Search State Tree</h3>

<p><em>search tree</em> 는 <em>plan</em> 이 어떠할지를 나타내는 일종의 <em>what if tree</em> 입니다. </p>

<ul>
<li>The start state is the root node</li>
<li>Children correspond to successors</li>
<li>Nodes show states, but correspond to <strong>PLANS</strong> that achieve those states</li>
<li>For most problems, we can never actually build the whole tree</li>
</ul>

<p><em>general tree search</em> 알고리즘은</p>

<pre><code>function TREE-SEARCH(problem, strategy) returns a solution, or failure

  initialize the search tree using the initial state of problem

  loop do
    if there are no candidates for expansion 
      then return failure

    choose a leaf node for expansion according to strategy

    if the node contains a goal state
      then return the corresponding solution
      else expand the node and 
           add the resulting nodes to the search tree

  end
</code></pre>

<p>여기서 중요한 요소는 <em>fringe (현재 고려중인 nodes)</em>, <em>expansion</em>, <em>exploration strategy</em> 다. 특히 어떤 <em>fringe nodes</em> 를 선택할 것인가가 중요한 질문이 됩니다.</p>

<p>널리 알려진 방법으로 <em>Depth-First Serach</em>, <em>Breadth-First Search</em> 등이 있습니다. 이들 <em>search algorithm</em> 의 성능을 평가하기 위해 다음 요소를 고려할 수 있습니다. </p>

<ul>
<li><strong>complete:</strong> guaranteed to find a solution if one exists</li>
<li><strong>optimal:</strong> guaranteed to find the least cost path</li>
<li>time complexity</li>
<li>space complexity</li>
</ul>

<p>그리고 <em>DFS</em> 은 <em>branching factor</em> <code>b</code>, <em>depth</em> <code>m</code> 이라 했을때 </p>

<ul>
<li>At any given time during the search, the number of nodes on the fringe can be no larger than <code>b*m</code></li>
<li>The number of nodes expanded throughout the entire search can be as large as <code>b^m</code></li>
</ul>

<p><em>BFS</em> 알고리즘에서 <em>branching factor</em> <code>b</code>, <em>depth</em> <code>s</code> 라 했을때 </p>

<ul>
<li>At any given time during the search, the number of nodes on the fringe can be large as <code>b^s</code></li>
<li>The number of nodes expanded throughout the entire search can be as large as <code>b^s</code></li>
</ul>

<p>두 방법을 섞은 <em>iterative deepening</em> 이란 알고리즘도 있습니다. <em>limit 1</em> 까지는 <em>DFS</em> 를 돌려보고, 실패하면 <em>limit2</em> 까지 <em>DFS</em> 를 돌려보는 방식입니다. </p>

<p><em>Uniform Cost Search (UCS)</em> 란 것도 있는데 <em>priority queue</em> 를 이용해서 더 낮은 <em>cost</em> 부터 탐색하는 방식입니다. <em>UCS</em> 는 <em>complete</em>, <em>optimal search</em> 입니다. 단점으로는 </p>

<ul>
<li>Explores options in every direction</li>
<li>No information about goal location</li>
</ul>

<p><br/></p>

<p>지금까지 배운 <em>search algorithm</em> 은 모두 <em>uninformed search</em> 입니다. 간단히 정리하면</p>

<ul>
<li>search operates <strong>over models of the world</strong></li>
<li>the agent doesn't actually try all the plans out in the real world</li>
<li>planning in all <strong>"in simulation"</strong></li>
<li><strong>your search is only as good as your models</strong></li>
</ul>

<p>위에서 본 <em>search algorithm</em> 은 <em>fringe strategies</em> 만 다르고 모두 동일합니다. 개념상으로는 모든 <em>fringes</em> 는 <em>priority queue</em>  입니다. <em>DFS</em> 와 <em>BFS</em> 의 경우에는 각각 <em>stack</em>, <em>queue</em> 를 이용해서 <em>priority queue</em> 의 <em>log(n)</em> 오버헤드를 피할 수 있습니다.</p>

<p><br/></p>

<h3 id="informedsearch">Informed Search</h3>

<p>이번시간에는 <em>state</em> 의 정보를 이용하는 <em>informed search</em> 와 <em>graph search</em> 를 배웁니다. <em>informed search</em> 의 기본적인 아이디어는 <em>direction</em> 을 결정할때, <em>goal</em> 에 가까운 방향인지를 알 수 있는 정보를 이용하는 것입니다.</p>

<p>(1) <strong>informed search</strong></p>

<ul>
<li>heuristics</li>
<li>greedy search</li>
<li>A* search</li>
</ul>

<p>(2) <strong>Graph Search</strong></p>

<p><br/></p>

<h3 id="searchheuristics">Search Heuristics</h3>

<p><em>A heuristic is:</em></p>

<ul>
<li>A function that <strong>estimatees</strong> how close a state is to a goal</li>
<li>Designed for a particular search problem</li>
</ul>

<p>문제에 따라 <em>heuristics</em> 는 다릅니다. 루마니아 투어 문제의 경우 <em>직선거리</em> 가 될 수 있고, 팬케잌 문제(하노이탑) 의 경우 잘못 올려진 팬케잌의 수가 <em>heuristic function</em> 이 될 수 있습니다.</p>

<p>이런 <em>heuristics</em> 을 어떻게 알고리즘에 적용할까요? 하나는 <em>DFS</em> 처럼 같은 <em>sibling</em> 사이에서 더 낮은 <em>heuristics</em> 값을 가지는 <em>fringe</em> 를 선택하는 방법이 있습니다. 이걸 <em>greedy search</em> 라 부릅니다.</p>

<p>반면 <em>BFS</em> 처럼 같은 <em>heuristics</em> 값을 가지는 모든 <em>fringe</em> 를 탐색할 수도 있습니다. 이걸 <em>A* search</em> 라 부릅니다.</p>

<p><br/></p>

<h3 id="greedysearch">Greedy Search</h3>

<p><em>greedy search</em> 는 <em>heuristic</em> <em>(estimate of distance to nearest goal for each state)</em> 을 이용해서 <em>fringe</em> 를 선택하지만, <em>DFS</em> 처럼 <em>badly-guided</em> 될 수 있습니다. 항상 <em>optimal</em> 한 솔루션을 찾아주진 않는다는 이야기입니다.</p>

<p></br></p>

<h3 id="asearch">A* Search</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/ucs_plus_greedy.jpg'  alt="" /></p>

<p><em>A* Search</em> 는 <code>f(n) = g(n) + h(n)</code> 을 이용합니다. 즉, 지금까지 온 거리 <code>g(n)</code> 과 앞으로 남은 (예측) 거리 <code>h(n)</code> 을 더한 값을 이용해서 어떤 <em>fringe</em> 를 선택할지 결정합니다. </p>

<p><em>A*</em> 와 관련해서 생각해 볼 한가지는 <em>goal fringe</em> 를 <em>enqueue</em> 할 때가 아니라 <em>dequeue</em> 할때 <em>stop</em> 해야한다는 것 입니다. 이는 현재 <em>queue</em> 에 있는 것중 <em>goal</em> 까지 더 작은 <code>g(n)</code> 을 가진 <em>fringe</em> 가 존재할 수 있기 때문이죠.</p>

<p><em>A* search</em> 는 <em>admissible</em> 하면 <em>optimal</em> 입니다. 여기서 <em>admissible (optimistic)</em> 하다는 뜻은 <em>heuristics</em> 값 <code>h(n)</code>이 절대로 실제 <em>cost</em> <code>h*(n)</code> 보다 높지 않다는 뜻입니다. (always underestimate)</p>

<p><code>0 &lt;= h(n) &lt;= h*(n)</code></p>

<ul>
<li><strong>Inadmissible (pessimistic)</strong> heuristics <strong>break</strong> optimality by trapping good plans on the fringe</li>
<li><strong>Admissible (optimistic)</strong> heuristics slow down bad plans but never outweigh true costs</li>
</ul>

<p><br/></p>

<p><em>uniform-cost search</em> 와 <em>A* search</em> 를 기하학적으로 비교해보면, <em>UCS</em> 는 정원의 등고선을 그리며 <em>goal</em> 을 탐색하지만 <em>A*</em> 는 <em>goal</em> 쪽으로 기운 타원형태의 등고선이 만들어집니다.</p>

<p>정리하자면</p>

<ul>
<li><strong>DFS, BFS:</strong> uninformed search, don't consider cost</li>
<li><strong>UCS:</strong> uninformed search, only consider cost</li>
<li><strong>Greedy search:</strong> informed search, only consider heuristic</li>
<li><strong>A* search:</strong> informed search which uses both cost and heuristic</li>
</ul>

<p><br/></p>

<h3 id="admissibleheuristics">Admissible Heuristics</h3>

<p>어려운 <em>search problem</em> 을 최적으로 풀어내려면 <em>admissible heuristics</em> 를 만들어야 하는데, 이 <em>admissible heuristics</em> 은  본래 문제에서 <em>constaints</em> 가 조금 줄어들어 새로운 <em>action</em> 을 사용할 수 있는 <em>relaxed problem</em> 의 솔루션이 될 수 있습니다. </p>

<p>그리고 <em>inadmissible heuristic</em> 도 때로는 유용할 수 있습니다. <em>optimal solution</em> 이 꼭 필요하지 않다면요. </p>

<p>그러나 이번에는 <em>admissible heuristics</em> 을 만드는 연습을 해보겠습니다. <em>8 puzzle</em> 을 <em>search problem</em> 으로 해서요. 먼저 해야 할 질문은</p>

<ul>
<li>What are the states?</li>
<li>How many states?</li>
<li>What are actions?</li>
<li>How many successor from the start state?</li>
<li>What should the costs be?</li>
</ul>

<p>(1) 만약 <em>heuristic</em> 을 <em>number of tiles misplaced</em> 로 한다면, 이건 <em>admissible</em> 일까요? </p>

<p>당연히 <em>admissible heuristic</em> 입니다. 왜냐하면 어느 <em>action</em> 도 한번에 <code>1</code> 개 이상의 타일을 옮길 수 없으니까요. 그런데 이건 <em>relaxed problem heuristic</em> 입니다. 최대 <code>8</code> 번만에 문제를 풀려면 타일을 직접 정확한 위치에 붙여야 합니다. 부직포 붙이듯이요.</p>

<p>(2) 만약 타일을 직접 목적지로 한번에 움직이진 않지만, 다른 타일을 무시하고 움직일 수 있다면 어떨까요? 아까보단 <em>less relaxed</em> 하다고 생각해봅시다. 이 경우 <em>manhattan distance</em> 를 이용할 수 있습니다.   이것도 마찬가지로 <em>relaxed heuristic</em> 이지만 아까보단 좀 덜 루즈합니다. </p>

<p>아까보다는 <em>heuristic</em> <code>h</code> 값이 더 커졌으니까, 가장 정확한 <em>heuristic</em> (actual cost) 값은 이것보다는 적어도 크다고 생각할 수 있습니다. 일종의 <em>lower bound</em> 라고 보면 쉽습니다. </p>

<p>그리고 <em>heuristic</em> 이 더 정확해졌기 때문에, <em>expanded nodes</em> 수도 이전보다 훨씬 줄어들게 됩니다.</p>

<p>(3) <em>actual cost</em> 를 <em>heuristic</em> 으로 사용하면 어떨까요? 이 값은 당연히 <em>admissible</em> 합니다. <code>h(n) = h*(n)</code> 이니까요. 게다가 <em>expanded nodes</em> 수도 가장 적습니다. </p>

<p>다만 문제는, 가장 정확한 <em>heuristic</em> 이기 때문에 매 턴마다 이 값을 계산하기 위한 연산 비용이 비쌉니다. 이것이 <em>A*</em> 알고리즘이 가진 <em>trade-off</em> 입니다. <em>quality of estimate</em> 와 <em>work per node</em>  를 적절히 조절해서 <em>heuristic</em> 을 만들어야 합니다.</p>

<blockquote>
  <p>As heuristics get closer to the true cost, you will expand fewer nodes but usually do more work per node to compute the heuristic itself</p>
</blockquote>

<p>나침반을 보고 길을 찾을때, <em>loose heuristic</em> 은 좀 더 넓은 범위에서 맞다고 알려주어 이용하기 쉽다면, <em>actual cost</em> 의 경우에는 나침반이 제시하는 올바른 방향이 너무나 작기때문에 자세히 보고, 여러번봐야 하는것과 비슷합니다.</p>

<p>정리하자면 <em>heuristic</em> 이 <em>actual cost</em> 에 가깝다고 해서 반드시 좋은건 아닙니다. 연산시간을 고려하면 적정 수준의 <em>loose heuristic</em> 을 사용할 필요가 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/heuristic_dominance.jpg'  alt="" /></p>

<p>모든 <em>heuristic</em> 값이 더 크면 <em>dominance</em> 라고 말합니다. 다시 말해 더 정확한, <em>actual cost</em> 에 가깝다는 뜻입니다. 그리고 <em>admissible</em> 한 두 <em>heuristics</em> 에 대해 그 <em>max</em> 값도 당연히 <em>admissible</em> 합니다.</p>

<p><em>bottom lattice</em> 를 <em>zero heuristic</em>, <em>top</em> 을 <em>exact</em> 라 부릅니다. 만약 <em>zero heuristic</em> 을 이용하면 <em>uniform-cost search</em> 와 동일합니다.</p>

<h3 id="graphsearch">Graph Search</h3>

<p><em>tree search</em> 는 중복되는 부분에 대해 다시 탐색하므로 비효율적입니다. 이 부분을 개선하기 위해 <strong>모든 state 를 단 한번만</strong> <em>expand</em> 할 수 있습니다. <em>set of expanded states</em> 를 유지하고, <em>state</em> 를 탐색하기 전에 이미 <em>expanded</em> 되었는지 검사하면 됩니다.</p>

<p><em>graph search</em> 는 <em>completeness</em> 엔 문제가 없으나 <em>not-optimal</em> 일 수 있습니다. 아래 예제를 보면 <em>sub-optimal solution</em> 을 리턴합니다. <em>admissible heuristic</em> 임에도 불구하고요.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/a_star_graph_suboptimal.jpg'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/consistency.jpg'  alt="" /></p>

<p>이건 <em>consistency</em> 속성이 만족되지 않아서 그렇습니다. <em>goal</em> 까지의 <em>admissibility</em> 뿐만 아니라, 각 <em>arc</em> 마다도 <code>h &lt;= actual cost</code> 를 만족하면 <em>consistent</em> 하다고 말합니다. 만약 <em>heuristic</em> 이 <em>consistent</em> 하면 <em>f value</em> 가 절대로 줄지 않기 때문에 결과적으로 <em>graph search</em> 를 통한 결과도 <em>optimal</em> 이 됩니다.</p>

<ul>
<li><em>Fact 1:</em> In tree search, A* expands nodes in increasing total <em>f value</em> (<strong>f-contours</strong>)</li>
<li><em>Fact 2:</em> For every state <code>s</code>, nodes that reach <code>s</code> optimally are expanded before nodes that reach <code>s</code> suboptimally</li>
</ul>

<p><br/></p>

<h3 id="optimality">Optimality</h3>

<p>(1) Tree Search</p>

<ul>
<li>만약 <em>heuristic</em> 이 <em>admissible</em> 이면 A* 는 <em>optimal</em> 입니다</li>
<li><em>UCS</em> 는 <code>h = 0</code> 인 <em>special case</em> 입니다</li>
</ul>

<p>(2) Graph Search</p>

<ul>
<li>만약 <em>heuristic</em> 이 <em>consistent</em> 이면, A* 는 <em>optimal</em> 입니다.</li>
<li><em>UCS</em> 도 <code>h = 0</code> 이어서 <em>consistent heuristic</em> 이므로 <em>optimal</em></li>
</ul>

<blockquote>
  <p>Consistency implies admissibility</p>
</blockquote>

<p>일반적으로 대부분의 <em>natural admissible heuristic</em> 는 <em>consistent</em> 합니다. 특히 <em>relaxed problems</em> 에서 나왔다면 더더욱요</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <strong>Artificial Integelligence (CS 188)</strong> by <em>Dan Klein, Pieter Abbeel</em> <br />
(2) <a href='http://imgkid.com/cute-box-robot-tumblr.shtml' >Title Image</a>  </p>]]></description><link>http://1ambda.github.io/artificial-intelligence-2/</link><guid isPermaLink="false">82a14f90-2790-4df3-bef8-a080f0141d64</guid><category><![CDATA[edx]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[CS188]]></category><category><![CDATA[search]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 19 Feb 2015 06:59:46 GMT</pubDate></item><item><title><![CDATA[Artificial Intelligence 1, Intro]]></title><description><![CDATA[<p><img src='http://www.land-of-web.com/wp-content/uploads/2012/08/w30.jpg'  alt="" /></p>

<h3 id="ai"> AI</h3>

<p>사람처럼 행동하는것? 사람처럼 생각하는것? 무엇이 <em>AI</em> 일까?</p>

<blockquote>
  <p>Act Rationally</p>
</blockquote>

<p>여기서 <em>rational</em> 은</p>

<ul>
<li>Maximally achieving pre-defined goals</li>
<li>Rationality only concerns what decisions are made. not the thought process begind them</li>
<li>Goals are expressed in terms of the utility of outcomes</li>
</ul>

<p>따라서 <em>rational</em> 의 의미는 <strong>maximizing your expected utility</strong> </p>

<p><br/></p>

<h3 id="brain">Brain</h3>

<p>인간의 뇌는 <em>rational decision</em> 을 내리는데 상당히 뛰어나지만, 완벽하지는 않다. 이런 <em>brain</em> 를 모방해서 인공지능을 만들어보려 했지만 뇌는 <em>software</em> 만큼 <em>modular</em> 하지 않기 때문에 <em>reverse engineering</em> 해서 인공지능을 만들긴 어려웠다.</p>

<p>과학자들이 뇌를 분석하는 과정에서 얻은 <em>lessons learned</em> 는 <strong>memory</strong> 와 <strong>simuation</strong> 이 <em>decision making</em> 에서 아주 중요한 요소라는 것이다.</p>

<p><br/></p>

<h3 id="whatcanaido">What Can AI Do?</h3>

<p>(1) <strong>Language</strong></p>

<ul>
<li>Translation</li>
</ul>

<p>(2) <strong>Vision (Perception)</strong></p>

<ul>
<li>Object and face recognition</li>
<li>Scene segmentation</li>
<li>Image classification</li>
</ul>

<p>(3) <strong>Robotics</strong></p>

<ul>
<li>Vehicles</li>
<li>Rescure</li>
<li>Soccer!</li>
<li>Lots of automations</li>
</ul>

<p>(4) <strong>Logic</strong></p>

<ul>
<li>Theorem provers</li>
<li>NASA fault diagnosis</li>
<li>Question answering</li>
</ul>

<p>(5) <strong>Game Playing</strong></p>

<p>(6) <strong>Decision Making</strong></p>

<ul>
<li>Scheduling (e.g airline routing)</li>
<li>Route Planning (e.g Google maps)</li>
<li>Medical diagnosis</li>
<li>Web search engines</li>
<li>Spam classifiers</li>
<li>Automated help desks</li>
<li>Fraud dections</li>
<li>Productrecommendations</li>
<li>Lots more!</li>
</ul>

<p><br/></p>

<h3 id="designingrationalagents">Designing Rational Agents</h3>

<p>CS188 에서는 <em>rational agent</em> 를 디자인하는 방법을 배운다. <em>rational agent</em> 란 <em>행동(act)</em> 과 <em>인지 (perceive)</em> 를 할 수 있는 <em>개체 (entity)</em> 다. 즉, <em>환경 (environment)</em> 를 인식해서 그에 맞는 판단을 내린 후 행동하는 소프트웨어로 볼 수 있다. </p>

<ul>
<li>A <strong>rational agent</strong> selects actions that maximize its (expected) <strong>utility</strong></li>
<li>Characteristics of the <strong>percepts</strong>, <strong>environment</strong>, and <strong>action space</strong> dictate techniques for selecting rational actions</li>
</ul>

<p>이 수업에서 배우는 것은 어떤 <em>environment</em> 와 어떤 <em>percept</em> 를  가지고 있는지를 파악한 후, 이와 관련된 기존의 테크닉을 이용해서 <em>언제</em>, <em>어떻게</em> 문제를 풀 수 있는지를 배운다.</p>

<p><br/></p>

<h3 id="coursetopics">Course Topics</h3>

<p>Part 1: <strong>Making Decisions</strong></p>

<ul>
<li>Fast search / planning</li>
<li>Constraint satisfaction</li>
<li>Adversarial and uncertain search</li>
</ul>

<p>Part 2: <strong>Reasoning under Uncertainty</strong></p>

<ul>
<li>Bayer' nets</li>
<li>Decision theory</li>
<li>Machine learning</li>
</ul>

<p>Throughout: <strong>Applications</strong></p>

<ul>
<li>Natural language processing</li>
<li>Vision</li>
<li>Robotics</li>
<li>Games</li>
</ul>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <strong>Artificial Integelligence (CS 188)</strong> by <em>Dan Klein, Pieter Abbeel</em> <br />
(2) <a href='http://www.land-of-web.com/inspiration/photography/meet-the-danbo-cute-little-cardboard-robot-photos.html' >Title Image</a>  </p>]]></description><link>http://1ambda.github.io/artificial-intelligence-1/</link><guid isPermaLink="false">a5116bfa-3786-420b-860a-a78024e945aa</guid><category><![CDATA[edx]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[CS188]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 19 Feb 2015 04:51:28 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, MapReduce]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<h3 id="intro">Intro</h3>

<p><em>map</em> 과 <em>reduce</em> 라는 단어는 <em>functional language</em> 에서 왔다.</p>

<ul>
<li><em>map:</em> processes each record sequentially and independently</li>
<li><em>reduce:</em> processes set of all records in batches</li>
</ul>

<pre><code class="lisp">(map square '(1 2 3 4))
;; (1 4 9 16)

(reduce + '(1 4 9 16))
;; (+16 (+9 (+4 1)))
;; 30
</code></pre>

<p><br/></p>

<h3 id="mapreduce">MapReduce</h3>

<p><img src='http://webmapreduce.sourceforge.net/docs/User_Guide/images/map-reduce.png'  alt="" /></p>

<p align="center">(<a href='http://webmapreduce.sourceforge.net/' >http://webmapreduce.sourceforge.net/</a>)</p>

<blockquote>
  <p><em>Map:</em> <strong>Parallelly</strong> process <strong>a large number</strong> of individual records to generate intermediate key/value pairs
  <br/> <br />
  <em>Reduce:</em> processes and merges all intermediate values associated per key</p>
</blockquote>

<p>각 키는 하나의 <em>reducer</em> 에 할당되고, <em>partitioning keys</em> 에 의해 <em>reduce</em> 가 진행된다. 자주 쓰이는 기법으로 <em>hash partitioning</em> 이 있다. <code>hash(key) % # of reduce servers</code></p>

<pre><code class="java">public static class MapClass extends MapReduceBase  
            implements Mapper&lt;LongWriteable, Text, Text, IntWritable&gt; {

  private final static IntWritable one = new IntWritable(1);
  private Text word = new Text();

  public void map(LongWritable key, Text value, 
                  OutputCollector&lt;Text, IntWritable&gt; output,
                  Reporter reporter) throws IOException {

    String line = value.toString();
    StringTokenizer itr = new StringTokenizer(line);

    while (itr.hasMoreTokens()) {
      word.set(itr.nextToken());
      output.collect(word, one);
    }
  }
}

public static class ReduceClass extends MapReduceBase  
            implements Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {

  public void reduce(Text key, Iterator&lt;IntWritable&gt; values,
                     OutputCollector&lt;Text, IntWritable&gt; output,
                     Reporter reporter) throw IOException {

    int sum = 0;
    while (values.hasNext()) {
      sum += values.next().get();
    }

    output.collect(key, new IntWritable(sum));
  }                     
}

public void run(String inputPath, String outputPath) throw Exception {

  // The job
  JobConf conf = new JobConf(WordCount.class);
  conf.setJobName("mywordcount");

  // The keys are words
  (srings) conf.setOutputKeyClass(Text.class);

  // The values are counts (ints)
  conf.setOutputValueClass(IntWritable.class);
  conf.setMapperClass(MapClass.class);
  conf.setReducerClass(ReduceClass.class);

  FileInputFormat.addInputPat(conf, new Path(inputPath);
  FileOutputFormat.setOutputPath(conf, new Path(outputPath));

  JobClient.runJob(conf);
}
</code></pre>

<p><br/></p>

<h3 id="mapreduceapplication">MapReduce Application</h3>

<p>(1) <strong>Distributed Grep</strong> </p>

<ul>
<li><em>input:</em> large set of files</li>
<li><em>output:</em> lines that match pattern</li>
<li><em>map:</em> emits a line if it matches the supplied pattern</li>
<li><em>reduce:</em> copies the intermediate data to output</li>
</ul>

<p>(2) <strong>Reverse Web-Link Graph</strong></p>

<ul>
<li><em>input:</em> web graph(tuple <code>(a,b)</code> where page <code>a</code> -> page <code>b</code>)</li>
<li><em>output:</em> for each page, list of pages that link to it</li>
<li><em>map:</em> process we log and for each input <code>&lt;source, target&gt;</code>, it outputs <code>&lt;target, source&gt;</code></li>
<li><em>reduce:</em> emits <code>&lt;target, list(source)&gt;</code></li>
</ul>

<p>(3) <strong>Count of URL Access Frequency</strong></p>

<ul>
<li><em>input:</em> log of accessed URLs</li>
<li><p><em>output:</em> for each URL, the number of total accesses for that URL</p></li>
<li><p><em>map:</em> process web log and outputs <code>&lt;URL, 1&gt;</code></p></li>
<li><em>multiple reducers:</em> emits `<URL, URL_count></li>
<li><strong>chain another MapReduce job to calculate</strong> <code>overall_count</code></li>
</ul>

<p>(4) <em>Sort</em></p>

<ul>
<li><em>map</em> task's output is sorted (e.g., <em>quicksort</em>)</li>
<li><em>reduce</em> task's input is osrted (e.g., <em>mergesort</em>)</li>
</ul>

<p>따라서 정렬을 하기 위해</p>

<ul>
<li><em>map:</em> <code>&lt;key, value&gt;</code> -> <code>&lt;value, _&gt;</code> (identity)</li>
<li><em>reduce:</em> <code>&lt;key, value&gt;</code> -> <code>&lt;key, value&gt;</code> (identity)</li>
</ul>

<p>이 때 <em>parttition key</em> 로 <em>range</em> 를 사용하는 것이 가능하다. 다만, 특정 구간에 <em>data</em> 가 몰려있을 수 있으므로 <em>dstiribution</em> 을 고려해 <em>reducer</em> 에게 할당해주면 된다.</p>

<p><br/></p>

<h3 id="scheduling">Scheduling</h3>

<p>일반 <em>user</em> 는</p>

<ul>
<li>Write a Map program, write a Reduce program</li>
<li>Submit job; wait for result</li>
<li>Need to know nothing about parallel/distributed programming</li>
</ul>

<p>그러나 내부적으로는</p>

<ul>
<li>Parallelize Map</li>
<li>Transfer data from Map to Reduce</li>
<li>Parallelize Reduce</li>
<li>Implement Stroage for Map input, Map output, Reduce input, Reduce output</li>
</ul>

<p>그리고 <em>reduce</em> 가 시작되기 전에 반드시 <em>map</em> 이 끝나야 한다. 다시 말해서 <em>map phase</em> 와 <em>reduce phase</em> 사이에는 <em>barrier</em> 가 있어야 한다. 그렇지 않으면 결과가 부정확할 수 있다.</p>

<p>이제 하나하나씩 살펴보자.</p>

<p>(1) <em>Parallelize Map:</em> Easy. Each map task is independent of the other</p>

<p>(2) <em>Transfer data from Map to Reduce:</em> All map output records with same key assigned to same Reduce task. Use <strong>Partitionning Function</strong></p>

<p>(3) <em>Parallelize Reduce:</em> Easy. Each reduce task is independent of the other</p>

<p>(4) <em>Implement Storage for Map input, Map output, Reduce input and Reduce output:</em></p>

<ul>
<li>Map input: from <strong>distributed file system</strong></li>
<li>Map output: to local disk at Map node; Use <strong>local file systems</strong></li>
<li>Reduce input: from (multiple) remote disks; Uses local file systems</li>
<li>Reduce output: to <strong>distributed file system</strong></li>
</ul>

<p>DFS 의 예로 <em>Google File System</em>, <em>HDFS</em> 등이 있다.</p>

<p><br/></p>

<p>하둡은 스케쥴러로 <em>YARN, Yet Another Resouce Negotiator</em>를 사용한다. <em>YARN</em> 은 각 서버를 <em>a collection of containers</em> 로 취급한다. 여기서 <em>container = some CPU + some Memory</em> 다.</p>

<p><em>YARN</em> 은 크게 3파트로 나눌 수 있는데</p>

<ul>
<li><em>Global Resource Manager(RM):</em> scheduling</li>
<li><em>Per-server Node Manager(NM):</em> Daemon and server-specific functions</li>
<li><em>Per-application(job) Application Master(AM):</em> Container negotiation with RM and NMs, Detecting task failures of that job</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week1/YARN.jpg'  alt="" /></p>

<p><em>container</em> 가 필요하면 <em>AM1</em> 이 <em>RM</em> 에게 알리고, <em>Node B</em> 의 <em>NM2</em> 에서 <em>Task</em> 가 끝나면, <em>RM</em> 이 <em>Node A</em> 의 <em>AM1</em> 에게 사용 가능한 컨테이너가 있다는 사실을 알려 <em>AM1</em> 이 <em>NM2</em> 에게 컨테이너를 사용하겠다는 요청을 보내는 식이다.</p>

<p><br/></p>

<h3 id="faulttolerance">Fault-Tolerance</h3>

<p>(1) Server Failure</p>

<ul>
<li><em>NM</em> hearbeats to <em>RM</em>. If server fails <em>RM</em> lets all affected <em>AMs</em> know, and <em>AMs</em> take action</li>
<li><em>NM</em> keeps track of each task running at its server. If task fails while in-progress, mark the task as idle and restart it</li>
<li><em>AM</em> heartbeats to <em>RM</em>. On failure, <em>RM</em> restarts <em>AM</em>, which then syncs up with its running tasks</li>
</ul>

<p>(2) RM Failure</p>

<ul>
<li>Use old checkpoints and bring up secondary <em>RM</em></li>
<li>Heartbeats also used to piggyback container requests. Avoids extra mesages</li>
</ul>

<p>요약하자면, <em>NM</em>, <em>AM</em> 은 <em>RM</em> 에게 <em>heartbeat</em> 를 보낸다. <em>NM</em> 에서 오류가 나면 <em>RM</em> 이 영향을 받는 <em>AM</em> 에게 알리고, 해당 <em>AM</em> 이 적절히 처리한다. 또한 <em>NM</em> 은 <em>task</em> 를 유지하면서, <em>task</em> 에러가 발생하면 재시작한다. <em>AM</em> 에서 오류가 나면 <em>RM</em> 이 재시작하고, 해당 <em>AM</em> 의 태스크와 싱크를 맞춘다. <em>RM</em> 에서 오류가 날 경우엔 <em>secondary RM</em> 을 이용한다.</p>

<h3 id="stragglers">Stragglers</h3>

<p><em>slow nodes</em> 를 부르는 다른말이다. <em>speculative execution</em> 으로 해결할 수 있다. 보통 느린 이유는 <em>disk</em>, <em>network bandwidth</em>, <em>CPU</em>, <em>memory</em> 등 때문인데 <em>task</em> 를 복제해서 다른 <em>node</em> 에서 돌린 뒤 먼저 완료되는 노드의 결과를 이용하는 방식이다.</p>

<blockquote>
  <p>Perform backup (replicated) execution of straggler task: task considered done when first replica completed</p>
</blockquote>

<h3 id="locality">Locality</h3>

<p><em>cloud</em> 의 <em>hierarchical topology</em> 때문에 <em>GFS</em>, <em>HDFS</em> 등은 각 <em>chunk</em> 를 3군데에 복제한다. 이때 같은 <em>rack</em> 에 위치할수도 아닐수도 있다.</p>

<p><em>MapReduce</em> 연산에서는 <em>map task</em> 를 스케쥴링할때 가능하면 다음의 순서로 배치한다.</p>

<p>(1) <em>chunk</em> 가 있는 머신에 or failing that <br />
(2) 아니면 같은 <em>rack</em> 에 or failing that <br />
(3) Anywhere  </p>

<p><br/></p>

<h3 id="summary">Summary</h3>

<p>(1) MapReduce uses parallelization + aggregation to schedule applications across clusters.</p>

<p>(2) Need to deal with failure</p>

<p>(3) Plenty of ongoing research work in scheduling and fault-tolerance for Mapreduce and Hadoop</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera <br />
(3) <a href='http://webmapreduce.sourceforge.net/docs/User_Guide/sect-User_Guide-Introduction-What_is_Map_Reduce.html' >MapReduce Image</a>  </p>]]></description><link>http://1ambda.github.io/cloud-computing-1-1/</link><guid isPermaLink="false">663ff3ef-8d2f-4c15-8897-90acbda32548</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[MapReduce]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 13 Feb 2015 12:34:11 GMT</pubDate></item><item><title><![CDATA[Coding The Matrix 1, Function, Field and Vector]]></title><description><![CDATA[<p><img src='http://th06.deviantart.net/fs71/PRE/i/2012/348/f/a/3d_cube_by_colorsark-d5nztba.jpg'  alt="" /></p>

<h3 id="thefunction">The Function</h3>

<blockquote>
  <p><strong>Function Invertibility Theorem:</strong> A function <code>f</code> is invertible if and only if it is <strong>one-to-one</strong> and <strong>onto</strong></p>
</blockquote>

<p><br/></p>

<h3 id="thefield">The Field</h3>

<pre><code class="pyhon">In [6]: 1+3j + (10+20j)  
Out[6]: (11+23j)

In [7]: x = 1+3j

In [8]: (x-1)**2  
Out[8]: (-9+0j)

In [9]: x.real  
Out[9]: 1.0

In [10]: x.imag  
Out[10]: 3.0

In [11]: type(1+2j)  
Out[11]: complex  
</code></pre>

<blockquote>
  <p>Such a collection of "numbers" with <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code> is called a <strong>field</strong>. Different fields are like different classes obeying the same interface</p>
</blockquote>

<p><em>field</em> <code>C</code> 는 <em>complex numbers</em> 다. 이걸 공부해야 하는 이유는</p>

<ul>
<li><code>C</code> is similar enough to <code>R</code> to be familiar but different enough to illustrate the idea of a filed</li>
<li>Complex numbers are intellectual ancestors of vectors</li>
<li>In more advanced parts of linear algebra, complex numbers play an important role</li>
</ul>

<p><br/></p>

<h3 id="playingwithc">Playing with C</h3>

<p><em>complex numbers</em> <code>C</code> 상에서는 한 축이 <em>real number</em>, 다른 축이 <em>imagenary number</em> (<em>python</em> 에선 <code>j</code> 로 표시) 다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/c_function_composition.jpg'  alt="" /></p>

<p>이 때 <em>translation</em> <code>f = z + z0</code> 를 <em>arrow</em> 처럼 볼 수 있다. <code>z0</code> 에서 시작해서 <code>z + z0</code> 를 향하는 화살표로</p>

<p>따라서 <code>f1(z) = z + z1</code>, <code>f2(z) = z + z2</code> 가 있을때 <em>function composition</em> <code>(f1 * f2)(z)</code> 는, <em>adding arrow</em> 처럼 생각할 수 있다.</p>

<p><a href='http://resources.codingthematrix.com/' >http://resources.codingthematrix.com/</a> 여기서 준비물을 구하고 아래 코드를 실행해 보자.</p>

<pre><code>In [1]: from plotting import plot

In [2]: L = [2+2j, 3+2j, 1.75+1j, 2+1j, 2.25+1j, 2.5+1j, 2.75+1j, 3+1j, 3.25+1j]

In [3]: plot(L)

In [4]: plot({z/2 for z in L})  
</code></pre>

<p>벡터와 비슷하게 스케일링은 양수를 곱하면 된다. <em>arrow</em> 를 뒤집고 싶으면 <code>-1</code> 을 곱하면 되고, </p>

<p>반시계방향으로 90도 <em>rotation</em> 을 원하면 <code>f(z) = iz</code> <em>translation</em> 을 사용하면 된다. <code>x+yi</code> 가 <code>-y+xi</code> 가 된다.</p>

<p><em>complex number</em> 에서는 <code>z</code> 와 <code>1 + 0i</code> 의 각도를 <em>argument</em> 라 부르는데, 이를 구하기 위한 공식을 오일러가 만들어 두었다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/argument_def.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/euler_argument.jpg'  alt="" /></p>

<p>어느 <em>real number</em> <code>θ</code> 에 대해서, <code>e^(θi)</code> 가 단위 원 위의 <em>argument</em> <code>θ</code> 를 가진 점 <code>z</code> 가 된다.</p>

<p>따라서 <code>θ = π</code> 일때, <code>e^(πi) = -1</code> 이다.</p>

<pre><code class="python">In [1]: from plotting import plot  
In [2]: from math import e, pi  
In [3]: plot([e**(t*2*pi*1j/20) for t in range(20)])  
</code></pre>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/rotation.jpg'  alt="" /></p>

<p>따라서 기존 <code>z</code> 값에 원하는 라디안 값 <code>k</code> 만큼 <code>e^(ki)</code> 를 곱해주면 <em>exponentiation law</em> 에 의해서, 그만큼 회전한다.</p>

<pre><code class="python">In [11]: plot([e**(pi*1j/4) * z for z in L])  
</code></pre>

<p><br/></p>

<h3 id="playingwithgf2">Playing with GF(2)</h3>

<p><em>Galois Field 2</em> has just two elements <code>0</code> and <code>1</code></p>

<p><em>GF(2)</em> 에서는 특이하게도 <em>addition</em> 이 <em>XOR</em> 과 같다. <em>multiplication</em> 나 <em>usual algebraic laws</em> (e.g multiplication distribution) 는 기존과 동일하다.</p>

<pre><code class="python">In [1]: from GF2 import one

In [2]: def encrypt(p, k): return p+k

In [3]: k = one

In [4]: p = one

In [5]: c = en  
%env       encrypt    enumerate

In [5]: c = encrypt(p, k)

In [6]: c  
Out[6]: 0  
</code></pre>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/encryption.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/encryption2.jpg'  alt="" /></p>

<p>더 자세히는, <code>p</code> 를 어떻게 선택하는지는 <code>c</code> 의 <em>probability distribution</em> 에 영향을 주지 않기때문에 <em>Eve</em> 가 <code>c</code> 를 관찰한다 할지라도 <code>p</code> 에 대해 정보를 얻을 수 없다.</p>

<p>왜 이 <em>cryptosystem</em> 이 <em>perfect secrecy</em> 를 만드는걸까? </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/perfect_secrecy1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/perfect_secrecy2.jpg'  alt="" /></p>

<p><code>p = 0</code> 에 대해 <code>k</code> 를 받아 <code>c</code> 를 돌려주는 함수를 <code>f0</code> 이라 하면, <code>f0</code> 은 <em>one-to-one,  onto function</em> 이다. 따라서 <code>k</code> 를 선택하는 확률이 균일하다면 <code>c</code> 의 확률도 <em>uniformly distribution</em> 이다. <code>f1</code> 도 마찬가지다.</p>

<p>이 아이디어가 <em>one-time pad</em> 라는 <em>cryptosystem</em> 의 근간이다.</p>

<blockquote>
  <p>If each bit is encrypted with its own one-bit key, the cryptosystem is <strong>unbreakable</strong></p>
</blockquote>

<p><br/></p>

<p><em>GF(2)</em> 를 <em>network coding</em> 에도 사용할 수 있다. 커스터머 <code>c</code>, <code>d</code> 에게 동시에 <em>video streaming</em> 을 하면 중간지점에서 병목이 발생할 수 있는데 <code>b1 + b2</code> 를 더해 나중에 <code>c</code> 와 <code>d</code> 에서 <em>substraction</em> 을 이용해 원래 비트를 구하면 된다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/network_coding.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="vector">Vector</h3>

<p><em>quaternions</em> (4원수) 에 관한 이야기부터 시작한다.</p>

<blockquote>
  <p>해밀턴은 복소수가 2차원 평면상의 점으로 표현될 수 있다는 사실로부터, 3차원 공간에서 점을 표현하는 같은 방법을 찾으려 하였다. 3차원 공간에서의 정점은 3개의 수로 이루어지며, 해밀턴은 그 3개의 수들을 어떻게 더하고 곱할 수 있는지에 관해 생각해왔다. 그러나 그는 두개의 정점간의 나누기를 어떻게 정의할지 알지 못했고, 난관에 부딪히고 말았다.</p>
  
  <p>1843년 10월 16일, 해밀턴은 그의 아내와 더블린의 로열 운하(영어: Royal Canal, 아일랜드어: An Chanáil Ríoga)을 걷고 있었다. 브로엄 다리(Brougham Bridge, 현재는 브룸 다리 Broom Bridge)를 걷고 있을 때, 나누기에 관한 해답이 그의 뇌리를 스쳤다. 그는 3개의 요소(Triples)를 나누지는 못하지만, 4개의 요소(quadruples)를 나눌 수 있다는 걸 생각했다. 4개의 요소 중, 3요소를 이용해 3차원 공간의 정점을 표현 할 수 있다. 해밀턴은 3차원 공간상의 정점에 대한 그의 새로운 수체계를 표현할 수 있었다. 그는 이 수체계의 기본 규칙을 다리에 새겨놓았다.</p>
  
  <p><code>i^2 = j^2 = k^2 = ijk = -1</code></p>
  
  <p>해밀턴은 위의 기본적인 규칙을 적용한 4개의 요소를 "사원수"라고 명명했다. 그 후 그는 사원수를 연구하고 알리는데 그의 남은 여생을 바쳤다. 그는 "사원수론자"(Quaternionists)라는 학파를 창시하고, 몇권의 책을 출판하여 사원수를 전파시켰다. 그의 마지막 책 《사원수 원론》(Elements of Quaternions)는 800여 쪽으로 구성되어 있고, 해밀턴 사망 직후에 출판되었다.</p>
  
  <p>해밀턴의 죽음 이후, 그의 제자인 피터 거스리 테이트는 사원수의 연구를 계속하였다. 당시 더블린에서는 사원수가 의무적인 시험의 하나였다. 현재는 공간 운동학, 맥스월 방정식 등의 벡터를 이용하여 설명하는 물리와 기하학의 논제들은 그 당시에는 모두 사원수를 이용하여 설명되었다. 또한 사원수에 관한 전문적인 연구학회인 사원수 학회(영어: The Quaternion Society)도 존재하였다.</p>
  
  <p>1880년대 중반부터 조사이어 윌러드 기브스와 올리버 헤비사이드가 제안한 벡터 해석학이 사원수 표현을 대신하기 시작했다. 벡터는 사원수와 같은 현상을 설명하였기 때문에, 고전 사원수 연구에서 많은 아이디어와 용어 등을 빌려왔다. 그러나 벡터 해석이 보다 간결한 개념과 표기법을 가지고 있었기에 사원수는 수학과 물리에서 비주류가 되었다. 이는 해밀턴의 사원수가 이해하기 난해하고, 표기가 친숙하지 않았으며, 그의 저작물에 길고 불분명한 표현이 많았기 때문이다.</p>
  
  <p>그러나 사원수는 20세기 말에 공간상에서의 회전에 관한 사원수의 유용성에 의해서 다시 주목받기 시작했다. 사원수를 이용한 회전의 표현은 행렬을 사용하는 표현에 비해 더욱 간결했고 계산이 빨랐다. 이런 이유로, 사원수는 컴퓨터 그래픽, 제어이론, 신호처리, 자세제어(attitue control), 물리학, 생물정보학, 분자동역학, 컴퓨터 시뮬레이션, 궤도역학(orbital mechanics)등에 사용되고 있다. </p>
</blockquote>

<p></br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/vectors_are_functions.jpg'  alt="" /></p>

<p><em>vector</em> 를 정의역(<em>domain</em>) 에서 치역(<em>image</em>) 로 대응되는 일종의 <em>function</em> 이라 볼 수 있다. <em>python</em> 에서는 <em>dictionary</em> 로 쉽게 나타낼 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/sparsity.jpg'  alt="" /></p>

<p><em>vector</em> 에서 <code>0</code> 이 많으면 <em>sparse vector</em> 라 부르고, <code>k</code> 개 만큼만 <code>0</code> 이 아닌 원소가 있으면 <em>k-sparse</em> 라 부른다. <em>vector</em> 의 몇번째 원소가 <code>0</code>이 아닌지를 나타내야되기 때문에 <em>k-sparse vector</em> 는 <em>k proportional space</em>  가 필요하다. </p>

<p><em>physical sensors</em> 로 얻어지는 <em>signal</em> 은 대부분 <em>sparse vector</em> 가 아니기 때문에 공간을 아끼기 위해, <em>signal</em> 을 <em>lossy compression</em> 으로 압축해서 보내는 법을 강의 후반부에서 배울 것이다.</p>

<p><br/></p>

<h3 id="additionmultiplication">Addition, Multiplication</h3>

<pre><code class="python">In [1]: from plotting import plot  
In [2]: v = [3, 2]  
In [3]: def scalar_vector_mult(alpha, v): return [alpha * x for x in v]  
In [4]: plot([scalar_vector_mult(i/10, v) for i in range(11)])  
</code></pre>

<p><img src='http://latex.codecogs.com/gif.latex?%5Calpha%5B3%2C%202%5D%20&plus;%20%5B0.5%2C%201%5D%20%5C%5C%20%3D%20%5Calpha%28%5B3.5%2C%203%5D%20-%20%5B0.5%2C%201%5D%29%20&plus;%20%5B0.5%2C%201%5D%20%5C%5C%20%3D%20%5Calpha%5B3.5%2C%203%5D%20-%20%5Calpha%5B0.5%2C%201%5D%20&plus;%20%5B0.5%2C%201%5D%20%5C%5C%20%3D%20%5Calpha%5B3.5%2C%203%5D%20-%20%281%20-%20%5Calpha%29%5B0.5%2C%201%5D%20%5C%5C%20%3D%20%5Calpha%5B3.5%2C%203%5D%20-%20%5Cbeta%5B0.5%2C%201%5D%20%5C%5C%20%5C%5C%20%28where%5C%20%5Calpha%2C%20%5Cbeta%20%3E%200%2C%20%5C%20%5Calpha%20&plus;%20%5Cbeta%20%3D%201%29'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/convex_comb.jpg'  alt="" /></p>

<p><em>arbitrary line segment</em> 를 <em>addition</em>, <em>multiplication</em> 을 이용해 <code>a[3, 2] + [0.5, 1]</code> 처럼 표현할 수 있는데, 여기서 식을 좀 더 변형해 <em>convex combination</em> 을 만들 수 있다. 이걸 이용하면 <code>u, v</code> 의 비중이 얼마냐에 따라 <em>output</em> 이 어떻게 달라지는지를 쉽게 표현할 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/convex_comb_ex.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/affine_comb.jpg'  alt="" /></p>

<p><code>[0.5, 1]</code> 부터 <code>[3.5, 3]</code> 까지 <em>infinite line</em> 을 표현하기 위해 <em>affine combination</em> 을 이용할 수 있다. 더 자세한 내용은 <a href='http://en.wikipedia.org/wiki/Linear_combination' >Wiki: line combination</a> 을 참고하자</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/line_comb.jpg'  alt="" /></p>

<p></br></p>

<h3 id="dictionarybasedrepresentation">Dictionary-based Representation</h3>

<p>앞서 언급했듯이 <em>vector</em> 는 <em>domain</em> <code>D</code> 로 부터 어떤 <em>field</em> 로 <em>mapping</em> 하는 <em>function</em> 이다. 파이썬에서는 이런 <em>function</em> 을 <em>dictionary</em> 로 표현할 수 있다.</p>

<pre><code class="python">class Vec:  
    def __init__(self, domain, function):
        self.D = domain
        self.f = function


def zero_vec(D):  
    return Vec(D, {d: 0 for d in D})


def setItem(v, d, val):  
    v.f[d] = val


def getItem(v, d):  
    return v.f[d] if d in v.f else 0


def list2vec(L):  
    return Vec(set(range(len(L))), {k:v for k, v in enumerate(L)})

# vec test
v = Vec({'A', 'B', 'C'}, {'A': 1})  
for d in v.D:  
    if d in v.f:
        print(v.F[d])

# zero_vec test
D = {'A', 'B', 'C'}  
v = zero_vec(D)  
for d in v.D:  
    print v.f[d]

# list2vec test
L = [1, 2, 3, 4]  
V = list2vec(L)

for d in V.D:  
    print(d)
    print(V.f[d])
</code></pre>

<p><br/></p>

<h3 id="vectorsovergf2">Vectors over GF(2)</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/GF2_perfect_secrecy.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/all_or_nothing_secret.jpg'  alt="" /></p>

<p>두명에게 나누어 <code>v</code> 를 전송하기 위해 <em>uniform distribution</em> 으로 <code>vA</code> 를 얻어 <code>vB = v - vA</code> 를 만든 뒤 각 한명씩에게 <code>vA</code>, <code>vB</code> 를 전송하는 것이다.</p>

<p><code>vA</code> 는 랜덤 <em>n-vector</em> 고 <code>vB</code> 는 <code>f(x) = v - x</code> 의 <em>output</em> 인데, 이 함수의 <em>input</em> 이 랜덤하게 골라졌으므로 이것만으로는 어떤것도 얻을 수 없다.</p>

<p><img src='http://cdn.phys.org/newman/gfx/news/2012/jhygjfvjgv.jpg'  alt="" /></p>

<p><em>RSA</em> 가 이 테크닉을 사용한다고 한다.</p>

<ul>
<li>Split each password into two parts</li>
<li>Store the two parts on two separate servers</li>
</ul>

<p><br/></p>

<h3 id="dotproduct">Dot-Product</h3>

<p><em>inner product</em> (내적) 이라 부른다. <em>scalar</em> 값을 돌려주고 두 벡터가 이루는 각을 알 수 있다. 외적과 내적에 관한 자세한 내용은 <a href='http://mrw0119.tistory.com/12' >프로그래밍에 미치다 - 외적, 내적 분해</a> 를 참고하자.</p>

<p>내적은 <em>linear equation</em> 에 사용할 수 있다.</p>

<pre><code class="python">D = {"radio", "sensor", "CPU", "memory"}  
duration = {"radio": 0.1, "sensor": 0.5, "CPU": 1, "memory": 0.5} # second  
rate = {"radio": 500, "sensor": 20, "CPU": 1000, "memory": 200} # mA

duration * rate  
</code></pre>

<p><em>linear equation</em> 과 관련해서 중요한 질문들을 던져보자.</p>

<ul>
<li>Is there an algorithm for solving a system of linear equations?</li>
<li>How can we know whether there is only one solution</li>
<li>What if our data are slightly inaccurate</li>
</ul>

<p>이후의 강의들에서 위에서 던진 질문들을 해결할 것이다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/dot_product_measuring_similarity.jpg'  alt="" /></p>

<p>두 음성이 비슷한지 <em>dot-product</em> 로 비교할 수 있다. 매 부분마다 음성이 비슷한지 비교해야 하므로 연산이 느릴 수 있지만 <em>Fast Fourier Transform</em> 을 이용하면 계산을 빠르게 수행할 수 있다.</p>

<p><br/></p>

<h3 id="dotproductovergf2">Dot-Product over GF(2)</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/dot_product_auth.jpg'  alt="" /></p>

<p>몇번의 질문을 컴퓨터가 던지는것과 비슷하게 <em>n-vector password</em> <code>x</code> 에 대해 컴퓨터가 <em>random n-vector</em> <code>a</code> 를 보내고, 사람이 <em>dot-product</em> 값 <code>a * x = b</code>  를 보낸다.</p>

<p><em>eavesdropper</em> 가 <code>a1, ..., an</code> <code>b1, ..., bn</code> 값을 도청한다면 패스워드를 알기 위해선 다음의 질문을 반드시 해결해야 한다</p>

<ul>
<li><strong>How many solutions for that linear equation?</strong></li>
<li><strong>How to compute them?</strong></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/attacking_simple_auth.jpg'  alt="" /></p>

<p>만약 <em>Eve</em> 가 <code>01011</code> 과 <code>11110</code> 을 관찰했다면 <code>01011 + 11110</code> 에 대해서는   그림에서 보듯이 해킹이 가능하다. 따라서 추가적으로 던져야 할 질문은</p>

<ul>
<li><strong>If a vector satisfies the equations, then what other equations does the vector satisfy?</strong></li>
</ul>

<p><br/></p>

<h3 id="triangularsystem">Triangular System</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/triangular_system.jpg'  alt="" /></p>

<ul>
<li>If <code>rowlist[i][i]</code> is zero procedure will raise <code>ZeroDivisionError</code></li>
<li>If this never happens, solution found is the only solution to the system</li>
</ul>

<p>위의 코드는 <code>D = {0, 1, ..., n-1}</code> <em>domain</em> 에 대해서만 작동하기 때문에 다른 도메인에서 돌아갈 수 있도록 코드를 수정하면</p>

<pre><code class="python">def trianuglar_solve(rowlist, domain, b):  
    x = zero_vec(set(label_list))

    for r in reversed(range(len(rowlist))):
        c = label_list[r]
        x[c] = (b[r] - x * rowlist[r]) / rowlist[r][c]

    return x
</code></pre>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://colorsark.deviantart.com/art/3D-Cube-342632998' >Title image</a> <br />
(2) <strong>Coding the Matrix</strong> by <em>Philip Klein</em> <br />
(3) <a href='http://ko.wikipedia.org/wiki/%EC%82%AC%EC%9B%90%EC%88%98' >Wiki: 4원수</a> <br />
(4) <a href='http://wiki.mathnt.net/index.php?title=%ED%95%B4%EB%B0%80%ED%84%B4%EC%9D%98_%EC%82%AC%EC%9B%90%EC%88%98' (quarternions)">Math Wiki: 4원수</a> <br />
(5) <a href='http://en.wikipedia.org/wiki/Linear_combination' >Wiki: line combination</a> <br />
(6) <a href='http://mrw0119.tistory.com/12' >프로그래밍에 미치다 - 외적, 내적 분해</a>  </p>]]></description><link>http://1ambda.github.io/coding-the-matrix-1/</link><guid isPermaLink="false">46c525c5-23be-4306-9722-8ec9f3f90112</guid><category><![CDATA[coursera]]></category><category><![CDATA[linear algebra]]></category><category><![CDATA[vector]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 12 Feb 2015 11:00:01 GMT</pubDate></item><item><title><![CDATA[Pattern Discovery 1]]></title><description><![CDATA[<p><img src='https://m1.behance.net/rendition/modules/7116731/disp/d18c13cd5b49bf40b41e6ef0610b26d3.png'  alt="" /></p>

<p><strong>Patterns represent intrinsic and important properties of datasets</strong>. Pattern discovery is uncovering patterns (inherent regularities) from massive data sets </p>

<ul>
<li>What products were often purchased together?</li>
<li>What are the subsequent purchases after buying an iPad?</li>
</ul>

<p><br/></p>

<h3 id="supportconfidence">Support, Confidence</h3>

<pre><code>;; item bought

Beer, Nut, Diaper  
Beer, Coffee, Diaper  
Beer, Diaper, Eggs  
Nuts, Eggs, Milk  
Nuts, Coffee, Diaper, Eggs, Milk  
</code></pre>

<p><em>support</em> <code>s</code> 는 전체 구매 중에서, 해당 아이템이 구매되었을 확률이다. <em>min support</em> 를 50% 로 한다면, </p>

<ul>
<li><em>freq 1-itemset:</em> Beer(60%), Nuts(60%), Diaper(80%), Eggs(60%)</li>
<li><em>freq 2-itemset:</em> {Beer, Diaper} (60%)</li>
</ul>

<p><em>confidence</em> <code>c</code> 는 <code>X</code> 가 포함되어있을때 <code>Y</code> 까지 구매되었을 조건부 확률이다. <code>c = sup(X ∪ Y) / sup(X)</code></p>

<p><em>association rule</em> 은, <em>min support</em> 와 <em>min confidence</em> 를 정해놓고, 그 이상이 되는 <em>rule</em> <code>X -&gt; Y</code> 를 찾는 것이다.</p>

<ul>
<li><code>Beer -&gt; Diaper</code> (s:60%, c:100%)</li>
<li><code>Diaper -&gt; Beer</code> (s:60%, c:75%)</li>
</ul>

<p><br/></p>

<h3 id="closedpatterns">Closed Patterns</h3>

<p>이렇게 패턴을 구하면, 다수개의 물품이 있는 <em>transaction</em> 에서는 너무 많은 패턴이 생긴다.</p>

<pre><code>;; TDB1 

T1: {a1, ..., a50}  
T2: {a1, ..., a100}  
</code></pre>

<p><em>min supoort</em> 를 <code>1</code> 이라 하면 <em>1-itemset</em>, <em>2-itemset</em>, .. <em>100-itemset</em> 처럼 <code>2^100 - 1</code> 개의 <em>sub pattern</em> 이 생긴다.</p>

<p>이 문제를 해결하기 위해 <em>lossless compression</em> 인 <em>closed pattern</em> 이란 개념을 도입해 보자.</p>

<blockquote>
  <p><strong>closed pattern:</strong> A pattern(itemset) <code>X</code> is <strong>closed</strong> if <code>X</code> is frequent, and there exists no super pattern <code>Y ⊃ X</code>, with the same support as <code>X</code></p>
</blockquote>

<p>위와 똑같은 <code>TDB</code> 에 대해 <em>closed pattern</em> 을 구하면</p>

<p><code>P1: "{a1, ..., a50}: 2" , P2: "{a1, ..., a100}: 1"</code></p>

<p><br/></p>

<p><em>closed pattern</em> 대신 <em>max pattern</em> 을 이용할 수 있다.</p>

<blockquote>
  <p><strong>max pattern:</strong> A pattern <code>X</code> is a <strong>max-pattern</strong> if <code>X</code> is frequent and there exists no frequent super-pattern <code>Y ⊃ X</code></p>
</blockquote>

<p>정의를 보면 <em>support</em> 값을 신경쓰지 않는다. 위와 같은 <code>TDB</code> 에 대해 <em>max-pattern</em> 을 찾으면</p>

<p><code>P: "{a1, ..., a100}: 1</code></p>

<p>당연히 <em>lossy compression</em> 이다. </p>

<p><br/></p>

<h3 id="downardclosureproperty">Downard Closure Property</h3>

<p><em>Apriori property</em> 라 부르기도 하는데, 핵심은 이렇다.</p>

<p><code>{beer, diaper, nuts}</code> 가 <em>frequent</em> 하면 <em>subitem</em> 인 <code>{beer diaper}</code> 는 적어도 그 만큼은 <em>frequent</em> 해야한다는 것이다.</p>

<blockquote>
  <p><em>Apriori:</em> Any subset of a frequent itemset must be frequent</p>
</blockquote>

<p>따라서 <code>S</code> 의 어떤 <em>subset</em> 도 <em>infrequent</em> 하면 <code>S</code> 가 <em>frequent</em> 할 일이 없으므로, 가지치기 할 수 있다는 것이다.</p>

<blockquote>
  <p><em>Apriori pruning principle:</em> if there is any itemset which is infreqent, its superset should not even be generated</p>
</blockquote>

<p><br/></p>

<h3 id="theapriorialgorithm">The Apriori Algorithm</h3>

<p><em>level-wise</em>, <em>candidate generation and test</em></p>

<pre><code>initially, scan DB once to get frequent 1-itemset

repeat  
  generate length-(k+1) candidate itemsets from length-k frequent itemsets
  test the candidates against DB to find frequent (k+1) itemset
  Set k := k + 1

until no frequent or candidate set can be generated  
</code></pre>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/apriori_algorithm.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/apriori_example.jpg'  alt="" /></p>

<p><em>apirori</em> 알고리즘이 나온 이래로, 성능을 개선하기 위한 많은 기법들이 발표됬다.</p>

<p>(1) Reduce passes of transaction database scans <br />
- partitioning
- dynamic itemset counting</p>

<p>(2) Shrink the number of candidates <br />
- Hashing
- Pruning by support lower bounding
- Sampling</p>

<p>(3) Exploring special data structures <br />
- Tree projection
- H-miner
- Hypercube decomposition</p>

<p><br/></p>

<h3 id="partitioning">Partitioning</h3>

<blockquote>
  <p><em>Theorem:</em> Any itemset that is potentially frequent in TDB must be frequent in at least one of the partitions of TDB</p>
</blockquote>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/partitioning.jpg'  alt="" /></p>

<p>어느 <em>local TDB</em> 에서도 <em>frequent</em> 하지 않으면 <em>global TDB</em> 에서도 <em>frequent</em> 하지 않기 때문에, <em>global</em> 에서 <em>frequent</em> 하려면  적어도 <em>partitioning</em> 된 <em>local TDB</em> 중 하나에서는 <em>frequent</em> 해야 한다.</p>

<p>따라서 <em>scan 1</em> 에서 <em>partitining</em> 하고 <em>local pattern</em> 을 찾고, <em>scan 2</em> 에서 <em>global frequent pattern</em> 을 구하면 된다. 딱 2번만 <em>TDB</em> 에 접근한다.</p>

<p><br/></p>

<h3 id="directhashingandpruning">Direct Hashing and Pruning</h3>

<p><em>DHP</em> 는 <em>candidates</em> 의 수를 줄이기 위해 사용하는 기법이다.</p>

<blockquote>
  <p><em>observation:</em> A <code>k</code>-itemset whose corresponding hashing bucket count is below the threshold cannot be frequent</p>
</blockquote>

<p>기본적인 아이디어는 <em>item</em> 이 <em>frequent</em> 하다면, <em>hashing bucket</em> 에 들어갔을때 그 <em>count</em> 값이 <em>threshold</em> 보다 높아야 한다는 것이다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/DHP.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="verticaldataformat">Vertical Data Format</h3>

<blockquote>
  <p><em>ECLAT</em> (Equivalence Class Transformation) is a depth first search algorithm using set intersection    </p>
</blockquote>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/ECLAT.jpg'  alt="" /></p>

<p><em>ECLAT</em> 은 <em>item</em> 기준으로 접근하는 방법이다. <code>t(X) = t(Y)</code> 이면 <code>X</code> 와 <code>Y</code> 가 언제나 같이 일어나고, <code>t(X) ⊂ t(Y)</code> 이면 <code>X</code> 가 있을땐 언제나 <code>Y</code> 가 있다.</p>

<p><em>diffset</em> 연산을 이용하면 공간을 많이 아낄 수 있다. <em>intersection</em> 은 교집합이므로, 공통부분과 그렇지 않은 부분이 생기는데, 다른 부분만 보관하는 것이다.</p>

<p><br/></p>

<h3 id="fpgrowth">FP Growth</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/FPGrowth.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/FPGrowth_example.jpg'  alt="" /></p>

<p><em>FP-tree</em> 를 만들고, 이를 이용해 <em>conditinal pattern bases</em> 를 구한다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/conditional_pattern_bases.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/conditional_pattern_bases2.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/scaling_FPGrowth.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="miningclosedpattern">Mining Closed Pattern</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week1/mining_closed_pattern.jpg'  alt="" /></p>

<p><em>closed pattern</em> 에 대해 쓸 수 있는 다양한 기법이 있다. <em>itemset merging</em> 도 그중 하나인데, </p>

<p><em>d-proj. db</em> 인 <code>{acef, acf}</code> 를
<em>acfd-proj. db</em> 인 <code>{e}</code> 로 바꾸어, <code>{acfd:2}</code> 를 얻을 수 있다.</p>

<p>이외에도 위 그림에 나온 많은 테크닉들이 있다.</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='https://www.behance.net/gallery/625042/Icon-and-pattern-with-a-marketing-theme' >Title image</a> <br />
(2) <em>Pattern Discovery</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/pattern-discovery-1/</link><guid isPermaLink="false">ad3d19ae-0fcc-41f5-bba3-829c06518bf2</guid><category><![CDATA[coursera]]></category><category><![CDATA[pattern discovery]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 12 Feb 2015 07:57:41 GMT</pubDate></item><item><title><![CDATA[AI Planning 4, STN, HTN]]></title><description><![CDATA[<p><img src='http://uxmag.com/sites/default/files/legacy/articleimage_15.jpg'  alt="" /></p>

<p>지금까지 <em>State-Space Planning</em>, <em>Plan-Space Planning</em> 기법을 배웠는데, 이 두 가지는 같은 문제를 푸는 방법이었다. 이제 문제를 조금 변형해, 인간의 사고와 비슷하게 <em>Task</em> 중심으로 분할해서 해결하는 법을 배워보자. </p>

<h3 id="stn">STN</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_planning.jpg'  alt="" /></p>

<p><em>terms</em> 는 <em>constant</em>, <em>variable</em>, <em>object</em> 따위의 것들이고 <em>literals</em> 는 참이거나 거짓이 될 수 있는 <em>proposition</em> 이다. </p>

<p><em>task network</em> 에서 새롭게 도입되는 것은</p>

<ul>
<li><strong>task:</strong> to be performed</li>
<li><strong>method:</strong> describing ways in which tasks can be performed</li>
<li><strong>organized collections of tasks:</strong> called task networks</li>
</ul>

<p><em>DWR</em> 예제로 보면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/DWR_STN_example.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="task">Task</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/tasks_def.jpg'  alt="" /></p>

<p><em>task</em> 는 <code>T_S</code> 처럼 <em>non-primitive</em> 일 수도, <code>t1, ..., tn</code> 처럼 <em>subsete</em> 에 속하는 <em>primitive task</em> 일 수 있다. </p>

<p><em>task</em> 를 <code>t_i(r1, ..., rk)</code> 라 표기하는데, <code>r</code> 은 <em>task</em> 에 의해 조작되는 <em>object</em> 등의 <em>term</em> 이다. </p>

<p>그리고 슬라이드에 나와 있듯이 <em>ground task</em> 는 <em>variable</em> 이 아니라 <em>action</em> 처럼 <em>constant</em> 를 가져야 하고, <em>action</em> 은 <em>ground primitive task</em> 만 <em>accomplish</em> 할 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/simple_task_network_def.jpg'  alt="" /></p>

<p><em>STN</em> 은 <em>acyclic directed graph</em> <code>(U, E)</code> 다. 각 <em>node</em> 는 <em>task</em> 고, <em>edge</em> 는 <em>task</em> 의 <em>partial ordering</em> 을 정의한다. <code>t_i &lt; t_j</code> 처럼</p>

<p>그리고 <em>task network</em> 는 모든 <em>node</em> 가 <em>ground/primitive</em> 일때만 <em>ground/primitive</em> 고, 하나라도 아니라면 <em>unground/non-primitive</em> 다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/total_ordered_STN.jpg'  alt="" /></p>

<p><em>STN</em> <code>w</code> 는 위상 정렬처럼, 모든 <em>edge</em> 가 <em>node</em> 에 대해 순서를 정의할 수 있으면 <em>totally ordered</em> 하다고 말한다. 그러면 <code>w</code> 는 <em>task</em> 의 시퀀스로 나타낼 수 있다. <code>w = &lt;t1, ..., tn&gt;</code></p>

<p>그리고 <code>w</code> 가 <em>totally ordered</em>, <em>ground</em>, <em>primitive</em> 이면 <code>w</code> 를 위한 <em>plan</em> <code>ㅠ</code> 는</p>

<p><code>ㅠ(w) = &lt;a1, ..., an&gt;</code> where <code>ai = ti</code>, <code>1 &lt;= i &lt;= n</code></p>

<p><br/></p>

<p>DWR 예제로 STN 의 표기법을 알아보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STNs_DWR_ex.jpg'  alt="" /></p>

<p><code>take</code> <em>task</em> 는 똑같은 <em>operator</em> 이름이 있으므로 <em>primitive</em> 고, 변수가 없으므로 <em>ground</em> 다. </p>

<p><code>move-stack</code> 은 <em>DWR domain</em> 에 정의한 같은 이름의 <em>operator</em> 가 없으므로 <em>non-primitive</em> 이고, 변수가 있으므로 <em>unground</em> 다.</p>

<p>이 3개의 <em>task</em> 를 기반으로 <em>task network</em> 를 구성할 수 있다.</p>

<p><code>w1</code> 은 <code>(t1, t2), (t1, t3)</code> 고, <code>t2, t3</code> 에 대한 <em>ordering</em> 이 없으므로 <em>partially ordered network</em> 다.</p>

<p><br/></p>

<h3 id="methodsrefinements">Methods (Refinements)</h3>

<blockquote>
  <p><strong>method:</strong> describing ways in which tasks can be performed</p>
</blockquote>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_method_def.jpg'  alt="" /></p>

<p>메소드는 <em>name</em>, <em>task</em>, <em>precond</em> <em>network</em> 로 구성되어 있다.</p>

<ul>
<li><em>name(m)</em>: <code>n(x1, ..., xk)</code> 의 형태로 <em>unique</em> 한 심볼 <code>n</code> 과 다뤄지는 <em>variable</em> 인 <code>x</code> 를 포함한다</li>
<li><em>task(m)</em>: <em>non-primitive task</em></li>
<li><em>precond(m)</em>: set of literals</li>
<li><em>network(m)</em>: task network <code>(U, E)</code> containing the set of subtasks <code>U</code> of <code>m</code></li>
</ul>

<p>잘 보면 <em>effect</em> 가 없는데, 여기선 <em>goal</em> 을 달성하는 것이 아니라 <em>task</em> 를 수행해야 하기 때문에 <em>effect</em> 는 없고 <em>precond</em> 만 신경쓴다.</p>

<p>그리고 <em>task</em> 는 무엇을 달성해야 하는지를 나타내기 때문에, <em>task</em> 가 같으면 같은 <em>method</em> 가 아니냐고 질문할 수 있으나, <em>network</em> 때문에 다르다. <em>network</em> 는 <em>subtask</em> 를 <em>ordering</em> 한 것으로 <strong>어떻게</strong> <em>task</em> 를 수행할지를 나타내기 때문이다.</p>

<p>만약 <em>method</em> 의 <em>network</em> 가 <em>partially ordered</em> 이면 <em>method</em> 도 <em>partially ordered metohd</em> 라 부른다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_method_DWR_ex.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_method_DWR_ex2.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_method_DWR_ex3.jpg'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/app_relev.jpg'  alt="" /></p>

<p><em>appicability</em> 는 <em>action</em> 과 비슷하다. </p>

<p>만약 <em>substitution</em> <code>σ</code> 에 대해, <code>σ(t) = task(m)</code> 이면 메소드 인스턴스 <code>m</code> 이 태스크 <code>t</code> 와 <em>relevant</em> 하다고 말한다. <del>왜죠?</del></p>

<p>무슨 뜻인가 하면, 우리가 달성하려고 하는 <code>t</code> 에 대해 <code>σ(t)</code> 가 메소드의 태스크인 <code>task(m)</code> 과 동일하면, 해당 <code>t</code> 를 위해 메소드 <code>m</code> 을 사용할 수 있다는 뜻이다.</p>

<p>그리고 태스크 <code>t</code> 와 <em>relevant</em> 인 <em>method</em> <code>m</code> 에 대해 </p>

<ul>
<li><code>δ(t, m, σ) = σ(network(m))</code> 또는</li>
<li><code>δ(t, m, σ) = σ(&lt;subtasks(m)&gt;)</code> if <code>m</code> is <strong>totally ordered</strong></li>
</ul>

<p>로 <em>decomposition</em> 할 수 있다. 그냥 분해인데, 표기법을 저렇게 사용한다고 보면 된다. 당연히 <em>decomposition</em> 되면 <em>subtask</em> 가 되는데, <em>totally ordered</em> 면 <em>subtask</em> 만 돌려주면 되고, 아니라면 <em>network</em> 를 돌려주면 된다는 이야기. DWR 예제로 보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_method_DWR_ex2.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/method_app_relev_DWR_ex.jpg'  alt="" /></p>

<p><em>substitution</em> 을 적용했을때<em>task</em> 이름이 같으므로 <em>relevant</em> 하고 <em>precond</em> 를 검사해보면 <em>applicable</em> 하다는 것을 알 수 있다.</p>

<p><br/></p>

<h3 id="decomposition">Decomposition</h3>

<p><em>method decomposition</em> 을 자세히 살펴보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/method_decomp_DWR_ex.jpg'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/decomposition_def.jpg'  alt="" /></p>

<p><code>w</code> 를 <em>STN</em> 이라고 하면, <code>U</code> 에 속하는 <em>task</em> <code>t</code> (<em>predecessors</em> 가 없는) 에 대해 <em>relevant</em> 메소드 <code>m</code> 이 있고, <em>substitution</em> <code>σ</code> 와, <code>m</code> 의 <em>network</em> <code>(U_m, E_m)</code> 이 있다. 이 때 <em>decomposition</em> <code>δ(w, t, m, σ)</code> 은</p>

<ul>
<li><code>t</code> is replaced in <code>U</code> by <code>σ(U_m)</code></li>
<li>edges in <code>E</code> involving <code>t</code> are replaced by edges to appropriate nodes in <code>σ(U_m)</code></li>
</ul>

<p><br/></p>

<h3 id="domainsproblemsandsolution">Domains, Problems and Solution</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_planning_domain.jpg'  alt="" /></p>

<p><em>STN planning domain</em> <code>D = (O, M)</code> 이다. <code>O</code> 는 <em>STRIPS planning operators</em>, <code>M</code> 은 <em>STN methods</em> 다. 만약 모든 메소드가 <em>totally ordered</em> 이면 <code>D</code> 도 <em>total-order STN planning domain</em> 이다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_planning_problem.jpg'  alt="" /></p>

<p><em>STN planning problem</em> <code>P</code> 는 <code>P = (s_i, w_i, O, M)</code> 으로 구성된다. 잘보면 <em>goal</em> 대신 <em>initial state network</em> 인 <code>w_i</code> 가 있다. <code>w_i</code> 와 <code>D = (O, M)</code> 이 <em>totally ordered</em> 면 <code>P</code> 를 <em>total order STN planning problem</em> 이라 부른다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/STN_planning_solution.jpg'  alt="" /></p>

<p>(1) <code>w_i</code> 와 <em>plan</em> <code>ㅠ</code> 가 <em>empty</em> 여서 태스크가 없거나  </p>

<p>(2) <em>predecessors</em> 가 없는 <em>primitive task</em> <code>t</code> 에 대해, <code>a1 = t</code> 가 <code>s_i</code> 에 <em>applicable</em> 하고, <code>ㅠ = &lt;a2, ..., an&gt;</code> 이 <code>P' = (γ(s_i, a1), w_i - {t}, O, M)</code> 의 솔루션이거나  </p>

<p>(3) <em>predecessors</em> 가 없는 <em>non-primitive task</em> <code>t</code> 에 대해 <em>relevant</em> 메소드 <em>m</em> 이 <code>s_i</code> 에 대해 <em>applicable</em> 하고, <code>ㅠ</code> 가 <code>P' = (s_i, δ(w, t, m, σ), O, M)</code> 면 된다.</p>

<p>즉 <em>primitive task</em> 일때는 <em>action</em> 으로 시작하고, 아닐때는 <em>decomposition</em> 한 네트워크에 대해 <code>ㅠ</code> 를 찾으면 된다.</p>

<p></br></p>

<h3 id="stnplanning">STN Planning</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/state_vs_plan_planner.jpg'  alt="" /></p>

<p>여기서 <em>TFD</em> 는 <em>Total-order Forward Decomposition</em> 의 약자다.</p>

<pre><code>function Ground-TFD(s, &lt;t, ..., tk&gt;, O, M)  
  // empty plan, no task
  if k = 0 return &lt;&gt;

  if t1.isPrimitive() thne
    actions = {(a, σ), a = σ(t1) and a applicable in s}

    if actions.isEmpty() then return failure
    (a, σ) = actions.chooseOne()
    plan &lt;- Ground-TFD(γ(s, a), σ(&lt;t2, ..., tk&gt;), O, M)

    if plan = failure then return failure
    else return &lt;a&gt; * plan // add plan 

  else 
    methods = {(m, σ) | m is relevant for σ(t1) and m is appicable in s}

    if methods.isEmpty then return failure

    (m, σ) = methods.chooseOne()
    // prepend subtasks
    plan &lt;- subtasks(m) * σ(&lt;t2, ..., tk&gt;)

    return Ground-TFD(s, plan, O, M)
</code></pre>

<p><em>DWR</em> 예제를 보면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/DWR_decompos_tree_ex.jpg'  alt="" /></p>

<p><code>move-stack</code> 은 <em>non-primitive</em> 이므로 <em>decomposition</em> 하고, 이 과정을 반복하면서 <em>ground, primitive task</em> 를 얻어 <em>action</em> 으로 해결한다.</p>

<p><br/></p>

<h3 id="tfdvsfowardbackwardsearch">TFD vs Foward/Backward Search</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/TFD_vs_fwd_backwd.jpg'  alt="" /></p>

<ul>
<li>TFD consider only applicable actions like forward search</li>
<li>TFD consider only relevant actions like backward search</li>
<li>TFD generate actions execution order. current world state always known</li>
<li>Ground-TFD can be generalized to Lifted-TFD resulting in same advantages as lifted backward search</li>
</ul>

<p><em>TFD</em> 의 경우 <em>action execution order</em> 를 생성하기 때문에, 현재 어디에 위치해 있는지를 알 수 있다. 이 때문에 <em>goal</em> 까지 더 빠르게 가기 위한 <em>good heuristics</em> 를 적용할 수 있다.</p>

<p><em>Lifted-TFD</em> 는 <em>variable</em> 을 최대한 유지해, 불필요한 <em>binding</em> 을 막는다.</p>

<p><br/></p>

<p><em>Partial-order FD</em> 코드도 살펴보자.</p>

<pre><code>function Ground-PFD(s, w, O, M)  
  if w.U = {} return &lt;&gt;

  task &lt;- { t ∈ U | t has no predecessors in w.E}.chooseOne()

  if task.isPrimitive() then
    actions = {(a, σ) | a = σ(t1) and a applicable in s}

    if actions.isEmpty() then return failure

    (a, σ) = actions.chooseOne()
    plan &lt;- Ground-PFD(γ(s, a), σ(w-{task}), O, M)

    if plan = failure then return failure
    else return &lt;a&gt; * plan

  else
    methods = {(m, σ) | m is relevant for σ(t1) and m is applicable in s}

    if methods.isEmpty then return failure

    (m, σ) = methods.chooseOne()

    return Gound-PFD(s, δ(w, task, m, σ), O, M)    
</code></pre>

<p><em>TFD</em> 와 별 차이가 없다. 초기에 <em>TFD</em> 가 아니므로 인자로 <em>network</em> 인 <code>w</code> 를 받아, <code>task</code> 를 직접 구하는거 이외에는.</p>

<p><br/></p>

<h3 id="htnplanning">HTN Planning</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/precond_STN_planning.jpg'  alt="" /></p>

<p><em>STN planning</em> 에서는 <em>ordering constaints</em> 를 유지해야 하고, <em>applicability</em> 를 테스트하기 위해서 <em>precondition</em> 을 이용했다. 또한 <em>effect</em> 없이 <em>precond</em> 만 이용하므로 반드시 <em>forward search</em> 를 해야 했다.</p>

<p><em>HTN planning</em> 에서는 <em>ordering constaints</em> 나 <em>precondition</em> 이외에 추가적으로 <em>general constraints</em> 를 유지하여 다른 종류의 <em>constraints</em> 를 조합하는 등 더 유연하게 플래닝할 수 있다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/HTN_methods_def.jpg'  alt="" /></p>

<p>예를 들어 <em>HTN methods</em> 는 <code>constr(m)</code> 을 포함한다. <em>DWR</em> 예제를 보자.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/HTN_method_DWR_ex.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/HTN_method_DWR_ex2.jpg'  alt="" /></p>

<p><code>move-one</code> 같은 경우 <code>no-move</code> 대신 이용하는데, 이는 <em>HTN planning</em> 에서는 <em>task</em> 가 없으면 <em>constraints</em> 를 추가할 수 없기 때문이다. </p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/HTN_vs_STRIPS.jpg'  alt="" /></p>

<p><em>HTN</em> 은 <em>STN</em> 의 더 유연한 버전이고, <em>STN</em> 은 <em>undecidable</em> 한 문제를 풀 수 있지만, <em>STRIPS</em> 에서는 불가능하다. <em>STRIPS</em> 에서는 유한한 오브젝트, 아톰 등으로 구성된 유한한 상태 공간을 탐색하기 때문이다. 반대로 <em>STN</em> 이 <em>background</em> 를 더 필요로 하지만, 더 <em>expressie</em> 함을 알 수 있다.</p>

<p>그렇다고 <em>STRIPS</em> 가 후지다는 것이 아니라, 서로 다른 종류의 문제를 풀 수 있는 두개의 방법이라 보면 된다.</p>

<p>참고로 <em>non-recursive STN</em> 은 <em>STRIPS</em> 로 번역될 수 있다고 한다. 그리고 <em>regular STN</em> 은 <em>STRIPS</em> 와 동일하다고 하는데, <em>regular</em> 란 뜻은 <em>recursive call</em> 이 그리 많지 않은 것을 의미한다.</p>

<h3 id="sipe2htnplanner">SIPE-2 HTN Planner</h3>

<p><a href='https://www.youtube.com/watch?v=gE0wPgT2qrw' >Youtube: SIPE-2 HTN Planner by David Wilkins</a></p>

<h3 id="refs">Refs</h3>

<p>(1) <strong>Artificial Integelligence Planning</strong>, by Dr.Gerhard Wickler, Prof. Austin Tate <br />
(2) <a href='http://uxmag.com/articles/psychological-usability-heuristics' >brain image</a>  </p>]]></description><link>http://1ambda.github.io/ai-planning-4/</link><guid isPermaLink="false">6235b69f-6206-4ec8-af7f-780a8f1d76cb</guid><category><![CDATA[coursera]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[STN]]></category><category><![CDATA[HTN]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 01 Feb 2015 02:42:11 GMT</pubDate></item><item><title><![CDATA[AI Planning 3, PSP, PoP]]></title><description><![CDATA[<p><img src='http://www.dailygalaxy.com/.a/6a00d8341bf7f753ef019affc63311970d-800wi'  alt="" /></p>

<h3 id="partialplan">Partial Plan</h3>

<p>이 전까지는 <em>plan</em> 을 <em>goal state</em> 를 달성하기 위한 <em>action</em> 의 나열로서 봤다. <em>plan</em> 자체를 하나의 솔루션으로 본 것이다. <em>partial plan</em> 은 이와 달리, 탐색 공간이 <em>state</em> 가 아니라 <em>plan</em> 으로 구성되어있다는 생각에서 시작한다.</p>

<ul>
<li><strong>state-space search:</strong> search through graph of nodes rpresenting world states</li>
<li><strong>plan-space search:</strong> search through graph of plans.</li>
</ul>

<p>(1) <strong>nodes</strong> are partially specified plans. <br />
(2) <strong>arcs</strong> are plan refinement opreations. <br />
(3) <strong>solutions</strong> are partial-order plans.</p>

<p><em>partial plan</em> 이란</p>

<ul>
<li>subset of the actions</li>
<li>subset of the organizational structure including temporal ordering of actions and rationale (<em>what the action achieves in the plan</em>)</li>
<li>subset of varaible bindings</li>
</ul>

<p>좀 더 <em>formal</em> 한 정의는</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/partial_plan_def.jpg'  alt="" /></p>

<ul>
<li><code>A</code> 는 <em>partially instantiated</em> 된 <em>operators</em> 다.</li>
<li><code>&lt;</code> 는 <em>ordering constraint</em></li>
<li><code>B</code> 는 <em>variable binding</em></li>
<li><code>L</code> 은 <em>casual links</em> 로 <em>action</em> 간 <em>ordering</em> 과 여기에 필요한 <em>proposition</em> (<em>effect</em>, <em>precond</em>), <em>binding constraint</em> 를 포
함한다. <code>a_i</code> 를 <em>producer</em> <code>a_j</code> 를 <em>consumer</em> 라 부르기도 한다. </li>
</ul>

<p><br/></p>

<h3 id="planrefinemeents">Plan Refinemeents</h3>

<p><em>partial plan</em> 의 구성요소는</p>

<ul>
<li>initial state</li>
<li>goal conditions</li>
<li>set of operators with different varaibles</li>
</ul>

<h4 id="addingactions">Adding Actions</h4>

<p><em>unsatisfied pre-cond</em>, <em>unsatisfied goal condition</em> 을 위해서 <em>partial plan</em> 에 <em>action</em> 을 추가해야 한다. <em>forward search</em> 나 <em>backward search</em> 에서는 앞이나 뒤에만 <em>action</em> 을 추가할 수 있었지만 <em>partial plan</em> 에선 그런 제약이 없다. </p>

<p>예제를 보면 <em>initial state</em> 와 <em>goal</em> 로만 구성된 <em>empty plan</em> 에서 시작해서 <em>partial plan</em> 을 점점 키워간다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/adding_action_ex.jpg'  alt="" /></p>

<p><br/></p>

<h4 id="addingcasuallinks">Adding Casual Links</h4>

<p>위에서 언급했듯이 <em>partial plan</em> 은 <em>action</em> 간 <em>casual links</em> 를 포함하고 있다. <em>action</em> 간 <em>invalid pre-cond, effect</em> 를 방지하기 위해서 필요하다. </p>

<p>두 종류의 <em>provider</em> 가 있을 수 있다.</p>

<p>(1) <em>action</em> 의 <em>effect</em> <br />
(2) <em>initial state</em> 를 담고있는 <em>atom</em> </p>

<p>마찬가지로 <em>consumer</em> 도</p>

<p>(1) <em>action</em> 의 <em>pre-condition</em> 거나 
(2) <em>goal condition</em> 일 수 있다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/adding_casual_links_ex.jpg'  alt="" /></p>

<p><br/></p>

<h4 id="addingvariablebindng">Adding Variable Bindng</h4>

<ul>
<li>new operators introduce new (copies of) variables into the plan</li>
<li>solution plan must contain actions</li>
<li>varaible binding constraints keep track of possible values for varaibles and co-designation</li>
</ul>

<p>새로운 <em>operator</em> 가 사용될때 마다, 새로운 <em>varaible</em> 이 <em>plan</em> 에 추가된다. 그런데 솔루션에는 <em>action</em> 이 있어야 하므로 <em>possible value</em> 를 테이블로 유지해야 한다. <em>casual links</em> 를 추가하면서 <em>effect</em> 와 <em>pre-cond</em> 를 연결했지만, <em>variable</em> 까지 고려하면 <em>invalid</em> 한 경우가 생길수도 있으므로 이를 막기 위해 <em>varaible binding</em> 이 필요하다. 예제를 보면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/adding_variable_ex.jpg'  alt="" /></p>

<h4 id="addingorderingconstraints">Adding Ordering Constraints</h4>

<p><em>partial plan</em> 은 <em>ordering constraint</em> 를 포함하고 있다. </p>

<ul>
<li>binary relation specifying the temporal order between actions in the plan</li>
</ul>

<p><em>ordering constraints</em> 를 추가해야 하는 이유는</p>

<ul>
<li>all actions must come after initial state</li>
<li>all actions must come before goal</li>
<li>casual link implies ordering constaint</li>
<li>to avoid possible interference between actions</li>
</ul>

<p>예제를 보자. 그림에서 <em>variable binding</em> 이 표시되어 있진 않지만, 있다고 보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/adding_ordering_const.jpg'  alt="" /></p>

<h3 id="planspacesearch">Plan-Space Search</h3>

<p>지금까지 <em>partial plan</em> 을 구성하는 방법에 대해 배웠고, 이제 <em>partial plan</em> 을 노드로 삼는 <em>plan-space search</em> 에 대해 알아보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/initial_search_state.jpg'  alt="" /></p>

<p>최초에는 두개의 더미 <em>action</em> 인 <em>init</em>, <em>goal</em> 을 가지고 <code>init &lt; goal</code> 의 <em>ordering constaint</em> 를 가진다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/initial_search_state_ex.jpg'  alt="" /></p>

<p>이제 <em>plan refinement operators</em> 를 적용해서 하나 이상의 <em>successor</em> 를 찾기 위한 <em>successor function</em> 을 정의해 보자.</p>

<ul>
<li>adding an action to <code>A</code></li>
<li>adding an ordering constaint to <code>&lt;</code></li>
<li>adding a binding constaint to <code>B</code></li>
<li>adding a casual link to <code>L</code></li>
</ul>

<p>보면 알겠지만 <em>plan-space search</em> 는 두 가지 문제를 <em>decoupling</em> 한다.</p>

<p>(1) <em>which actions to execute as part of our plan</em> <br />
(2) <em>how to organize these actions?</em>, <em>what is the organizational structure that underlies our plan?</em></p>

<p><em>plan-space search</em> 를 다른관점에서 볼 수도 있다. <em>possible plan</em> 을 <em>partial plan</em> 으로 줄여가는 것이다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/total_vs_partial_order.jpg'  alt="" /></p>

<p><em>planning problem</em> <code>P</code> 는 <em>state transition system</em>, <em>initial state</em>, <em>goal</em> 로 구성된다. 이때 <em>plan</em> <code>ㅠ</code> 에 대해 <code>r(s_i, ㅠ)</code> 가 <code>g</code> 를 만족시키면, <code>ㅠ</code> 는 솔루션이다.</p>

<p><code>r(s_i, ㅠ)</code> 는 <em>ground action</em> 의 시퀀스로만 정의되는데</p>

<ul>
<li>partial order corresponds to total order in which all partial order constaints are respected</li>
<li>partial instantiation corresponds to grounding in which variables are assigned values consistent with binding constraints</li>
</ul>

<p>생각해보면 <em>partially instantiated varaibles</em> 을 <em>fully ground plan</em> 으로 바꿀 수 있는 경우의 수가 많기 때문에 어떤 것을 사용할지 결정해야 한다. 이를 위해 <em>partial order solution</em> 을 정의하면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/partial_order_solution.jpg'  alt="" /></p>

<p>위 슬라이드에서 볼 수 있듯이 두 가지 조건이 갖추어지면 <em>plan</em> <code>ㅠ</code> 가 <em>(partial order) solution</em> 이 될 수 있다.</p>

<ul>
<li>its ordering constaints <code>&lt;</code> and binding constraints <code>B</code> are consistent and</li>
<li>for every total order seq <code>&lt;a1, ... , ak&gt;</code> of all the actions in <code>A - {init, goal}</code> that is </li>
</ul>

<p>(1) totally ordered and grounded and respects <code>&lt;</code> and <code>B</code> <br />
(2) <code>r(s_i, &lt;a1, ..., ak&gt;)</code> must satisfy <code>g</code></p>

<p>흥미로운점은 <em>casual links</em> 가 아무런 역할도 하지 않는다는 것이다. 두번째는 위 과정을 <em>goal test</em> 로 쓰기 위해 <em>computational procedure</em> 로 바꾸면, 퍼포먼스가 별로라는 사실도 알 수 있다.</p>

<p>만약 우리가 모든 <em>total order seq</em> 를 테스트 해야하고, 수 많은 <em>seq</em> 가 있다면 <em>goal</em> 을 검증하기 위해 수 많은 작업을 해야한다.</p>

<p>물론 <em>plan</em> 을 만드는 과정에서 <em>action</em> 의 <em>pre-cond</em> 가 <em>casual links</em> 에 의해 지정되기 때문에, 우리가 만들고 있는 <em>plan</em> 이 <em>goal</em> 을 만족하는지, 아닌지 알 수 있다. 문제는 <em>pre-cond</em> 만으로는 <em>goal</em> 을 만족하는지 아닌지 충분하지 않다는 점이다.</p>

<h3 id="threatsandflaws">Threats and Flaws</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/threat_example.jpg'  alt="" /></p>

<p>위 그림에서 <em>action</em> <code>3</code> 과 <code>1</code> 은 <code>at(robot, loc1)</code> 을 서로 추가하고, 삭제한다. 따라서 병렬로 실행되면 <em>dummy action</em> 인 <em>goal</em> 이 실행되지 않을 수 있다. 이 경우를 <em>threat</em> 라고 부르며, 간단한 해결 방법으로 <em>action</em> <code>2</code> 에서 <code>1</code> 로 <em>ordering</em> 을 추가할 수 있다. 정의를 보면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/threat_def.jpg'  alt="" /></p>

<p><em>casual link</em> <code>a_i -&gt; [p] -&gt; a_j</code> 에 에 대해 <em>threat</em> <code>a_k</code> 는 <code>p</code> 와 <em>unifiable effect</em> <code>~ q</code> 를 가지고 있고, <em>ordering constraint</em> <code>a_i &lt; a_k</code>, <code>a_k  &lt; a_j</code> 가 있다. 다시 말해 <code>a_i</code> 의 <em>effect</em> 를 상쇄할 수 있다는 말이다.</p>

<p><em>unsatisfied sub-goal</em> 과 <em>threat</em> 같은 것들을 <em>flaw</em> 라 부른다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/flaws_def.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/flawless_plan.jpg'  alt="" /></p>

<p>만약 <em>partial plan</em> <code>ㅠ = (A, &lt;, B, L)</code> 가 </p>

<p>(1) <code>ㅠ</code> has no flaws <br />
(2) the ordering constaints <code>&lt;</code> are not circular <br />
(3) the variable bindings <code>B</code> are consistent  </p>

<p>이면 <em>partial plan</em> <code>ㅠ</code> 는 <em>planning problem</em> <code>P</code> 의 솔루션이다.</p>

<p><br/></p>

<h3 id="pspalgorithm">PSP algorithm</h3>

<p><em>plan-space planning</em> 을 잠깐 복습해보면,</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/psp_as_search_prb.jpg'  alt="" /></p>

<p><em>operator</em>, <em>initial state</em> <em>goal</em> 로 구성된 <em>planning problem</em> 이 주어졌을때, <em>search problem</em> 은 위 슬라이드처럼 정의할 수 있다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/PSP_basic_ops.jpg'  alt="" /></p>

<p><em>PSP, Plan-Space Planner</em> 의 기본적인 아이디어는 <em>partial plan</em> <code>ㅠ</code> 가 <em>flaw</em> 가 없을때 까지 <code>&lt;</code>, <code>B</code> 를 <em>valid</em> 하게 유지하면서 <em>refine</em> 하는 것이다. 따라서 <em>flaw</em> 를 찾고, 이걸 해결할 수 있는 <em>resolvers</em> 를 구한 뒤 적절히 선택해 나아가면 된다. 알고리즘은 </p>

<pre><code>function PSP(plan)  
  allFlaws &lt;- plan.openGoals() + plan.threats()

  if allFlaws.empty() then return plan

  flaw &lt;- allFlaws.selectOne()
  allResolvers &lt;- flaw.getResolvers(plan)

  if allResolver.empty() then return failure

  resolver &lt;- allResolvers.chooseOne()
  newPlan &lt;- plan.refine(resolver)

  return PSP(newPlan)
</code></pre>

<p>여기서 <code>chooseOne()</code> 과 <code>selectOne()</code> 이라는 두개의 선택 함수를 볼 수 있는데</p>

<ul>
<li><code>chooseOne()</code> is non-deterministic choice</li>
<li><code>selectOne()</code> is deterministic selection</li>
</ul>

<p><code>chooseOne()</code> 의 경우 <em>non-deterministic</em> 이기 때문에 실패할 경우 <em>backtracking</em> 할 수 있도록 해야 한다.</p>

<p>반면 <code>selectOne()</code> 은 <em>deterministic</em> 이기 때문에 <em>backtracking</em> 이 필요 없다. 대신 고려해야 할 것은</p>

<p>(1) <em>order</em> 가 <em>effcientcy</em> 에 영향을 미치기 때문에 어떤걸 선택하느냐가 중요하다. (<em>order</em> 는 <em>completeness</em> 와는 관련 없다) <br />
(2) 모든 <em>flaw</em> 는 <em>plan</em> 이 <em>solution</em> 이 되기 전에 <em>resolved</em> 되야 한다.  </p>

<p><br/></p>

<h3 id="pspimplementation">PSP Implementation</h3>

<pre><code>function PSP(plan)  
  allFlaws &lt;- plan.openGoals() + plan.threats()

  if allFlaws.empty() then return plan

  flaw &lt;- allFlaws.selectOne()
  allResolvers &lt;- flaw.getResolvers(plan)

  if allResolver.empty() then return failure

  resolver &lt;- allResolvers.chooseOne()
  newPlan &lt;- plan.refine(resolver)

  return PSP(newPlan)
</code></pre>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/plan_openGoals.jpg'  alt="" /></p>

<p><em>unachieved sub-goal</em> 의 리스트는 <em>action</em> 을 추가하면서 <em>precondition</em> 때문에 늘어나고, <em>casual link</em> 을 추가할때는 <em>protected proposition</em> 때문에 감소한다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/plan_threats.jpg'  alt="" /></p>

<p><em>threat</em> 의 경우에는 새로운 액션 <code>a_new</code> 에 대해 기존의 링크 <code>L</code> 내에 있는 모든 <code>a_i -&gt; [p] -&gt; a_j</code> 에 대해 <code>a_new &lt; a_i</code>, <code>a_j &lt; a_new</code> 인지 검사하고, 참이면 패스한다. 참이 아닐경우 <code>p</code> 와 <code>~q</code> 의 <em>effect</em> 가 상쇄되는지 검사하여 <em>threat</em> 인지 검사한다.</p>

<p><em>casual link</em> <code>a_i -&gt; [p] -&gt; a_j</code> 를 추가할때는 기존의 <em>action</em> <code>a_old</code> 에 대해 <em>threat</em> 가 될 수 있는지 위처럼 검사한다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/flaw_getResolvers.jpg'  alt="" /></p>

<p>먼저 <em>unachieved precondition</em> 을 제거하는 <em>resolver</em> 를 구하는 방법을 알아보자. 기존의 <em>valid action</em> 의 <em>effect</em> <code>q</code> 에 대해 <em>unachieved precondition</em> <code>p</code> 를 해겨할 수 있으면 <em>resolver</em> 를 추가한다. <em>operator</em> 로 부터 직접 <em>action</em> 을 만들어 <em>casual link</em> 까지 추가할 수도 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/flaw_getResolvers2.jpg'  alt="" /></p>

<p><em>threat</em> 를 제거하는 <em>resolver</em> 는 위처럼 구할 수 있다. <code>a_i -&gt; [p] -&gt; a_j</code> 에 대한 <em>threat</em> <code>a_t</code> 에 대해 <code>a_t &lt; a_i</code>, <code>a_j &lt; a_t</code> 를 추가하거나, <em>variable binding</em> 을 추가하는 방법이 있다. <code>v</code> 의 <em>substitution</em> 이 <code>v</code> 와 다르면서, 동시에 <code>B</code> 와 <em>consistent</em> 해야만 <em>resolver</em> 다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/plan_refine.jpg'  alt="" /></p>

<p><em>ordering</em> 이나 <em>binding constraints</em>, <em>casual links</em>, <em>new action</em> 을 추가하면서 <em>refinement</em> 를 할 수 있다. 이 때 <em>resolver</em> 를 찾기 위한 <em>unachieved precondition</em>, <em>threat</em> 를 업데이트 해야 한다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/maintain_ordering_consts.jpg'  alt="" /></p>

<p><em>ordering constaints</em> 는 질의하거나, 새로운 <em>ordering</em> 을 추가하기 위해 유지해야 한다. 이를 위한 표현 방법으로 위 슬라이드처럼 3가지 방법중 하나를 사용할 수 있다.</p>

<p><em>transitive closure</em> 를 유지하는 방법의 경우, <em>query (질의)</em> 는 빠르나 새로운 연산의 추가가 느릴 수 있다. 그러나 <em>planner</em> 의 경우 <em>query</em> 가 더 자주사용되는 연산이므로 좋은 표현 방법이다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/maintain_vcs.jpg'  alt="" /></p>

<p><em>unary constriants</em> 와 <em>equality</em> 는 <em>linear time</em> 으로 구할 수 있다. <em>inequality</em> 의 경우에는 <em>exponential time</em> 이 필요하고, 일반적으로 <em>NP-complete</em> 문제라고 알려져 있다.</p>

<p><em>inequality</em> 를 도입하는 것은 <em>threat</em> 를 풀 수 있는 <em>resolver</em> 이기 때문에 꼭 필요한데, 퍼포먼스가 문제가 될 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/PSP_sound_comp.jpg'  alt="" /></p>

<p><em>sound</em> 는, <em>planner</em> 가 리턴하는 것이 <em>solution</em> 이란 뜻이고 <em>complete</em> 하다는 것은 <em>solution</em> 이 있으면 <em>planner</em> 가 반드시 찾아낸다는 뜻이다. </p>

<p><br/></p>

<h3 id="thepopplanner">The PoP Planner</h3>

<p><em>Partial Order Planning</em></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/PSP_data_flow.jpg'  alt="" /></p>

<p><em>PoP</em> 플래너는 모든 <em>threat</em> 를 위 슬라이드에 표시된 초록색 부분에서 루프로 다룬다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/PoP_impl.jpg'  alt="" /></p>

<p><em>action</em>, <em>precondition</em> 을 하나의 <em>set</em> 으로 하여 <em>agenda</em> 라는 <em>input</em> 으로 취급한다. 그리고 <em>flaw type</em> 에 의해서 <em>search control</em> 이 진행된다. 코드로 보면</p>

<pre><code>funciton PoP(plan, agenda)  
  if agenda.empty then return plan

  (a_g, p_g) &lt;- agenda.selectOne()
  agenda &lt;- agenda - (a_g, p_g)
  relevant &lt;- plan.getProviders(p_g)

  if relevant.empty() then return failure

  // non-deterministic, use backtracking
  (a_p, p_p, σ) &lt;- relevant.chooseOne() 
  plan.L &lt;- plan.L ∪ &lt;a_p -&gt; [σ(p_g)] -&gt; a_g&gt;
  plan.B &lt;- plan.B ∪ σ

  if a_p is not in plan.A then
    plan.add(a_p)
    agenda &lt;- agenda + a_p.preconditions

  newPlan &lt;- plan

  for each threat on &lt;a_p -&gt; [p] -&gt; a_g&gt; or due to a_p do
    allResolvers &lt;- threat.getResolvers(newPlan)

    // backtracking
    if allResolvers.empty() then return failure

    resolver &lt;- allResolvers.chooseOne()
    newPlan &lt;- newPlan.refine(resolver)

  return PoP(newPlan, agenda)
</code></pre>

<p><em>back-propagation</em> 과 비슷하게 <em>goal</em> 부터 시작한다. <em>plan</em> 의 <em>casual links</em>, <em>binding</em> 을 추가해 가면서 진행한다.</p>

<h4 id="statespacevsplanspace">State-Space vs Plan-Space</h4>

<p><em>state-space</em> 플래너와 <em>plan-space</em> 플래너를 비교하면, </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/3-partial-plan/state_vs_plan_planner.jpg'  alt="" /></p>

<p>(1) <em>state-space</em> 는 유한한 탐색 공간을 가진다. 매 스탭마다 유한한 수의 오브젝트와 릴레이션을 다루기 때문이다. 반면 <em>plan-space</em> 에선 탐색공간이 무한할 수 있다. 그러나 무한한 공간을 모두 다 탐색하는 것은 아니고, 솔루션을 찾기 위해 그 일부만 탐색한다.</p>

<p>(2) <em>state-space</em> 는 보통 <em>graph</em> 로 표현되고, 실제로는 <em>tree</em> 를 탐색한다.  반면 <em>plan-space</em> 에서는 어떤 <em>intermediate representation</em> 을 사용하는지 명확하지 않다. 이건 상당히 중요한데, 대부분의 모던 휴리스틱 기법들이 <em>explicit representation of intermediate states</em> 에 의존하기 때문이다.</p>

<p>(3) <em>state-space</em> 기법에선 <em>action ordering</em> 이 어떻게 탐색할지를 결정하는 반면 <em>plan-space</em> 에서 <em>action</em> 의 선택과 <em>organization</em> 은 독립적이다. 더 유연하다.</p>

<p>(4) <em>state-space</em> 에선 <em>casual structure</em> 가 <em>implicit</em> 한 반면 <em>plan-space</em> 에선 <em>casual links</em> 라는 <em>explicit representation</em> 으로 보여진다. 왜 이 <em>action</em> 을 사용하는지에 대한 명확한 기준이 있기 때문에 <em>current plan</em> 이 잘못되었을 때 수정하기 더 쉽다.</p>

<p>(5) <em>state-space</em> 에서는 <em>search-node</em> 가 더 간단하다. <em>set of ground atoms</em> 기 때문에 <em>successor</em> 를 계산하기도 더 쉽다. 반면 <em>plan-space</em> 에서는 <em>constraint network</em> 를 유지해야 하기 때문에 복잡하고, <em>successor</em> 를 계산하기도 쉽지 않다.</p>

<p>요즘에는 효율적인 휴리스틱 때문에 <em>state-space</em> 가 좀 더 많이 이용되는 편이라고 한다.</p>

<h3 id="refs">Refs</h3>

<p>(1) <strong>Artificial Integelligence Planning</strong>, by Dr.Gerhard Wickler, Prof. Austin Tate <br />
(2) <a href='http://www.dailygalaxy.com/my_weblog/2013/10/artificial-intelligence-will-it-end-the-human-epoch.html' >brain image</a>  </p>]]></description><link>http://1ambda.github.io/ai-planning-3/</link><guid isPermaLink="false">6a780098-7f04-4775-882d-bfcb570c396b</guid><category><![CDATA[coursera]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[PSP]]></category><category><![CDATA[PoP]]></category><category><![CDATA[state-space]]></category><category><![CDATA[plan-space]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 25 Jan 2015 04:59:52 GMT</pubDate></item><item><title><![CDATA[AI Planning 2, Heuristic Search and STRIPS]]></title><description><![CDATA[<p><img src='http://imgs.xkcd.com/comics/ai.png'  alt="" /></p>

<p>이번 시간에는 <em>A* algorithm</em>, <em>heuristics</em>, <em>forward search</em> 등을 배운다.</p>

<h3 id="heuristicsearchstrategies">Heuristic Search Strategies</h3>

<p><em>FIFO</em> 나 <em>LIFO</em> 는 와 달리 <em>heuristic algorithm</em> 은 <em>search space</em> 에 대한 정보를 이용한다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/heuristic_function.png'  alt="" /></p>

<p><em>heuristic function</em> <code>h: state space -&gt; R</code> 은, <em>problem-specific knowledge</em> 를 <em>problem-independent way</em> 로 표현한다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/best_first_search.png'  alt="" /></p>

<p><em>best-first search</em> 알고리즘은 <em>general tree search</em> 알고리즘의 인스턴스로, 가장 낮은 <code>f(n)</code> 값을 가지는 노드를 선택해 탐색한다. 이를 위해 <code>f(n)</code> 값을 오름차순으로 정렬하는 <em>priority queue</em> 이용한다. </p>

<p>만약 <code>f(n) = h(n)</code> 이면, <em>greedy best-first search</em> 라 부른다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/greedy_best_fs.png'  alt="" /></p>

<p><em>optimal</em> 이 아닐 수 있다는 점에 유의하자.</p>

<p>루마니아 투어 문제를 다시 보자.</p>

<p><img src='https://spark-public.s3.amazonaws.com/aiplan/resources/touring-romania-map.png'  alt="" />
<img src='https://spark-public.s3.amazonaws.com/aiplan/resources/touring-romania-heuristic.png'  alt="" /></p>

<p><em>heuristic function</em> 으로 <em>straight line distance</em> 를 이용했는데, 실제 거리와는 차이가 있다. (꼬불꼬불하니까)</p>

<h3 id="aalgorithm">A* algorithm</h3>

<p><em>greedy best-first search</em> 알고리즘은 쉽지만, 항상 <em>optmial solution</em> 를 돌려주지 않는다는 단점이 있다. 여기서 배울 <em>A* algorithm</em> 은 항상 <em>optimal solution</em> 을 찾아낸다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/a_star_algorithm.png'  alt="" /></p>

<p><code>h(n)</code> 은 휴리스틱 펑션이고, <code>g(n)</code> 은 <code>n</code> 에 도달하기 까지의 비용이다. 그리고 이 두 함수를 이용해 만든 <em>evaluation function</em> <code>f(n)</code> 을 <em>best-first search</em> 에 적용해 최적의 해를 찾아낸다.</p>

<blockquote>
  <p>A* search is optimal if <code>h(n)</code> is admissible</p>
</blockquote>

<p><em>A* search</em> 를 이용해 <em>Touring Romania</em> 문제를 풀어보면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/a_star_touring.png'  alt="" /></p>

<p><em>greedy best-first search</em> 와 비교해보면 트리가 좀 더 큰데, 이건 <em>A* search</em> 가 일반적으로 좀 더 느리다는 사실을 보여준다.</p>

<p><br/></p>

<p><em>8-puzzle</em> 문제도 <em>A* search</em> 로 풀어보자. <em>empty tile</em> 을 옮긴다고 생각하고, <em>cost function</em> <code>g(n)</code> 은 모든 경우 <code>1</code> 로 볼 수 있다. 몇 가지 <code>h(n)</code> 을 생각해 볼 수 있는데,</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/eight_puzzle_heuristics.png'  alt="" /></p>

<p><em>Manhattan block distance</em> 는 제 자리까지 얼마나 더 움직여야하는지를 의미한다.</p>

<h3 id="propertiesofa">Properties of A*</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/admissible_heuristics.png'  alt="" /></p>

<p><em>admissible</em> 이란 말은, 항상 <code>h(n) &lt;= actual distance</code> 임을 의미한다. <code>f(n) = g(n) + h(n)</code> 이므로, <em>heuristic function</em> 이 <em>admissible</em> 하면 가장 적은 <code>f(n)</code> 을 찾는 <em>A* search</em> 는 <em>optimal solution</em> 을 돌려준다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/a_star_completeness.png'  alt="" /></p>

<p><em>A* search</em> 는 <em>complete</em> 하다. 이는 탐색 과정에서 <em>goal node</em> 를 포함한 <em>contour</em> (윤곽, 등고선) 에 도달하기 때문이다. 여기서 <em>contour</em> 란 같은 비용으로 도달할 수 있는 <em>sets of state</em> 다. <em>initial node</em> 에서 시작해서 <em>f-value</em> 가 증가하는 방향으로 탐색이 이루어지므로 결국 꼭지점(<em>goal</em>) 에 도달한다. 사실 <em>heuristics</em> 이 없다면 <em>A* search</em> 는 다익스트라 알고리즘과 동일하다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/touring_romania_contours.png'  alt="" /></p>

<p>기하학적으로 보면 <em>heuristic</em> 이 더 정밀해질 수록 타원이 <em>goal state</em> 에 가깝게 넓어진다.</p>

<p>그리고 <em>completeness</em> 속성은, 거꾸로 말하면 <em>optimal path</em> 를 찾기 위해서 그보다 더 적은 <em>cost</em> 를 가지는 모든 <em>path</em> 를 탐색해야 함을 말한다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/a_star_optimally_efficient.png'  alt="" /></p>

<p><em>A*star</em> 알고리즘은 같은 <em>heuristic</em> 을 이용해, 가장 적은 수의 <em>node</em> 를 확장하면서 <em>optimal solution</em> 을 돌려준다. 만약 이보다 더 적은 <em>node</em> 를 확장하면서, <em>optimal solution</em> 을 돌려준다면 <em>optmial solution</em> 이 아닐 수 있다.</p>

<p>물론 효율성을 결정하는건 <em>heuristic</em> 의 연산 비용 등이 있겠지만, 적어도 <em>node</em> 수와 관련해서는 <em>A* search</em> 가 최적이다.</p>

<h3 id="agraphsearch">A* Graph Search</h3>

<pre><code>function aStarTreeSearch(problem, h)  
  fringe &lt;- priorityQueue(new searchNode(problem.initialState))
  allNodes &lt;- hashTable(fringe)

  loop
    if empty(fringe) then return failure

    node &lt;- selectFrom(fringe) // lowest f-value

    if problem.goalTest(node.state) then
      return pathTo(node)

    for successor in expand(problem, node)
      if not allNodes.contains(successor) then
        fringe &lt;- fringe + successor @ f(successor) // g + h
        allNodes.add(successor)
</code></pre>

<p>여기서 <code>fringe &lt;- fringe + successor @ f(successor)</code> 부분은 <code>fringe</code> 가 우선순위 큐이므로, 우선순위를 결정할 값으로 <em>f-value</em> 인 <code>f(successor)</code> 을 이용한다는 뜻이다.</p>

<p>그리고 <code>if not allNodes.contains(successor) then</code> 부분에서, 사실 노드를 두번째로 발견할 때 더 짧은 경로일 수 있으므로 비교하는 부분이 필요하다. 그러나 <em>heuristic</em> 이 <em>admissible</em> 하지 않으므로 <em>A* search</em> 가 최적해를 돌려주지 않을 수 있다.</p>

<p>최악의 경우 <em>A*</em> 알고리즘은 <code>O(b)</code> 의 <em>time, space complexity</em> 를 가진다. 여기서 <code>b</code> 는 <em>branching factor</em> 이란 뜻이다. 다시 말해서 <em>exponential complexity</em> 란 말이다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/eight_puzzle_search_space.png'  alt="" /></p>

<p><em>eight-puzzle</em> 문제를 다시 보자.</p>

<p>그림에서 볼 수 있듯이, 빈 타일을 움직이다 보면 <em>initial state</em> 로 돌아올 수 있다. 만약 이 문제를 그래프로 표현하면 이미 방문한 노드를 다시 방문하고 있는지 해시테이블을 이용해 검사할 수 있다. 대신, 해시테이블을 만들고 사용하기 위한 비용이 든다. </p>

<p>반면 트리로 문제를 풀게되면, <em>exponential</em> 하게 <em>search space</em> 가 증가하기 때문에 <em>worst case</em> 에선 최적해를 찾기 위해 상당한 시간이 걸릴 수 있다.</p>

<p>한가지 더 생각해볼 문제는 <em>permutation</em> 이다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/permutation.png'  alt="" /></p>

<p>만약 모든 <em>action</em> 이 <em>independent</em> 하다면, <em>solution</em> 까지의 <code>n</code> <em>action</em> 중  <code>n-1</code> <em>contour</em> 를 모두 방문해야 하므로 <code>(n-1)!</code> 의 성능이 나온다.</p>

<h3 id="goodheuristics">Good Heuristics</h3>

<p><em>heuristics</em> 이란 <em>goal node</em> 까지의 <em>estimatied value</em> 를 돌려주는 함수라고 기술적으로 정의할 수 있다.</p>

<ul>
<li><strong>heuristics</strong> are criteria, methods, or principles for deciding which among several alternative courses of action promises to be the most effeictive in order to achieve some goal</li>
</ul>

<p>그렇다면, 무엇이 <em>good heuristics</em> 일까?</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/good_heuristics.png'  alt="" /></p>

<p>평가해야할 <em>state</em> 를 줄이고, 적정 시간 내에 <em>solution</em> 을 찾을 수 있어야 한다. 간단할수록 정확도가 떨어지며, 정확할수록 복잡해진다. <em>accuracy</em> 와 관련해서는, 최적의 <em>actions</em> 을 찾아낸다는 보장은 없지만 <em>good heuristics</em> 이라면 그렇지 않은 것 보다 더 자주 <em>best course of actions</em> 를 찾을 수 있어야 한다.</p>

<ul>
<li>문제가 주어졌을때, 어떻게 좋은 <em>heuristics</em> 을 찾아낼 수 있을까?</li>
<li>이 과정을 자동화 할 수 있을까?</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/relaxed_problem.png'  alt="" /></p>

<p><em>heuristics</em> 을 찾는 한 가지 방법은 <em>relaxed problem</em> 을 이용하는 것이다. <em>original problem</em> 에서 <em>action</em> 에 대한 <em>restriction</em> 을 좀 제거해서, 이에 대해 얻은 <em>optimal solution</em> 의 비용은 원본 문제에 대한 <em>admissible and consistent heuristic</em> 이다.</p>

<p>이는 <em>restriction</em> 이 제거되었기 때문에, 아무리 많아봐야 (<em>at most</em>) <em>original problem</em> 에 대한 <em>cost</em> 를 가지기 때문이다. 그러므로 <em>admissible</em> 하다. <em>eight-puzzle</em> 을 예로 들어보면 타일을 움직이는 <em>action</em> 에 대해 <em>adjacent</em> 또는 <em>blank</em> 조건을 버릴 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/8_puzzle_relaxed.png'  alt="" /></p>

<p>지금까지 배운내용들을 좀 정리하면</p>

<ul>
<li><p>Heuristic funciton encodes problem specific knowledge in a problem-independent way by mapping a state to a real number. This information about search states can be used to make the search more efficient</p></li>
<li><p>Greedy best-first search simply uses the heuristic function as the evaluation function. But better solution is provided by the A* algorithm. The evaluation function used by A* algorithm is simply the sum of the heuristic function for a node plus the cost of getting to thast node in the first place.</p></li>
<li><p>A* is optimal. It does not expand more nodes than absolutely necessary. But A* is not the answer to all questions, specifically when it comes to graph search.</p></li>
</ul>

<p><br/></p>

<h3 id="summary">Summary</h3>

<p>(1) <em>heuristic function</em> <code>h: state space -&gt; R</code> 은 <em>problem-specific knowledge</em> 를 <em>problem-independent way</em> 로 표현한다. 여기서 <code>h(n)</code> 값은 노드 <code>n</code> 에서 <em>goal</em> 까지의  <em>estimated cost</em> 의 최소 값이다.</p>

<p>(2) <em>best-first search</em> 는 <em>evaluation function</em> 인 <code>f</code> 를 기준으로 <code>f-value</code> 를 정렬해 다음에 어떤 노드를 탐색할지 결정한다.</p>

<p>(3) 만약 <code>f = h</code> 이면 <em>greedy best-first search</em> 라 부른다.</p>

<p>(4) <em>A* Search</em> 는 <em>evaluation function</em> <code>f(n) = h(n) + g(n)</code> 을 이용한다. <code>h(n)</code> 은 <em>heuristic function</em>, <code>g(n)</code> 은 <code>n</code> 까지 도달하는 비용이다. </p>

<p>(5) 따라서 <code>f(n)</code> 은 <code>n</code> 을 통과하여 <em>goal</em> 까지 도달하는데 걸리는 <em>cheapest solution</em> 의 <em>estimated cost</em> 다.</p>

<p>(6) 만약 <em>heuristic function</em> <code>h(n)</code> 이 <em>admissible</em> 하면, 다시 말해 <code>h(n) &lt;= actual distance</code> 이면 <em>A*</em> 는 <em>optimal solution</em> 을 돌려준다. 이는 <code>f(n) = g(n) + h(n)</code> 이기 때문이다.</p>

<p>(7) <em>A* search</em> 는 <em>complete</em> 하다. 이 말은 탐색과정에서 같은 비용으로 도달할 수 있는 모든 <em>state</em> 의 집합인 <em>contour</em> (등고선) 을 방문하면서 결국에는 <em>goal node</em> 를 찾는다는 뜻이다. </p>

<p>(8) 기하학적으로 보면 <em>heuristic</em> 이 정밀해질 수록 타원(등고선) 이 <em>goal state</em> 에 가깝게 넓어진다. </p>

<p><br/></p>

<h3 id="strips">STRIPS</h3>

<p>이제부터는 <em>STRIPS</em> 에 대해 알아보자. <em>planning</em> 의 본질은 원하는 <em>goal</em> 을 얻기 위한 <em>action</em> 을 결정하는 것이다. 즉, 시스템이 이런 결정을 내릴 수 있도록 해 주는 장치가 <em>planner</em> 인데, <em>STRIPS</em> 도 플래너다. </p>

<p><a href='http://en.wikipedia.org/wiki/STRIPS' >Wikipedia: STRIPS</a> 에 의하면</p>

<blockquote>
  <p>In artificial intelligence, STRIPS (Stanford Research Institute Problem Solver) is an <strong>automated planner</strong> developed by Richard Fikes and Nils Nilsson in 1971 at SRI International. The same name was later used to refer to the formal language of the inputs to this planner. This language is the base for most of the languages for expressing automated planning problem instances in use today; such languages are commonly known as action languages.</p>
</blockquote>

<p><em>STRIPS</em> 는 어떤 <em>action</em> 을 사용할지를 결정하는 시스템이므로 <em>representation</em> 과 <em>algorithm</em> 이 필요하다. </p>

<h3 id="structuredstates">Structured States</h3>

<p><em>representation</em> 의 일부인 <em>state</em> 에 대해 먼저 알아보자. <em>state</em> 에 <em>access</em> 할때는 </p>

<ul>
<li>goal test</li>
<li>applicable actions, successor states</li>
<li>equality test, hash function</li>
<li>heuristics estimate</li>
</ul>

<p>이런 행동을 하려면 <em>standardized</em> 된 <em>action</em> <em>state</em> 의 표현 방법이 있어야 하는데, <em>STRIPS repsentation</em> 이 하는 일이 바로 이것이다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/DWR_domain_object.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/DWR_domain_PDDL.jpg'  alt="" /></p>

<p>먼저 <em>object</em> 를 정의하고, 이를 <em>PDDL</em> <em>(Planning Domain Definition Language)</em> 로 작성한다. <em>robot</em> 은 쉽게 오브젝트라 생각할 수 있지만 <em>piles</em>, <em>pallet</em> 은 떠오르지 않을 수 있다. </p>

<p>두 <em>object</em> 간 관계는 <em>predicates</em> 라 부른다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/DWR_domain_predicates.jpg'  alt="" /></p>

<p>여기서 <code>?l1</code>, <code>?l2</code> 등 물음표로 시작하는 것은 변수고 그 타입은 <code>- location</code> 처럼 뒤에 나온다. <a href='https://spark-public.s3.amazonaws.com/aiplan/resources/DWR-operators.txt' >DWR-operators</a> 링크에서 예제 <em>PDDL</em> 을 볼 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/states_in_strips.jpg'  alt="" /></p>

<p>우리가 작성한 <em>language</em> <code>L</code> 에는 많은 <em>predicates</em>, <em>objects (constant symbols)</em> 이 있지만, <em>functional symbol</em> 은 없다. </p>

<blockquote>
  <p>A state in a STRIPS planning domain is <strong>a set of ground atoms</strong> of <code>L</code></p>
</blockquote>

<p>여기서 <em>atom</em> 이란 <em>a predicate</em> 고, <em>ground</em> 하다는 것은 <em>predicate</em> 과 관련된 <em>object</em> 가 <em>variable</em> 이 아니고, 구체적인 인스턴스라는 뜻이다. </p>

<p>(1) <em>ground atom</em> <code>p</code> 가 <em>state</em> <code>s</code> 내에 있을때에만 <code>p</code> 가 참이다.</p>

<p>(2) <em>literal</em> 은 <em>positive</em> 일 수도 있고, <em>negative</em> 일 수도 있는 <em>atom</em> 이다. 이 때 <em>ground literals</em> <code>g</code> 내에 있는 모든 <em>positive literal</em> 이 <code>s</code> 내에 있고, <code>g</code> 내에 있는 모든 <em>negative literal</em> 이 <code>s</code> 내에 없으면 <em>state</em> <code>s</code> 는 <em>ground literals</em> <code>g</code> 를 만족시킨다.</p>

<h3 id="structuredoperators">Structured Operators</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/operators_actinos_strips.jpg'  alt="" /></p>

<p><em>planning operators</em> 는 <em>name</em>, <em>pre-condition</em>, <em>effect</em> 로 구성되는데, <em>pre-cond</em> 과 <em>effect</em> 는 <em>literals</em> 의 집합이다.</p>

<p>그리고 <em>action</em> 은 <em>planning operator</em> 의 <em>ground instance</em> 다. </p>

<p>쉽게 말해서 <em>operator</em> 는 <em>variable</em> 가 있는 <em>predicate</em> 의 집합이고, <em>action</em> 은 거기서 변수를 <em>constant</em> (실제 <em>object</em>) 로 치환한 것이다. <em>operator</em> 가 좀 더 <em>generic</em> 하다고 보면 이해하기 쉽다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/DWR_domain_operators.jpg'  alt="" /></p>

<p>이 <em>operator</em> 를 <em>PDDL</em> 로 표현하면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/DWR_domain_operators_PDDL.jpg'  alt="" /></p>

<p>이제까지 본 <em>literals</em> 를 이용해 <em>applicable</em> 한지, 그리고 어떻게 <em>state transition</em> 을 하는지 살펴보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/state_transition_applicable.jpg'  alt="" /></p>

<p><code>L+</code>, <code>L-</code> 를 각각 <em>positive</em> <em>negative literals</em> 이라고 하자.</p>

<p><em>action</em> <code>a</code> <em>state</em> <code>s</code> 에 대해 <code>a</code> 의 <em>pre-cond+</em> 가 <code>s</code> 에 있고, <em>pre-cond-</em> 가 <code>s</code> 에 없으면 <em>applicable</em> 하다.</p>

<p>그리고 <em>applicable action</em> 에 대해서 <em>state transition</em> <code>r</code> 는 <em>state</em> <code>s</code> 에서 <code>a</code> 의 <em>effect-</em> 를 빼고, 거기에 <em>effect+</em> 를 합치는 것으로 정의한다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/finding_applicable_action.jpg'  alt="" /></p>

<ul>
<li><code>A</code> 는 <em>applicable actions</em> 다. 초기에는 <em>empty</em> </li>
<li><code>op</code> 는 <em>operator</em> </li>
<li><code>precs</code> 는 <em>remaining pre-cond</em></li>
<li>4번째 인자는 <em>value</em> 로 치환된 <em>substitution</em> 리스트다.</li>
<li><code>s</code> 는 <em>state</em></li>
</ul>

<p>먼저 <code>precs+</code> 가 비었는지 검사하고, 무언가 있다면 <code>pp</code> <em>positive pre-cond</em> 를 뽑아내, <em>propositions of state</em> <code>sp</code> 에서 <em>state</em> <code>s</code> 를 하나씩 검사한다. 만약 <em>substitution</em> 이 <em>valid</em> 하면 재귀적으로 반복한다.</p>

<p>더 이상 <code>precs+</code> 가 없으면 <code>precs-</code> 를 검사하면서, 만약 <em>state</em> 가 <em>negative pre-cond</em> <code>np</code> 를 만족하지 못하면, 리턴하고 모두 만족하면 <em>variable</em> 을 모두 치환하여 <em>applicable action</em> 리스트인 <code>A</code> 에 추가한다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/applicable_actions_ex.jpg'  alt="" /></p>

<p>그림에서 왼쪽 케이스를 보면 로봇 <code>r1</code> 이 도착지점인 <code>loc2</code> 에 존재할 수 없기 때문에 <em>not valid</em> </p>

<h3 id="domainsandproblems">Domains and Problems</h3>

<p><em>classical planning</em> 은 다음의 요소로 구성된다.</p>

<ul>
<li><strong>task:</strong> find solution for planning prolem</li>
<li><strong>planning problem:</strong> </li>
</ul>

<p>(1) initial state (atoms - relation, objects) <br />
(2) planning domain (operators - name, prec, effects) <br />
(3) goal  </p>

<ul>
<li><strong>solution</strong> (plan) </li>
</ul>

<p>STRIPS 도 마찬가지로</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/STRIPS_planning_domains.jpg'  alt="" /></p>

<p>따라서 <em>STRIPS planning</em> 문제는 <em>planning domain</em>, <em>inital state</em>, <em>goal</em> 로 구성된다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/STRIPS_planning_problems.jpg'  alt="" /></p>

<p><em>DWR domain</em> 간단예제를 좀 보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/DWR_domain_strips_ex1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/DWR_domain_strips_ex2.jpg'  alt="" /></p>

<p>전체 문제는 여기로 <a href='http://projects.laas.fr/planning/DWR-pb1' >DWR-pb1</a></p>

<p><br/></p>

<p>지금까지 본 것은 <em>planner</em> 에게 주어야할 <em>input</em> 이었다. 이제 <em>output</em> 인 <em>plan</em> 이 무엇인지 보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/classical_plans.jpg'  alt="" /></p>

<h3 id="statespacesearch">State-Space Search</h3>

<p>지금까지는 <em>representation</em> 에 대해 봤다. 지금부터는 STRIPS 에서 알고리즘을 어떻게 적용할지 알아보자. 기본적인 아이디어는</p>

<ul>
<li>search space is subset of state space</li>
<li>nodes correspond to world states</li>
<li>arcs correspond to state transitions</li>
<li>path in the search space correspaonds to plan</li>
</ul>

<p>따라서 <em>standard search algorithm</em> (e.g BFS, DFS, A*) 를 <em>planning problem</em> 에 적용할 수 있다. 좀 더 자세히 보자. <em>state-space planning</em> 을 <em>search problem</em> 으로 바꾸기 위해</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/state_space_to_search_problem.png'  alt="" /></p>

<p><em>initial state</em>, <em>goal</em>, 을 정하고 <em>path cost function</em> 으로 <em>action</em> 의 길이를 사용한다. <em>successor function</em> 은 </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/reachable_successor_states.png'  alt="" /></p>

<p><em>successor state</em> 를 표시하기 위해 감마를 사용하고, 지수 위치에 있는 <code>0, m</code> 등은 몇번째 <em>succssor</em> 인지를 나타낸다. <code>U</code> 는 합집합, 유니온이다. 따라서 <em>transitive closure</em> 는 가능한 모든 합집합이다. (<em>reachable states from initial state</em>)</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/solution_existence.png'  alt="" /></p>

<p>따라서 <em>STRIPS planning problem</em> 에서는 <em>goal state</em> <code>S_g</code> 와 <em>reachable state</em> 인 <em>transitive closure</em> 의 교집합이 <em>empty</em> 가 아니어야 솔루션이 존재한다.</p>

<h3 id="forwardstatespacesearch">Forward State-Space Search</h3>

<pre><code>function fwdSearch(O, s_i, g)  
  state &lt;- s_i
  plan &lt;- &lt;&gt;

  loop
    if state.satisfies(g) then 
      return plan

    applicables &lt;- {ground instance from O applicable in state}

    if applicable.isEmpty() then 
      return failure

    action &lt;- applicable.chooseOne() ; non-deterministic
    state &lt;- r(state, action)
    plan &lt;- plan * &lt;action&gt; ; add action to plan
</code></pre>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/DWR_example_fwd_search.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/forward_search_properties.png'  alt="" /></p>

<p><em>forward search</em> 는 두가지 속성을 가지는데</p>

<ul>
<li><strong>sound:</strong> if the function returns a plan as a solution then this plan is indeed a solution</li>
<li><strong>complete:</strong> if there exists solution plan then there is an execution trace of the function that will return this solution plan</li>
</ul>

<h3 id="backwardstatespacesearch">Backward State-Space Search</h3>

<p><em>backward search</em> 는 <em>intial state</em> 부터 시작하는 것이 아니라 <em>goal</em> 부터 시작해서 거꾸로 진행하는 알고리즘이다. 먼저 <em>relevant</em> 와 <em>regression set</em> 의 개념부터 알아보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/relevance_regression_sets.png'  alt="" /></p>

<p><em>action</em> <code>a</code>, <em>goal state</em> <code>g</code> 에 대해 </p>

<ul>
<li><code>g</code> 와 <code>effect(a)</code> 의 교집합이 <em>empty</em> 가 아니고</li>
<li><code>g+</code> 와 <code>effect-(a)</code>, <code>g-</code> 와 <code>effect+(a)</code> 의 교집합이 <em>empty</em> 이면</li>
</ul>

<blockquote>
  <p><code>a</code> is relevant for <code>g</code></p>
</blockquote>

<p>이 때 <em>releavant action</em> <code>a</code> 에 대해 <code>g</code> 의 <em>regression set</em> 은 </p>

<p><code>r^(-1) (g, a) = (g - effect(a)) U precond(a)</code> 로 정의한다. <em>relavant action</em> 의 <em>effect</em> 를 제거하고, 그의 <em>pre-condition</em> 을 넣으면 <em>previous state</em> 가 되기 때문이다. 예제를 좀 보면</p>

<pre><code>(define (problem random-pbl1)
  (:domain random-domain)
  (:init
     (S B B) (S C B) (S A C)
     (R B B) (R C B))
  (:goal (and (S A A))))

(define (domain random-domain)
  (:requirements :strips)
  (:action op1
    :parameters (?x1 ?x2 ?x3)
    :precondition (and (S ?x1 ?x2) (R ?x3 ?x1))
    :effect (and (S ?x2 ?x1) (S ?x1 ?x3) (not (R ?x3 ?x1))))
  (:action op2
    :parameters (?x1 ?x2 ?x3)
    :precondition (and (S ?x3 ?x1) (R ?x2 ?x2))
    :effect (and (S ?x1 ?x3) (not (S ?x3 ?x1)))))  
</code></pre>

<p>여기서 <em>relevant action</em> 은 <code>(op1 A A A)</code>, <code>(op1 A A C)</code>, <code>(op1 A B A)</code> 다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/regression_function.png'  alt="" /></p>

<p>따라서 <em>backward search</em> 알고리즘을 이용하면, <em>state-space planning</em> 을 <em>search problem</em> 으로 바꿀때는</p>

<ul>
<li>initial state <code>g</code></li>
<li>goal test: <code>s_i</code> satisfies <code>s</code></li>
<li>path cost function: length of actions</li>
<li>successor function: <code>r^-1 (s)</code></li>
</ul>

<p>예제를 좀 보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/2-heuristic-strips/regression_with_operators.png'  alt="" /></p>

<h3 id="summary">Summary</h3>

<p><em>STRIPS</em> 세션을 정리하면</p>

<ul>
<li>STRIPS representation provides a standardized way of representing the <strong>internal structure of states</strong>, namely a sets of ground atoms. So we have objects thar are related by some relations, and sets of these atoms describe what the world states look like.</li>
<li>define interal structure of operators look like. negative effects, positive effects.</li>
<li>define planning domains (initial, goal state), problem using PDDL</li>
<li>to solve planning problem, we can use forward, backward search. Buy they are actually inefficient</li>
</ul>

<p>따라서 다음시간엔 <em>forward, backward</em> 보다 더 효율적인 알고리즘을 배운다.</p>

<h3 id="refs">Refs</h3>

<p>(1) <strong>Artificial Integelligence Planning</strong>, by Dr.Gerhard Wickler, Prof. Austin Tate <br />
(2) <a href='http://imgs.xkcd.com/comics/ai.png' >xkcd image</a> <br />
(3) <a href='http://en.wikipedia.org/wiki/STRIPS' >Wikipedia - STRIPS</a>  </p>]]></description><link>http://1ambda.github.io/ai-planning-2/</link><guid isPermaLink="false">03874979-cc59-4b5f-b9b1-eccfefd1ccc2</guid><category><![CDATA[coursera]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[STRIPS]]></category><category><![CDATA[heuristic]]></category><category><![CDATA[forward-search]]></category><category><![CDATA[backward-search]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 18 Jan 2015 00:26:31 GMT</pubDate></item><item><title><![CDATA[AI Planning 1, Intro]]></title><description><![CDATA[<p><img src='http://www.jcjones.com/Portals/96864/images/IT%20strategic%20planning.png'  alt="" /></p>

<p><br/></p>

<p><em>planning</em> 이란</p>

<ul>
<li>explicit deliberation process that chooses and organizes actions by anticipating their outcomes</li>
<li>aims at acheving some <strong>pre-stated objecives</strong></li>
</ul>

<p>결국 <em>AI planning</em> 이란</p>

<blockquote>
  <p>computational study of this deliberation process</p>
</blockquote>

<p><br/></p>

<p>이런 관점에서 볼 때 <em>AI planning</em> 을 연구하는 이유는</p>

<ul>
<li><p><strong>scientific goal of AI:</strong> <em>understand inteligence</em>. planning is an important component of rational behaviour</p></li>
<li><p><strong>engineering goal of AI:</strong> <em>build intelligent entitie</em> which are choosing and organizing actions for autonomous intelligent machines</p></li>
</ul>

<p><br/></p>

<p><em>planning</em> 을 크게 <strong>domain-specific</strong>, <strong>domain-independent</strong> 로 분류할 수 있다.</p>

<ul>
<li><strong>domain-specific planning:</strong> use specific representations and techniques adapted to each problem. </li>
</ul>

<p>중요한 도메인으로 path and motion, perception, manipulation, commuication planning 등이 있다.</p>

<ul>
<li><strong>domain-independent planning:</strong> use generic representations and techniques. exploit commonalities to all forms of planning. leads to general understanding of planning</li>
</ul>

<blockquote>
  <p><em>domain-independent planning</em> complements <em>domain-specific planning</em> </p>
</blockquote>

<p><br/></p>

<h3 id="conceptualmodelforplanning">Conceptual Model for Planning</h3>

<p>모델로 <em>state-transition system</em> 을 사용하는데, 이 시스템은 <code>(S, A, E, r)</code> 로 구성된다. </p>

<ul>
<li><code>S = {s1, s2,  ... }</code> is a finite or recursively enumerable set of states</li>
<li><code>A = {a1, a2,  ... }</code> is a finite or recursively enumerable set of actions</li>
<li><code>E = {e1, e2,  ... }</code> is a finite or recursively enumerable set of events</li>
<li><code>r: S x (A u E) -&gt; 2^S</code> is a state trasition function</li>
<li>if <code>a</code> in <code>A</code> and <code>r(s, a)</code> is <strong>not empty</strong>, <code>a</code> is applicable in <code>s</code></li>
</ul>

<p><em>state trasition function</em> 은 상태 <code>S</code> 와 액션 <code>A</code> 또는 이벤트 <code>E</code> 를 받아, 가능한 모든 상태 <code>2^S</code> 를 만든다.</p>

<p><em>state trasition system</em> 은 그래프를 이용해서 표현할 수 있다. <code>G = (N, E)</code> 에서 <em>node</em> <code>N</code> 은 상태를, <em>edge</em> <code>E</code> 는 <em>state transition</em> 을 나타낸다.</p>

<p><em>state trasition system</em> 은 모든 가능한 상태를 표현하는 좋은 방법이다. 그러나 우리가 실제로 원하는건 <em>plan</em> 이다. 여기서 <em>plan</em> 이라 하면 주어진 특정 <em>state</em> 에서 시작해서, 원하는 <em>objective</em> 를 얻기까지의 <em>action</em> 을 말한다.</p>

<p><em>objective</em> 는 조건을 만족하는 특정 상태 <code>s</code> 나, 상태의 집합이 될 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/plan_execution.png'  alt="" /></p>

<p><em>planning</em> 문제를 풀기 위해 <em>plan execution</em> 을 이용하는 경우가 많다. <em>planner</em> 는 <em>state transition system</em> <code>sigma</code> 와 <em>initial state</em>, <em>objectives</em> 를 받아 <em>plan</em> 을 만들고, <em>controller</em> 가 이와 <em>current state</em> (<em>observation</em>) 을 받아 가능한 <em>action</em> 을 만든다. <em>system</em> 은 <em>action</em> 과 외부의 <em>event</em> 에 의해 변화한다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/dynamic_planning.png'  alt="" /></p>

<p>그러나 많은 경우 <em>model</em> 과 현실의 <em>system</em> 이 일치하지 않기 때문에, <em>dynamic planning</em> 이란 방법을 사용한다.</p>

<p>만약 <em>controller</em> 가 <em>real system</em> 과 <em>model</em> 이 다른 경우를 인식해서 <em>planner</em> 에게 <em>execution status</em> 를 넘겨주어 새로운 <em>plan</em> 을 만들도록 한다. 이걸 <em>plan revision</em> 이라 부른다.</p>

<h3 id="searchproblem">Search Problem</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/search_problem.png'  alt="" /></p>

<p><em>search problem</em> 의 4가지 요소는 </p>

<ul>
<li>initial state</li>
<li>successor function</li>
<li>goal</li>
<li>path cost</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/problem_formulation.png'  alt="" /></p>

<p>여기서 <em>static</em> 이란 말은 <em>no-event</em> 라는 뜻이다. <em>implicit time</em> 은 <em>activity</em> 의 <em>duration</em> 을 고려하지 않는다는 뜻이다.</p>

<h3 id="searchnode">Search Node</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/search_node.png'  alt="" /></p>

<p><em>search problem</em> 을 풀기 위한 알고리즘을 보기 전에, 어떻게 표현할 것인지를 먼저 이야기 하자. <em>search node</em> 의 구성 요소는</p>

<ul>
<li>state</li>
<li>parent node</li>
<li>action</li>
<li>path cost</li>
<li>depth</li>
</ul>

<p>이제 <em>general tree search algorithm</em> 을 보면</p>

<pre><code>function treeSearch(problem, strategy)  
  fringe &lt;- { new searchNode(problem.initialState) }

  loop
    if empty(fringe) then return failure

    node &lt;- selectFrom(fringe, strategy)

    if problem.goalTest(node.state) then
      return pathTo(node)

    fringe &lt;- fringe + expand(problem, node)
</code></pre>

<p>여기서 <code>problem</code> 은 <em>search problem</em> 으로, 위에서 언급 했듯이 <em>initial state</em>, <em>successor function</em>, <em>goal</em>, <em>path cost</em> 를 포함한다.</p>

<p><code>fringe</code> 는 아직 방문하지 않은 노드의 집합이고 마지막 부분에서 <code>expand</code> 함수는 <em>successor function</em> 을 적용해서 새로운 노드를 돌려준다. 이 과정을 <code>fringe</code> 가 비거나, 원하는 노드를 찾을때 까지 반복한다.</p>

<p>재밌는 사실은 <em>search graph</em> 가 유한하더라도 <em>search tree</em> 가 무한할 수 있다. 노드가 두개이면서 <em>bi-directed</em> 인 그래프를 생각해 보자.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/search_strategy.png'  alt="" /></p>

<p>위에서 본 <em>strategy</em> 는 <em>successfor function</em> 적용을 스케쥴링하는 요소다.</p>

<ul>
<li>selects the next node to be expanded from the fringe</li>
<li>determines the order in which nodes are expanded</li>
<li><strong>aim:</strong> produce a goal state as quickly as possible</li>
</ul>

<p><em>strategy</em> 가 <em>deterministic</em> 이면, 알고리즘도 <em>deterministic</em> 이라 볼 수 있다. 반대로 <em>strategy</em> 가 없으면 <em>non-deterministic</em> 이다.</p>

<p>대부분의 <em>search tree</em> 는 상당히 크다. 요즘 나오는 컴퓨터 메모리에도 올리기 부담스러울 정도로. 따라서 <em>strategy</em> 가 메모리에 올라갈 <em>tree</em> 부분을 결정하고, 그에 따라 알고리즘이 실패할지, 성공할지를 결정하므로 매우 중요하다.</p>

<h3 id="exampleproblem">Example Problem</h3>

<ul>
<li><strong>Sliding-Block Puzzle</strong> (<em>toy problem</em>)</li>
<li><strong>N-Queens</strong> (<em>toy problem</em>)</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/DWR_domain.png'  alt="" />
<img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/DWR_state.png'  alt="" />
<img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/DWR_action.png'  alt="" />
<img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/DWR_system.png'  alt="" /></p>

<h3 id="context">Context</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/o_plan_agent.png'  alt="" /></p>

<p><img src='https://spark-public.s3.amazonaws.com/aiplan/resources/AI-Planners-Chronology-1990-AI-Magazine.png'  alt="" /></p>

<p align="center">AI Planning, Coursera</p>

<p>그림의 윗 부분을 보면 <em>AI planning</em> 은 3가지 문제로부터 출발한 것을 볼 수 있다.</p>

<ul>
<li>Studies of Human Problem Solving</li>
<li>Operations Research</li>
<li>Theorem Proving</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/practical_ai_planner.png'  alt="" />
<img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/nonlin.png'  alt="" />
<img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/o_plan.png'  alt="" /></p>

<p><em>O-Plan</em> 은 유닉스 시스템 어드민의 역할을 수행했다고 한다. 쉘 스크립트를 만들고, 볼륨을 삭제하거나 추가하는 등</p>

<p><em>practical AI planner</em> 의 특징으로는</p>

<ul>
<li>hierarchical task network (HTN) planning</li>
<li>partial order planning (POP)</li>
<li>rich domain model</li>
<li>detailed constraint mgmt, simuilations and analyses</li>
<li>intergration with other systems (UI, DB, spreadsheets, etc)</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/ai-planning/1-intro/planning_area_tech.png'  alt="" /></p>

<h3 id="coursereading">Course Reading</h3>

<p>(1) <a href='http://aaaipress.org/ojs/index.php/aimagazine/article/download/833/751' >Review of AI Planners to 1990</a>  </p>

<p>Hendler, J.A., Tate, A. and Drummond, M. (1990) “AI Planning: Systems and Techniques”, AI Magazine Vol. 11, No. 2, pp.61-77, Summer 1990, AAAI Press. </p>

<p>(2) <a href='http://www.aiai.ed.ac.uk/project/ix/documents/2003/2003-luc-tate-oplan-web.pdf' >O-Plan Paper</a>  </p>

<p>Tate, A. and Dalton, J. (2003) “O-Plan: a Common Lisp Planning Web Service”, invited paper, in Proceedings of the International Lisp Conference 2003, October 12-25, 2003, New York, NY, USA, October 12-15, 2003. (4 pages) </p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://www.jcjones.com/Portals/96864/images/IT%20strategic%20planning.png' >Planning Image</a> <br />
(2) <a href='https://spark-public.s3.amazonaws.com/aiplan/resources/AI-Planners-Chronology-1990-AI-Magazine.png' >AI Planning History Image</a>  </p>]]></description><link>http://1ambda.github.io/ai-planning-1/</link><guid isPermaLink="false">4a959a91-fe5a-47d6-b77b-f5b6b976928a</guid><category><![CDATA[artificial intelligence]]></category><category><![CDATA[planning]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 17 Jan 2015 13:53:19 GMT</pubDate></item></channel></rss>