<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Old Lisper]]></title><description><![CDATA[Lisp, Emacs, Scala]]></description><link>http://1ambda.github.io/</link><generator>Ghost 0.5</generator><lastBuildDate>Mon, 08 Dec 2014 13:35:32 GMT</lastBuildDate><atom:link href="http://1ambda.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Machine Learning, Week 9]]></title><description><![CDATA[<p>이번시간엔 <em>anomaly detection</em> 과 <em>recommender system</em> 을 배운다.</p>

<h3 id="anomalydectectoin">Anomaly Dectectoin</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236753_7590.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236757_2205.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>anomaly</em> 는 정상집단에서 떨어진 데이터라 보면 된다. 공장에서 품질이 떨어지는 제품을 골라낼때 사용할 수 있는데, 위 그림은 비행기 엔진 공장을 예로 들어 설명한다.</p>

<p>데이터로부터 <code>p(x)</code> 를 만들어, 검사할 데이터가 <em>threshold</em> 를 넘는지 안넘는지 검사해 <em>anomaly</em> 로 판정할 수 있다.</p>

<p>참고로, <em>anomaly</em> 가 너무 많으면, <em>false positive</em> 가 높은 것인데 이 때는  <em>threshold</em> 를 줄이면 된다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236761_2830.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>anomaly detection</em> 은 <em>fraud detection</em> 에 많이 사용된다. 데이터로부터 모델 <code>p(x)</code> 를 만들고 <em>unusual user</em> 를 검사하기 위해 <code>p(x) &lt; e</code> 인지 검사하면 된다.</p>

<p>이외에도 항공기 엔진 예제처럼 제품의 품질 관리나, 데이터 센터에서의 노드 과부하 탐지등에 사용할 수 있다.</p>

<h3 id="gaussiandistribution">Gaussian Distribution</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236829_8964.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236829_8964.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>gaussian density</em> 공식은</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%28x%3B%20%5Cmu%2C%20%5Csigma%5E2%29%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20%5Cexp%28-%20%7B%28x%20-%20%5Cmu%29%5E2%20%5Cover%202%5Csigma%5E2%7D%29'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236839_1788.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>평균과 분산은</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cmu%20%3D%20%7B1%20%5Cover%20m%7D%20%5C%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x%5E%7B%28i%29%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csigma%5E2%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29'  alt="" /></p>

<p><br/></p>

<h3 id="anomalydetectionalgorithm">Anomaly Detection Algorithm</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236899_7015.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>각 <em>feature</em> 가 가우시안 분포를 따른다고 하면, </p>

<p><img src='http://latex.codecogs.com/gif.latex?p%28x%29%20%5C%5C%20%5C%5C%20%3D%20p%28x_1%3B%20%5Cmu_1%2C%20%5Csigma_1%5E2%29%5C%20p%28x_2%3B%20%5Cmu_2%2C%20%5Csigma_1%5E2%29%20%5Ccdots%5C%20p%28x_n%3B%20%5Cmu_n%2C%20%5Csigma_1%5En%29%20%5C%5C%20%5C%5C%20%3D%20%5Cprod_%7Bj%20%3D%201%7D%5En%20p%28x_j%3B%20%5Cmu_j%2C%20%5Csigma_j%5E2%29'  alt="" /></p>

<p>이렇게 가정하려면, 각 <em>feature</em> 가 독립적이어야 하지만 실제로는 독립적이지 않더라도 어느정도 동작한다. 이 때 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cmu_j%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x_j%5E%7B%28i%29%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csigma_j%5E2%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%7B%28x_j%5E%7B%28i%29%7D%20-%20%5Cmu_j%29%5E2%7D'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236904_6921.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>따라서 <code>p(x)</code> 는 아래 식이 된다. <code>p(x)</code> 는 <em>feature</em> 가 나올 확률로 이해하면 된다. 이 때 <code>p(x)</code> 가 상당히 작으면, 평균에 가깝지 않은 <em>feature</em> 가 많이 나왔다는 뜻이므로 <em>anomaly</em> 라 볼 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?p%28x%29%20%5C%5C%20%5C%5C%20%3D%20%5Cprod_%7Bj%3D1%7D%5En%20%5C%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma_j%5E2%7D%7D%20%5C%20%5Cexp%28-%7B%28x_j%20-%20%5Cmu_j%29%5E2%20%5Cover%202%5Csigma_j%5E2%7D%29'  alt="" /></p>

<p><br/></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236907_7102.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>두 <em>feature</em> <code>x1, x2</code> 의 가우시안 분포를 3차원으로 조합하면 <code>p(x)</code> 가 좌측 하단 3차원 원뿔의 높이가 된다.</p>

<h3 id="evaluatinganomalydetection">Evaluating Anomaly Detection</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236992_3664.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236996_4034.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>anomaly</em> 를 잘 나타낼거 같은 <em>feature</em> 를 골라내고, 이를 이용해 모델을 만든다. </p>

<p>우리가 가진 데이터가 <em>anomaly</em> 를 알려주는 <code>y</code> 가 있다면, 위 그림처럼 <em>training set</em> 으로 <em>non-anomalous</em> 을 이용하고, <em>CV, Test Set</em> 으로 나머지를 반반씩 분할하면 된다.</p>

<p>즉 <em>good example</em> 로 모델을 만들고, <em>anomaly</em> 가 섞여있는 <em>cv, test set</em> 으로 평가한다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361237001_5250.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>이 때 <em>skewed classess</em> 이기 때문에 (<code>y = 0</code> 이 대다수, <code>y = 1</code> 은 희박) 단순히 정확도로 평가하긴 좀 무리가 있다. <em>precision, recall, f1 score</em> 등을 이용해 평가해야 한다.</p>

<p><em>threshold</em> 인 <code>e</code> (엡실론) 를 고르기 위해 <em>cross validation</em> 을 이용할 수 있다. <em>f1 score</em> 를 최대화 하는 <code>e</code> 를 고른다거나.</p>

<h3 id="anomalydectectionvssupervisedlearning">Anomaly Dectection vs Supervised Learning</h3>

<p><code>y</code> 값이 있는 데이터라면, 왜 <em>supervised learning</em> 을 이용하지 않을까? </p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361242897_8389.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<h4 id="anomalydetection">Anomaly Detection</h4>

<p><em>anomaly detection</em> <em>skewed class</em> 가 있을 때 사용한다.</p>

<blockquote>
  <p>Many different <strong>types</strong> of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like</p>
  
  <p>Future anomalies may look nothing like any of the anomalous examples we've seen so far</p>
</blockquote>

<p>보면 알겠지만 <em>anomaly</em> 가 굉장히 다양할 수 있기 때문에 <em>anomaly</em> 를 특정 형태로 구분짓는 알고리즘을 쓰긴 좀 힘들다.</p>

<p>게다가, 가지고 있는 데이터 셋에서 보지 못했던 새로운 종류의 <em>anomaly</em> 가 나올 수도 있다.</p>

<h4 id="supervisedlearning">Supervised Learning</h4>

<p><em>positive, negative example</em> 이 많을 때 사용한다.</p>

<blockquote>
  <p>Enough positive examples for algorithms to get a sense of what positive examples are like, futre positive example likly to be similar to ones in training set</p>
</blockquote>

<p><em>supervised learning</em> 에서 <em>positive example</em> 은 어떤 특정 형태기 때문에, 미래에 발견할 <em>positive example</em> 도 비슷한 형태라 생각될 때 사용한다.</p>

<p><em>SPAM filtering</em> 에서는 다양한 타입의 <em>positive example</em> 이 있어도, 우리가 충분한 양의 <em>positive example</em> 이 있기 때문에 커버할 수 있어 <em>supervised learning</em> 을 사용한다.</p>

<p><br/></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361243087_2169.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><br/></p>

<h3 id="choosingwhatfeaturestouse">Choosing What Features to Use</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361244210_3429.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>feature</em> 의 분포가 가우시안이면 고맙지만, 아닐경우 변환이 필요하다. 왼쪽 아래 분포에 로그를 씌우면, 가우시안 분포 비슷하게 보인다.</p>

<p>다른 방법으로는 <code>log(x_2 + c)</code>, <code>sqrt(x_3)</code> 등등이 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361245473_5316.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>흔한 에러는 <code>p(x)</code> 가 <em>normal, anomalous</em> 에 대해서 모두 높은 경우인데, 슬라이드의 아래쪽에서 볼 수 있듯이 <code>x2</code> 라는 <em>feature</em> 를 만들어서 <em>anomaly</em> 를 발견하는 알고리즘을 만들 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361246077_9679.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>anomaly</em> 를 위한 <em>feature</em> 를 고를 때 특이하게 높거나, 낮을 수 있는 것을 고르면 된다. 데이터 센터 예제에서는 <em>CPU load / network traffic</em> 등이 있을 수 있다. 네트워크 트래픽이 낮은데 <em>CPU load</em> 가 높다면 확실히 <em>anomaly</em> 기 때문이다.</p>

<h3 id="multivariategaussiandistribution">Multivariate Gaussian Distribution</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361257865_7961.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>feature</em> 를 <em>CPU laod, memory use</em> 로 했을 때 낮은 CPU 부하에도 메모리 사용량이 높으면 <em>anomaly</em> 라 볼 수 있다.</p>

<p>그런데, 슬라이드의 왼쪽 그림에서 녹색으로 표시한 <em>anomaly</em> 는 지금까지 설명했던 알고리즘으로 찾기가 힘들다. 적당한 수준의 <em>memory use</em> 와 그리 낮지 않은 <em>cpu load</em> 를 가지기 때문이다.</p>

<p>실제 <em>normal example</em> 이 타원형이기 때문에, 원으로 <em>anomaly</em> 를 찾기는 어렵다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361258533_5107.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>따라서 <code>p(x_1)p(x_2)...</code> 을 이용한 모델 말고 다른 방법으로 모델을 만들어야 한다. </p>

<p><code>u</code> 를 <code>n</code> 벡터라 하고, <code>Sigma</code> 를 <code>u</code> 의 <em>convariance matrix</em> 라 하자. 그러면</p>

<p><img src='http://latex.codecogs.com/gif.latex?p%28x%3B%20%5Cmu%2C%20%5CSigma%29%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%20%282%5Cpi%29%5E%7Bn/2%7D%20%5C%20%7C%5CSigma%7C%5E%7B1/2%7D%7D%20%5C%20%5Cexp%28-%7B1%5Cover%202%7D%28x%20-%20%5Cmu%29%5ET%20%5C%20%5CSigma%5E%7B-1%7D%28x%20-%20%5Cmu%29%29'  alt="" /></p>

<p>여기서 <code>|Sigma|</code> 는 <code>Sigma</code> 의 행렬식인데, 여기를 참고하자.</p>

<ul>
<li><a href='http://ghebook.blogspot.com/2011/06/matrix.html' >행렬</a></li>
<li><a href='http://ghebook.blogspot.com/2011/06/determinant.html' >행렬식</a></li>
<li><a href='http://ghebook.blogspot.kr/2011/06/geometric-meaning-of-determinant.html' >행렬식의 기하학적 의미</a></li>
<li><a href='http://darkpgmr.tistory.com/104' >행렬식과 기하학적 활용</a></li>
</ul>

<p>이제 위 식을 이용해서 나온 <code>p(x)</code> 를 3차원, 2차원으로 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259228_7695.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259243_2967.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259236_1052.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><br/></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259583_5151.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cmu%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x%5E%7B%28i%29%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5CSigma%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%20%5C%20%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29%5ET'  alt="" /></p>

<p><br/></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259728_6035.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><code>u, Sigma</code> 를 찾아 <code>p(x)</code> 를 만들고, 테스트 데이터에 대해 <code>p(x) &lt; e</code> 인지 비교한다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361260300_1768.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>original model</em> 은 <em>multivariate model</em> 에서 각 <em>feature</em> 간 상관 관계가 없는 (독립), 즉 <em>covariance matrix</em> 가 <em>diagonal matrix</em> 인 경우다. (</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361260755_3407.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<ul>
<li><strong>Original model</strong></li>
</ul>

<p>수동으로 <em>feature</em> 를 만들때 사용할 수 있다. 또는 적은 연산을 원할때, 다시 말해서 <code>n</code> 이 커서 연산이 무지막지하게 클 때 좋다.</p>

<p><code>m</code> 이 작아도 쓸 수 있다.</p>

<ul>
<li><strong>Multivariate Gaussian</strong></li>
</ul>

<p>계산 비용이 비싸지만, 자동으로 <em>feature</em> 간 상관관계를 모델에 포함시킨다.</p>

<p><code>Sigma</code> 가 <em>invertible</em> 이기 위해서는 <code>m &gt; n</code> 이어야 한다. 실제로는 <code>m</code> 이 <code>n</code> 보다 훨씬 클 때 사용하는 경우가 많다. (e.g. <code>m &gt;= 10n</code>)</p>

<p>만약에 <code>m &gt; n</code> 인데, <code>Sigma</code> 가 <em>non-invertible</em> 이면 <em>redundant feature</em> 가 있는 경우니 확인해 보자. (흔한 오류라고 함)</p>

<h3 id="recommendersystem">Recommender System</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361324993_7588.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<h3 id="contentbasedrecommendations">Content Based Recommendations</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361325560_4034.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>위 슬라이드는 유저 <code>j</code> 로 부터 <code>theta^(j)</code> 를 얻어, <em>feature</em> <code>x</code> 와 곱함으로써 <em>linear regression</em> 문제로 변경했다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361326084_2070.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><code>theta^(j)</code> 는 어떻게 훈련시킬까?</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%7D%20%5C%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%7B1%20%5Cover%202m%5E%7B%28j%29%7D%7D%5C%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202m%5E%7B%28j%29%7D%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2'  alt="" /></p>

<p>여기서 <code>m^(j)</code> 는 유저 <code>j</code> 에 의해 점수를 받은 영화의 수인데, 어차피 상수이므로 제거하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%7D%20%5C%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%7B1%20%5Cover%202%7D%5C%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361326247_4648.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>이 때 각 유저마다의 <code>theta(j)</code> 를 합 해 최소화 시키는 방식으로 전체 <code>theta</code> 를 훈련시킬 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%2C%20%5Ccdots%20%5Ctheta%5E%7B%28n_u%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361326573_9477.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>gradient descent</em> 는</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28j%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28j%29%7D%20-%20%5Calpha%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%20%28%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%29x_k%5E%7B%28i%29%7D%20%5C%20%28for%5C%20k%20%3D%200%29'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28j%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28j%29%7D%20-%20%5Calpha%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%20%28%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%29x_k%5E%7B%28i%29%7D%20&plus;%20%5Clambda%5Ctheta_k%5E%7B%28j%29%7D%5C%20%28for%5C%20k%20%5Cneq%200%29'  alt="" /></p>

<h3 id="collaborativefiltering">Collaborative Filtering</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361327928_4438.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>content-based recommendation</em> 에서 <em>feature</em> 를 구하긴 사실 어려운 일이다. 누가 이 영화가 얼마만큼 로맨스고, 아닌지를 판별해줄까? </p>

<p>문제를 좀 변경해서, 만약에 유저로부터 <code>theta(j)</code> 를 얻어낼 수 있다면 그 정보로 부터 <em>feature</em> <code>x(i)</code> 를 추출할 수 있다. 왜냐하면 <code>(\theta^(j))^T * x^(i) ~ y^(i, j)</code> 이기 때문이다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361328443_4320.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><code>x^(i)</code> 를 얻기 위해, </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7Bx%5E%7B%28j%29%7D%2C%20%5Ccdots%20x%5E%7B%28n_m%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%20%5Csum_%7Bi%3A%20%5C%20r%28i%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%5Csum_%7Bk%3D1%7D%5En%28x_k%5E%7B%28i%29%7D%29%5E2'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361330430_7394.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<ul>
<li><code>theta</code> 가 주어지면 <code>x</code> 를 훈련할 수 있고</li>
<li><code>x</code> 가 주어지면 <code>theta</code> 를 훈련할 수 있다.</li>
</ul>

<p>따라서 최초의 랜덤 <code>theta</code> 에 대해 <code>x</code> 를 훈련하고, 다시 <code>theta</code> 를 훈련하고, 반복하면 된다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361495687_3476.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><code>theta</code> 와 <code>x</code> 를 반복해서 훈련시키는 것보다, 동시에 훈련시키는 것이 좀 더 효율적이다. 따라서</p>

<p><img src='http://latex.codecogs.com/gif.latex?J%28%7Bx%5E%7B%28j%29%7D%2C%20%5Ccdots%20x%5E%7B%28n_m%29%7D%2C%20%5Ctheta%5E%7B%28i%29%7D%2C%20%5Ccdots%20%5Ctheta%5E%7B%28n_u%29%7D%7D%29%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7B%28i%2C%20j%29%3A%20%5C%20r%28i%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%5Csum_%7Bk%3D1%7D%5En%28x_k%5E%7B%28i%29%7D%29%5E2%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2'  alt="" /></p>

<p>를 최소화 시키면 된다. 참고로 <code>x_0</code> 은 <em>collaborative filtering</em> 에서 필요가 없다. 알고리즘 자체가 <em>feature</em> 를 직접 찾아내니 <em>hard coded</em> 된 <em>feature</em> 는 사용하지 않는다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361495692_7530.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>(1) <code>x</code>, <code>theta</code> 를 작은 값으로 초기화 한다.</p>

<p>이는 <em>symmetry breaking</em> 을 하기 위함이다. 작은 랜덤값들로 초기화 하여 <code>x^(i)</code> 가 서로 다른 값들을 가지도록 도와준다.</p>

<p>(2) <em>cost function</em> <code>J</code> 를 <em>gradient descent</em> 등으로 최소화 시킨다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?x_k%5E%7B%28i%29%7D%20%3A%3D%20x_k%5E%7B%28i%29%7D%20-%20%5Calpha%20%5Csum_%7Bj%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5Ctheta_k%5E%7B%28j%29%7D%20&plus;%20%5Clambda%20x_k%5E%7B%28i%29%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28i%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28i%29%7D%20-%20%5Calpha%20%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5Cx_k%5E%7B%28i%29%7D%20&plus;%20%5Clambda%20%5Ctheta_k%5E%7B%28j%29%7D'  alt="" /></p>

<p>(3) 유저의 <em>parameter</em> <code>theta</code> 와 영화의 <em>feature</em> <code>x</code> 에 대해 <code>theta^T * x</code> 를 이용해 예측하면 된다.</p>

<h3 id="vectorizationlowrankmatrixfactorization">Vectorization: Low Rank Matrix Factorization</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361496844_8727.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361496849_5252.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>collaborative filtering</em> 은 <em>low rank matrix factoriazation</em> 이라 부르기도 한다. 위 슬라이드처럼 <code>X, THETA</code> 를 구성하고 <code>X * THETA^T</code> 를 구하면 된다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361496854_2443.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>low rank matrix factorization</em> 을 이용해서 <em>feature</em> 를 찾으면, 두 영화 <code>i, j</code> 가 얼마나 유사한지 <code>||x^(i) - x^(j)||</code> 으로 판단할 수 있다.</p>

<h3 id="implementationdetailmeannormalization">Implementation Detail: Mean Normalization</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361497832_3797.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>만약 위 슬라이드의 <code>Eve</code> 처럼 아무 영화도 평가 안한 사람에게는, <code>theta</code> 가 <code>0</code> 으로 나온다. (첫번째 <em>term</em> 이 <code>0</code> 이고, <em>regularization term</em> 은 <code>theta</code> 를 최소화한다.)</p>

<p>그렇게 되면, 어떤 영화도 높은 <em>rating</em> 을 받을 수 없으므로 (<code>theta^T * x</code>). 추천할 거리가 없다. 이건 별로 좋은 상황이 아닌데, <em>mean normalization</em> 을 이용하면 이 문제를 해결할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361497813_3878.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>mean normalized</em> 데이터를 이용하면, 추천 안한 사람이 <code>theta = 0</code> 을 갖더라도, 남들이 추천한 선호도 <code>u</code> 에 따라서 영화를 추천받을 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20&plus;%20%5Cmu_i'  alt="" /></p>

<p>잘보면 <em>feature scaling</em> 과는 다르게 특정 <em>range</em> 로 나누질 않는데, 이건 이미 <em>rating</em> 자체가 일정 범위 <code>1-5</code> 를 갖기 때문이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a> <br />
(4) <a href='http://ghebook.blogspot.com/2011/06/matrix.html' >http://ghebook.blogspot.com</a> <br />
(5) <a href='http://darkpgmr.tistory.com/104' >http://darkpgmr.tistory.com</a>  </p>]]></description><link>http://1ambda.github.io/machine-learning-week-9/</link><guid isPermaLink="false">0247c02a-4927-4ae8-957c-adf6590fac09</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine learning]]></category><category><![CDATA[anomaly detection]]></category><category><![CDATA[recommender system]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 07 Dec 2014 15:39:40 GMT</pubDate></item><item><title><![CDATA[A Poor Man's Concurrency Monad]]></title><description><![CDATA[<p><em>FP 101x</em> 의 최종 보스입니다. <del>Rose Tree 는 거들뿐</del> <em>Koen Claessen</em> 가 1999년에 발표한 <a href='http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.8039' ><em>Poor Man's Concurrenc Monad</em></a> 를 배경으로 하는 과제인데, 언어에 <em>primitive</em> 추가 없이 <em>concurrency</em> 를 모델링 하는 방법을 보여줍니다. </p>

<h3 id="continuation">Continuation</h3>

<p>먼저 용어부터 정의하고 가면, <em>continuation</em> 은 실행 가능한 <em>computation</em> 입니다. 필요할 때 사용할려고 미뤄둔 계산인데, 이게 프로세스를 모델링 하기에 적당합니다. 왜냐하면 프로세스도 멈추었다가, 나중에 다시 실행을 해야 하니까요!</p>

<p>나중에 쓰려고 미뤄둔 계산, 즉 <em>continuation</em> 을 지속적으로 넘겨가면서 사용하는 방식을 <em>continuation passing style</em> 이라 부릅니다. <em>CPS</em> 로 작성된 함수는 리턴하는 법이 없습니다. 다만 자신의 계산을 <em>continuation</em> 으로 만들어 넘겨줄 뿐이지요.</p>

<p>코드를 먼저 보시지요. 피타고라스 계산을 하스켈에서 <em>CPS</em> 로 작성하는 방법입니다. </p>

<pre><code class="haskell">square :: Int -&gt; Int  
square x = x * x

add :: Int -&gt; Int -&gt; Int  
add x y = x + y

square_cps :: Int -&gt; (Int -&gt; r) -&gt; r  
square_cps x = \cont -&gt; cont (square x)

add_cps :: Int -&gt; Int -&gt; (Int -&gt; r) -&gt; r  
add_cps x y = \cont -&gt; cont (add x y)

pythagoras_cps :: Int -&gt; Int -&gt; (Int -&gt; r) -&gt; r  
pythagoras_cps x y = \cont -&gt;  
  square_cps x $ \squared_x -&gt;
  square_cps y $ \squared_y -&gt;
  add_cps squared_x squared_y cont

&gt; square_cps 3 print
-- "9"

&gt; add_cps 3 4 print
-- "7"

&gt; pythagoras_cps 3 4 print
-- "25"
</code></pre>

<p>위 예제에서는 <code>print</code> 가 나중에 쓸려고 모셔둔 계산, 즉 <em>continuation</em> 입니다. 이 타입 <code>(Int -&gt; r) -&gt; r</code> 을 잘 기억해 두세요.</p>

<h3 id="processmodeling">Process Modeling</h3>

<p>프로세스를 모델링 하려면 상태와 작업 두 가지를 나타내야 합니다. 먼저 프로세스가 하는 작업에 대해서 모델링을 해 보겠습니다. 프로세스는 의 작업은 <code>Action</code> 이라 부르겠습니다. <code>Action</code> 은 <code>Atom</code> 이라 부르는 <code>IO</code> 연산일 수도 있고, 자식을 만드는 <code>Fork</code> 나, 프로세스를 멈추는 <code>Stop</code> 이 될 수 있습니다.</p>

<p><code>Atom</code> 은 <em>side-effect</em> 를 만드는 <em>atomic</em> 연산이라 보면 됩니다.</p>

<pre><code class="haskell">data Action =  
   = Atom (IO Action)
   | Fork Action Action
   | Stop
</code></pre>

<p>프로세스는 상태를 모델링 하기 위해 프로세스의 동작에 대해서 조금 논의해 봅시다. 프로세스는 자신의 작업이 있습니다. 우리는 <code>Action</code> 으로 표현했지요. 프로세스가 어떤 이유에서든지 중단된다면, 나중을 위해서 이 <code>Action</code> 을 기억해 둬야 합니다. 다시 작업을 해야하니까요!</p>

<p>아까 위에서 보았던 <code>(Int -&gt; r) -&gt; r</code> 기억 나시나요? <em>continuation</em> <code>Int - r</code> 을 이용해 결과 <code>r</code> 을 만들어 냈던 타입이지요. 이 타입을 잘 보면, <em>continuation</em> 이 공급될 때 <em>result <code>r</code></em>  을 얻을 수 있습니다. 여기서 결과인 <code>r</code> 은 다른 프로세스에게 밀려 중단된 작업 <code>Action</code> 이라 보시면 되고, 공급되는 <em>continuation</em> 은 <em>CPU</em> 와 같은 리소스라 보시면 됩니다. (그렇게 생각하는 편이 <del>정신건강에</del> 좋습니다.)</p>

<p>그러면, 비슷하게, 이런 타입을 생각해 볼 수 있습니다.</p>

<pre><code class="haskell">data Concurrent a = ((a -&gt; Action) -&gt; Action)  
</code></pre>

<p>이 타입은 <code>a -&gt; Action</code> <em>continuation</em> 을 받아, 결과 <code>Action</code> 을 돌려줍니다. </p>

<p>그러면 프로세스의 <strong>미뤄진 작업의 상태</strong>를 표현하는 <code>Concurrent</code> 에 <em>continuation</em> 을 공급해 <strong>미뤄진 작업</strong> <code>Action</code> 을 얻어내는 <code>action</code> 이란 함수를 만들 수 있습니다.</p>

<pre><code class="haskell">action :: Concurrent a -&gt; Action  
action (Concurrent concur) = concur (\a -&gt; Stop)  
</code></pre>

<p>또한 어떤 <em>continuation</em> 을 받던 무조건 멈추는 <code>Action</code> 을 돌려주는 <code>stop</code> 함수도 생각해 볼 수 있겠죠. 이건 <strong>멈춰진 작업의 상태</strong> 를 표현하는 <code>Concurrent</code> 라 보셔도 좋습니다.</p>

<pre><code>stop :: Concurrent  
stop = Concurrent (\cont -&gt; Stop)  
</code></pre>

<p>이제 <code>IO</code> 를 <code>Concurrent</code> 로 표현하기 위해 <code>IO a -&gt; Concurrent a</code> 로 변환해주는 <code>atom</code> 을 만들겁니다. 다시 말해서 이 함수는 <strong>멈춰진 <code>IO</code> 연산</strong> 을 돌려줘 하므로 <code>Concurrent</code> 내에 <code>Atom (IO Action)</code> 을 담아야 합니다. </p>

<p><code>cont a</code> 가 <code>Action</code> 이므로, <code>do</code> 내에서 <code>return (cont a)</code> 이면 <code>IO Action</code> 타입을 얻을 수 있겠죠? 쉽게 생각해서 <em>continuation</em> 인 <code>cont</code> 가 공급될 때 <code>IO</code> 를 수행한다 보면 되겠습니다.</p>

<pre><code class="haskell">atom :: IO a -&gt; Concurrent a  
atom \io -&gt; Concurrent $ \cont -&gt; Atom $ do a &lt;- io  
                                            return (cont a)
</code></pre>

<p>이제 프로세스를 분할하는 <code>Fork</code> 작업을 생각해 봅시다. 타입만 보면 <code>Fork Action Aciton</code>  입니다. 즉 두개의 <code>Action</code> 을 <code>Concurrent</code> 내에 담아야 합니다.</p>

<pre><code class="haskell">fork :: Concurrent a -&gt; Concurrent ()  
fork concur = Concurrent $ \cont -&gt; Fork (action concur) (cont ())  
</code></pre>

<p>보면, <code>action concur</code> 로 현재 미뤄진 작업에 대한 <code>Action</code> 을 추출하고, <em>continuation</em> 를 받아 <code>cont ()</code> 로 <em>continuation</em> 에 있는 다음 <code>Action</code> 을 뽑아냅니다. <em>continuation</em> 의 타입이 <code>a -&gt; Action</code> 인거 기억 나시죠?</p>

<p>비슷하게, 두개의 미루어진 작업을 받아 <code>Fork</code> 로 만드는 <code>par</code> 함수도 만들어 봅시다.</p>

<pre><code class="haskell">par :: Concurrent a -&gt; Concurrent a -&gt; Concurrent a  
par (Concurrent a) (Concurrent b) = Concurrent $ \cont -&gt; Fork (a cont) (b con))  
</code></pre>

<p>이제 <code>Concurrent</code> 간 <em>composition</em> 을 위해 <code>&gt;&gt;=</code>, <code>return</code> 을 구현하면</p>

<pre><code class="haskell">instance Monad Concurrent where  
    -- g :: \a -&gt; Concurrent b
    (Concurrent A) &gt;&gt;= g = 
      \contB -&gt; A (\contA -&gt; case g a of (Concurrent B) -&gt; B contB  
</code></pre>

<p>직관적인 이해는, <code>&gt;&gt;=</code> 자체는 두 <code>Concurrent</code> 간 연결입니다. 서로 다른 타입 <code>a, b</code> 에 대해서 <code>Concurrent</code> 가 어떻게 연결되야 하는지 생각해 보면 됩니다. </p>

<p><code>Concurrent a</code> 의 <code>Action</code> 을 얻기 위한  <em>continuation</em> 은, 다음 작업을 의미하는데 이 <em>continuation</em> <code>a' -&gt; Action</code> 에서의 <code>Action</code> 이 <code>Concurrent b</code> 의 <code>Action</code> 이라 보면 됩니다.</p>

<p>다시 말해서, <code>Concurrent a</code> 의 <code>Action</code> 의 다음 작업이 <code>Concurrent b</code> 의 <code>Action</code> 이란 뜻이지요. </p>

<p>마지막으로 <code>Action</code> 을 라운드 로빈 방식으로 스케쥴링하는 <code>roundRobin</code> 함수와, 실제로 <code>Concurrent a</code> 을 이용해 <code>roundRobin</code> 함수를 이용하는 <code>run</code> 함수를 보면,</p>

<pre><code class="haskell">roundRobin :: [Action] -&gt; IO ()  
roundRobin [] = return ()  
roundRobin (Atom x:xs) = x &gt;&gt;= \ac -&gt; roundRobin (xs ++ [ac])  
roundRobin (Fork x y : xs) = roundRobin (xs ++ [x, y])  
roundRobin (Stop : xs) = roundRobin xs

run :: Concurrent a -&gt; IO ()  
run x = roundRobin [action x]  
</code></pre>

<p>몇개의 헬퍼 함수와 테스트 코드도 좀 보겠습니다.</p>

<pre><code class="haskell">genRandom :: Int -&gt; [Int]  
genRandom 1337 = [1, 96, 36, 11, 42, 47, 9, 1, 62, 73]  
genRandom 7331 = [17, 73, 92, 36, 22, 72, 19, 35, 6, 74]  
genRandom 2600 = [83, 98, 35, 84, 44, 61, 54, 35, 83, 9]  
genRandom 42   = [71, 71, 17, 14, 16, 91, 18, 71, 58, 75]

loop :: [Int] -&gt; Concurrent ()  
loop xs = mapM_ (atom . putStr . show) xs

ex0 :: Concurrent ()  
ex0 = par (loop (genRandom 1337)) (loop (genRandom 2600) &gt;&gt; atom (putStrLn ""))

ex1 :: Concurrent ()  
ex1 = do atom (putStr "Haskell")  
         fork (loop $ genRandom 7331) 
         loop $ genRandom 42
         atom (putStrLn "")

myex0 = run $ (ho &gt;&gt; ho &gt;&gt; ho) &gt;&gt;  
              (hi &gt;&gt; hi &gt;&gt; hi) &gt;&gt; atom (putStr "\n")
  where ho = atom (putStr "ho")
        hi = atom (putStr "hi")

myex1 = run $ fork (ho &gt;&gt; ho &gt;&gt; ho) &gt;&gt;  
              (hi &gt;&gt; hi &gt;&gt; hi) &gt;&gt; atom (putStr "\n")
  where ho = atom (putStr "ho")
        hi = atom (putStr "hi")

myex2 = run $ fork (put3 "ba") &gt;&gt; fork (put3 "di") &gt;&gt;  
        put3 "bu" &gt;&gt; atom (putStr "\n")
  where put3 = sequence . take 3 . repeat . atom . putStr

myex3 = run $ par (put3 "ba") (put3 "di" &gt;&gt; stop) &gt;&gt;  
        atom (putStr "\n")
  where put3 = sequence . take 3 . repeat . atom . putStr

myex4 = run $ (par (put3 "ba") (put3 "di")) &gt;&gt;  
        atom (putStr "\n")
  where put3 = sequence . take 3 . repeat . atom . putStr

myex5 :: Concurrent ()  
myex5 = do fork (atom $ putStrLn "test")  
           atom $ putStrLn "hello"

myex6 :: Concurrent ()  
myex6 = do val &lt;- par (atom $ return "hi") (atom $ return "hello")  
           atom $ putStrLn val
</code></pre>

<h2 id="references">References</h2>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em> <br />
(3) <a href='http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.8039' >A Poor Man's Concurrency Monad</a></p>]]></description><link>http://1ambda.github.io/a-poor-mans-concurrency-monad/</link><guid isPermaLink="false">15feb78a-f5db-44ac-9bb6-acd63bdca8fd</guid><category><![CDATA[haskell]]></category><category><![CDATA[continuation]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 06 Dec 2014 15:35:51 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 8]]></title><description><![CDATA[<p>고차함수가 있는 다른언어와 비교했을 때 하스켈은 무슨 특징이 있을까요? 하스켈은 <em>expression</em> 을 평가하기 위해 디폴트로 <em>lazy evaluation</em> 을 사용한다는 점에서 다른 언어들과 다릅니다.</p>

<p>이번시간엔 <em>evaluation</em> 의 개념부터 시작해서, 다양한 종류의 <em>evaluation</em> 전략들을 살펴보겠습니다.</p>

<h3 id="evaluation">Evaluation</h3>

<ul>
<li>Avoid doing <strong>unnecessay evaluation</strong></li>
<li>Allows programs to be <strong>more modular</strong></li>
<li>Allows us to program with <strong>infinite lists</strong></li>
</ul>

<p>하스켈은 <em>lazy evaluation</em> 을 이용해 위에 나열한 것들을 제공합니다. <em>lazy evaluation</em> 을 이야기 하기 전에 먼저 <em>evaluation</em> 이 무엇인지 살펴봅시다.</p>

<blockquote>
  <p>Basically, expressions are evaluated or reduced by successively applying definitions until no further simplification is possible</p>
</blockquote>

<p>예를 들어서 <code>square n = n * n</code> 이란 <em>definition</em> 이 있을때, <em>expression</em> <code>square(3 + 4)</code> 는 이렇게 두 가지 방식으로 평가될 수 있습니다.</p>

<pre><code class="haskell">square (3 + 4)  
square 7  
7 * 7  
49

-- bad
square (3 + 4)  
(3 + 4) * (3 + 4)
7 * (3 + 4)  
7 * 7  
49  
</code></pre>

<p>만약에 아래 버전처럼 <code>(3 + 4) * (3 + 4)</code> 로 평가된다면, 똑같은 계산을 두번이나 하게 될 겁니다. 더 심각한 문제는 <em>side effect</em> 가 발생한다면 값이 달라질 수도 있다는 것이지요!</p>

<p>아래 예제를 한번 봅시다. <em>evaluation</em> 전략에 따라 값이 달라지는 것을 보여줍니다.</p>

<pre><code class="haskell">-- initially, n := 0

-- left first
n + (n := 1)  
0 + (n := 1)  
0 + 1  
1

-- right first
n + (n := 1)  
n + 1  
1 + 1  
2  
</code></pre>

<blockquote>
  <p><strong>FACT:</strong> In Haskell, two diffrent (but terminating) ways of evaluating the same expression will always give the same final result.</p>
</blockquote>

<p>다행히도 하스켈은 어떤 전략을 사용하든 <em>terminating expression</em> 에 대해서는 항상 같은 결과를 돌려줍니다. </p>

<h3 id="reductionstrategies">Reduction Strategies</h3>

<p>일반적으로 평가방법은 크게 두 가지로 나눌 수 있습니다. 어떤 <em>reducible subexpression (redex)</em> 를 선택하냐에 따라 </p>

<p>(1) <strong>Innermost reduction:</strong> An inner most redex is always reduced <br />
(2) <strong>Outermost reduction:</strong> An outermost redex is always reduced</p>

<pre><code class="haskell">loop = tail loop

// innermost reduction
fst (1, loop)  
fst (1, tail loop)  
fst (1, tail (tail loop))  
...

// outermost reduction
fst (1, lop)  
1  
</code></pre>

<p>위 결과를 보면 <em>innermost</em> 가 종료되지 않는 경우에도, <em>outermost</em> 는 결과를 돌려줄 수 있다는 사실을 알 수 있습니다. </p>

<p>또한 어느 하나의 <em>reduction sequence</em> 라도 종료된다면 <em>outermost reduction</em> 도 종료됩니다. 같은 결과를 돌려주면서요. 원문을 첨부하면,</p>

<blockquote>
  <p>For a given expression if there exists any reduction sequence that terminates, then outermost reduction <strong>also</strong> terminates, with the same result</p>
</blockquote>

<p><em>innermost</em> 에 비해 더 많은 경우에 종료되므로 <em>outermost</em> 가 좋다고 볼 수도 있겠습니다. 그러나, <em>outermost reduction</em> 은 좀 비효율적입니다.</p>

<pre><code class="haskell">// innermost
square (3 + 4)  
square 7  
7 * 7  
49

// outermost
square (3 + 4)  
(3 + 4) * (3 + 4)
7 * (3 + 4)  
7 * 7  
49  
</code></pre>

<p>따라서 하스켈에서는 <em>outermost</em> 에 <em>sharing</em> 을 더해 <em>lazy evalution</em> 이라 부르고 이 방법을 <em>evalution</em> 에 이용합니다.</p>

<pre><code class="haskell">square (3 + 4) -- sharing, n = (3 + 4)  
= n * n -- reduced shared expression `n` into 7
= 7 * 7
= 49
</code></pre>

<p><em>innermost, outermost</em> 예제를 좀 더 살펴봅시다.</p>

<pre><code class="haskell">mult :: (Int, Int) -&gt; Int  
mult (x, y) = x * y  
</code></pre>

<p>이제 <code>mult(1 + 2, 3 + 4)</code> 를 <em>innermost</em> 로 평가한다고 한다면,</p>

<pre><code class="haskell">mult(1 + 2, 3 + 4)  
mult(3, 3 + 4) -- conventionally, we select left innermost  
mult(3, 7)  
3 * 7 -- apply outermost  
24  
</code></pre>

<p><em>innermost</em> 는 <em>argument (인자)</em> 가 먼저 평가 되어야 하기 때문에, 인자가 <em>value</em> 인 경우 사용할 수 있습니다. 반대로 <em>outermost</em> 전략을 사용한다고 결정하려면 인자가 <em>name</em> 이어야 합니다. </p>

<p>어떤 함수들의 경우는 <em>outermost</em> 를 사용함에도 먼저 인자가 평가되어야 합니다. 예를 들어 <code>*, +</code> 같은 <em>built-in operator</em> 는 무조건 인자가 먼저 평가되야 합니다. 이런 함수들을 <em>strict</em> 하다고 말 합니다.</p>

<p>좀 더 엄밀한 정의는</p>

<blockquote>
  <p>A function f is said to be strict if, when applied to a nonterminating expression, it also fails to terminate.</p>
</blockquote>

<p><code>mult</code> 를 <em>curried function</em> 으로 재 작성해 봅시다.</p>

<pre><code class="haskell">mult :: Int -&gt; Int -&gt; Int  
mult x = \y -&gt; x * y

-- evaluation
mult (1 + 2) (3 + 4)  
mult 3 (3 + 4)  
(\y -&gt; 3 * y)(3 + 4)
(\y -&gt; 3 * y)(7)
3 * 7  
</code></pre>

<p>이제 인자가 한턴에 하나씩 계산됩니다. 이는 <code>mult 3 (3 + 4)</code> 에서 <em>left, innermost redex</em> 가 <code>mult 3</code> 이기 때문입니다. <code>mult (3, 3 + 4)</code> 에선 <code>3 + 4</code> 가 <em>left, innermost redex</em> 였지만요.</p>

<p>참고로 하스켈에서 <em>lambda expression</em> 내부의 <em>redex</em> 를 선택하는건 불가능합니다. 이는 람다도 함수이고, 함수 내부는 볼 수 없는 <em>black box</em> 이기 때문입니다.</p>

<blockquote>
  <p>Note that in Haskell, the selection of redexes within lambda expressions
  is prohibited. The rational for not “reducing under lambdas” is that functions are viewed as black boxes that we are not permitted to look inside.</p>
</blockquote>

<p>일반적으로 <em>innermost</em> 전략을 <em>call by value</em>, <em>outermost</em> 전략을 <em>call by name</em> 이라 부릅니다.</p>

<h3 id="infinitelist">Infinite List</h3>

<p>여기 <code>1</code> 의 무한한 나열을 표현하는 <code>ones</code> 에 대해 <em>expression</em> <code>head ones</code> 가 어떻게 평가되는지 <em>innermost</em> 와 <em>lazy evaluation</em> 의 두 가지 방법을 비교해 봅시다. </p>

<pre><code class="haskell">ones :: [Int]  
ones = 1 : ones

-- innermost
head one  
head (1 : one)  
head (1 : 1 : one)  
...

-- lazy evaluation
head one  
head (1: ones)  
1  
</code></pre>

<p><em>innermost</em> 의 경우에는 <em>evaluation</em> 이 끝나지 않습니다. 반면 <em>lazy evaluation</em> 은 식이 끝나면서 결과를 얻을 수 있죠.</p>

<blockquote>
  <p>Using <strong>lazy evaluation</strong>, expressions are only evaluated as much as required to produce the final result</p>
</blockquote>

<p>즉 필요한 만큼만 평가됩니다. 따라서 <em>lazy evaluation</em> 을 이용한 평가방법이 있으므로 <code>ones = 1 : ones</code> 처럼 무한할 <strong>가능성이 있는</strong> 데이터를 표현할 수 있습니다.</p>

<h3 id="modularprogramming">Modular Programming</h3>

<pre><code class="haskell">take 5 ones  
-- [1, 1, 1, 1, 1]
</code></pre>

<p>위의 예제에서 볼 수 있듯이 <em>lazy evaluation</em> 을 이용하면 <em>expression</em> 을 두 부분으로 나눕니다. </p>

<ul>
<li><strong>Control Part:</strong> <code>take 5</code></li>
<li><strong>Data:</strong> <code>ones</code></li>
</ul>

<p>인자를 받아 주어진 숫자만큼 복사하는 <code>replicate</code> 함수도 만들어 볼까요?</p>

<pre><code class="haskell">replicate' :: Int -&gt; a -&gt; [a]  
replicate' 0 _ = []  
replicate' n x = x : replicate' (n - 1) x  
</code></pre>

<h3 id="generateprimes">Generate Primes</h3>

<p>무한한 길이의 원소를 표현할 수 있다는 법을 배웠습니다. 이 방법을 이용해 존재하는 모든 소수의 집합을 표현하는 리스트를 만들어 볼까요? </p>

<p><em>Sieve of Eratosthenes (에라토스테네스의 체)</em> 란 방법을 사용하겠습니다. 알고리즘은 <a href='http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes' >여기</a> 를 참조하세요.</p>

<pre><code class="haskell">primes :: [Int]  
primes = seive [2..]

seive :: [Int] -&gt; [Int]  
seive (p : xs) = p : [x | x &lt;- xs, x `mod` p /= 0]

take 10 primes  
-- [2,3,5,7,9,11,13,15,17,19]

takeWhile (&lt;15) primes  
-- [2, 3, 5, 7, 11, 13]
</code></pre>

<h3 id="strictapplication">Strict Application</h3>

<p>하스켈에선 <em>lazy evaluation</em> 이 기본이지만, <em>strict</em> 버전으로 함수를 적용할 수 있는 방법도 제공합니다. <code>$!</code> 키워드를 이용하면 되는데요, <code>f $! x</code> 같은 경우 <code>f</code> 를 적용하기 전에 <code>x</code> 가 모두 평가되야 합니다.</p>

<p>더 엄밀히 말하면 <em>top-level of evaluation</em> 이 이루어지는데요, 인자 <code>x</code> 의 타입이 <code>Int</code> 나 <code>Bool</code> 같은 <em>basic type</em> 일 경우는 <em>complete evaluation</em> 이 이루어집니다.</p>

<p>반대로, <code>(Int, Bool)</code> 같은 복합타입이라면 <em>pair of expression</em> 이 얻어질 때 까지만 평가가 이루어집니다. 유사하게 타입이 리스트라면 <code>[]</code> 나 <code>a : b</code> 같은 컨싱이 얻어질때까지만 평가가 이루어집니다.</p>

<blockquote>
  <p>More formally, an expression of the form <code>f $! x</code> is only a redex once evaluation of the argument x, using lay evaluaion as normal, has reached the point where it is known that the result is not an undefined value, at which point the expression can be reduced to the normal application <code>f x</code></p>
</blockquote>

<p>예를 들어 <code>square $! (1 + 2)</code> 의 경우</p>

<pre><code class="haskell">square $! (1 + 2)  
square $! 3  
square 3  
3 * 3  
9  
</code></pre>

<p>다수개의 인자를 갖는 <em>curried function</em> 과 <code>$!</code> 가 쓰일 경우에는 다양한 형태가 될 수 있습니다.</p>

<pre><code class="haskell">(f $! x) y    -- forces top-level evaluation of x
(f x) $! y    -- forces top-level evaluation of y
(f $! x) $! y -- forces top-level evaluation of x and y
</code></pre>

<p>하스켈에서 <em>strict application</em> 은 주로 프로그램의 <em>space performance</em> 을 개선하기 위해 사용됩니다. 예를 들어 다음과 같은 <code>sumWith</code> 함수가 있다고 합시다. </p>

<pre><code class="haskell">sumWith :: Int -&gt; [Int] -&gt; Int  
sumWith v [] = v  
sumWith v (x:xs) sumWith (v + x) xs  
</code></pre>

<p><em>lazy evaluation</em> 에서는</p>

<pre><code class="haskell">sumWith 0 [1, 2, 3]  
sumWith (0 + 1) [2, 3]  
sumWith ((0 + 1) + 2) [3]  
sumWith (((0 + 1) + 2) + 3) []  
(((0 + 1) + 2) + 3)
...
...
6  
</code></pre>

<p>계산 전에 <code>(((0 + 1) + 2) + 3)</code> 가 만들어 지는걸 볼 수 있습니다. <code>sumWith 0 [1.. 10000]</code> 같은 큰 수의 계산일 경우 공간이 좀 아까울 수 있지요.</p>

<p>따라서 <code>sumWith</code> 에 <code>$!</code> 를 이용하면</p>

<pre><code class="haskell">sumWith v [] = v  
sumWith v (x:xs) = (sumWith $! (v + x)) xs

sumWith 0 [1, 2, 3]  
sumWtih $! (0 + 1) [2, 3]  
sumWith $! 1 [2, 3]  
sumWith 1 [2, 3]  
...
</code></pre>

<p><code>sumWith</code> 뿐만 아니라 고차함수인 <code>foldl</code> 등에도 적용해 볼 수 있습니다.</p>

<pre><code class="haskell">foldl' :: (a -&gt; b -&gt; a) -&gt; a -&gt; [b] -&gt; a  
foldl' f v [] = v  
foldl' f v (x:xs) ((foldl' f) $! (f v x)) xs  
</code></pre>

<p>이러면, <code>sumWith</code> 를 <code>foldl' (+)</code> 로 정의할 수 있습니다.</p>

<h2 id="references">References</h2>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em>  </p>]]></description><link>http://1ambda.github.io/haskell-intro8/</link><guid isPermaLink="false">d903754f-78ce-4128-8c4f-51567d031c97</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[lazy evaluation]]></category><category><![CDATA[call by value]]></category><category><![CDATA[call by name]]></category><category><![CDATA[strict]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 04 Dec 2014 08:46:14 GMT</pubDate></item><item><title><![CDATA[Graph Challenges, Minimum Spanning Trees, Shortest Paths]]></title><description><![CDATA[<h3 id="graphprocesschallenge1">Graph Process Challenge 1</h3>

<h4 id="isagraphbipartite">Is a graph bipartite?</h4>

<p>그래프가 <em>bipartite</em> 인가 하는 문제는, 그래프의 노드를 이렇게 두 그룹으로 나눌 수 있느냐 하는 문제다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Simple-bipartite-graph.svg/330px-Simple-bipartite-graph.svg.png'  alt="" /></p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Biclique_K_3_5.svg/330px-Biclique_K_3_5.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<p>알고리즘이 얼마나 어려운가는 이렇게 나눠볼 수 있겠는데</p>

<ol>
<li>Any programmer could do it  </li>
<li>Typical diligen algorithms student could do it  </li>
<li>Hire an expert  </li>
<li>Intractable  </li>
<li>No one knows  </li>
<li>Impossile</li>
</ol>

<p><em>biparting</em> 문제는 <em>DFS-based solution</em> 을 이용할 수 있으므로, 난이도 2정도에 해당한다 볼 수 있겠다. </p>

<p>생각해 볼 수 있는 응용은, 질병의 전파 경로를 그래프로 그리고 <em>biparting</em> 이 가능한지 보는 것이다.</p>

<h4 id="findacycle">Find a cycle</h4>

<p>이것도 난이도 (2) 정도. 마찬가지로 <em>simple DFS-based solution</em> 을 이용하자.</p>

<p>잘 알려진 응용으로, <em>euler tour</em> 가 있다. 각 <em>edge</em> 를 단 한번씩만 방문하는 <em>cycle</em> 이 있는지를 검사하는 문제다. 여기서 시작점과 끝 점이 같으면 <em>euler circuit</em> 이고, 다르면 <em>euler path</em> 라 부른다.</p>

<p><a href='http://ko.wikipedia.org/wiki/%EC%98%A4%EC%9D%BC%EB%9F%AC_%EA%B2%BD%EB%A1%9C' >여기</a>에 의하면 그래프에 오일러 회로가 존재하려면 </p>

<p>(1) 연결된 그래프여야 하고 <br />
(2) 모든 꼭지점의 차수가 짝수여야 한다.</p>

<p>반면 오일러 경로라면, 연결그래프에서 정확히 두 개의 꼭지점만 홀수 차수여야 한다.</p>

<p>각 <em>node</em> 를 정확히 한번씩만 지나는 <em>cycle</em> 을 <em>traveling salesman problem, TSP</em> 혹은 <em>hamiltonian path problem</em> 이라 부른다.</p>

<p>오일러 순회와 경로처럼 시작점과 끝점이 같은지, 아닌지에 따라 구분할 수 있다. <em>hamiltonian cycle</em> 은 전형적인 <em>NP-complete problem</em> 으로 알려져있다. 난이도로 구분하자면 <em>(4) intractable</em> 정도 되시겠다.</p>

<h4 id="graphisomorphismproblem">Graph Isomorphism Problem</h4>

<blockquote>
  <p>Are two graphs identical except for vertex names?</p>
</blockquote>

<p>그래프의 형태가 같은지 묻는 문제다. 예를 들어 다음의 두 그래프는 같은 형태다.</p>

<p><img src='http://www.biodatamining.org/content/figures/1756-0381-4-10-3-l.jpg'  alt="" /></p>

<p align="center">(<a href='http://www.biodatamining.org/' >http://www.biodatamining.org/</a>)</p>

<p>두 그래프의 노드를 <code>n!</code> 으로 배열해 가면서 같은지 비교하는 단순한 방법은 그래프가 커지면 기하 급수적으로 성능이 느려진다. 더 나은 알고리즘이 있는지 연구자들이 노력하고 있지만, 아직 모른다. 난이도는 <em>(5) No one knows</em></p>

<h4 id="graphsplanarity">Graphs Planarity</h4>

<p>그래프를 <em>crossing edge</em> 가 없는 그래프로 그릴 수 있느냐 하는 문제다.</p>

<blockquote>
  <p>평면 그래프(planar graph)는 평면 상에 그래프를 그렸을 때, 두 변이 꼭지점 이외에 만나지 않도록 그릴 수 있는 그래프를 의미한다.</p>
</blockquote>

<p>이건 난이도 <em>(3) Hier an expert</em> 문제다. <em>DFS</em> 기반의 <em>linear time</em> 알고리즘이 1970년대에 발표되었다.</p>

<h3 id="minimumspanningtrees">Minimum Spanning Trees</h3>

<p><em>undirected, positive edge weights</em> 그래프에서 </p>

<p>(1) <em>connected, acyclic</em> <strong>(tree)</strong> <br />
(2) <em>includes all of the vertices</em> <strong>(spanning)</strong>   </p>

<p>인 서브 그래프를 <strong><em>spanning tree</em></strong> 라 부른다.</p>

<p><strong><em>minimum spanning tree</em></strong> 는 여기서 <em>min weight</em> 를 갖는 <em>spanning tree</em> 를 찾는 문제다.</p>

<h4 id="applications">Applications</h4>

<ul>
<li>dithering</li>
<li>cluster analysis</li>
<li>max bottleneck paths</li>
<li>network design</li>
</ul>

<p>등에 활용할 수 있다.</p>

<h3 id="mstgreedyalgorithm">MST: Greedy Algorithm</h3>

<p>간단한 설명을 위해서 그래프가 연결되어있고 <em>weight</em> 가 모두 다르다 하자. 그럼 <em>MST</em> 는 하나만 존재할 것이다.</p>

<p>먼저 <em>cut, crossing edge</em> 용어 정리를 하면</p>

<blockquote>
  <p><strong>Cut:</strong> A cut is a graph is a partition of its vertices into two (nonempty) sets</p>
  
  <p><strong>Crossing edge:</strong> A crossing edge connects a vertex in one set with a vertex in the other</p>
</blockquote>

<p>그러면, 이런 <em>cut property</em> 가 존재한다.</p>

<blockquote>
  <p>Given any <strong>cut</strong>, the crossing edge of min weight is in the MST</p>
</blockquote>

<p>증명은 <em>min-weight crossing edge</em> <code>e</code> 가 <em>MST</em> 내에 없다고 하자. <em>MST</em> 는 연결되야 하므로 다른 <em>crossing edge</em> <code>f</code> 가 대신 사용될 것이다. </p>

<p>(1) 다른 <em>crossing edge</em> <code>f</code> 가 없으면 <em>connected</em> 가 아니므로 <em>MST</em> 가 아니다. <br />
(2) 만약 <code>f</code> 가 있어서 <code>f</code> 를 대신 사용하는 <em>MST</em> 에 <code>e</code> 를 추가하면 사이클이 생긴다. 이 때 <code>f</code> 를 제거하면 <em>weight</em> 가 더 짧다. 따라서 <code>f</code> 가 포함되면 <em>MST</em> 가 아니다.</p>

<p>따라서 <em>min-weight crossing edge</em> 가 <em>MST</em> 내에 존재한다. 이 사실을 이용하면 <em>MST</em> 를 찾는 <em>greedy algorithm</em> 을 만들 수 있다.</p>

<pre><code>- Start with all edges colored gray
- Find cut with no black corssing edges; 
   color its min-weight edge black
- Repeat until V - 1 edges are colored black
</code></pre>

<p>즉 어떤 <em>cut</em> 에 대해서 <em>min-weight crossing edge</em> 가 <em>MST</em> 에 포함되므로, 이미 찾은 <em>MST edge</em> 를 포함하지 않는 <em>cut</em> 을 찾아, <em>min-weight crossing edge</em> 을 추가해 나가면 된다.</p>

<h4 id="correcteness">Correcteness</h4>

<p>(1) Any edge colored black is in the MST (vis cut property) <br />
(2) Fewer than <code>V - 1</code> black edges => cut with no black crossing edges</p>

<p>모든 <em>MST</em> 는 <code>V - 1</code> 개의 <em>edge</em> 로 구성된다. 따라서 <code>V - 1</code> 개의 <em>black edge</em>, 즉 <em>MST</em> 의 원소를 찾아내면 된다. </p>

<h3 id="edgeweightedgraphapi">Edge-Weighted Graph API</h3>

<pre><code class="java">public class Edge implements Comparable&lt;Edge&gt; {  
  Edge(int v, int w, double weight)
  int either()
  int other(int v)
  int compareTo(Edge that)
  ...
}

// allow self-loops and parallel edges
public class EdgeWeightedGraph {  
  EdgeWeightedGraph(int V) // V vertices
  void addEdge(Edge e)
  Iterable&lt;Edge&gt; adj(int v) // edges incident to v
  Iterable&lt;Edge&gt; edges() // all edges
  Int V() // # of vertices
  int E() // # of edges
}

public class MST {  
  MST(EdgeWeigtedGraph G)
  Iterable&lt;Edge&gt; edges()
  double totalWeight()
}
</code></pre>

<h4 id="removingassumptions">Removing assumptions</h4>

<ul>
<li>What if edge weights are not all distinct?</li>
</ul>

<blockquote>
  <p>Greedy MST algorithm still correct if equal weights are present. (our correctness proof fails, but that can be fixed)</p>
</blockquote>

<ul>
<li>What if graph is not connected?</li>
</ul>

<blockquote>
  <p>Compute MS forest = MST of each components</p>
</blockquote>

<h3 id="kruskalsalgorithm">Kruskal's Algorithm</h3>

<pre><code>- Sort edges in ascending order of weight. 
- Add next edge to tree T 
  unless doing so would create a cycle 
  (until V - 1 edges added) 
</code></pre>

<p><em>kruskal's algorithm</em> 은 <em>greedy MST</em> 의 일종이라 볼 수 있다.</p>

<p>선택된 <em>edge</em> <code>e = v &lt;-&gt; w</code> 라 하고 이것을 <em>crossing edge</em> (<em>cut</em> 이라 볼 수 있다), 하면 </p>

<p><em>black edge</em> 간 <em>no cycle</em> 인 <code>e</code> 를 선택한 것이므로 <code>v &lt;-&gt; w</code> 사이엔 <em>black crossing edge</em> 가 없다. </p>

<p>게다가 선택하는 <em>crossing edge</em> 는 가장 작은 <em>weight</em> 를 가진다. 이 전에 이미 더 작은 <em>weight</em> 의 <em>edge</em> 를 모두 선택했기 때문이다.</p>

<p>따라서 크루스칼 알고리즘은 <em>greedy MST</em> 의 일종이다.</p>

<h4 id="cyclecheck">Cycle Check</h4>

<p>어떻게 <em>Cycle check</em> 를 할까? 한 가지 방법은 <em>edge <code>e = v - w</code></em> 에 대해 <code>v - w</code> 가 연결되어있는지 <em>DFS</em> 를 돌리면 된다. 그러면 <code>O(V)</code> 로 사이클을 검사할 수 있다.</p>

<p>단순히 연결되어있는지만 검사하는 것이므로 <em>union find</em> 를 쓰면 <code>O(log* V)</code> 로도 가능하다. <a href='http://1ambda.github.io/union-find-algorithms-week-1/' >Union-find</a> 를 참고하자.</p>

<h4 id="kruskalmstimplementation">Kruskal MST Implementation</h4>

<pre><code class="java">EdgeWeightedGraph G;  
int V = G.V()  
UF uf = new UF(V);

Queue&lt;Edge&gt; mst = new Queue&lt;Edge&gt;();  
MinPQ&lt;Edge&gt; pq = new MinQP&lt;Edge&gt;();

for (Edge e : G.edges())  
  pq.enqueue(e);

while (!pq.isEmpty() &amp;&amp; mst.size() &lt; V - 1) {  
  Edge e = pq.dequeue();
  int v = e.either();
  int w = e.other(v);

  if (!uf.connected(v, w)) {
    uf.union(v, w);
    mst.enqueue(e);
  }
}
</code></pre>

<p><em>running time</em> 은 <code>E log E</code> 다. </p>

<ul>
<li>build <code>pq</code>: <code>1 * E</code></li>
<li>dequeue: <code>E * log E</code></li>
<li>union: <code>V * log* V</code></li>
<li>connected: <code>E * log* V</code> </li>
</ul>

<h3 id="primsalgorithm">Prim's Algorithm</h3>

<pre><code>- start with vertex 0 and greedily grow tree T
- add to T the min weight edge with exactly one endpoint in T
- repate until V - 1 edge
</code></pre>

<h4 id="correctness">Correctness</h4>

<p>마찬가지로 <em>prim's algorithm</em> 도 <em>greedy MST</em> 의 일종이다.</p>

<p>방문한 노드와 방문하지 않은 노드를 <em>cut</em> 해 거기서 <em>min-weight edge</em> 를 선택한다. 따라서 <em>cut</em> 자체가 방문하지 않은 노드와 방문한 노드 두 집합을 만드므로 <em>crossing edge</em> 중에는 <em>black edge</em> 가 없다. </p>

<h4 id="primmstimplementation">Prim MST Implementation</h4>

<p><em>lazy implementation</em> 으로 현재 선택할 수 있는 <em>edge</em> 를 <em>weight</em> 기준으로 <em>priority queue</em> 에 유지하는 방법이 있다.</p>

<p><em>queue</em> 에 있는 <em>edge</em> <code>e = (v, w)</code> 를 꺼낸 뒤</p>

<p>(1) <code>v, w</code> 둘 다 이미 방문했으면 패스하고, <br />
(2) <code>v</code> 혹은 <code>w</code> 둘 중 하나만 방문했을 경우에만 <code>w or v</code> 의 <em>edge</em> 를 추가하고, <code>w or w</code> 를 방문 처리 한다. </p>

<pre><code class="java">// lazy Prim MST

boolean[] marked // MST vertices  
Queue&lt;Edge&gt; mst = new Queue&lt;Edge&gt;();  
MinPQ&lt;Edge&gt; pq = new MinPQ&lt;Edge&gt;();  
WeightedGraph G;

visit(G, 0);

while (!pq.isEmpty()) {  
  Edge e = pq.dequeue();
  int v = e.either();
  int w = e.other(v);

  if (marked[v] &amp;&amp; marked[w]) continue;

  mst.enqueue(e);

  // add v or w
  if (!marked[v]) visit(G, v);
  if (!marked[w]) visit(G, w);
}

void visit(int v) {  
  marked[v] = true;
  for (Edge g : G.adj(v)) {
    if (!marked[e.other(v)]) pq.insert(e);
  }
}
</code></pre>

<p><em>running time</em> 은 <code>O(E log E)</code> 다.</p>

<p>좀 더 나은 알고리즘은 <em>MST</em> 에 <em>edge</em> <code>e = (v, w)</code> 를 추가할때, 이미 방문한 <code>w</code> 와 방문하지 않은 <code>v</code> 에 대해</p>

<p><code>v</code> 에서 갈 수 있는 모든 <em>edge</em> <code>e = (v, x)</code> 을 생각해 보면, </p>

<p>(1) <code>x</code> 가 이미 방문한 <em>vertex</em> 면 패스 <br />
(2) <em>queue</em> 에 <code>(k, x)</code> 가 없으면 추가 (<code>k</code> 는 이미 방문한 <em>vertex</em>) <br />
(3) <code>x</code> 까지의 거리가, <code>e = (v, x)</code> 가 더 짧으면 업데이트 (<em>decreaseKey operation</em>)</p>

<p>여기서 <code>decreaseKey</code> 연산을 빠르게 구현하기 위해 <em>indexed priority queue</em> 를 이용할 수 있다.</p>

<pre><code>void decreaseKey(int i, Key key)  
</code></pre>

<p>전체 러닝타임은 </p>

<ul>
<li><code>V</code> <em>insert</em></li>
<li><code>V</code> <em>delete min</em></li>
<li><code>E</code> <em>decrease key</em></li>
</ul>

<p>인데, <em>Priority Queue</em> 구현하는데 어떤 자료구조를 사용하느냐에 따라 각 연산의 시간이 달라진다.</p>

<p>(1) Array implementation optimal for dnse graph  </p>

<p>O(<code>V^2</code>)</p>

<p>(2) Binary heap much faser for sparse graphs  </p>

<p>O(<code>E log V</code>)</p>

<p>(3) 4-way heap worth the trouble in performance-critical situations  </p>

<p>O(<code>E log_(1/V) V</code>)</p>

<p>(4) Fibonacchi heap best in theor, but not worth implementing  </p>

<p>O(<code>E + V log V</code>)</p>

<h3 id="mstcontext">MST Context</h3>

<p><em>linear time MST</em> 알고리즘이 있을까? 1995년에 <em>linear time randomized MST</em> 가 발견 되었지만 <em>deterministic</em> 알고리즘은 여전히 연구중이다.</p>

<h3 id="shortestpathsapi">Shortest Paths API</h3>

<pre><code class="java">public class Directed Edge {

  DirectedEdge(int v, int w, deouble weight)
  int from()
  int to()
  double weight()
}

// allow self-loop, parallel
public class EdgeWeightedDigraph {

  EdgeWeightedDigraph(int V)
  void addEdge(DirectedEdge e)
  Iterable&lt;DirectedEdge&gt; adj(int v)
  int V() // # of vertices
}

// shortest path
public class SP {

  SP(EdgeWeightedDigraph G, int s)
  double distTo(int v)
  Iterable &lt;DirectedEdge&gt; pathTo(int v)
}
</code></pre>

<h3 id="shortestpathproperties">Shortest Path Properties</h3>

<p><em>directed, weighted graph</em> 에서 <em>shortest path tree, SPT</em> 가 존재하는데, 이는 <em>cycle</em> 이면 <em>shortest</em> 가 될 수 없기 때문이다.</p>

<p>위에서 본 <code>pathTo</code> 함수는 이렇게 구현할 수 있다.</p>

<pre><code class="java">// edgeTo[v] is last edge on shortest path from s to v
public Iterable&lt;DirectedEdge&gt; pathTo(int v) {  
  Stack&lt;DirectedEdge&gt; path = new Stack&lt;DirectedEdge&gt;();
  for (DirectedEdge e = edgeTo(v); e != null; e = edgeTo(e.from())
    path.push(e);

  return path;
}
</code></pre>

<h4 id="edgerelaxation">Edge relaxation</h4>

<p><em>relax edge <code>e = v -&gt; w</code></em>,</p>

<ul>
<li><code>distTo[v]</code> is length of shortest known path from <code>s</code> to <code>v</code></li>
<li><code>distTo[w]</code> is length of shortest known path from <code>s</code> to <code>w</code></li>
<li><code>edgeTo[w]</code> is last edge on shortest known path from <code>s</code> to <code>w</code></li>
</ul>

<p>여기서 만약 <code>e = v -&gt; w</code> 가 <code>w</code> 로의 더 짧은 거리라면, <code>distTo[w]</code> 와 <code>edgeTo[w]</code> 를 업데이트하면 된다.</p>

<p><img src='http://www.csupomona.edu/' ~ftang/courses/CS241/notes/images/graph/relax1.jpg" alt="" title="" />  </p>

<p><img src='http://faculty.ycp.edu/' ~dbabcock/PastCourses/cs360/lectures/images/lecture21/relaxation.png" alt="" /></p>

<p align="center">(<a href='http://www.csupomona.edu/' ~ftang'>http://www.csupomona.edu/~ftang</a>)</p>

<pre><code class="java">void relax(DirectedEdge e) {  
  int v = e.from();
  int w = e.to();

  if (distTo(w) &gt; distTo(v) + e.weight()) {
    distTo[w] = distTo[v] + e.weight();
    edgeTo[w] = e;
  }
}
</code></pre>

<h4 id="shortestpathsoptimalityconditions">Shortest-paths optimality conditions</h4>

<blockquote>
  <p>Let <code>G</code> be an edge-weighted digraph, then <code>distTo[]</code> are the shortest path distance from s iff:</p>
</blockquote>

<ul>
<li><code>distTo[s]</code> = 0</li>
<li>For each vertex <code>v</code>, <code>distTo[v]</code> is the length of some path from <code>s</code> to <code>v</code></li>
<li>For each edge <code>e = v -&gt; w</code>, <code>distTo[w] &lt;= distTo[v] + e.weight()</code></li>
</ul>

<p><strong>necessary condition</strong> </p>

<p>만약 어떤 <code>e = v -&gt; w</code>에 대해 <code>distTo[w] &gt; distTo[v] + e.weight()</code> 이면, <code>e</code> 를 이용한 <code>w</code> 까지의 거리가 <code>distTo[w]</code> 보다 더 짧다. 그러면 <code>distTo[w]</code> 는 <em>shortest path</em> 가 아니다.</p>

<p><strong>sufficient condition</strong></p>

<ul>
<li>Suppose <code>s = v0 -&gt; v1, ... -&gt; vk = w</code> is a shortest path from <code>s</code> to <code>v</code></li>
</ul>

<p>그러면</p>

<pre><code>distTo[v1] &lt;= distTo[v0] + e1.weight();  
...
distTo[vk] &lt;= distTo[v_k-1] + ek.weight(); 

// e_i is, i th edge on shortest path from s to w
</code></pre>

<p>이제 <code>distTo[v] = 0</code> 이라 하면</p>

<p><code>distTo[w] &lt;= e1.weight + ..., + ek.weight()</code></p>

<p>이 때 우변이 <em>shortest path</em> 위에 있는 <em>edge</em> 의 <em>weight</em> 값이므로, <code>distTo[w]</code> 는 <code>w</code> 까지의 <em>shortest path</em> 다.</p>

<p>(여기서는 필요충분조건 <code>p &lt;=&gt; q</code> 를 증명하기 위해 <code>p -&gt; q</code>, <code>q -&gt; p</code> 를 증명했다.)</p>

<h4 id="genericshortestpathsalgorithm">Generic Shortest-paths Algorithm</h4>

<pre><code>initialize distTo[s] = 0 and distTo[v] = infinity for all other vertices

Repeat until optimality conditions are satisfied,  
  Relax any edge
</code></pre>

<p>어떤 <em>edge</em> 를 고를까 하는 문제로 발전할 수 있다.</p>

<p>(1) <em>Dijkstra's algorithm</em>: <strong>non-negative weights</strong> <br />
(2) <em>Topological sort</em>: <strong>no directed cycles</strong> <br />
(3) <em>Bllman-Ford algorithm</em>: <strong>no negative cycles</strong></p>

<h3 id="dijkstrasalgorithm">Dijkstra's Algorithm</h3>

<pre><code>- Consider vertices in increasing order of dinstance from s
  (non-tree vertex with the lowest distTo[] value)

- Add vertex to tree and relax all edges pointing from that vertex
</code></pre>

<h4 id="correctness">Correctness</h4>

<blockquote>
  <p>Dijkstra's algorithm computes a SPT in any edge-weighted digraph with non-negative weights</p>
</blockquote>

<p>모든 <code>e = v -&gt; w</code> 는 단 한번씩만 <em>relaxed</em> 되기 때문에 알고리즘은 언젠간 종료된다. (<code>v</code> 가 <code>T</code> 에 추가되었을 때) </p>

<p>그리고 이 과정에서 <code>distTo[w] &lt;= distTo[v] + e.weight()</code> 가 유지된다. 왜냐하면 <code>distTo[w]</code> 는 줄어들기만 하고, <em>weight</em> 가 음수인 <em>edge</em> 가 없기 때문에 <code>distTo[v]</code> 는 변함이 없기 때문이다. </p>

<pre><code class="java">DirectedEdge[] edgeTo;  
double[] distTo;  
IndexMinPQ&lt;Double&gt; pq;

void DijkstraSP(EdgeWeightedDigraph G, int s) {  
  int V = G.V();
  edgeTo = new DirectedEdge[V];
  distTo = new double[V];
  pq = new IndexMinPQ&lt;Double&gt;(V);

  for(int v = 0; v &lt; V; v++) {
    distTo[v] = Double.POSITIVE_INFINITY;
  }

  distTo[s] = 0.0;
  pq.insert(s, 0.0);

  while (!ps.isEmpty()) {
    int v = pq.dequeue();
    for(DirectedEdge e: G.adj(v))
      relax(e);
  }
}

void relax(DirectedEdge e) {  
  int v = e.from();
  int w = e.to();

  if (distTo[w] &gt; distTo[v] + e.weight()) {
    distTo[w] = distTo[v] + e.weight();
    edgeTo[w] = e;

    if (pq.contains(w)) pq.decreaseKey(w, distTo[w]);
    else pq.insert(w, distTo[w]);
  }
}
</code></pre>

<p>프림 알고리즘과 마찬가지로 </p>

<p><code>T(n) = V insert + V delete-min + E decrease key</code> 인데, 이 연산들은 <em>Priority Queue</em> 구현에 따라 다를 수 있다. </p>

<p><em>undordered array</em> 라면 <code>V^2</code>, <em>binary heap</em> 이라면 <code>E log V</code> </p>

<p>따라서 <em>dense graph</em> 에서는 <em>array</em> 를, <em>sparse graph</em> 라면 <em>binary heap</em> 이 낫다.</p>

<h4 id="dijkstraandprim">Dijkstra and Prim</h4>

<p>둘 다 <em>spanning tree</em> 를 만들어 낸다. </p>

<ul>
<li>다익스트라는 <em>directed path</em> 에서 <em>source</em> 에서 가장 가까운 <em>vertex</em> 를 선택한다면, </li>
<li>프림 알고리즘은 <em>undirected edge</em> 내 에서 <em>tree</em> 에서 가장 가까운 <em>vertex</em> 를 선택한다.</li>
</ul>

<h3 id="edgeweighteddags">Edge-Weighted DAGs</h3>

<p><em>cycle</em> 이 없는 그래프는 <em>shortest path</em> 를 찾기 더 쉽다.</p>

<p><em>toplogical order</em> 순서로 <em>relaxing</em> 해 가면 된다. 어차피 방문 자체는 <em>topological order</em> 로 해야만 모든 <em>vertex</em> 를 방문할 수 있기 때문이다. </p>

<p>이 알고리즘에서 재미난 점은 음수 <em>weight</em> 가 있던 말던 상관이 없다는 것이다.</p>

<blockquote>
  <p>Topological sort algorithm computes SPT in <strong>any</strong> edge-weighted DAG in time proprotional to <code>E + V</code></p>
</blockquote>

<p>다익스트라와 마찬가지로 모든 <em>edge <code>e = v -&gt; w</code></em> 는 단 한번만 <em>relaxed</em> 되고, 이 과정에서 <code>distTo[w] &lt;= distTo[v] + e.weight()</code> 다.</p>

<p>(1) <code>distTo[w]</code> 는 줄어들기만 하고, <br />
(2) <em>topological order</em> 이기 때문에 한번 방문된 <code>v</code> 에 대해 이후의 <em>vertex</em> 에서 <code>v</code> 로 갈 수 없다. 있다면 <em>cycle</em> 이고 그럼 <em>toplogical order</em> 가 안된다. 따라서 <code>distTo[v]</code> 는 변하지 않는다. 따라서 <em>weight</em> 가 음수든 양수든 상관이 없다.</p>

<pre><code class="java">DirectedEdge[] edgeTo;  
double[] distTo;

public AcyclicSP(EdgeWeightedDigraph G, int s) {  
  int V = G.V();
  edgeTo = new DirectedEdge[V];
  distTo = new double[V];

  for(int v = 0; v &lt; V; v++) {
    distTo[v] = Double.POSITIVE_INFINITY;
  }

  distTo[s] = 0.0;

  Topological t = new Topological(G);

  for (int v : t.order()) {
    for (DirectedEdge e : G.adj(v)) {
      relax(e);
    }
  }
}
</code></pre>

<p>응용으로 <em>seam carving</em> 이 있다. 수직이나 수평으로 <em>shortest path</em> 를 찾아서 제거하면 된다.</p>

<p><img src='http://rahuldotgarg.appspot.com/data/SeamCarvingWeb/evaluation_files/image002.jpg'  alt="" /></p>

<p align="center">(<a href='http://rahuldotgarg.appspot.com/' >http://rahuldotgarg.appspot.com</a>)</p>

<p><em>longest path</em> 를 찾는법은 모든 <em>weight</em> 를 <em>negate</em> 하고, 찾고, 다시 결과의 <em>weight</em> 에 마이너스를 붙이면 된다. 이게 가능한 이유는 <em>no cycle</em> 이기 때문에 <em>weight</em> 가 음수든, 양수든 상관이 없기 때문이다.</p>

<p>응용해서 <em>Critical path method, CPM</em> 에 활용할 수 있다.</p>

<p>작업간 의존관계가 있으므로 이를 이용해서 <em>DAG</em> 를 그리면 된다. 각 <em>job</em> 당 <em>start vertex, finish vertex</em> 가 되며, 그 <em>weight</em> 는 <em>duration</em> 으로 하고 한 작업과 다음 작업의 <em>weight</em> 는 <code>0</code> 으로 했을때의 <em>longest path</em> 를 찾으면 된다. </p>

<p><img src='http://algs4.cs.princeton.edu/44sp/images/scheduling-critical-path.png'  alt="" /></p>

<p align="center">(<a href='http://algs4.cs.princeton.edu/44sp/' >http://algs4.cs.princeton.edu/44sp/</a>)</p>

<h3 id="negativeweights">Negative Weights</h3>

<p>다익스트라 알고리즘은 <em>negative weight</em> 에 대해서 작동하지 않는다. 모든 <em>weight</em> 에 일정 수 <code>n</code> 을 더해 모두 양수로 만들어도 똑같다. 심지어 이 경우는  <em>shortest path</em> 자체가 바뀐다. 따라서 다른 알고리즘이 필요하다.</p>

<p>진도를 빼기 전에 용어를 좀 정의하고 가면</p>

<p><em>negative cycle</em> 은, <em>directed cycle</em> 내의 모든 <em>weight</em> 를 더했을 때 음수인 경우를 말한다. 이 경우 <em>SPT</em> 는 없다. 이는 쉽게 보일 수 있는데</p>

<p><em>negative cycle</em> 이 존재하면 한번 이 사이클을 돌면, 전체 값이 음수이므로 어느 경로를 택해도 이전보다 더 짧아진다.</p>

<p>따라서 이 사이클을 돌면 내부 <em>vertex</em> 를 무한정 <em>relaxing</em> 할 수 있다.  </p>

<h4 id="bellmanfordalgorihm">Bellman-Ford Algorihm</h4>

<p><em>Bellman-Ford Algorihm</em> 은 <em>negative cycle</em> 이 있는지 검사할 수 있다.</p>

<ul>
<li>Initialize <code>distTo[s] = 0</code> and <code>distTo[v] = inf</code> 
for all other vertice</li>
<li>Repeat V times, relax each Edge</li>
</ul>

<pre><code>for (int i = 0; i &lt; G.V(); i++)  
  for(int v = 0; v &lt; G.V(); v++)
    for(DirectedEdge e: G.adj(v)) // pass i
      relax(e);     
</code></pre>

<p>벨만 포드 알고리즘은 <em>negative cycle</em> 이 없을때 <code>O(E * V)</code> 로 <em>shortest path</em> 를 찾아낸다. </p>

<p>증명은 <a href='http://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm' #Proof_of_correctness">여기</a>를 참조하도록 하자.</p>

<p>알고리즘을 잘 보면, 한 <em>pass</em> 에서 <code>distTo[v]</code> 가 변하지 않으면 그 이후에도 안 변한다. </p>

<blockquote>
  <p>If <code>distTo[v]</code> does not change during pass <code>i</code>, no need to relax any edge pointing from <code>v</code> in pass <code>i + 1</code></p>
</blockquote>

<p>따라서 <code>distTo[]</code> 가 변화한 <code>v</code> 의 리스트를 유지해서, 이것 대상으로 <em>relax</em> 하면 성능을 더 개선할 수 있다.</p>

<h4 id="findinganegativecycle">Finding a negative cycle</h4>

<p>벨만 포드 알고리즘은 <em>negative cycle</em> 을 찾아내는데 사용할 수도 있다. <em>negative cycle</em> 이 있을 경우 무한히 <em>relax</em> 를 해 내기 때문이다.</p>

<p>따라서 <code>V - 1</code> 까지 진행 한 후 <code>V</code> 번째에서 어느 <em>vertex</em> <code>v</code> 라도 업데이트 된다면, <em>negative</em> 사이클이 있다.</p>

<p><em>negative cycle</em> 은 <em>arbitrage detection</em> 에 사용할 수 있다.</p>

<h3 id="shortestpathcostsummary">Shortest Path Cost Summary</h3>

<p>(1) <strong>Topological Sort:</strong> No directed cycles</p>

<p>다익스트보다 더 빠르고, <em>negative weight</em> 도 문제 없다.</p>

<ul>
<li>typical: <code>E + V</code></li>
<li>worst: <code>E + V</code></li>
<li>extra space: <code>V</code></li>
</ul>

<p>(2) <strong>Dijkstra(binary heap):</strong> No negative weights</p>

<p>거의 <em>linear time</em> 이다.</p>

<ul>
<li>typical: <code>E logV</code></li>
<li>worst: <code>E logV</code></li>
<li>extra space: <code>V</code></li>
</ul>

<p>(3) <strong>Bellman Ford:</strong> No negative cycles</p>

<ul>
<li>typical: <code>E * V</code></li>
<li>worst: <code>E * V</code></li>
<li>extra space: <code>V</code></li>
</ul>

<p>(4) <strong>Bellman Ford(queue):</strong> No directed Cycles</p>

<ul>
<li>typical: <code>E + V</code></li>
<li>worst: <code>E * V</code></li>
<li>extra space: <code>V</code></li>
</ul>

<p><em>SPT</em> 를 정리하면</p>

<p><em>directed cycle</em> 은 문제를 더 어렵게 만들고,
<em>negative weight</em> 도 문제를 더 어렵게 만들고,
<em>negative cycles</em> 는 문제를 풀 수 없게 만든다. (내가 배운 한도 내에서는)</p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Part 2</em> by <strong>Robert Sedgewick</strong> <br />
(2) <a href='http://en.wikipedia.org/wiki/Bipartite_graph' >Wikipedia: Bipartite Graph</a> <br />
(3) <a href='http://www.biodatamining.org/content/4/1/10/figure/F3?highres=y' >http://www.biodatamining.org/</a> <br />
(4) <a href='http://ko.wikipedia.org/wiki/%ED%8F%89%EB%A9%B4_%EA%B7%B8%EB%9E%98%ED%94%84' >Wikipedia: 평면그래프</a> <br />
(5) <a href='http://www.csupomona.edu/' ~ftang">CS241 Lecture Notes: Graph Algorithms</a> <br />
(6) <a href='http://rahuldotgarg.appspot.com/data/SeamCarvingWeb/evaluation.htm' >Seam Carving for Content-Aware Image Resizing</a> <br />
(7) <a href='http://algs4.cs.princeton.edu/44sp/' >Algorithms: Shortest Path</a> <br />
(8) <a href='http://stackoverflow.com/questions/19760077/what-does-bellman-ford-algorithm-detects-negative-weight-or-negative-cycle' >What does bellman ford algorithm</a></p>]]></description><link>http://1ambda.github.io/graph-challenges-minimum-spanning-trees/</link><guid isPermaLink="false">22c06085-7f5c-45eb-8efc-31870d3ed425</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[graph]]></category><category><![CDATA[minimum spanning tree]]></category><category><![CDATA[shortest-path]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 03 Dec 2014 06:01:51 GMT</pubDate></item><item><title><![CDATA[Hash Table, Universal Hashing, Bloom filters]]></title><description><![CDATA[<h3 id="hashtable">Hash Table</h3>

<p>해시 테이블의 연산은 <em>key</em> 를 이용해 이런 작업들을 한다.</p>

<p>(1) <strong>insert:</strong> add new record <br />
(2) <strong>delete:</strong> delete existing record <br />
(2) <strong>lookup:</strong> check for a particular record</p>

<p>가끔 사람들이 <em>dictionary</em> 라 부르기도 하는데, 해시테이블은 알파벳 순서같은 특정 <em>order</em> 로 데이터를 저장하진 않는다.</p>

<p>이 3가지 연산이 거의 <code>O(1)</code> 라 보면 된다. 물론 이건 해시테이블을 잘 설계 했을때다. 슬프게도, 해시테이블은 <em>잘못</em> 구현하기 쉽다. 해시테이블이 <code>O(1)</code> 성능이 나오려면</p>

<ul>
<li>properly implemented</li>
<li>non-pathological data</li>
</ul>

<p>여기서 <em>non-pathological</em> 이란 <em>collision</em> 을 만들지 않는 데이터를 말한다.</p>

<h4 id="application">Application</h4>

<p>(1) 주어진 <em>object stream</em> 을 <em>de-duplication</em> 하기 위해 해시테이블을 쓸 수 있다. 해시테이블에 들어오는 객체를 <em>lookup</em> 해 보고 없으면 채워 넣고, 있으면 무시한다.</p>

<p>(2) <em>2-Sum Problem</em> 에도 해시테이블을 쓸 수 있다. <em>2-Sum</em> 을 푸는 <code>O(n logn)</code> 방법은, (<code>x + y = t</code>)</p>

<p>먼저 정렬 후 <code>A</code> 의 원소 <code>x</code> 에 대해 <code>t - x</code> 를 이진탐색하는 방법이다. 이렇게 하면 <code>O(n logn)</code> 으로 해결할 수 있다.</p>

<p>해시테이블을 이용하면 정렬 할 필요도 없고, 이진탐색 대신 <em>lookup</em> 으로 <code>O(1)</code> 시간에 원소를 검색할 수 있으므로 더 빨라진다.     </p>

<p>해시 테이블을 만드는데 <code>O(n)</code>, 탐색에 <code>O(1 * n)</code> 에서, <code>O(n)</code> 만에 <em>2-Sum</em> 을 해결할 수 있다.</p>

<p>(3) 이외에도</p>

<ul>
<li>symbol tables in compilers</li>
<li>blocking network traffic</li>
<li>search algorithm (e.g <strong>game tree exploration</strong>)</li>
</ul>

<h3 id="hashtableimplementation">Hash Table Implementation</h3>

<p>모든 집합을 의미하는 <em>universe <code>u</code></em> 에 대해 a reasonable size* 의 <em>evolving set</em> <code>s &lt;= u</code>* 을 유지하면 된다.</p>

<ul>
<li>배열로 구현할 경우 <em>lookup</em> 은 <code>O(1)</code> 이지만 메모리가 <code>O(|u|)</code> 다.</li>
<li>리스트로 구현할 경우 <code>O(|s|)</code> 의 메모리를 차지하지만, <em>lookup</em> 이 <code>O(|s|)</code> 다.</li>
</ul>

<p>더 나은 방법은 없을까?</p>

<p>(1) <em>bucket size</em> 인 <code>n ~ |s|</code> 인 <code>n</code> 을 고른다. 이 때 <code>|s|</code> 는 그렇게 많이 안 변한다고 가정하자. <br />
(2) 그 후 <em>hash function</em> <code>h: u -&gt; {0, 1, ..., n-1}</code> 인 <code>h</code> 를 고르면 된다. <br />
(3) 길이 <code>n</code> 의 배열 <code>A</code> 에, <code>A[h(x)]</code> 위치에 <code>x</code> 를 저장하면 된다.</p>

<p>이제 충돌 문제를 고민해 보자. 한 방에 <code>23</code> 명만 있어도, 생일이 같은 2명이 존재할 확률이 <code>50%</code> 가 넘으므로, </p>

<p><code>n</code> 에 비해 그리 크지 않은 <em>input size</em> 에 대해서도 충돌이 발생할 확률이 꽤 높다.</p>

<blockquote>
  <p><strong>Collision:</strong> dinstinct <code>x, y in u</code> such that <code>h(x) = h(y)</code></p>
</blockquote>

<h3 id="resolvingcollisions">Resolving Collisions</h3>

<p>충돌을 해결하기 위한 첫 번째 방법은</p>

<p>(1) <strong>Chaining:</strong></p>

<p><code>A[h(x)]</code> 을 리스토로 만들어 충돌이 발생하는 원소를 리스트에 저장한다.</p>

<p>(2) <strong>Open Addressing:</strong></p>

<p>충돌이 발생하면 새로운 <em>bucket</em> 을 찾도록 해 하나의 <em>bucket</em> 당 하나의 원소만 들어갈 수 있도록 한다.</p>

<blockquote>
  <p>hash function now specifies probe sequence <code>h_1(x), h_2(x), ...</code> keep trying til find open slot.</p>
</blockquote>

<p><br/></p>

<p><em>open addressing</em> 에서는 <em>probing, 탐사</em> 방식을 통해 비어있는 <em>bucket</em> 을 찾는다. 몇 가지 방법이 있는데</p>

<ul>
<li><strong>linear probing:</strong> 순차적으로 탐색한다. 캐쉬 히트는 높으나, 클러스터링에 취약하다.</li>
<li><strong>double hashing probing:</strong> 해쉬 함수 충돌이 발생하면 2차 해쉬 함수를 이용한다. 계산 비용이 비싸고, 캐쉬효율도 낮지만, 클러스터링에 영향을 받지 않는다.</li>
<li><strong>quadratic probing:</strong> 2차 함수를 이용해서 탐색을 위치를 찾는데, 캐싱과 클러스터링에서 두 방식의 중간정도의 성능을 보여준다.</li>
</ul>

<h4 id="clustering">Clustering</h4>

<p><em>key <code>k</code></em> 에 대한 최초의 해쉬 함수 값 <code>h(k)</code> <em>home position</em> 이라 부르는데, 같은 <em>home position</em> 를 갖는 <em>key</em> 들을 모아 <em>cluster</em> 라 부른다. <em>cluster</em> 가 커지면 커질수록, 클러스터의 중간을 <em>home position</em> 으로 하는 키가 들어올 확률도 높아지고, 인접한 클러스터와 합쳐지는 속도도 빨라진다.</p>

<p>결국 <em>linear probing</em> 의 경우 <em>load factor</em> 가 높아질수록 해쉬 테이블의 성능이 <code>O(n)</code> 으로 떨어진다.</p>

<h4 id="chainingvsopenaddessing">Chaining vs Open-addessing</h4>

<p><a href='http://sweeper.egloos.com/viewer/925740' >여기</a>를 인용하면</p>

<p><em>chaining</em> 은 <em>open addressing</em> 에 비해 다음의 장점을 가진다.</p>

<blockquote>
  <p>삭제 작업이 간단하다. 삭제 작업이 빈번하다면 <em>open addressing</em> 보다는 <em>chaining</em> 이 낫다.</p>
  
  <p><strong>chaining</strong> 은 클러스터링에 거의 영향을 받지 않아 충돌의 최소화만 고려하면 된다. 반면 <strong>open addressing</strong> 은 클러스터링까지 피해야 하므로 해쉬함수를 구현하기가 쉽지 않다.</p>
  
  <p><em>load factor</em> 가 높아져도 성능 저하가 선형적이다. 아래 그림에서 볼 수 있듯이, <em>open-addressing</em> 방법처럼 급격히 <em>lookup time</em> 이 늘지 않는다. 따라서 테이블 확장을 상당히 늦출 수 있다.</p>
</blockquote>

<p><img src='http://pds5.egloos.com/pds/200702/14/32/d0014632_11023351.jpg'  alt="" /></p>

<blockquote>
  <p>데이터의 크기가 <em>5 words and more</em> 이면, <em>open addressing</em> 보다 메모리 사용량이 적다. </p>
</blockquote>

<p>반면 <em>open addressing</em> 은</p>

<blockquote>
  <p>어떠한 포인터도 저장할 필요가 없고, 테이블 외부에 추가적인 공간이 필요 없으므로 메모리 효율이 높다.</p>
  
  <p>특히 <em>linear probing</em> 에서 뛰어난 <em>locality</em> 때문에 데이터가 캐쉬라인을 채울 정도로 크지 않다면 좋은 성능을 낼 수 있다.</p>
</blockquote>

<p>정리하자면,</p>

<blockquote>
  <p>open-addressing 방식은 테이블에 모두 저장될 수 있고 캐쉬 라인에 적합할 수 있을 정도로 데이터의 크기가 작을수록 성능이 더 좋아진다. 메모리 비용을 아끼려면, 이 방법이 적합하다.</p>
  
  <p>반면 테이블의 높은 load factor가 예상되거나, 데이터가 크거나, 데이터의 길이가 가변일 때 chained 해쉬 테이블은 open-addressing 방식보다 적어도 동등하거나 훨씬 더 뛰어난 성능을 보인다. 삭제가 중요하고, 빈번한 연산이라면 <em>chianing</em> 이 더 낫다.</p>
</blockquote>

<h3 id="whatmakesagoodhashfunction">What Makes a Good Hash Function?</h3>

<p><em>chaining</em> 을 생각해 보자. </p>

<ul>
<li><strong>insert:</strong> <code>O(1)</code></li>
<li><strong>lookup, delete:</strong> <code>O(list length in the bucket)</code></li>
</ul>

<p>이때 하나의 버켓에 들어있는 <em>list length</em> 는 <code>m/n</code> 부터 <code>m</code> 까지 일 수 있기 때문에 (<code>m</code> 개의 오브젝트에 대해), 해쉬 함수에 따라 성능이 정말 달라진다.</p>

<p>이로부터 좋은 해쉬함수의 기준을 알 수 있다.</p>

<blockquote>
  <ol>
  <li>Should lead to good performance => <em>"spread data out"</em> <br />
  (gold standard: completely random hashing)</li>
  <li>Should be easy to store / very fast to evaluate  </li>
  </ol>
</blockquote>

<h3 id="quickanddirtyhashfunction">Quick and Dirty Hash Function</h3>

<p>좋은 해쉬함수를 설계할 수 있다면 좋겠지만, 시간이 없을때 객체 <code>u</code> 를 받아 정수 <code>n</code> 으로 만들어 <em>bucket</em> 을 찾는 해쉬함수를 이렇게 디자인할 수 있다.</p>

<ul>
<li><code>u -&gt; n</code>: <em>hash code</em></li>
<li><code>n -&gt; bucket</code>: <em>compression function</em> using <code>mod</code></li>
</ul>

<p>여기서 <code>n</code> 은 어떻게 고를까? </p>

<p>(1) 우리가 <em>compression function</em> 으로 <code>mod</code> 를 사용하기 때문에 소수여야 한다. 소수가 아니라면, <code>n</code> 으로 나누어지는 모든 수는 <code>mod n == 0</code> 이 되어, 같은 <em>bucket</em> 에 할당될 것이다. 물론 이 수는 너무 커서는 안되고, 객체를 담을 수 있을만한 적당한 숫자여야 한다.</p>

<p>(2) <em>input data</em> 의 패턴을 고려해 <code>n</code> 을 정해야 한다. 예를 들어 <em>memory location</em> 이 4의 배수일 때, 테이블 사이즈 <code>n</code> 을 <code>2^j</code> 로 정해버리면, <code>mod n == 0</code> 이 되는 경우가 많아 <em>empty bucket</em> 이 많이 생길 것이다.</p>

<p>그리고 <code>n</code> 을 <code>2^k, 10^k</code> 로 정해버리는 경우 <code>mod</code> 연산이 시프팅으로 쉽게 구현되는데 이는 나머지 데이터를 고려하지 않고 일부의 데이터만으로 버킷을 찾아가므로 별로 좋은 선택이 아니다.</p>

<h3 id="loadfactor">Load Factor</h3>

<p><em>evenly spread out</em> 에 대해 고민해 보았으니, 이제 <em>non-pathological</em> 을 생각해 보자.</p>

<p>용어부터 정의하고 가면 <em>load factor</em> 는 해시테이블에 들어있는 오브젝트 수를, 버킷 수로 나눈 것이다.</p>

<p><em>open addressing</em> 의 경우에는 <em>load factor</em> 가 1보다 클 수 없지만 <em>chaining</em> 은 가능하다.</p>

<p>(1) <em>load factor</em> <code>a = O(1)</code> 이어야 연산이 <em>constant time</em> 이다. <br />
(2) <em>open addressing</em> 이라면 <code>x &lt;&lt; 1</code> 이어야 한다.</p>

<p>따라서 해시 테이블의 성능을 위해서는 <em>load factor</em> 를 조절해야 한다.</p>

<h3 id="pathologicaldatasets">Pathological Data Sets</h3>

<p>모든 데이터에 대해 <em>evenly spread out</em> 할 수 있는 해시함수가 있다면 좋겠지만, <strong>그런 해시 함수는 없다.</strong></p>

<p>모든 해시 함수는 자신만의 <em>pathological data set</em> 이 있다. 이는 쉽게 보일 수 있는데, <em>universe <code>u</code></em> 와 대해 버켓 수 <code>n</code> 에 대해 해시함수 <code>h: u -&gt; {0, 1, ..., n-1}</code> 이 있다고 하자.</p>

<p>비둘기 집 원리에 의해 모든 <em>bucket</em> 은 적어도 <code>|u|/n</code> 개의 데이터를 담고 있다. 따라서 <code>u</code> 중에서 어느 한 <em>bucket</em> 에만 담을 수 있는 데이터 셋을 고르면, 그것이 바로 <em>pathological data set</em> 이다.</p>

<p>이런 <em>pathological data set</em> 은 <em>service attack</em> 에 쓰이기도 한다. 따라서 오픈소스라면 리버스엔지니어링 하기 쉽지 않게끔 해시함수를 설계하는 것도 필요하다.</p>

<p>그럼 모든 해시 함수가 이런 데이터 셋을 가지고 있고, 심지어 공격에도 이용할 수 있다면 어떻게 해시함수를 설계해야 이런 문제를 조금이나마 피할 수 있을까?</p>

<p>(1) <strong>use a cryptographic hash function</strong> (e.g., <strong>SHA-2</strong>)  </p>

<p>infeasible to reverse engineer a pathological data set</p>

<p>(2) <strong>use randomization</strong>  </p>

<p>design a family <code>H</code> of hash funcitons such that data sets <code>S</code>, "almost all" functions <code>h in H</code> spread <code>S</code> out "pretty evenly" (compare to quicksort guarantee)</p>

<p>이제 <em>universal hashing</em> 이 무엇인지 알아보자</p>

<h3 id="universalhashingfunctions">Universal Hashing Functions</h3>

<blockquote>
  <p>Let <code>H</code> be a set of hash functions from <code>u</code> to <code>{0, 1, ..., n-1}</code></p>
  
  <p><code>H</code> is <strong>universal</strong> if and only if,</p>
  
  <p>for all <code>x, y in u (x != y)</code> <code>P[h(x) = h(y)] &lt;= 1/n</code> when <code>h</code> is chosen unifomly at random from <code>H</code> where <code>n</code> is the number of buckets. </p>
</blockquote>

<h4 id="hashingipaddresses">Hashing IP Addresses</h4>

<p><em>IP Address</em> 를 예로 들어 설명해보면 <em>IP</em> 를 <code>(x1, x2, x3, x4)</code> (<code>xi = 0 to 255</code>), <em>bucket</em> 수 <code>n</code> 을 소수라 하자.</p>

<p><em>tuple <code>a = (a1, a2, a3, a4), where ai in {0, ..., n-1}</code></em> 에 대해서</p>

<p><code>h_a</code> 를 이렇게 정의하자. 이러면 <code>h_a</code> 는 <code>n^4</code> 개 존재한다.</p>

<p><code>h_a(x1, x2, x3, x4) = (a1x2 + a2x2 + a3x3 + a4x4) mod n</code></p>

<p>이제 <code>h_a</code> 의 집합 <code>H</code> 는 <em>universal</em> 이다.</p>

<p><code>H = { h_a | a1, a2, a3, a4 in {0, 1, ..., n-1} }</code></p>

<h4 id="proof">Proof</h4>

<p>서로 다른 <em>IP</em> <code>(x1, x2, x3, x4), (y1, y2, y3, y4)</code> 를 생각해보자.</p>

<p>만약 <code>x4 != y4</code> 라면, 충돌이 일어날 확률은 얼마일까? 충돌에 대한 식을 좀 정리하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?collision%5C%20means%20%5C%5C%20%5C%5C%20%28a_1x_1%20&plus;%20a_2x_2%20&plus;%20a_3x_3%20&plus;%20a_4x_4%29%20%5Cmod%20n%20%3D%20%28a_1y_1%20&plus;%20a_2y_2%20&plus;%20a_3y_3%20&plus;%20a_4y_4%29%20%5Cmod%20n%20%5C%5C%20%5C%5C%20so%2C%20%5C%5C%20%5C%5C%20a_4%28x_4-y_4%29%20%5Cmod%20n%20%3D%20%5Csum_%7Bi%20%3D%201%7D%5E3%20a_i%28y_i%20-%20x_i%29%20%5Cmod%20n'  alt="" /></p>

<p>이 때 <code>a1, a2, a3</code> 를 고정하면 얼마나 많은 <code>a4</code> 에 대해 아래 식이 성립할까? </p>

<p><img src='http://latex.codecogs.com/gif.latex?a_4%28x_4-y_4%29%20%5Cmod%20n%20%3D%20%5Csum_%7Bi%20%3D%201%7D%5E3%20a_i%28y_i%20-%20x_i%29%20%5Cmod%20n'  alt="" /></p>

<p><code>xi, yi, a1, a2, a3</code> 가 <em>fixed</em> 기 때문에 우변은 <code>{0, ..., n-1}</code> 사이의 숫자고 <code>a4</code> 만 랜덤이다.</p>

<p>이 때</p>

<ul>
<li><code>x4 != y4</code> 이므로 <code>x4 - y4 != 0</code> 이다</li>
<li><code>n</code> 이 <code>ai</code> 의 최대값보다 큰수이면서 동시에 소수인데다가</li>
<li><code>a4</code> 가 <em>uniform at random</em> 이기 때문에</li>
</ul>

<blockquote>
  <p>left-hand side equally likely to be any of <code>{0, 1, ..., n-1}</code>.</p>
</blockquote>

<p>따라서 좌변이 특정 숫자인 우변과 같을 확률은 <code>1/n</code> 이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5Bh_a%28x%29%20%3D%20h_a%28y%29%5D%20%3D%20%7B1%20%5Cover%20n%7D'  alt="" /></p>

<h3 id="analysisofchaining">Analysis of Chaining</h3>

<p><em>universal hash functions</em> 의 정의를 한번 더 보고 넘어가면,</p>

<p><code>H</code> 가 해시함수 <code>u -&gt; {0, ..., n-1}</code> 의 집합일때 <code>H</code> 가 다음을 만족하면 <em>universal</em> 하다.</p>

<ul>
<li><code>x != y</code> 인 <code>u</code> 내의 <code>x, y</code> 에 대해 충돌이 일어날 확률 <code>P &lt;= 1/n</code> 이고</li>
<li><code>H</code> 내에서 <code>h</code> 가 <em>uniformly at random</em> 하게 선택될때</li>
</ul>

<p>만약 해시 테이블이 <em>chaining</em> 을 이용해 구현되었을때, <em>universal family</em> <code>H</code> 로부터 해시함수 <code>h</code> 가 <em>uniformly a random</em> 하게 선택되면 모든 연산이 <code>O(1)</code> 이다.</p>

<p>그리고, <code>|S| = O(n)</code> 다시 말해 <em>load factor</em> <code>alpha = |S| / n = O(1)</code> 임을, 해시 함수를 평가하는데 <code>O(1)</code> 임을 가정한다.</p>

<h4 id="proof">Proof</h4>

<p><em>unsuccessful lookup</em> 을 분석할건데, 다른 연산이 이보다는 항상 더 빠르므로 다른 연산의 <em>upper bound</em> 라 보면 된다.</p>

<p><code>S</code> 를 <code>|S| = O(n)</code> 인 데이터셋이라 하자. <code>x not in S</code> 인 <code>x</code> 를 <em>lookup</em> 한다 하면 <em>running time</em> 은</p>

<p><code>O(1) + O(list length in A[h(x)])</code> 다. 즉 <code>h(x)</code> 를 평가하는데 걸리는 시간과 해당 버킷 내의 리스트를 순회하는 시간의 합이다.</p>

<p>그런데 여기서 <code>A[h(x)]</code> 버킷의 리스트 길이를 <code>L</code> 이라 하면 이 <code>L</code> 은 <code>h</code> 선택에 따라 달라지는 <em>random variable, 확률변수</em> 다.</p>

<p>그럼 <em>average list length</em> 를 구해, <code>O(L)</code> 을 구해보자. 기대값의 선형성을 이용할건데, <code>E(L)</code> 을 위한 <code>1 or 0</code> 의 확률변수를 도입하자.</p>

<p><code>x != y</code> 인 <code>y in S</code> 에 대해 <code>z_y</code> 를 충돌이 날경우 <code>1</code> 로, 아닐 경우를 <code>0</code> 으로 하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?z_y%3D%20%5Cbegin%7Bcases%7D%201%2C%20%26%20%5Cmbox%7Bif%20%7Dh%28x%29%20%3D%20h%28y%29%20%5C%5C%200%2C%20%26%20%5Cmbox%7Bif%20%7Dh%28x%29%20%5Cneq%20h%28y%29%20%5Cend%7Bcases%7D'  alt="" /></p>

<p>이 때 해시함수가 무엇이든, 충돌이 날 경우에만 같은 버킷으로 들어가므로 버킷의 길이는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?L%20%3D%20%5Csum_%7By%5C%20%5Cin%5C%20S%7D%20z_y'  alt="" /></p>

<p>따라서</p>

<p><img src='http://latex.codecogs.com/gif.latex?E%28L%29%20%5C%5C%20%5C%5C%20%3D%20E%5B%5Csum_%7By%5C%20%5Cin%5C%20S%7D%20z_y%5D%20%5C%5C%20%5C%5C%20%3D%20%5Csum_%7By%5C%20%5Cin%5C%20S%7D%20E%28z_y%29%20%5C%20%5C%20%5Cmbox%7B%28apply%20linearity%20of%20expectation%29%7D%20%5C%5C%20%5C%5C%20%3D%20%5Csum_%7By%5C%20%5Cin%20%5C%20S%7D%20%7B1%20%5Cover%20n%7D%20%5C%5C%20%5C%5C%20%5Cleq%20%7CS%7C%20' *%20%7B1%20%5Cover%20n%7D%20%5C%5C%20%5C%5C%20%3D%20O%281%29" alt="" /></p>

<p>중간에 <code>H</code> 가 <em>universal</em> 이므로 <code>P[h(y) = h(x)] &lt;= 1/n</code> 이다.</p>

<h3 id="openaddressingperformance">Open Addressing Performance</h3>

<p><em>open addressing</em> 퍼포먼스를 계산할건데, <em>quick and dirty idealized analysis</em> 를 위해 <em>heuristic assumtion</em> 을 도입하면,</p>

<blockquote>
  <p>All <code>n!</code> probe sequences equally likely    </p>
</blockquote>

<p>이상적인 경우를 가정하면 얻어지는 것은</p>

<blockquote>
  <p>expected insertion time ~= <code>1 / (1 - a)</code> where <code>a = load factor</code></p>
</blockquote>

<p>다시 말해서, <code>a = 0.5</code> 라면 새로운 데이터를 집어넣기 위해 <code>2</code> 만큼 <em>probe</em> 해야한다는 소리다. 반면 <code>a ~= 1</code> 이면 (<code>1</code>에 가까워지면) <em>insertion</em> 타임은 어마어마하게 커진다.</p>

<blockquote>
  <p>A random probe finds an empty slot with probability <code>1 - a</code></p>
</blockquote>

<p>이 문제를 "<em>head</em> 를 얻기 위해 동전을 몇번 뒤집어야 하는가" 로 치환할 수 있다. 여기서 <code>Pr[heads] = 1 - a</code> 라 보면</p>

<p><em>head</em> 를 얻기 위해 동전을 뒤집는 수 <code>N</code> 에 대해 기대값 <code>E[N]</code> 은</p>

<p><img src='http://latex.codecogs.com/gif.latex?E%5BN%5D%20%3D%201%20&plus;%20%5Calpha%20%5C%20E%5BN%5D'  alt="" /></p>

<p>식을 풀면</p>

<p><img src='http://latex.codecogs.com/gif.latex?E%5BN%5D%20%3D%20%7B1%20%5Cover%201-%20%5Calpha%7D'  alt="" /></p>

<h4 id="linearprobing">Linear Probing</h4>

<p><em>open addressing</em> 방법으로 <em>linear probing</em> 을 사용할 경우, 아까의 <em>heuristic assumption</em> 자체가 성립하지 않는다.</p>

<p>따라서 다른 가정으로</p>

<blockquote>
  <p>initial probe uniformly random, independent for different keys.</p>
</blockquote>

<p>그러면 가정아래,  <em>expected insertion time</em> 은 <code>1 / (1 - a)^2</code> 에 가까워진다. (<em>D.E Knuth</em> 가 발견했다고 한다.)</p>

<h3 id="bloomfilter">Bloom Filter</h3>

<p>하던대로 <em>supported operation</em> 부터 이야기 하자.</p>

<p>블룸 필터는 해시테이블과 비슷하게 빠른 삽입, 탐색을 지원한다. 해시테이블과 비교했을때 메모리가 덜 든다. 반면 단점은</p>

<p>(1) Can't store an associated object <br />
(2) No deletions <br />
(3) small <strong>false positive</strong> pobability (but no false negative)</p>

<p>블룸 필터는 다양한 곳에 사용한다. </p>

<ul>
<li>early spell checkers (original)</li>
<li>list of forbidden passwords (canonical)</li>
<li>network routers (mordern)</li>
</ul>

<p>만약 메모리가 아주 비싸고, <em>false positive</em> 를 참을만 하다면 블룸필터는 좋은 선택이다. 연산도 아주 빠르다.</p>

<p>블룸 필터의 구성요소를 보자.</p>

<p>(1) 자료구조는 <code>n</code> 비트의 배열이다. <br />
(2) <code>k</code> 개의 해시 함수가 필요하다. (<code>k</code> 는 <em>small constant</em>)</p>

<p><em>insertion</em> 은 <code>i = 1, ..., k</code> 에 대해 <code>A[h_i(x)] = 1</code> 로 세팅하면 된다. 이미 <code>1</code> 이어도 덮어쓴다. 참고로 덮어쓰기때문에 <em>false positive</em> 는 있어도 <em>false negative</em> 는 없다. 자그마한 종양만 보여도 무조건 암이라 주장하는 소심한 의사라 보면 이해가 쉽다.</p>

<p><em>lookup</em> 은 <code>i = 1, ..., k</code> 에 대해 모든 <code>A[h_i(x)] = 1</code> 이면 찾으려는 <code>x</code> 가 존재한다.</p>

<p><em>false positive</em> 는 <code>A[h_i(x)]</code> 가 다른 <em>insertion</em> 에 의해 <code>1</code> 로 세팅 되었을때 발생한다.</p>

<p>블룸필터를 이미지로 보면</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Bloom_filter.svg/720px-Bloom_filter.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<p>블룸필터를 쓰는 것이 합리적인 선택이 되려면</p>

<p>(1) <code>n / |S|</code> 즉, 오브젝트당 비트 수가 충분히 작아야 한다. <br />
(2) <em>false positive</em>, 즉 에러 확률이 작아야한다.</p>

<p>동시에 두 조건을 작은 값으로, 모두 만족시키지 못한다면 그냥 해시 테이블을 쓰는 것이 더 낫다. </p>

<p>근데, 자세히 살펴보면 <em>space</em> 와 <em>error prob</em>, 이 두 조건은 <em>trade-off</em> 다.  </p>

<h3 id="bloomfilterheuristicanalysis">Bloom Filter: Heuristic Analysis</h3>

<p><em>heuristic assumption</em> 은</p>

<blockquote>
  <p>all <code>h_i(x)</code>' is uniformly random and independent (across different <code>i</code>'s and <code>x</code>'s</p>
</blockquote>

<p><code>k</code> 개의 해시함수를 가지는 <code>n</code> 비트 블룸 필터에 데이터셋 <code>S</code> 를 먼저 넣어놓자. 이제 블룸필터 <code>A</code> 의 각 비트가 1일 확률은,</p>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%281%20-%7B1%20%5Cover%20n%7D%29%5E%7Bk%7CS%7C%7D'  alt="" /></p>

<p>인데 이것은 한 비트가 <code>0</code> 일 확률을 <code>1</code> 에서 뺀 것이다. <code>0</code> 일 확률은 <code>k</code> 개의 해쉬 함수를 <code>|S|</code> 개의 모든 원소를 다 집어 넣은 후에도 <code>0</code> 인 확률이므로 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%281%20-%20%7B1%20%5Cover%20n%7D%29%5E%7Bk%7CS%7C%7D'  alt="" /></p>

<p>이 때 <code>e^x</code> 가 <code>1 + x</code> 의 <em>upper bound</em> 임을 이용하면, 각 비트가 1일 확률은</p>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%281%20-%7B1%20%5Cover%20n%7D%29%5E%7Bk%7CS%7C%7D%20%5C%5C%20%5C%5C%20%5Cleq%201%20-%20e%5E%7B-k%7CS%7C%20%5Cover%20n%7D%20%5C%20%5Cmbox%7B%5C%20%5C%20%281/n%20%5Csim%200%29%7D'  alt="" /></p>

<p>이 때 <code>n / |S| = b</code>, <code>b</code> 는 오브젝트당 비트 수 이므로</p>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%281%20-%7B1%20%5Cover%20n%7D%29%5E%7Bk%7CS%7C%7D%20%5C%5C%20%5C%5C%20%5Cleq%201%20-%20e%5E%7B-k%7CS%7C%20%5Cover%20n%7D%20%5C%5C%20%5C%5C%20%3D%201%20-%20e%5E%7B-k%20/%20b%7D'  alt="" /></p>

<p>이제 블룸필터에 한번도 입력되지 않은 데이터에 대해 <em>false positive</em> 확률 <code>P[FP]</code> 를 계산하면,</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5BFP%5D%20%5C%5C%20%5C%5C%20%5Cleq%20%281%20-%20e%5E%7B-k%20/%20b%7D%29%5Ek%20%5C%5C%20%5C%5C'  alt="" /></p>

<p>이 때 고정된 수 <code>b</code> 에 대해 에러일 확률 <code>P[FP]</code> 를 최소화 하는 <code>k</code> 를 찾으면</p>

<p><code>k ~ (ln2) * b</code> 다. 로그를 계산하면, <code>k ~ 0.693 * b</code> </p>

<p>따라서 </p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5BFP%5D%20%5Csim%20%28%7B1%20%5Cover%202%7D%29%5E%7B%28ln2%29b%7D'  alt="" /></p>

<p>이므로 오브젝트당 비트수 <code>b</code> 에 따라서 <em>false positive</em>, 즉 에러 확률이 <em>exponentially</em> 작아진다.</p>

<p>식을 거꾸로 풀면</p>

<p><img src='http://latex.codecogs.com/gif.latex?b%20%5Csim%201.44%20' *%20log_2%7B1%20%5Cover%20P%5BFP%5D%7D" alt="" /></p>

<p>이 두 식은 오브젝트당 비트수 <code>b</code> 와 <em>false positive</em> 의 <em>trade off</em> 를 보여준다.</p>

<p>만약 <code>b = 8</code> 이고 <code>k = 5, 6</code> 이면 에러 확률은 <code>2%</code> 정도다. </p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong> <br />
(2) <a href='http://sweeper.egloos.com/viewer/925740' >Hash Table</a> <br />
(3) <a href='http://www.slideshare.net/tanmaytan21/application-of-hashing-in-better-alg-design-tanmay' >http://www.slideshare.net/tanmaytan21</a> <br />
(4) <a href='http://en.wikipedia.org/wiki/Hash_table' >Wikipedia: Hash Table</a> <br />
(5) <a href='http://www.slideshare.net/sajidmarwatt/advance-algorithm-hashing-lec-ii' >http://www.slideshare.net/sajidmarwatt</a> <br />
(6) <a href='http://en.wikipedia.org/wiki/Primary_clustering' >Wikipedia: Primary Clustering</a> <br />
(7) <a href='http://en.wikipedia.org/wiki/Bloom_filter' >Wikipedia: Bloom Filter</a>    </p>]]></description><link>http://1ambda.github.io/hash-table-universal-hashing-bloom-filters/</link><guid isPermaLink="false">883e3230-b261-4993-9b7c-566513bcf026</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[universal hashing]]></category><category><![CDATA[bloom filter]]></category><category><![CDATA[open addressing]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Mon, 01 Dec 2014 07:44:37 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 8]]></title><description><![CDATA[<p>이번시간에는 <em>PCA</em> 와 <em>clustering</em> 을 배운다. <em>PCA</em> 가 어떻게 돌아가는지 알기위해 <em>covariance matrix</em>, <em>eigen decomposition</em>, <em>singular value decomposition</em> 등의 배경지식도 익혀보자. <del>K-means 는 거들뿐</p>

<h3 id="unsupervisedlearningintro">Unsupervised Learning Intro</h3>

<p><em>clustering</em> 은 다양한 분야에 활용할 수 있다.</p>

<ul>
<li>Market Segmentation</li>
<li>Social Network Analysis</li>
<li>Organize Computing Clusters</li>
<li>Astronomical Data Analysis</li>
</ul>

<h3 id="kmeans">K-Means</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360978231_7390.png'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360978245_9923.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>랜덤한 위치에 <em>centroid</em> 를 잡고, 가까운 점들을 색칠 한뒤 그 점들의 중심으로 <em>centroid</em> 를 옮겨가면서 집단을 만들어 낸다.</p>

<p><em>k-means</em> 의 인풋은 <em>centroid</em> 의 수인 <code>k</code> 와 <code>x1, x2, ... , xm</code> 의 트레이닝 셋이다. 구체적인 알고리즘은</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360978315_1086.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>매 이터레이션마다 <code>i to m</code> 까지 루프를 돌면서 클러스터링된 원소들의 배열인 <code>c^(i)</code> 에 <code>1 to K</code> 사이의 값을 넣는다. 이때 <code>c^(i)</code> 에 삽입될 값은, 해당 원소로부터 가장 가까운 <em>centroid</em> 의 인덱스다.</p>

<blockquote>
  <p><code>c^(i)</code> is index of cluster <code>(1, ..., K)</code> to which example <code>x^(i)</code> is currently assigned</p>
</blockquote>

<p>따라서 각 원소로부터의 거리를 최소로 하는 <code>k</code> 에 대해 <code>c^(i) = k</code> 다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_k%20%5Cleft%20%7B%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20%5Cmu_k%20%5Cright%20%5C%7C%20%7D%20%5C%5C%20%5C%5C%20%5CRightarrow%20c%5E%7B%28i%29%7D%20%3D%20k'  alt="" /></p>

<h3 id="optimizationobjective">Optimization Objective</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360979250_8035.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>k-means</em> 에서 최소화 하려는 <em>cost function</em> 은</p>

<p><img src='http://latex.codecogs.com/gif.latex?J%28c%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%29%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20%5Cmu_%7Bc%5E%7B%28i%29%7D%7D%20%5Cright%20%5C%7C'  alt="" /></p>

<p>다시 말해서 각 점에서 <em>centroid</em> 까지의 거리를 최소화 하는 것이 목표다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7Bc%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%7D%20%5C%20%5C%20J%28c%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%29'  alt="" /></p>

<p>이 함수 <code>J</code> 를 다른말로는 <em>distortion function</em> 이라 부른다. 알고리즘을 다시 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360979289_8146.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>(1) <em>clustering assignment step</em> 에서는 <code>mu</code> 를 고정시키고 <code>c^(i)</code> 에 대해서 <code>J</code> 를 최소화 한다. <br />
(2) <em>move centroid step</em> 에서는 <code>c^(i)</code> 를 고정시키고 <code>mu</code> 에 대해서 <code>J</code> 를 최소화 한다.</p>

<h3 id="randominitialization">Random Initialization</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360980200_9803.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위쪽 예제는 <em>centroid</em> 의 랜덤 초기화에서 좋게 배치된 경우이고, 아래쪽은 운이 나쁜 경우를 설명하는 그림이다. 이것이 설명하는 바는 <em>centroid</em> 의 초기화에 따라 결과가 달라질 수 있다는 것이다. 아래 그림을 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360980222_7891.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>따라서 <em>local optima</em> 를 피가히 위해, 그리고 좋은 <em>clustering</em> 을 얻기 위해 <em>random initialization</em> 이용하여 <em>k-mean</em> 를 여러번 돌릴 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360980246_7140.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>여러번 <em>k-mean</em> 를 돌려 얻은 <code>J</code> 에 대해 최소값을 가지는 <code>J</code> 를 이용해 클러스터링을 얻을 수 있다.</p>

<p>그러나 <code>K</code> 가 매우 크다면, <em>random initialization</em> 들어가는 계산 비용에 비해 별로 좋은 결과를 돌려주지 못할 것이다. </p>

<p><em>random initialization</em> 을 하는 방법으로</p>

<blockquote>
  <p>Pick <code>k</code> distinct random integers <code>i_1, ..., i_k</code> from <code>{1, ..., m}</code>. <br />
  Set <code>mu_1 = x^(i_1), ..., mu_k = x^(i_k)</code></p>
</blockquote>

<h3 id="choosingthenumberofcluster">Choosing the Number of Cluster</h3>

<p><code>K</code> 값을 선택하기 위해 <em>Elbow method</em> 를 이용할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360981609_7528.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><code>K</code> 값의 변화에 따라 <em>distortion function</em> <code>J</code> 값이 급격히 감소하는 지점을 선택하는 방법이다. 그런데 <code>J</code> 값이 오른쪽 그림처럼 좀 애매하게 감소하면 어떻게 할까?</p>

<blockquote>
  <p>Sometimes, you are running K-means to get clusters to use for some later / downstream purpose. Evaluate K-means based on a metric for hwo well it perfomrs for that later purpose.</p>
</blockquote>

<p>예를 들어서, 몸무게 / 키 에 따라 집단을 분류해 그에 맞추어 티셔츠를 만든다고 할 때 <code>K = 3 or 5</code> 에 대해서는 단순히 좋은 클러스터링을 얻는것은 물론  어떤 <code>K</code> 가 수지타산이 더 맞을지 티셔츠 비즈니스적인 관점에서 생각을 해봐야 한다.</p>

<p><img src='http://my.csdn.net/uploads/201208/28/1346132804_2121.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<h3 id="dimensionalityreduction">Dimensionality Reduction</h3>

<p>이번엔 <em>unsupervised learning</em> 의 또 다른 기법인 <em>dimensionality reduction</em> 을 알아보자. 이 기법의 <em>motivation</em> 은 2가지다.</p>

<p>(1) Data Compression <br />
(2) Data Visualization  </p>

<h3 id="datacompression">Data Compression</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361235893_4367.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>두 축을 보면 하나는 인치로, 다른 하나는 센치다. <em>highly redundant data</em> 이기 때문에 하나의 차원으로 축소할 수 있다.</p>

<p>중복된 <em>feature</em>만 차원을 줄일 수 있는 것은 아니다</p>

<p>예를 들어 데이터의 한 축을 <em>pilot skill</em> 다른 축을 <em>pilot enjoyment</em> 라 하고 두 <em>feature</em> 간 관계를 거의 직선으로 나타낼 수 있다고 하자. 이 새로운 직선을 <em>pliot aptitude</em> 라 부르고 두개의 <em>feature</em> 를 대신하는 새로운 <em>feature</em> 로 사용할 수 있다.</p>

<p><em>feature</em> 가 한 두개면 중복되는 것을 걸러내거나, 새로운 <em>feature</em> 로 만들기 쉬운데 만약 수백개라면 이것도 일이다.</p>

<p>위 그림을 다시 보면 <code>x_1, x_2</code> 를 <code>z_1</code> 으로 대신하고 있다. <em>feature</em> 의 수가 줄어든 것이다.</p>

<p>이렇게 차원을 줄이면 연산량이 줄어들의 전체 알고리즘의 성능도 빨라진다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361235907_7086.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위 그림이 <em>dimensionality reduction</em> 에 대한 <em>intuition</em> 을 제공한다. 3차원의 데이터를 2차원의 평면으로 투영해 새로운 <em>feature set</em> 인 <code>z</code> 를 사용해 데이터를 나타낼 수 있다.</p>

<p>그림은 3차원 -> 2차원 이지만, 만약 10000 개를 1000 개를 줄일 수 있다면 어마어마한 중복을 줄일 수 있다.</p>

<p>조금 더 이해가 잘되는 3차원 그림을 가져오면</p>

<p><img src='http://scipy-lectures.github.io/_images/pca_3d_axis.jpg'  alt="" />
<img src='http://scipy-lectures.github.io/_images/pca_3d_aligned.jpg'  alt="" /></p>

<p align="center">(<a href='http://scipy-lectures.github.io/' >http://scipy-lectures.github.io</a>)</p>

<h3 id="datavisualization">Data Visualization</h3>

<p><em>dimensionality reduction</em> 의 두 번째 <em>motivation</em> 은 바로 <em>data visualization</em> 이다. </p>

<p><em>GDP</em>, <em>Country size</em> 등 다양한 <em>feature</em> 500개를 2개로 줄여 그래프에 그려보면 데이터에 대한 어떤 <em>intuition</em> 을 얻을 수도 있다. 즉 데이터가 주로 어떤 종류의 <em>feature</em> 에 의해 많이 영향을 받는지 파악할수 있다는 것이다.</p>

<p>강의에 나온 예제에서는 <code>z_1</code> 은 <em>country size / GDP</em>, <code>z_2</code> 는 <em>per person GDP</em> 였다.</p>

<p><em>visualization</em> 을 위한 경우 <code>2, 3</code> 개 정도로 차원을 줄일 수 있다.</p>

<h3 id="principalcomponentanalysisproblemformulation">Principal Component Analysis Problem Formulation</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236095_4842.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>2개의 <em>feature</em> <code>x_1, x_2</code> 를 하나로 줄인다고 하자. 이 경우 <em>projection error</em> (파란선의 길이) 를 최소로 하는 선 (빨강)을 찾으려고 할 것이다. 반면 자주색 선의 경우 <em>projection error</em> 가 가장 큰 선이라 볼 수있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236100_6448.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>따라서 <code>n</code> 차원을 <code>k</code> 차원으로 축소할때는 각 데이터를 <code>k</code> 개의 벡터 <code>u</code> 에 대해 투영시켰을때의 <em>projection error</em> 를 최소로 하는 벡터 <code>u</code> 를 찾으면 된다. </p>

<blockquote>
  <p>Reduce from <code>n</code>-dimension to <code>k</code>-dimension, find <code>k</code> vectors <code>u^1, ..., u^k</code> onto wihch to project the data, so as to minimized the projection error</p>
</blockquote>

<p>쉽게 생각하면 <code>k</code> 개의 <em>direction</em> 을 찾는다고 생각하면 된다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236106_9904.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>왼쪽 그림은 <em>linear regression</em> 에서 찾아내는 오차, 즉 <code>y</code> 값과 <em>prediction</em> 간의 거리이고 </p>

<p>우측 그림은 <em>PCA</em> 로 찾아낸 선과 각 점사이의 <em>projection error</em> 를 파란샌으로 나타냈다. </p>

<p>두 그림에서 볼 수 있듯이 <em>PCA</em> 는 <em>linear regression</em> 이 아니다. <em>PCA</em> 에서는 <code>y</code> 값이란 개념이 없다. </p>

<h3 id="pcaalgorithm">PCA Algorithm</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236182_1422.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>PCA</em> 전에는 <em>preprocessing step</em> 을 거친다. 이는 다양한 <em>feature</em> 간 스케일이 다르기 때문에 비교할만한 스케일을 얻기 위함이다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>그 후에는 <code>n</code> 차원으로부터 <em>projection error</em> 가 최소인 <code>k</code> 개의 벡터를 얻는 계산을 수행한다.</p>

<p>(1) 먼저 <code>Sigma</code> 라 부르는 <em>covariance matrix</em> 를 계산하고 (작은 시그마) <br />
(2) 그 후에 <code>Sigma</code> 의 <em>eigenvectors</em> 를 계산한다.  </p>

<p>여기서 <code>svd</code> 는 <em>sigular value decomposition</em> 을 의미한다. </p>

<p><code>Sigma</code> 를 얻기 위한 <em>vectorization</em> 은 <code>(1/m) * X' * X</code> 다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236425_3920.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><code>svd</code> 함수의 리턴값으로 <code>U</code> 매트릭스가 나오는데, 이건 <code>n x n</code> 매트릭스다. 여기서 첫 <code>k</code> 개의 컬럼을 취한다. 이 매트릭스를 <code>Y</code> 라 부르면 새로운 <em>feature vector</em>  <code>z</code> 는</p>

<p><code>z = Y^T * x</code></p>

<p>정리하면 아래 그림과 같다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236428_5117.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h3 id="pcadetails">PCA Details</h3>

<p>넘어가기 전에 잠깐 <em>PCA</em> 에서 다룬 <em>covariance matrix</em> 나 <em>eigen vector</em> 를 좀 보고 넘어가자.</p>

<h4 id="covariance">Covariance</h4>

<p>두 확률 변수 <code>X</code>, <code>Y</code> 에 대해서 <em>covariance</em> 는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csigma%28X%2C%20Y%29%20%3D%20E%5B%28X%20-%20E%28X%29%29%28Y%20-%20E%28Y%29%29%5D%20%5C%5C%20%5C%5C%20%3D%20E%28XY%29%20-%20E%28X%29E%28Y%29%20%5C%20%7B%5Ccolor%7BBlue%7D%20%28by%5C%20linearity%5C%20of%5C%20expectation%29%7D'  alt="" /></p>

<p>보면 알겠지만, 독립이면 <em>covariance</em> 값이 <code>0</code> 이다. 따라서 두 변수간 상관정도라 보면 된다. 공분산이 양수면 양의 상관관계를, 음수이면 음의 상관관계를 가진다. </p>

<p>이해를 위해서 <a href='http://darkpgmr.tistory.com/110' >여기</a>로 부터 인용을 하자면</p>

<blockquote>
  <p>x의 분산은 x들이 평균을 중심으로 얼마나 흩어져 있는지를 나타내고, x와 y의 공분산은 x, y의 흩어진 정도가 얼마나 서로 상관관계를 가지고 흩어졌는지를 나타낸다. 예를 들어, x와 y 각각의 분산은 일정한데 x가 E(x)보다 클때 y도 E(y)보다 크면 공분산은 최대가 되고, x가 E(x)보다 커질때 y는 E(y)보다 작아지면 공분산은 최소(음수가 됨), 서로 상관관계가 없으면 공분산은 0이 된다.</p>
</blockquote>

<p>공분산은 몇 가지 성질이 있는데 </p>

<p>(1) <code>X, Y</code> 가 독립이면 <em>covariance = <code>0</code></em> 이다. 그러나 역은 <em>gaussian random variable</em> 일때만 성립한다.  </p>

<p>(2) <img src='http://upload.wikimedia.org/math/0/6/0/060cda617e0812f174f5f75b6032b3dd.png'  alt="" title="" /></p>

<p>(3) <img src='http://upload.wikimedia.org/math/5/e/9/5e9674eac71398dcb022fc5cb76e2717.png'  alt="" title="" />  </p>

<p>(4) <img src='http://upload.wikimedia.org/math/8/2/3/823d4a54cac228efe1658718bfa7707a.png'  alt="" title="" />  </p>

<p>공분산마다 값이 다르기 때문에 비교를 위해 <code>X</code>, <code>Y</code> 의 표준편차로 나눈 것을 <em>correlation, 상관계수</em> 라 부른다.</p>

<p><img src='http://upload.wikimedia.org/math/0/7/6/076d3820a46afe55ee680f3c85e34c76.png'  alt="" /></p>

<p><br/></p>

<h4 id="covariancematrix">Covariance Matrix</h4>

<p>이제 <em>covariance matrix</em> 를 알아보자. 공분산 행렬은 데이터 <code>X</code> (벡터) 에 대해 <code>X</code> 의 두 원소 <code>X^(i), X^(j)</code> 간 공분산을 구한 행렬이다. <code>X</code> 를 <code>n</code> 벡터라 하면, <code>X</code> 의 공분산 행렬은 <code>n x n</code> 행렬이다. 그리고 <code>Cov(X, Y) = Cov(Y, X)</code> 이므로 <em>symmetric matrix, 대칭행렬</em> 이기도 하다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h4 id="eigenvectoreigenvalue">Eigen vector, Eigen value</h4>

<p>아까 슬라이드에서 잠깐 <em>eigen vector</em> 가 나왔는데, 우리말로 <em>고유벡터</em> 라 부른다. 고유벡터 <code>v</code> 는 행렬 <code>A</code> 곱했을때 상수 <code>λ</code> 와 다음의 관계를 가진다. (<code>A</code> 는 <code>n x n</code> 매트릭스)</p>

<p><img src='http://latex.codecogs.com/gif.latex?Av%20%3D%20%5Clambda%20v'  alt="" /></p>

<p>이해를 위해 <a href='http://darkpgmr.tistory.com/105' >여기</a>서 인용하면</p>

<blockquote>
  <p><em>square matrix</em> <code>A</code> 를 선형변환으로 봤을 때, 선형 변환 <code>A</code> 에 의한 변환 결과가 자기 자신의 상수배 <code>λ</code> 가 되는 <code>0</code> 이 아닌 벡터 <code>v</code> 를 <em>eigen vector</em> 라 하고, 이 <code>λ</code> 를 <em>eigen value</em> 라 한다.</p>
</blockquote>

<p>기하학적으로 보면</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Eigenvalue_equation.svg/375px-Eigenvalue_equation.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<h4 id="diagonalization">Diagonalization</h4>

<p><em>SVD</em> 에 대해 이야기 하기 전에 <em>matri diagonalizaion, 행렬 대각화</em> 도 좀 보자. </p>

<p>대각행렬은 <em>principal diagonal</em> 원소를 제외한 모든 원소가 0 인 <em>sqaure matrix</em> 인데, <em>sqaure matrix, 정방행렬</em> <code>A</code> 에 대해서</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5E%7B-1%7DAP%20%3D%20D'  alt="" /></p>

<p>인 <code>P</code> 와 <code>D</code> 가 존재하면 <code>A</code> 는 <em>diagonalizable matrix, 대각화 가능 행렬</em> <code>P</code> 를 <em>diagonalizing matrix, 대각화하는 행렬</em> 이라 부른다. </p>

<p>위 식에서 <code>D</code> 는 <em>diagonal matrix</em> 인데, </p>

<p><img src='http://latex.codecogs.com/gif.latex?D%20%3D%20%5Cbegin%7Bbmatrix%7D%20%5Clambda_1%20%26%200%20%26%20...%20%26%200%5C%5C%200%20%26%20%5Clambda_2%20%26%20...%20%26%200%5C%5C%20%5Cvdots%20%26%20%5Cvdots%20%26%20%5C%20%26%20%5Cvdots%5C%5C%200%20%26%200%20%26%20%5Ccdots%20%26%20%5Clambda_n%20%5Cend%7Bbmatrix%7D'  alt="" /></p>

<p>저 식에서 <code>A</code> 위주로 정리하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?A%20%3D%20PDP%5E%7B-1%7D'  alt="" /></p>

<p>이 때 <code>P</code> 가 고유벡터를 열벡터로 하는 행렬이고, <code>D</code> 가 고유값들을 대각 원소로 하는 대각행렬이면 <em>eigen decomposition</em> 이라 부른다.</p>

<p>위에서 <em>covariance matrix</em> 는 대칭행렬이라 말했는데, (<code>A = A^T</code>) 이 대칭행렬은</p>

<p>(1) 항상 <em>eigen decomposition</em> 이 가능하며 <br />
(2) <em>orthogonal matrix</em> 로 대각화가 가능하다. (<code>P^-1 = P^T)</code>  </p>

<h3 id="singularvaluedecomposition">Singular Value Decomposition</h3>

<p>이제, <em>Sigular Value Decomposition, 특이값 분해</em> 에 대해 이야기 하자. <em>SVD</em> 도 행렬을 대각화 하는 한 방법인데, <em>eigen decomposition</em> 과 달리 <code>m x n</code> 행렬에 적용 가능하다.</p>

<p><code>m x n</code> 행렬 <code>A</code> 에 대해 <em>SVD</em> 는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?A%20%3D%20U%20%5CSigma%20V%5ET'  alt="" /></p>

<p>여기서 <code>m x m</code> 의 <code>U</code> 는 <code>AA^T</code> 를 <em>eigen decomposition</em> 해서 얻은 <em>orthogonal matrix</em> 고, <code>U</code> 의 열벡터를 <code>A</code> 의 <em>left singular vector</em> 라 부른다. </p>

<p>이 때 <code>U</code> <em>eigen decomposition</em> 해서 나온 <em>diagonalizing matrix</em> 이므로 <code>U</code> 의 열벡터는 <code>AA^T</code> 의 <em>eigen vectors</em> 다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?AA%5ET%20%3D%20U%28%5CSigma%20%5CSigma%5ET%29U%5ET'  alt="" /></p>

<p><code>n x n</code> 의 <code>V</code> 는 <code>A^TA</code> 를 <em>eigen decomposition</em> 해서 얻은 <em>orthogonal matrix</em> 고 <code>V</code> 의 열벡터를 <code>A</code> 의 <em>right singular vector</em> 라 부른다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?A%5ETA%20%3D%20V%28%5CSigma%5ET%20%5CSigma%29V%5ET'  alt="" /></p>

<p>마찬가지로 <code>V</code> 도 <em>eigen decomposition</em> 의 결과로 얻은 <em>diagonalizing matrix</em> 이므로 <code>V</code> 의 열벡터는 <code>A^TA</code> 의 <em>eigen vectors</em> 다 </p>

<p><code>\\Sigma</code> 는 <code>AA^T, A^TA</code> 를 <em>eigen decomposition</em> 해서 얻은 <em>eigen value</em> 의 <em>square root</em> 를 대각원소로 하는 <code>m x n</code> 의 직사각 대각행렬이다. 이 때 대각 원소들이 <code>A</code> 의 <em>singular value, 특이값</em> 이다.</p>

<p><img src='http://cfile5.uf.tistory.com/image/277E3949525F5A872F520E'  alt="" /></p>

<p>(관련 그림과 설명은 <a href='http://darkpgmr.tistory.com/106' >여기</a>서 참조했습니다.)</p>

<p>이 때 <code>AA^T</code> 와 <code>A^TA</code> 의 고유값 <code>λ</code> 는 동일하며 0 이상이다. 그렇기 때문에 <em>square root</em> 를 씌우고, 동일한 행렬 <code>\\Sigma</code> 로 표현할 수 있다. (자세한 설명은 <a href='http://darkpgmr.tistory.com/106' >여기</a> 참조)</p>

<p><code>AA^T</code> 와 <code>A^TA</code> 의 공통의 고유값에 대해 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csigma_1%5E2%20%3E%3D%20%5Csigma_2%5E2%20%3E%3D%20%5Ccdots%20%3E%3D%20%5Csigma_s%5E2%20%3E%3D%200%20%5C%20%5C%20%28s%20%3D%20min%28m%2C%20n%29%29'  alt="" /></p>

<p>이고 여기에 <em>square root</em> 를 취한 것이 <code>A</code> 의 <em>singular value, 특이값</em> 이며, 이 특이값들을 대각원소로 하는 <code>m x n</code> 행렬이 <code>\\Sigma</code> 다.</p>

<p>이 때 <code>A</code> 의 특이값과 <em>left singular value</em> <code>u_i</code>, <em>right singular value</em> <code>v_i</code> 에 대해 </p>

<p><img src='http://latex.codecogs.com/gif.latex?Av_i%20%3D%20%5Csigma_i%20u_i'  alt="" /></p>

<p><em>SVD</em> 의 기하학적 의미는 <a href='http://darkpgmr.tistory.com/106' >여기</a>를 인용하면</p>

<blockquote>
  <p>행렬을 x' = Ax와 같이 좌표공간에서의 선형변환으로 봤을 때 직교행렬(orthogonal matrix)의 기하학적 의미는 회전변환(rotation transformation) 또는 반전된(reflected) 회전변환, 대각행렬(diagonal maxtrix)의 기하학적 의미는 각 좌표성분으로의 스케일변환(scale transformation)이다.</p>
  
  <p>행렬 R이 직교행렬(orthogonal matrix)이라면 RRT = E이다. 따라서 det(RRT) = det(R)det(RT) = det(R)2 = 1이므로 det(R)는 항상 +1, 또는 -1이다. 만일 det(R)=1라면 이 직교행렬은 회전변환을 나타내고 det(R)=-1라면 뒤집혀진(reflected) 회전변환을 나타낸다.</p>
  
  <p>따라서 식 (1), A = UΣVT에서 U, V는 직교행렬, Σ는 대각행렬이므로 Ax는 x를 먼저 VT에 의해 회전시킨 후 Σ로 스케일을 변화시키고 다시 U로 회전시키는 것임을 알 수 있다.</p>
</blockquote>

<p><img src='http://cfile2.uf.tistory.com/image/2725C84C5260AA5F28DFCA'  alt="" /></p>

<p align="center">(<a href='http://darkpgmr.tistory.com/106' >http://darkpgmr.tistory.com/106</a>)</p>

<p><br/></p>

<p>다시 처음의 슬라이드로 돌아가면 </p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>여기서 <code>svd</code> 함수의 인자 <code>Sigma</code> 가 <em>covariant matrix</em> 고 리턴값 <code>U, S, V</code> 가 각각 위에서 본 <code>U, \\Sigma, V</code> 다. </del>변수 이름을 헷갈리게 지으심;~~</p>

<p>마지막 질문이다. <em>PCA</em> 에서 데이터 매트릭스 <code>X</code> 에 대해 <em>covariant matrix</em> <code>XX^T</code> 로 구한 <em>eigen vector</em> 의 열벡터가, 왼쪽부터 순서대로 분산을 최대로 하는 벡터(방향)인데, (<a href='http://darkpgmr.tistory.com/110' >여기</a>참조)</p>

<p>왜 우리는 <em>SVD</em> 의 <code>U</code> 를 택하는 것일까? 다시 말해 <em>PCA</em> 와 <em>SVD</em> 는 무슨 관계일까?</p>

<p><a href='http://math.stackexchange.com/questions/3869/what-is-the-intuitive-relationship-between-svd-and-pca' >What is the intuitive relationship between SVD and PCA</a> 를 참조하면,</p>

<p>데이터 매트릭스 <code>X</code> 에 대해서, 공분산 매트릭스 <code>XX^T</code> 에 대해</p>

<p><img src='http://latex.codecogs.com/gif.latex?XX%5ET%20%3D%20WDW%5ET'  alt="" /></p>

<p>이 때 <code>X</code> 의 <em>SVD</em> 는</p>

<p><img src='http://latex.codecogs.com/gif.latex?X%20%3D%20U%20%5CSigma%20V%5ET'  alt="" /></p>

<p><code>U, V</code> 는 위에서 언급했듯이 <code>XX^T, X^TT</code> 의 고유값 분해로 얻은 대칭행렬 이므로 <code>VV^T = I, UU^T = I</code> 이다. 따라서</p>

<p><img src='http://latex.codecogs.com/gif.latex?XX%5ET%20%3D%20%28U%20%5CSigma%20V%5ET%29%28U%20%5CSigma%20V%5ET%29%5ET%20%5C%5C%20%5C%5C%20%3D%20%28U%20%5CSigma%20V%5ET%29%28V%20%5CSigma%20U%5ET%29%20%5C%5C%20%5C%5C%20%3D%20U%20%5CSigma%5E2%20U%5ET'  alt="" /></p>

<p>이므로 분산이 큰 순서대로의 벡터를 열벡터로 담고 있는 <code>XX^T = WDW^T</code> 에서의 <code>W</code> 가 바로 <em>SVD</em> 의 결과인 <code>U</code> 다.</p>

<p>실제로 <em>PCA</em> 를 하기 위해 <em>SVD</em> 를 이용하는건 <em>numerically</em> 더 낫다고 한다.</p>

<blockquote>
  <p>In fact, using the SVD to perform PCA makes much better sense numerically than forming the covariance matrix to begin with, since the formation of XX⊤ can cause loss of precision. This is detailed in books on numerical linear algebra, but I'll leave you with an example of a matrix that can be stable SVD'd, but forming XX⊤ can be disastrous</p>
</blockquote>

<p>다 정리하고 보니 드는 생각이, </p>

<blockquote>
  <p>"왜 공분산 행렬을 <em>eigen decomposition</em> 한 결과 <code>XX^T = WDW^T</code> 에서 <code>W</code> 가 공분산 행렬, 즉 데이터간 상관관계, 즉 데이터 그 자체를 설명하는 걸까?"</p>
</blockquote>

<p><a href='http://math.stackexchange.com/questions/23596/why-is-the-eigenvector-of-a-covariance-matrix-equal-to-a-principal-component' >여기</a> 에서 얻은 답은,</p>

<p>공분산 매트릭스 자체는 <em>diagonal matrix</em> 가 아니다. 다시 말해 데이터 <code>X</code> 의 각 변수간 상관 관계를 담고 있다. </p>

<p>그런데, 공분산 매트릭스를 대각화 한다면 변수간 상관관계는 사라진다. 다시 말해</p>

<p><code>XX^T = WDW^T</code> 에서 <code>D</code> 자체에는 본래 데이터 <code>X</code>의 변수간 상관 관계가 포함되어 있지 않다. 그러면, 그 데이터는 다 <code>W</code> 와 <code>W^T</code> 에 들어있다는 소리인데, <code>W^T</code> 는 <code>W</code> 로 표현 가능하므로 <code>W</code> 에 데이터간 상관 관계가 모두 담겨있다는 소리다.</p>

<blockquote>
  <p>Covariance matrix Cy (it is symmetric) encodes the correlations between variables of a vector. In general a covariance matrix is non-diagonal (i.e. have non zero correlations with respect to different variables).</p>
  
  <p>But it's interesting to ask, is it possible to diagonalize the covariance matrix by changing basis of the vector?. In this case there will be no (i.e. zero) correlations between different variables of the vector.</p>
  
  <p>Diagonalization of this symmetric matrix is possible with eigen value decomposition.</p>
</blockquote>

<p>그러면 마지막 질문, <code>W</code> 의 좌측열부터가 왜 높은 분산을 가질까? </p>

<h3 id="choosingthenumberofpca">Choosing the number of PCA</h3>

<p>적절한 <code>k</code> 의 수는 어떻게 구할까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236222_7050.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위에서 언급했듯이 <em>PCA</em> 가 하는 일은 <em>projection error</em> 를 최소화 하는 것이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B1/m%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20x_%7Bapprox%7D%5E%7B%28i%29%7D%20%5Cright%20%5C%7C%20%5Cover%201/m%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20%5Cright%20%5C%7C%20%7D%20%5Cleq%200.01'  alt="" /></p>

<p>인 <code>k</code> 를 구하면 99% 의 <em>variance</em> 가 유지된다. 적당한 <em>treshold</em> 값에 해당하는 <code>k</code> 값을 찾으면 된다.</p>

<p>알고리즘은 이런데 (좌측),</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236236_2278.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>매번 계산하는건 굉장히 비 효율적이다. 따라서 우측처럼 데이터에 대한 <em>singular value</em> 를 이용하면 더 계산이 쉬워진다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B%5Csum_%7Bi%20%3D%201%7D%5Ek%20%5Cover%20%5Csum_%7Bi%20%3D%201%7D%5En%20%7D%20%5Cgeq%200.99'  alt="" /></p>

<h3 id="reconstructionfromcompressedrepresentation">Reconstruction from Compressed Representation</h3>

<p>잘 보면 <em>PCA</em> 가 하는 일은 높은 차원의 데이터를 최대한 보존하면서 차수를 줄이는 일이다. 압축 알고리즘과 비슷하다. (실제로 이미지 압축에 쓴다고 한다.)</p>

<p>그럼 압축된 차원 <code>z</code> 에서 다시 본래의 데이터 차원 <code>x</code> 를 복구하려면 어떻게 해야할까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236299_8368.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위 그림처럼 <code>z = U^T * x</code> 라 할때 좌변에 <code>U</code> 를 곱하면 <code>x_app = U * z</code> 에서 <code>x_app</code> 는 거의 <code>x</code> 에 가까워진다.</p>

<h3 id="adviceforapplypca">Advice for Apply PCA</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236320_8959.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>supervised learning</em> 의 속도를 올리는데도 쓸 수 있다. 이미지가 <code>100 x 100</code> 이면 <code>10000</code> 개의 <em>feature</em> 인데, 이건 어마어마하다.</p>

<p>먼저 <em>input</em> <code>x</code> 를 뽑아내 여기에 대해 <em>PCA</em> 를 실행하면 차원을 줄인 <em>training set</em> 을 얻을 수 있다.</p>

<p>주의할점은 <code>U</code> 를 찾을때 <em>training set</em> 에만 하고 <em>cross validation</em> 이나 <em>test</em> 까지 포함해서 <code>U</code> 를 찾으면 안된다. 나중에 <em>training set</em> 으로만 찾아낸 <code>U</code> 를 이용해서 <em>CV, test</em> 에 대해 다시 <em>PCA</em> 하자.</p>

<p><br/></p>

<p>다른 <em>PCA</em> 응용으로는 </p>

<ul>
<li>Reduce memory, disk needed to store data</li>
<li>Speed up learning algorithm</li>
<li>Visualization (<code>k = 2 or 3</code>)</li>
</ul>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236325_5356.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>PCA</em> 를 이용하면 <em>feature</em> 의 수가 줄기 때문에 <em>overfitting</em> 을 방지하기 위해 사용할 수 있다고 생각하겠지만, 별로 좋은 생각은 아니다.</p>

<p>작동은 할지 모르겠지만 <em>regularization</em> 을 이용하는 편이 낫다. </p>

<p>왜냐하면 <em>PCA</em> 는 <code>y</code> 값이 없는 상태에서 작동하기 때문에 <code>y</code> 를 고려하지 않은 데이터가 손실이 발생할 수 있다. <code>1%</code> 만 손실된다 하더라도, 그 <code>1%</code> 가 <code>y</code> 와 관련해 굉장히 중요한 정보일 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236329_4045.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>또 다른 잘못된 <em>PCA</em> 의 사용으로는, 그냥 무작정 <em>PCA</em> 를 사용하는 것이다.</p>

<p><em>original data</em> <code>x</code> 에 대해 알고리즘을 구현도 안해보고, 바로 <em>PCA</em> 의 결과인 <code>z</code> 를 이용하려는건 좋은 생각이 아니다.</p>

<p><code>x</code> 대해 작업 해보고 결과가 별로일때 <em>PCA</em> 를 고려하자.</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a> <br />
(4) <a href='http://scipy-lectures.github.io/' >http://scipy-lectures.github.io</a> <br />
(5) <a href='http://en.wikipedia.org/wiki/Correlation_and_dependence' >Wiki: Correlation and dependence</a> <br />
(6) <a href='http://en.wikipedia.org/wiki/Covariance' >http://en.wikipedia.org/wiki/Covariance</a> <br />
(7) <a href='http://darkpgmr.tistory.com/110' >http://darkpgmr.tistory.com/110</a> <br />
(8) <a href='http://darkpgmr.tistory.com/105' >http://darkpgmr.tistory.com/105</a> <br />
(9) <a href='http://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors' >Wiki: Eigenvalues and Eigenvectors</a> <br />
(10) <a href='http://www.ktword.co.kr/abbr_view.php?m_temp1=4695&amp;id=762' >http://www.ktword.co.kr</a> <br />
(11) <a href='http://darkpgmr.tistory.com/106' >http://darkpgmr.tistory.com/106</a> <br />
(12) <a href='http://math.stackexchange.com/questions/3869/what-is-the-intuitive-relationship-between-svd-and-pca' >What is the intuitive relationship between SVD and PCA</a></p>]]></description><link>http://1ambda.github.io/machine-learning-week-8/</link><guid isPermaLink="false">7890e1dc-6d1c-4bc9-89a7-809af5f1ec82</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine lerning]]></category><category><![CDATA[k-means clustering]]></category><category><![CDATA[unsupervised learning]]></category><category><![CDATA[PCA]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 30 Nov 2014 05:39:31 GMT</pubDate></item><item><title><![CDATA[Intro to Computational Thinking and Data Science 3]]></title><description><![CDATA[<h3 id="optimizationproblems">Optimization Problems</h3>

<p>일반적으로 최적화 문제는 크게 두 파트로 구성된다.</p>

<blockquote>
  <ol>
  <li>An objective funciton that is to be maximized or minimized</li>
  <li>A set of constraint (possibly empty) that must be honored</li>
  </ol>
</blockquote>

<p>최적화 문제의 예로는</p>

<ul>
<li>Shortest path</li>
<li>Traveling salesman</li>
<li>Bin packaing</li>
<li>Sequence alignment</li>
<li>Knapsack</li>
</ul>

<p>이런 알려진 문제들을 공부함으로써 <em>problem reduction</em> 을 이용할 수 있다. </p>

<h3 id="knapsackproblem">Knapsack Problem</h3>

<p>먼저 <em>greedy approach</em> 를 사용해 보자. 이 방법을 적용하기 위해서는 무엇이 <em>best</em> 인지 정해야 한다. <em>value</em> 가 높은것이나, <em>value/weight</em> 가 높은것 등 다양한 기준을 세울 수 있다.</p>

<p>문제를 모델링 해보자. 아이템부터</p>

<pre><code class="python">class Item(object):  
    def __init__(self, n, v, w):
        self.name = n
        self.value = v
        self.weight = w

    def getName(self):
        return self.name

    def getValue(self):
        return self.value

    def getWeight(self):
        return self.weight

    def __str__(self):
        result = '&lt;' + self.name + ', ' + str(self.value)\
                 + ", " + str(self.weight) + '&gt;'

        return result

def buildItems():  
    names = ['clock', 'painting', 'radio',
             'vase', 'book', 'computer']

    vals = [175, 90, 20, 50, 10, 200]
    weights = [10, 9, 4, 2, 1, 20]

    Items = []

    for i in range(len(vals)):
        Items.append(Item(names[i], vals[i], weights[i]))

    return Items
</code></pre>

<p><em>greedy algorithm</em> 을 구현하면</p>

<pre><code class="python">def greedy(Items, maxWeight, predicate):  
    assert type(Items) == list and maxWeight &gt;= 0

    orderedItems = sorted(Items, key=predicate, reverse=True)

    result = []
    totalVal = 0.0
    totalWeight = 0.0
    i = 0

    while totalWeight &lt; maxWeight and i &lt; len(Items):
        if (totalWeight + orderedItems[i].getWeight()) &lt;= maxWeight:
            result.append(orderedItems[i])
            totalWeight += orderedItems[i].getWeight()
            totalVal += orderedItems[i].getValue()

        i += 1

    return (result, totalVal)

# predicate
def value(item):  
    return item.getValue()


def weightInverse(item):  
    return 1.0 / item.getWeight()


def density(item):  
</code></pre>

<p><em>predicate</em> 를 받아, 이 순서대로 <em>items</em> 를 정렬 한 뒤 반복문을 돌면서 아이템을 집어넣는다. <code>sorted</code> 함수는 <em>predicate</em> 에 따라 정렬 한 뒤 새로운 리스트를 생성한다.</p>

<pre><code class="python">orderedItems = sorted(Items, key=predicate, reverse=True)  
</code></pre>

<p>이제 테스트 코드를 작성하자.</p>

<pre><code class="python"># test
def testGreedy(Items, constraint, pred):  
    items, val = greedy(Items, constraint, pred)
    print ('Total value of items taken = ' + str(val))
    for item in items:
        print ' ', item

def simulation():  
    maxWeight = 20
    Items = buildItems()
    print ('Items to choose from')
    for item in Items:
        print ' ', item

    print 'by value'
    testGreedy(Items, maxWeight, value)
    print 'by 1 / weight'
    testGreedy(Items, maxWeight, weightInverse)
    print 'by density'
    testGreedy(Items, maxWeight, density)

simulation()  
</code></pre>

<p>결과는</p>

<pre><code>Items to choose from  
  &lt;clock, 175, 10&gt;
  &lt;painting, 90, 9&gt;
  &lt;radio, 20, 4&gt;
  &lt;vase, 50, 2&gt;
  &lt;book, 10, 1&gt;
  &lt;computer, 200, 20&gt;

by value  
Total value of items taken = 200.0  
  &lt;computer, 200, 20&gt;

by 1 / weight  
Total value of items taken = 170.0  
  &lt;book, 10, 1&gt;
  &lt;vase, 50, 2&gt;
  &lt;radio, 20, 4&gt;
  &lt;painting, 90, 9&gt;

by density  
Total value of items taken = 255.0  
  &lt;vase, 50, 2&gt;
  &lt;clock, 175, 10&gt;
  &lt;book, 10, 1&gt;
  &lt;radio, 20, 4&gt;
</code></pre>

<p>보면 알겠지만 탐욕적으로 접근했을때 항상 최적의 답안을 찾으리라는 보장이 없다. <del>패가망신</del></p>

<p>전체적인 성능은 <code>sorted</code> + <code>while</code> 에서, <code>O(n logn)</code> 이다. (<code>n</code> 은 아이템 갯수)</p>

<h3 id="01knapsackproblem">0/1 Knapsack Problem</h3>

<p><em>greedy</em> 는 최적의 답을 제공해 주지 않는다. 어떻게 해야할까? 한가지 방법은,</p>

<p>벡터 <code>L</code> 을 각 아이템의 가중치로 채우고, 벡터 <code>V</code> 를 각 아이템이 선택되었는지, 선택되지 않았는지를 <code>1/0</code> 으로 표시 한 뒤 <code>V * L</code> 이 최대가 되는 <code>V</code> 를 찾으면 된다. 물론 이 값은 무게의 최대치인 <code>W</code> 를 넘을 수 없다.</p>

<p>그럼 이제 문제는 다양한 종류의 <code>V</code> 를 만드는 문제로 치환된다. 일반적으로는 <code>V</code> 의 수는 <code>2^n</code> 이겠지만, 여기서는 <code>W</code> 란 제약조건이 있으므로 그것보다는 작은 수가 될 것이다.</p>

<p>넘어가기 전에 잠깐! 수의 크기에 대해 감을 잡고 넘어가자. 요즘 <em>CPU</em> 는 <code>1GHz</code> 는 그냥 넘으니까, 1초의 10억번이 넘는 연산을 할 수 있다. 한 작업에 대해 수백개의 명령이 필요하므로, 1초에 수백만의 작업을 할 수 있다. </p>

<p>수백만은 얼마나 큰 수일까? <code>10! = 3628800</code> 이다. 대략 11 ~ 10 개를 배열해도 백만가지의 순열이 만들어진다. 그리고 <code>2^20 = 1048576</code> 이므로 원소가 스무개인 집합의 부분집합이 백만개정도라 보면 된다. </p>

<p>따라서 최적해를 찾고자 할때는 <code>10!</code>, <code>2^22</code> 정도가 몇초 내외의 감당할만한 계산시간이라 볼 수 있다. </p>

<p><br/></p>

<h3 id="bruteforceapproach">Brute Force Approach</h3>

<p><em>power set</em> 을 만들어 보자.</p>

<pre><code class="python"># brute force
def int2bin(n, digit):  
    assert type(n) == int and type(digit) == int
    assert n &gt;= 0 and n &lt; 2 ** digit

    # binary string
    binStr = ''

    while n &gt; 0:
        binStr = str(n % 2) + binStr
        n = n // 2

    while digit - len(binStr) &gt; 0:
        binStr = '0' + binStr

    return binStr


def powerSets(Items):  
    count = 2 ** len(Items)
    binStrs = []

    for i in range(count):
        binStrs.append(int2bin(i, len(Items)))

    powerSet = []
    for bs in binStrs:
        elem = []
        for i in range(len(bs)):
            if bs[i] == '1':
                elem.append(Items[i])
        powerSet.append(elem)

    return powerSet
</code></pre>

<p>이제 테스트 함수를 작성하자.</p>

<pre><code class="python">def optimalItems(powerSet, constraint, getValue, getWeight):  
    optimalSet = None
    optimalValue = 0.0

    for Items in powerSet:
        ItemsValue = 0.0
        ItemsWeight = 0.0

        for item in Items:
            ItemsValue += getValue(item)
            ItemsWeight += getWeight(item)

        if ItemsWeight &lt;= constraint and ItemsValue &gt; optimalValue:
            optimalValue = ItemsValue
            optimalSet = Items

    return (optimalSet, optimalValue)


def bruteForceSolution():  
    Items = buildItems()
    pset = buildPowerSet(Items)

    items, value = optimalItems(pset, 20,
                                Item.getValue,
                                Item.getWeight)

    print ('brute force : ' + str(value))
    for item in items:
        print ' ', item
</code></pre>

<p>돌려보면</p>

<pre><code class="python">bruteForceSolution()

brute force : 275.0  
  &lt;clock, 175, 10&gt;
  &lt;painting, 90, 9&gt;
  &lt;book, 10, 1&gt;
</code></pre>

<p>다 좋은데, 아이템의 개수가 많아지면 <code>2^n</code> 으로 숫자가 커지므로 계산 비용이 어마어마하게 커진다. 다른 방법을 찾아보자.</p>

<h3 id="decisiontree">Decision Tree</h3>

<p>트리의 각 <em>depth</em> 를 아이템으로 표현하고, <em>left node</em> 를 <code>1 (selected)</code>, <em>right node</em> 를 <code>0 (unselected)</code> 로 정해 각 노드마다 전체 <em>value, weight</em> 를 기록하도록 하면 <em>search space</em> 를 상당히 줄일 수 있다. 왜냐하면 특정 아이템을 선택 한 후 무게를 초과하면, 그 하위 트리는 살펴보지 않아도 되기 때문이다.</p>

<p>이 트리를 <strong>decision tree</strong> 라 부른다.</p>

<pre><code class="python"># decision tree

def maxVal(items, avail):  
    if items == [] or avail == 0:
        result = (0, ())
    elif items[0].getWeight() &gt; avail:
        # do not take
        result = maxVal(items[1:], avail)
    else:
        current = items[0]
        # left branch : take the item
        leftValue, leftItems = maxVal(items[1:],
                                      avail - current.getWeight())
        leftValue += current.getValue()

        # right branch : do not take the item
        rightValue, rightItems = maxVal(items[1:],
                                        avail)

        if leftValue &gt; rightValue:
            result = (leftValue, leftItems + (current,))
        else:
            result = (rightValue, rightItems)

    return result


def decisionTreeSolution():  
    Items = buildItems()
    value, selected = maxVal(Items, 20)

    for item in selected:
        print item

    print ('decisition tree value : ' + str(value))
</code></pre>

<p>실행하면</p>

<pre><code class="python"># decisionTreeSolution()

&lt;book, 10, 1&gt;  
&lt;painting, 90, 9&gt;  
&lt;clock, 175, 10&gt;  
decisition tree value : 275  
</code></pre>

<p>모든 <em>power set</em> 을 살펴보지 않는다는 점에서 맘에 들지만, 가방의 용량이 상당히 크다면 <em>power set</em> 처럼 <code>2^n</code> 으로 증가할 수 있다.</p>

<h3 id="tradeoff">Trade Off</h3>

<p><em>greedy</em> 는 매 선택마다 최선을 택함으로써 <em>locally optimal</em> 을 찾지만 이게 <em>global optimal</em> 을 의미하진 않는다. 대신, 상당히 납득할만한 답안을 빠른 시간 안에 줄 수 있다.</p>

<h3 id="memoization">Memoization</h3>

<p><em>decision</em> 트리를 잘 보면 <em>sub-problem</em> 에서 같은 계산을 여러번 하는걸 볼 수 있다. 예를 들어 <code>{a, b, c, d}</code> 의 아이템이 있을때 <code>{a, c, d}</code> 와 <code>{b, c, d}</code> 는 다른 분기인데, 둘 다 <code>{c, d}</code> 를 계산하고 있다.</p>

<p>이 문제는 피보나치에서도 발견할 수 있는데,</p>

<pre><code class="python">def fib(n):  
    assert type(n) == int and n &gt;= 0

    if n == 0 or n == 1:
        return 1
    else:
        return fib(n-1) + fib(n-2)
</code></pre>

<p><code>fib(n-1)</code> 에서 <code>fib(n-2)</code> 를 계산하니까, <code>fib(n-2)</code> 를 두번 계산하는 셈이다.</p>

<p><img src='https://www.cs.cmu.edu/' ~adamchik/15-121/lectures/Recursions/pix/fib.bmp" alt="" /></p>

<p align="center">(<a href='https://www.cs.cmu.edu/' ~adamchik'>https://www.cs.cmu.edu/~adamchik</a>)</p>

<p>한번 계산한 결과는 저장해 놓고 다음에 쓰는 <em>memoization</em> 을 이용해 보자.</p>

<blockquote>
  <p><strong>Memoization:</strong> the first time we compute a function, keep track of the value; any subsequent time, just look up the value</p>
</blockquote>

<pre><code class="python">def fastFib(n, memo):  
    assert type(n) == int and n &gt;= 0

    if n == 0 or n == 1:
        return 1

    if n in memo:
        return memo[n]

    result = fastFib(n-1, memo) + fastFib(n-2, memo)
    memo[n] = result
    return result


def testFastFib(n):  
    assert type(n) == int and n &gt;= 0

    for i in range(n):
        print ('fast fib of', i, '=', fastFib(i, {}))
</code></pre>

<p><em>memoization</em> 은 <em>dynamic programming</em> 등에 사용할 수 있다. </p>

<h3 id="graph">Graph</h3>

<p><em>optimization problem</em> 은 <em>search problem</em> 이라 볼 수 있다. 다양한 탐색 공간 속에서 최적의 답을 검색해 나가는 문제와 동일하기 때문이다.</p>

<p>그래프를 모델링 해 보자.</p>

<pre><code class="python">class Node(object):  
    def __init__(self, name):
        self.name = str(name)

    def getName(self):
        return self.name

    def __str__(self):
        return self.name


class Edge(object):  
    def __init__(self, src, dest):
        self.src = src
        self.dest = dest

    def getSrc(self):
        return self.src

    def getDest(self):
        return self.dest

    def __str__(self):
        return str(self.src) + ' -&gt; ' + str(self.dest)


class WeightedEdge(Edge):  
    def __init__(self, src, dest, weight=1.0):
        self.src = src
        self.dest = dest
        self.weight = weight

    def getWeight(self):
        return self.weight

    def __str__(self):
        return str(self.src) + ' -&gt; ('\
            + str(self.weight) + ')'\
            + str(self.dest)


class Digraph(object):  
    def __init__(self):
        self.nodes = set([])
        self.edges = {}

    def addNode(self, node):
        if node in self.nodes:
            raise ValueError('duplicated node')
        else:
            self.nodes.add(node)
            self.edges[node] = []

    def addEdge(self, edge):
        src = edge.getSrc()
        dest = edge.getDest()

        if not(src in self.nodes and dest in self.nodes):
            raise ValueError('unknown node')

        self.edges[src].append(dest)

    def childrenOf(self, node):
        return self.edges[node]

    def hasNode(self, node):
        return node in self.nodes

    def __str__(self):
        res = ''

        for src in self.edges:
            for dest in self.edges[src]:
                res = res + str(src) + ' -&gt; ' + str(dest) + '\n'

        return res[:-1]


# undirected
class Graph(Digraph):  
    def addEdge(self, edge):
        Digraph.addEdge(self, edge)
        rev = Edge(edge.getDest(), edge.getSrc())
        Digraph.addEdge(self, rev)
</code></pre>

<p>그래프 최적화 문제의 예는</p>

<ul>
<li>Shortest path</li>
<li>Shortest weighted path</li>
<li>Cliques</li>
<li>Min cut</li>
</ul>

<p>이제 테스트 그래프를 만들어 보자.</p>

<pre><code class="python">def makeEdge(nodes, src, dest):  
    return Edge(nodes[src], nodes[dest])


def testGraph():  
    nodes = []

    # index will be the name of each node
    for idx in range(6):
        nodes.append(Node(idx))

    g = Digraph()

    for n in nodes:
        g.addNode(n)

    srcs = [0, 1, 2, 2, 3, 3, 0, 1, 3, 4]
    dests = [1, 2, 3, 4, 4, 5, 2, 0, 1, 0]

    for (s, d) in zip(srcs, dests):
        g.addEdge(makeEdge(nodes, s, d))

    print g
</code></pre>

<p>실행하면 이런 그래프를 얻을 수 있다.</p>

<p><img src='https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/L19_graph.png'  alt="" /></p>

<pre><code class="python">testGraph()

0 -&gt; 1  
0 -&gt; 2  
1 -&gt; 2  
1 -&gt; 0  
2 -&gt; 3  
2 -&gt; 4  
3 -&gt; 4  
3 -&gt; 5  
3 -&gt; 1  
4 -&gt; 0  
</code></pre>

<h3 id="dfs">DFS</h3>

<pre><code class="python"># assumes graph is a directed graph
def DFS(graph, start, end, path=[]):  
    path = path + [start]

    if start == end:
        return path

    for node in graph.childrenOf(start):
        if node not in path:
            newPath = DFS(graph, node, end, path)

            if newPath is not None:
                return newPath
</code></pre>

<p>테스트 코드를 돌려보면 알겠지만, 최단경로를 돌려주진 않는다.</p>

<pre><code class="python">def makeEdge(nodes, src, dest):  
    return Edge(nodes[src], nodes[dest])


def testGraph():  
    nodes = []

    # index will be the name of each node
    for idx in range(6):
        nodes.append(Node(str(idx)))

    g = Digraph()

    for n in nodes:
        g.addNode(n)

    srcs = [0, 1, 2, 2, 3, 3, 0, 1, 3, 4]
    dests = [1, 2, 3, 4, 4, 5, 2, 0, 1, 0]

    for (s, d) in zip(srcs, dests):
        g.addEdge(makeEdge(nodes, s, d))

    return g, nodes

def visit():  
    g, nodes = testGraph()
    path = DFS(g, nodes[0], nodes[5], [])

    for p in path:
        print p

visit()

0  
1  
2  
3  
5  
</code></pre>

<p>처음 찾은 목적지까지의 거리보다 더 짧은 목적지까지의 거리만을 탐색하는 알고리즘을 고려해보자. 가장 먼저 찾은 목적지까지거리를 <code>shortest</code> 에 저장하고, 이것보다 짧은 경로만 탐색한다.</p>

<pre><code class="python"># assumes graph is a directed graph
def shortestDFS(graph, start, end, path=[], shortest=None):  
    path = path + [start]

    if start == end:
        return path

    for node in graph.childrenOf(start):
        if node not in path:
            if shortest is None or len(path) &lt; len(shortest):
                newPath = shortestDFS(graph, node, end, path, shortest)
                if newPath is not None:
                    shortest = newPath

    return shortest
</code></pre>

<p>이부분이 핵심이다</p>

<pre><code class="python">if shortest is None or len(path) &lt; len(shortest):  
</code></pre>

<p>실제로 돌려보면 <code>0, 2, 3, 5</code> 로 최단경로를 돌려준다.</p>

<h3 id="clique">Clique</h3>

<p>각 점이 나머지 모든 점과 연결된 그래프를 <em>clique</em> 라 부르는데, 재미난 특징이 몇 개 있다.</p>

<p>(1) 모든 <em>edge</em> 의 수는 <code>n * (n - 1) / 2</code> 다. <br />
(2) 임의의 두 점 <code>A, B</code> 에 대해 길이가 <code>1 &lt;= m &lt;= (n-1)</code> 인 모든 경로는 <code>(n-2)! / (n-m-1)!</code> 이다. <br />
(3) <code>(2)</code> 를 이용하면, 모든 경로를 탐색할 경우의 퍼포먼스는 <code>O((n-2)!)</code> 이다. 여기서 <code>1/0! + 1/1! + 1/2! ... + 1/n! &lt;= e</code>, <code>e</code> 는 상수</p>

<h3 id="bfs">BFS</h3>

<pre><code class="python">def BFS(graph, start, end, q=[]):  
    init = [start]
    q.append(init)

    while len(q) != 0:
        # get a path from q
        current = q.pop(0)
        lastNode = current[len(current) - 1]
        if lastNode == end:
            return current

        for nextNode in graph.childrenOf(lastNode):
            if nextNode not in current:
                path = current + [nextNode]
                q.append(path)

    return None
</code></pre>

<h3 id="references">References</h3>

<p>(1) <em>MIT 6.00.2 2x</em> in <strong>edx</strong> <br />
(2) <a href='https://www.cs.cmu.edu/' ~adamchik/15-121/lectures/Recursions/recursions.html">https://www.cs.cmu.edu/</a></p>]]></description><link>http://1ambda.github.io/edx-600-2x-3/</link><guid isPermaLink="false">7426f518-4562-4acc-b98f-2d07e03a4ef4</guid><category><![CDATA[edx]]></category><category><![CDATA[decision tree]]></category><category><![CDATA[knapsack problem]]></category><category><![CDATA[memoization]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 28 Nov 2014 01:42:47 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 7]]></title><description><![CDATA[<p><em>the countdown problem</em> 은 프랑스 퀴즈 프로그램에서 유래한 문제입니다. 주어진 양수를 단 한번씩만 이용하여 특정 숫자를 만드는 문제입니다. 사용가능한 연산자는 <code>+, *, -, /</code> 입니다.</p>

<p>예를 들어 <code>(25 - 10) * (50 + 1) = 765</code> 입니다. </p>

<p>사람이 풀기엔 <em>search space</em> 가 좀 넓어서 답을 한번에 찾기 어렵지만, 컴퓨터는 무한한 인내심을 가지고 있기 때문에 풀기에 적합한 문제입니다.</p>

<h3 id="evaluatingexpressions">Evaluating Expressions</h3>

<p>이번시간엔 <em>bottom-up</em> 으로 접근해 볼까요? 먼저 연산자타입과 이를 적용하는 함수 <code>apply</code> 를 만들어보면</p>

<pre><code class="haskell">data Op = Add | Sub | Mul | Div

apply :: Op -&gt; Int -&gt; Int -&gt; Int  
apply Add x y = x + y  
apply Sub x y = x - y  
apply Mul x y = x * y  
apply Div x y = x `div` y  
</code></pre>

<p>그리고 우리가 가진건 양수이기 때문에, 연산의 결과가 양수인지 체크하기 위한 <code>valid</code> 함수를 만들어 보겠습니다. </p>

<pre><code class="haskell">valid :: Op -&gt; Int -&gt; Int -&gt; Bool  
valid Add _ _ = True  
valid Sub x y = x &gt; y  
valid Mul _ _ = True  
valid Div x y = x `mod` y == 0  
</code></pre>

<p>이제 수식을 나타내는 <code>Expr</code> 타입과 평가하기 위한 <code>eval</code> 함수를 만들면</p>

<pre><code class="haskell">data Expr = Val Int = App Op Expr Expr

eval :: Expr -&gt; [Int]  
eval (Val n) = [n | n &gt; 0]  
eval (App o l r) = [apply o x y | x &lt;- eval l,  
                                  y &lt;- eval r,
                                  valid o x y]
</code></pre>

<p>여기선 연산이 실패했음을 나타내기 위해 <code>[]</code> 를 사용했습니다. <code>Maybe</code> 타입 대신 리스트를 쓸 때의 장점은, <em>list comprehension</em> 을 이용할 수 있다는 점이지요!</p>

<h3 id="formalizingtheproblem">Formalizing The Problem</h3>

<p>우리가 풀어야할 문제는 가능한 모든 조합을 탐색해야하기 때문에 다양한 조합을 만들기 위한 <code>choices</code> 함수를 만들겠습니다.</p>

<pre><code class="haskell">-- subs [1, 2] -&gt; [[], [1], [2], [1, 2]]
subs :: [a] -&gt; [[a]]  
subs [] = [[]]  
subs (x:xs) = yss ++ map (x:) yss  
  where yss = subs xs

-- interleave 1 [2, 3] -&gt; [[1, 2, 3], [2, 1, 3], [2, 3, 1]]
interleave :: a -&gt; [a] -&gt; [[a]]  
interleave x [] = [[x]]  
interleave x (y:ys) = (x:y:ys) : map (y:) (interleave x ys)

-- perm [1, 2, 3] = [[1, 2, 3], [1, 3, 2], [2, 3, 1], ..]
perm :: [a] -&gt; [[a]]  
perm [] = [[]]  
perm (x:xs) = concat (map (interleave x) (perm xs))

-- choices [1, 2] -&gt; [[], [1], [2], [1, 2], [2, 1]]
choices :: [a] -&gt; [[a]]  
choices xs = concat (map (perm) (subs xs))  
</code></pre>

<p>여기서 <code>subs</code> 함수는 순서를 고려하지 않은 부분집합을, <code>perm</code> 는 순열을 돌려줍니다. <code>choices</code> 는 이 두 함수를 조합하여 부분집합의 순열리스트를 돌려줍니다.</p>

<p>이제 입력한 수식이 정답인지 알려주는 <code>solution</code> 함수를 볼까요? 입력한 수식의 결과가 주어진 수 <code>n</code> 과 같아야 하고, 수식에 있는 숫자가 주어진 숫자들의 나열 <code>ns</code> 와 같아야 합니다.</p>

<pre><code class="haskell">values :: Expr -&gt; [Int]  
values (Val n) = [n]  
values (App _ l r) = values l ++ values r

solution :: Expr -&gt; [Int] -&gt; Int -&gt; Bool  
solution e ns n = elem (values e) (choices ns) &amp;&amp; eval e == [n]  
</code></pre>

<h3 id="bruteforce">Brute Force</h3>

<p>브루트 포스 방법으로 풀려면, 사용가능한 수들을 받아, 가능한 모든 수식을 돌려주면 됩니다.</p>

<pre><code class="haskell">-- brute force
split :: [a] -&gt; [([a], [a])]  
split xs = [splitAt i xs | i &lt;- [1..(n-1)]]  
  where n = length xs

exprs :: [Int] -&gt; [Expr]  
exprs [] = []  
exprs [n] = [Val n]  
exprs ns = [e | (ls, rs) &lt;- split ns  
              , l &lt;- exprs ls
              , r &lt;- exprs rs
              , e &lt;- combine l r]

combine :: Expr -&gt; Expr -&gt; [Expr]  
combine l r = [App o l r | o &lt;- [Add, Sub, Mul, Div]]

-- brute force solutions
bSolutions :: [Int] -&gt; Int -&gt; [Expr]  
bSolutions ns n = [e | ns' &lt;- choices ns  
                     , e &lt;- exprs ns'
                     , eval e == [n]]
</code></pre>

<p>아주아주아주아주 느립니다. 제 컴퓨터에서는 2분이 지나도 답이 안나오네요.</p>

<pre><code class="haskell">&gt; length (Bolutions [1, 3, 7, 10, 25, 50] 765)
</code></pre>

<h3 id="fastversion">Fast version</h3>

<p>어느부분을 고쳐야 더 빨라질까요? 한가지 개선할 부분은, <code>valid</code> 가 너무 늦게 호출된다는 점입니다. 우리가 어마어마한 식을 만드는 반면, 답이 780개란 사실은 대부분의 식이 값보다는 형태에 의해 필터링 된다는 뜻입니다. 따라서 <code>valid</code> 를 좀 더 땡길 수 있다면 계산이 훨씬 빨라질겁니다.</p>

<pre><code class="haskell">eval :: Expr -&gt; [Int]  
eval (Val n) = [n | n &gt; 0]  
eval (App o l r) = [apply o x y | x &lt;- eval l,  
                                  y &lt;- eval r,
                                  valid o x y]

exprs :: [Int] -&gt; [Expr]  
exprs [] = []  
exprs [n] = [Val n]  
exprs ns = [e | (ls, rs) &lt;- split ns  
              , l &lt;- exprs ls
              , r &lt;- exprs rs
              , e &lt;- combine l r]

bSolutions :: [Int] -&gt; Int -&gt; [Expr]  
bSolutions ns n = [e | ns' &lt;- choices ns  
                     , e &lt;- exprs ns'
                     , eval e == [n]]
</code></pre>

<p>이 부분을 좀 고쳐보겠습니다. </p>

<pre><code class="haskell">results :: [Int] -&gt; [Result]  
results [] = []  
results [n] = [(Val n, n) | n &gt; 0]  
results ns = [res | (ls, rs) &lt;- split ns  
                  , lx &lt;- results ls
                  , ry &lt;- results rs
                  , res &lt;- combine' lx ry]

combine' :: Result -&gt; Result -&gt; [Result]  
combine' (l,x) (r, y) =  
  [(App o l r, apply o x y) | o &lt;- [Add, Sub, Mul, Div]
                            , valid o x y]

fastSolutions :: [Int] -&gt; Int -&gt; [Expr]  
fastSolutions ns n = [e | ns' &lt;- choices ns  
                       , (e, m) &lt;- results ns'
                       , m == n]
</code></pre>

<p>값을 평가하기 전에 먼저 <code>valid</code> 를 호출하고 계산된 값을 튜플에 저장해 놓았다가 나중에 비교합니다.</p>

<pre><code class="haskell">&gt; length (Bolutions [1, 3, 7, 10, 25, 50] 765)
-- 780
</code></pre>

<p>더 개선할 수 있을까요? 음.. 생각해보니 <code>x * y = y * x</code> 이기도 하고 <code>x * 1</code> 은 <code>x</code> 이기도 하네요. 이런것들을 좀 줄일수 있을겁니다. <code>valid</code> 함수를 고쳐보도록 하지요.</p>

<pre><code class="haskell">valid :: Op -&gt; Int -&gt; Int -&gt; Bool  
valid Add _ _ = True  
valid Sub x y = x &gt; y  
valid Mul _ _ = True  
valid Div x y = x `mod` y == 0

-- modified
valid :: Op -&gt; Int -&gt; Int -&gt; Bool  
valid Add x y = x &lt;= y  
valid Sub x y = x &gt; y  
valid Mul x y = x &lt;= y &amp;&amp; x /= 1 &amp;&amp; y /= 1  
valid Div x y = x `mod` y == 0 &amp;&amp; y /= 1  
</code></pre>

<p><code>x &lt;= y</code> 로 만들어 중복을 제거하고 <code>x /= 1</code> 을 이용해 1을 곱한 수식을 제거했습니다. 결과가 정말 빠르게 나옵니다. </p>

<p>책에서 말하기를 브루트 포스 방법은 44초, 그 다음버전은 4초, 마지막 버전은 0.44 초 만에 계산이 끝난다고 합니다. 연산 시간이 어마어마하게 줄어들었죠?</p>

<pre><code class="haskell">&gt; length (Bolutions [1, 3, 7, 10, 25, 50] 765)
-- 49
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em>  </p>]]></description><link>http://1ambda.github.io/haskell-intro7/</link><guid isPermaLink="false">334d7896-68cf-4d8b-943c-0a31e6ce3dfb</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 26 Nov 2014 16:22:28 GMT</pubDate></item><item><title><![CDATA[Process Mining, Week2]]></title><description><![CDATA[<p>지난 주 수업을 듣고 보니, 이벤트 로그를 만들어서 악성 사용자나, 비 정상적인 유저의 행동으로 부터 모델을 만들어서 어뷰징을 막거나, 부족한점을 개선해 서비스의 품질을 높일수도 있겠단 생각이 들었다.</p>

<p>근데 프로세스 마이닝에서 사용하는 이벤트 로그를 만들려면 <em>activity</em> 가 어떤 데이터가 되야할지 부터 정해야 하는데, 쉽지가 않다. 2주차에는 이런 고민들을 좀 해 보고, 프로세스 마이닝에서 사용하는 모델 표기법과 알파 알고리즘에 대해 논의한다.</p>

<p><img src='http://www.triua.com/wp-content/uploads/business-process-modeling-automation.jpg'  alt="" /></p>

<p align="center">(<a href='http://www.triua.com/' >http://www.triua.com/</a>)</p>  

<p><br/></p>

<h3 id="eventlogsandprocessmodels">Event Logs and Process Models</h3>

<p>지난 시간에 <strong>Play-in</strong>, <strong>Play-out</strong>, <strong>Replay</strong> 에 대해 잠깐 언급했는데, 이 중에서 <strong>Play-in</strong> 은 사람들이 정해진 규칙에 의해서가 아니라, 실제로 따르는 프로세스를 찾아낼 수 있다.</p>

<blockquote>
  <p><strong>Process discovery:</strong> learning de facto process models from observed behavior</p>
</blockquote>

<p>그리고 <strong>Replay</strong> 는 <em>conformance checking</em>, <em>prediction</em>, <em>bottleneck analysis</em> 에 사용할 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-17-728.jpg?cb=1305062721'  alt="" /></p>

<p align="center">(www.procesmining.org)</p>

<p>결국 <em>observed behavior</em> 의 기록인 <em>event-log</em> 를 모으는 것이 중요하다. 그런데, 모든 이벤트를 바로 <em>case id, activity name, timestamp</em> 로 매핑하긴 쉬운 일이 아니다.</p>

<p>예를 들어 이메일에서 <em>activity</em> 는 무엇일까? <del>어렵다.</del> 다양한 답이 나올 수 있지만, 딱 맘에 드는 답을 찾기 어렵다.</p>

<p><em>transactional information</em> 에서는 <em>event</em> 가 다양한 <em>state (상태)</em> 로 나타날 수 있다.</p>

<p><img src='http://www.cubrid.org/files/attach/images/220547/971/295/thread-state-diagram.png'  alt="" /></p>

<p align="center">(<a href='http://architects.dzone.com/' >http://architects.dzone.com</a>)</p>

<p>한 가지 더 생각해 볼 문제는 <em>case vs event</em> 다. <em>case</em> 는 <em>birth date</em> 처럼 변하지 않는 것이고, <em>event</em> 는 프로세스를 거치면서 변하는 속성들이다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter04gettingthedata-110510153210-phpapp01/95/process-mining-chapter-4-getting-the-data-6-728.jpg?cb=1305062568'  alt="" /></p>

<p>이벤트를 정의하는데 다양한 방법이 있어 혼란스러울 수 있겠지만, 다행히도 프로세스 마이닝에서 사용되는 표준 포맷이 있다. <em>eXtensible Event Stream, XES</em> 인데,</p>

<p><img src='http://fluxicon.com/blog/wp-content/uploads/2010/09/XES-Schema.png'  alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/' >http://fluxicon.com</a>)</p>

<p><br/> <br />
<em>control flow</em> 를 표현하는데는 다양한 방법이 있다. <em>BPMN, UML, Patri net</em> 등등..</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Animated_Petri_net_commons.gif/330px-Animated_Petri_net_commons.gif'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Petri_net' >http://en.wikipedia.org/wiki/Petri_net</a>)</p>

<p>이 표기법들을 선택하는데 2가지 기준을 세울 수 있다. </p>

<p>(1) <strong>search space:</strong> finding a model that captures reality well <br />
(2) <strong>visualization:</strong> what do end-users need to see?  </p>

<p>선택된 표기법이 <em>reality</em> 를 잘 반영하지 못할 수 있기 때문에, 다양한 표기법들을 알고, 사용해 보는것이 정말 중요하다.</p>

<h3 id="petrinets">Petri Nets</h3>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Animated_Petri_net_commons.gif/330px-Animated_Petri_net_commons.gif'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Petri_net' >http://en.wikipedia.org/wiki/Petri_net</a>)</p>

<p><em>Petri Net</em> 은 <code>token</code>, <code>place</code>, <code>transition</code>, <code>arc</code> 로 구성되어있다. 토큰은 한 <code>place</code> 에서 다음 <code>place</code> 로 이동할 수 있다. <em>petri net</em> 의 상태를 <em>marking</em> 이라 부른다. </p>

<p><em>transition</em> 의 경우 <em>input place</em> 가 토큰을 담고 있어야만 다음 <em>place</em> 로 토큰을 옮긴다. 다시 말해서 <em>transition</em> 이 <em>token</em> 을 <em>input places</em> 로 부터 <em>consume</em> 해서 <em>output place</em> 에 <em>token</em> 을 <em>produce</em> 한다.</p>

<p>독립적인 <em>transition</em> 이 있을때 모든 <em>transition</em> 은 동시에 작동할 수도, 하나씩만 작동할 수도 있다. </p>

<p>신호등을 모델링 해보면 <em>place</em> 는 <code>red, green,orange</code> 이고 <em>transition</em> 은 <code>rg, go, or</code> 이다. </p>

<p><img src='http://www.bpm-book.com/foswiki/pub/BpmBook/Exercise4-23/ex4-23.png'  alt="" /></p>

<p align="center">(<a href='http://www.bpm-book.com/' >http://www.bpm-book.com</a>)</p>

<p>하나의 신호등은 정말 그리기 쉬운데, 두개의 신호등을 모델링 하려면 좀 골치가 아프다. 우선 두개의 <em>petri net</em> 을 따로따로 사용할건가, 토큰만 두개로 늘릴건가를 생각해보자.</p>

<p>토큰이 두개인 경우는 하나의 신호등이 <code>green</code> 이고 다른 신호등이 <code>red</code> 인 경우, 어떤 신호등이 <code>green</code> 인지를 알려주지 않는다. <em>marking</em> 이 6가지가 나온다.</p>

<p>반면 두개의 <em>petri net</em> 을 사용하면 <em>marking</em> 이 9 가지가 되어 순서가 보존된다. 순열과 조합의 차이라 보면 되겠다.</p>

<p>근데, 두개의 <em>petri net</em> 을 사용하면 두 토큰이 동시에 <code>green</code> 에 있을 수 있다. 이건 교차로라면 교통사고를 야기할 수 있다.</p>

<p>그리고 한가지 더 생각해 볼 문제는 신호등의 순서다. <em>non-deterministic</em> 이면 한 신호등만 주구장창 파란불, 빨간불, 파란불, 이 될 수 있다. 따라서 한 신호등이 변하면 다음 신호등이 변하는 모델을 만들어야한다.</p>

<h4 id="reachabilitygraph">Reachability Graph</h4>

<p><em>transition</em> 에 따라 <em>marking</em> 이 변하는 그래프를 그릴 수 있는데, 이것을 <strong>reachability graph</strong> 라고 부른다. 이 그래프 내에서 각 상태가 <em>reachable marking</em> 이다.</p>

<h3 id="transitionsystemsandpetrinetproperties">Transition Systems and Petri Net Properties</h3>

<p><em>reachability graph</em> 는 한 상태에서 다른 상태로의 전환을 표현하므로 <em>transition system</em> 이라 볼 수 있다. 그리고, <em>reachability graph</em>는 <em>finite or infinite</em> 모두 가능하다.</p>

<h4 id="boundednesssafeness">Boundedness, Safeness</h4>

<p>어떤 <em>place</em> 에 <code>k</code> 이상의 토큰이 존재하는 <em>reachable marking</em> 이 없으면 <em><code>k</code>-bounded place</em> 라 부른다. 쉽게 생각하서 <em>upper bound</em> 라 보면 된다.</p>

<p>만약에 <em>petri net</em> 의 모든 <em>place</em> 가 <em>k-bounded</em> 면, 그 <em>petri net</em> 도 <em>k-bounded</em> 다. </p>

<p>이런 <code>k</code> 가 <em>petri net</em> 이나 <em>place</em> 가 있을수도 있고, 없을때도 있는데, 있을때만 <em>bounded petri net, bounded place</em> 라 부른다.</p>

<p>만약에 어떤 <em>petri net</em> 이 <em><code>1</code>-bounded</em> 면 <em>safe</em> 하다고 말한다.</p>

<h4 id="deadlock">Deadlock</h4>

<p>그리고, <em>dead marking</em> 은 더이상 적용 가능한 <em>transition</em> 이 없을때다. 그리고 <em>petri net</em> 에 <em>reachable dead marking</em> 이 있으면 잠재적으로 <em>deadlock</em> 이 발생할 수 있다.</p>

<p>따라서 모든 <em>reachable marking</em> 이 적어도 하나의 <em>transition</em> 이 있을때 <em>deadlock free</em> 하다고 말할 수 있다.</p>

<h4 id="safeness">Safeness</h4>

<p>어떤 <em>transition</em> <code>t</code> 대해, 어느 <em>reachable marking</em> 에서도 <code>t</code> 를 적용가능하면 <code>t</code> 는 <em>live</em> 하다. 그리고 모든 트랜지션이 <em>live</em> 면, <em>petri net</em> 은 <em>live</em> 다. </p>

<p><em>live petri net</em> 에서는 모든 트랜지션이 적용 가능하므로 <em>deadlock-free</em> 하다고 말할 수 있다.</p>

<h4 id="transitionsystem">Transition System</h4>

<p>이전에 보았던 <em>reachability graph</em> 는 <em>transition system</em> 의 특별한 종류다. 트랜지션 시스템은 <em>state</em> 와 <em>transitions</em> 로 구성되는데, 하나 이상의 <em>initial state</em> 와 0 개 이상의 <em>final states</em> 가 있다.</p>

<p>이 때 <em>initial state -> final state</em> 로의 <em>path</em> 를 <strong>complete trace</strong> 라 부른다.</p>

<p>모델로 부터 <em>transition system</em> 을 만들고 이것으로 부터 <em>complete trace</em> 를 만들 수 있는데, 문제는 트랜지션 시스템이 엄청나게 거대해 질 수 있거나 심지어는 무한할수도 있다는 사실이다.</p>

<p>단순히 <code>(token) -&gt; a1 -&gt; ()</code> 이란 간단한 모델에서 <code>a1, ..., ak</code> 만 해도 <code>2^k</code> 개의 트랜지션 시스템이 나온다. 어마어마하다</p>

<h3 id="workflownetsandsoundness">Workflow Nets and Soundness</h3>

<p><em>Petri net</em> 은 간편하긴 한데, 위에서 말했듯이 무한한 트랜지션 시스템이 나올 수 있고, 데드락이 발생할 수도 있다.</p>

<p>따라서 프로세스 마이닝에서는 모델을 만들기 위해 <em>end state</em> 가 있고, 위에서 언급한 <em>anomalies</em> 가 없는 <em>Petri net</em> 의 일종인 <em>Workflow Nets, WF-Nets</em> 를 사용하기도 한다.</p>

<p><img src='http://www.bpm-book.com/foswiki/pub/BpmBook/Exercise6-02/ex6-02.png'  alt="" /></p>

<p align="center">(<a href='http://www.bpm-book.com/' >http://www.bpm-book.com</a>)</p>

<p>본래 <em>WF-nets</em> 은 <em>BPM</em> 에서 쓰이던 것이다. <em>BPM</em> 은 IT 와 비즈니스를 연결해 주는 학문인데, </p>

<p><img src='http://bpmcenter.org/wp-content/uploads/BPM-lifecycle1.jpg'  alt="" /></p>

<p align="center">(<a href='http://bpmcenter.org/' >http://bpmcenter.org/</a>)</p>

<p><em>model-based analysis</em> 와 <em>data-based analysis</em> 를 반복하면서 모델을 개선한다.</p>

<p><em>BPM</em> 에서 모델의 역할은</p>

<p>(1) reason about processes (<strong>redesign</strong>) <br />
(2) make decisions inside processes (<strong>planning and control</strong>)  </p>

<p>안타깝게도 모델을 표현하는데 다양한 <em>notation</em> 이 있다. (언급 했듯이 <em>search space</em> 와 <em>visualization</em> 때문) 이 수업에서는 3 가지 표기를 사용한다.</p>

<ul>
<li>Business Process Model and Notation (<strong>BPMN</strong>)</li>
<li>Event-Driven Process Chains (<strong>EPCs</strong>)</li>
<li>Petri nets (Workflow nets)</li>
</ul>

<p>아래 이미지는 각각, <em>BPMN, EPCs</em> 다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-110510153158-phpapp01/95/process-mining-chapter-2-process-modeling-and-analysis-12-728.jpg?cb=1305062671'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-110510153158-phpapp01/95/process-mining-chapter-2-process-modeling-and-analysis-13-728.jpg?cb=1305062671'  alt="" /></p>

<p><br/></p>

<h4 id="goodmodel">Good Model</h4>

<p>좋은 모델이란 일반적으로 <em>sound WF-net</em> 을 말한다.</p>

<p><strong>Workflow net</strong> 이란</p>

<blockquote>
  <p>A <strong>Workflow net</strong> has one source place(start) and one sink place(end) and all other nodes are on a path from source to sink.</p>
</blockquote>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-110510153158-phpapp01/95/process-mining-chapter-2-process-modeling-and-analysis-10-728.jpg?cb=1305062671'  alt="" /></p>

<p><em>Workflow net</em> 이 <em>sound</em> 라는건</p>

<blockquote>
  <p>A workflow net is <strong>sound</strong> if and only if the following properties hold:</p>
  
  <p>(1) <strong>safeness:</strong> places cannot hold multiple tokens at the same time <br />
  (2) <strong>proper completion:</strong> if the sink place is marked, all other places are empty <br />
  (3) <strong>option to complete:</strong> it is always possible to reach the marking that marks just the sink place <br />
  (4) <strong>absence of dead parts:</strong> for any transition there is a firing sequence enabling it  </p>
</blockquote>

<p>작은 모델은 <em>soundness</em> 를 검사하기 쉬울지 모르지만, 모델이 커지만 좀 힘들 수도 있다. 여기에 사용할 수 있는 몇 가지 테크닉이 있다.</p>

<p>(1) 우선 <em>option to complete</em> 와 <em>proper completion</em> 을 보면, <em>proper completion</em> 이 거짓이면 <em>option to complete</em> 도 거짓이므로 검사할 필요가 없다. 반대로 <em>option to complete</em> 가 참이면 I<em>proper completion</em> 도 참이다.</p>

<blockquote>
  <p>option to complete impiles proper completion</p>
</blockquote>

<p>(2) 만약 <em>WF-net</em> 의 <em>end</em> 에서 <em>start</em> 로 트랜지션을 만든 <em>short-circuited petri net</em> 이 <em>live, bounded</em> 면 <em>WF-net</em> 은 <em>sound</em> 다.</p>

<blockquote>
  <p>A WF-net is <strong>sound</strong> if and only if the corresponding "short circuted" Petri net is <strong>live</strong> and <strong>bounded</strong></p>
</blockquote>

<h4 id="modelbasedanalysis">Model-based Analysis</h4>

<p>위에서 본 <em>soundness checking</em> 같은 검증이나 <em>performance analysis</em> 같은 시뮬레이션이 모델-베이스드 분석해서 주로 하는 일이다. 근데, 이런 검증이나 시뮬레이션은 모델이 높은 퀄리티를 가져야만 한다는 한계가 있다. 프로세스 마이닝은 이런 모델기반 분석과 실제 데이터를 연관시킨다. </p>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-110510153158-phpapp01/95/process-mining-chapter-2-process-modeling-and-analysis-24-728.jpg?cb=1305062671'  alt="" /></p>

<p><br/></p>

<h3 id="alphaalgorithm">Alpha Algorithm</h3>

<p><em>alpha algorithm</em> 을 이용해서 모델을 발견할 수 있다. 즉 아래 그림에서, <em>discovery</em> 에 해당하는 과정이다. 이벤트로그로 부터 모델을 만드는 과정을 <em>play-in</em> 이라 부르기도 한다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-3-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>이벤트 로그를 간략화 하면 <em>activity</em> 의 <em>order</em> 가 된다. 즉, <em>timestamp</em> 가 <em>order</em> 로 표현되고, 한 묶음의 <em>ordered activity</em> 가 모여서 <em>trace</em> 가 된다. 예를 들어서 다음은 이벤트 로그라 볼 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-5-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/> <br />
알파 알고리즘의 목적은 이렇게 간략화된 이벤트 로그를 이용해 모델을 뽑아내는 것이다.</p>

<h4 id="operations">Operations</h4>

<p>몇 가지 연산자를 알고 넘어가자</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-11-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/> <br />
(1) <strong>direct succession:</strong> <code>x &gt; y</code>, iff for some case x is directly followed by y <br />
(2) <strong>causality:</strong> <code>x -&gt; y</code>, iff <code>x &gt; y</code> and not <code>y &gt; x</code> <br />
(3) <strong>parallel:</strong> <code>x || y</code>, iff <code>x &gt; y</code> and <code>y &gt; x</code> <br />
(4) <strong>choice:</strong> <code>x # y</code>, iff not <code>x &gt; y</code> and <code>y &gt; x</code></p>

<p><br/></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-18-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>그러면 이 연산자를 조합해 패턴을 발견할 수 있다.</p>

<p>(1) <em>sequence:</em> <code>a -&gt; b</code> <br />
(2) <em>XOR split:</em> <code>a -&gt; b</code>, <code>a -&gt; c</code>, <code>b # c</code> <br />
(3) <em>XOR join:</em> <code>b -&gt; d</code>, <code>c -&gt; d</code>, <code>b # c</code> <br />
(4) <em>AND split:</em> <code>a -&gt; b</code>, <code>a -&gt; c</code>, <code>b || c</code> <br />
(5) <em>AND join:</em> <code>b -&gt; d</code>, <code>c -&gt; d</code>, <code>b || c</code></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-15-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<h4 id="footprint">Footprint</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-16-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>각 트랜지션 사이에 테이블을 하나 만들면 이처럼 생겼는데, <em>footprint</em> 라 부른다. 우리가 로그를 이용해 만든 모델과, 로그의 풋 프린트는 동일하다. </p>

<blockquote>
  <p>Log and model agree on footprint</p>
</blockquote>

<p><br/></p>

<h4 id="logics">Logics</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-19-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>알파 알고리즘은 이렇게 생겼는데, 너무 개략적으로 설명해 주셔서 나도 개략적으로 밖에 알지 못한다. 간략히 설명하면</p>

<p>(1) <em>activity</em> 를 <em>transition</em> 으로 매핑한다 <br />
(2) 첫 번째 트랜지션을 찾는다 <br />
(3) 마지막 트랜지션을 찾는다</p>

<p>두 인접한 트랜지션 사이에 있는 것은 <em>place</em> 이므로, 두 인접한 트랜지션을 찾아보자. 먼저</p>

<p>(4) <code>(A, B)</code> 를 계산한다  </p>

<p>이 때 <code>A</code> 내에 있는 모든 <code>a</code> 와 <code>B</code> 내에 있는 모든 <code>b</code> 에 대해 <code>a &gt; b</code> 이고, <code>a1 # a2</code>, <code>b1 # b2</code> 인 <code>(A, B)</code> 를 찾는다.</p>

<blockquote>
  <p>Find paris <code>(A, B)</code> of sets of activities such as that every element <code>a</code> in <code>A</code> and every element <code>b</code> in <code>B</code> are causally related, all element in <code>A</code> are independent and all elements in <code>B</code> are independent</p>
</blockquote>

<p>(5) <em>non-maximal pair</em> 를 제거한다. </p>

<p><code>(4)</code> 에서 찾은 <code>(A, B)</code> 는 부분집합을 가질 수 있다. 이러면 <em>sub-pair</em> 로 인해 <code>place</code> 가 또 생길 수 있으므로 제거한다.</p>

<p>예를 들어 <code>[({b}, {d}), ({b, e}, {d})]</code> 이 있다면 <em>sub-pair</em> <code>({b}, {d})</code> 를 제거한다.</p>

<blockquote>
  <p>Delete from set <code>X_L</code> all paris <code>(A, B)</code> that are not maximal</p>
</blockquote>

<p>(6) <em>place</em> <code>P_(A, B)</code> 의 위치를 결정한다. </p>

<blockquote>
  <p>Determine the place set. Each element <code>(A, B)</code> is a place. To ensure the workflow structure, add a source place and target place</p>
</blockquote>

<p>(7) <code>(2)</code> 와 <code>(3)</code> 에서 찾은 출발점과 끝점과 <code>(6)</code> 에서 찾은 <em>place</em> 의 <em>source transition</em> 과 <em>target transition</em> 과 잇는다.</p>

<blockquote>
  <p>Determine the flow relation. Connect each place P(A, B) with each element <code>a</code> of its set <code>A</code> of source transitions and with each element of its set <code>B</code> of target transitions. In addition, draw an arc from the source place to each start transition and an arc from each end transition to the sink place</p>
</blockquote>

<p>따라서 전체적인 알고리즘은</p>

<ul>
<li>먼저 <em>footprint</em> 를 만들고</li>
<li>여기서 집합 내부적으로 <code>#</code> 이고 집합간 <code>&gt;</code> 를 가지는 <code>(A, B)</code> 를 구한뒤  </li>
<li>중복을 제거하기 위해 <em>non-maximal pair</em> 를 제거한다  </li>
<li><code>(A, B)</code> 에서 하나씩 <em>pair</em> 를 뽑아서 잇고, 이것들과 초기 트랜지션 <code>T_I</code>, 마지막 트랜지션 <code>T_O</code> 와 잇는다.</li>
</ul>

<h4 id="intuition">Intuition</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-21-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>알파 알고리즘은 간단하지만 <em>loop</em>, <em>choice</em>, <em>concurrenc</em> 등 꽤 많은 연산을 찾아낸다. 그러나 한계가 있다.</p>

<h4 id="limitation">Limitation</h4>

<h4 id="implicitplaces">implicit places</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-29-728.jpg?cb=1305062521'  alt="" /></p>

<p>여기서 초록색 <em>place</em> 는 아무일도 하지 않음에도 <em>alpha algorithm</em> 이 찾아냈다. </p>

<h4 id="loopsoflength12">Loops of length 1, 2</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-30-728.jpg?cb=1305062521'  alt="" /></p>

<p>이벤트 로그를 보면 실제로는 <code>b</code> 가 <em>self-loop</em> 가 있음에도 알파 알고리즘은 찾아내지 못한다.</p>

<p><br/></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-31-728.jpg?cb=1305062521'  alt="" /></p>

<p>길이가 2인 루프도 마찬가지로 찾아내지 못한다.</p>

<h4 id="nonlocaldependency">Non-local dependency</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-32-728.jpg?cb=1305062521'  alt="" /></p>

<p>여기서 알파 알고리즘을 돌리면 <code>p1, p2</code> 를 못찾는다. 아래 그림은 알파 알고리즘이 찾기 힘든 모델이다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-33-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<h4 id="representationbias">Representation Bias</h4>

<p>알파 알고리즘이 가지는 표현적인 한계 때문에 다음과 같은 경우도 발생한다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-38-728.jpg?cb=1305062521'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-39-728.jpg?cb=1305062521'  alt="" /></p>

<h4 id="noiseandincompleteness">Noise and Incompleteness</h4>

<p>알파 알고리즘은 아주 기본적인 알고리즘이기 때문에 패턴을 잘못 인식하는 경우가 많다. </p>

<p>게다가, 이벤트 로그 자체가 완벽한 <em>trace</em> 가 아닐수도 있다는 것도 고려해야한다.</p>

<blockquote>
  <p><strong>Noise:</strong> the event log contains rare and infrequent behavior not representative for the typical behavior of the process</p>
  
  <p><strong>Incompleteness:</strong> the event log contains too few events to be able to discover some of the underlying control-flow structures</p>
</blockquote>

<p>즉 이벤트 로그 자체가 어떤 패턴을 발견하기엔 너무 적거나, 좀 노이지할 수가 있다는 뜻이다.</p>

<h4 id="fitnessvsprecisionsimplicityvsgeneralization">Fitness vs Precision, Simplicity vs Generalization</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-43-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>아래의 두 모델중 어떤게 더 이벤트 로그를 잘 반영한 것일까? 빈도가 적은 로그는 표현하지 않는것이 더 좋은가?</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-47-728.jpg?cb=1305062521'  alt="" /></p>

<h4 id="summary">Summary</h4>

<p>루프가 있거나, 모델에 <em>parallel</em> 이 있는 경우에 가능한 <em>trace</em> 의 수는 기하 급수적으로 많아진다. </p>

<p>그러나 우리가 가진 이벤트 로그는 일부분이다. 따라서 이런 로그로 만드는 모델은 어느정도 틀릴 수 밖에 없다. </p>

<p>알파 알고리즘의 단점을 좀 정리해 보면,</p>

<p>(1) <strong>implicit places:</strong> harmless and be solved through preprocessing <br />
(2) <strong>loops of length 1:</strong> can be solved in multiple ways <br />
(3) <strong>loops of length 2:</strong> idem. <br />
(4) <strong>non-local dependencies:</strong> challenging <br />
(5) <strong>representational bias:</strong> cannot discover transtions with duplicate or invisible labels. other algorithms may have a different bias. <br />
(6) <strong>discovered model does not need to be sound:</strong> some algorithm ensure this. <br />
(7) <strong>noise, incompleteness:</strong> challenging  </p>

<h3 id="references">References</h3>

<p>(0) <a href='http://issuu.com/wmpvanderaalst/docs/procminbook?e=14081202/9829483' >Book: Process Mining</a> <br />
(1) <a href='https://d396qusza40orc.cloudfront.net/procmin/lecture_slides/22-Petri%20Nets%20%281%29.pdf' >Slide</a> <br />
(2) <strong>Process Mining: Data science in Action</strong> by Wil van der Aalst <br />
(3) <a href='http://1ambda.github.io/www.processmining.org' >www.processmining.org</a> <br />
(4) <a href='http://fluxicon.com/' >http://fluxicon.com</a> <br />
(5) <a href='http://en.wikipedia.org/wiki/Petri_net' >http://en.wikipedia.org/wiki/Petri_net</a> <br />
(6) <a href='http://www.bpm-book.com/' >http://www.bpm-book.com</a> <br />
(7) <a href='http://bpmcenter.org/' >http://bpmcenter.org/</a></p>]]></description><link>http://1ambda.github.io/process-mining-week2/</link><guid isPermaLink="false">51bbba08-c9ac-44ee-9593-85f5b62054fb</guid><category><![CDATA[coursera]]></category><category><![CDATA[process mining]]></category><category><![CDATA[alpha algorithm]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 26 Nov 2014 04:30:43 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 6]]></title><description><![CDATA[<p>이번시간엔 어떻게 <em>type</em> 과 <em>class</em> 를 정의하는지 배울겁니다. 이렇게 <em>commonality</em> 를  추출해서 <em>type</em> 과 <em>class</em> 로 만듦으로써 작업의 양을 줄일 수 있습니다. 이 과정을 추상화라 부르기도 합니다.</p>

<p>마지막엔 이제까지 배운바를 적용해 봅시다. 항상 참인 명제를 검사하는 <strong>tautology checker</strong> 와 평가 시점을 조절하는 <strong>abstract machine</strong> 을 만들어 보겠습니다.</p>

<h3 id="typedeclarations">Type Declarations</h3>

<p>하스켈에선 존재하는 타입을 이용해서 새로운 타입을 만들 수 있습니다.</p>

<pre><code class="haskell">type String = [Char]  
</code></pre>

<p>지난시간에 2차원 좌표계를 구현할 때 만들었던 <code>Pos</code> 타입 기억 나시죠?</p>

<pre><code class="haskell">type Pos = (Int, Int)

origin :: Pos  
origin = (0, 0)

left :: Pos -&gt; Pos  
left (x, y) = (x-1, y)  
</code></pre>

<p><em>type</em> 은 함수와 마찬가지로 다양한 타입을 사용할 수 있습니다.</p>

<pre><code class="haskell">type Pair a = (a, a)

mult :: Pair Int -&gt; Int  
mult (a, b) = a * b

copy :: Int -&gt; Pair Int  
copy a = (a, a)  
</code></pre>

<p>여러개의 타입도 사용할 수 있습니다.</p>

<pre><code class="haskell">type Assoc k v = [(k, v)]

find :: Eq k =&gt; k -&gt; Assoc k v -&gt; v  
find k xs = head [v | (k', v) &lt;- xs, k == k']

&gt; find 2 [(1, 'a'), (2, 'c'), (3, 'f')]
-- 'c'
</code></pre>

<p>그리고 <em>nested (중첩)</em> 될 수 있습니다.</p>

<pre><code class="haskell">type Trans = Pos -&gt; Pos

left :: Trans  
left (x, y) = (x-1, y)  
</code></pre>

<p>하지만 <em>recursive</em> 로 정의될 수는 없습니다. 왜냐하면 <em>type</em> 이 단지 <em>synonym</em> 이기 때문입니다.</p>

<pre><code class="haskell">-- doesn't work
type Tree = (Int, [Tree

-- ghci

Cycle in type synonym declarations:  
  lecture9.hs:22:1-25: type Tree = (Int, [Tree])
Failed, modules loaded: none.  
</code></pre>

<p>그러나 하스켈에선 재귀적으로 타입을 정의할 수 있는 방법이 있긴 있습니다! 다만 <em>nominal type</em> 을 이용해야 합니다.(<code>data</code> 키워드를 사용합니다.) 많은 언어들이 이와 비슷한 제약조건을 가지고 있습니다.</p>

<p><em>object-oriented language</em> 에서는 전형적으로 <em>nominal type system</em> 을 사용합니다. 이는 <em>"두 타입이 같은지"</em>, <em>"한 타입이 다른 타입의 서브타입인지"</em> 검사하기 쉽기 때문입니다. 반면 <em>purely sructural type system</em> 에서는 이게 조금 어려워집니다. (참고로 <em>nominal vs structure</em> 은, <em>dynamic static</em> 과는 다른 문제입니다.)</p>

<h3 id="datadeclarations">Data Declarations</h3>

<p>기존타입과 관련없는 새로운 타입을 만들려면 <code>data</code> 키워드를 사용하면 됩니다.</p>

<pre><code class="haskell">data Bool = False | True  
</code></pre>

<p>이제 <code>Bool</code> 은 새로운 <em>type</em> 이고, 여기에 <code>False, True</code> 의 <em>value</em> 를 사용할 수 있습니다.</p>

<p>여기서 <code>False</code>, <code>True</code> 를 <em>type</em> <code>Bool</code> 을 위한 <em>constructor</em> 라 부릅니다. <em>type constructor</em> 의 이름은 반드시 대문자로 시작해야합니다.</p>

<p>새로운 타입을 조금 더 만들어 봅시다.</p>

<pre><code class="haskell">data Answer = Yes | No | Unknown

answers :: [Answer]  
answers = [Yes, No, Unknown]

flip :: Answer -&gt; Answer  
flip Yes = No  
flip No = Yes  
flip Unknown = Unknown  
</code></pre>

<p>좌표의 움직임을 추상화한 타입 <code>Move</code> 도 만들어 봅시다.</p>

<pre><code class="haskell">data Move = Left | Right | Up | Down

move :: Move -&gt; Pos -&gt; Pos  
move Up (x, y) = (x, y-1)  
move Left (x, y) = (x-1, y)  
move Down (x, y) = (x, y+1)  
move Right (x, y) = (x+1, y)

moves :: [Move] -&gt; Pos -&gt; Pos  
moves [] p = p  
moves (m:ms) p = moves ms (move m p)

&gt; move Left (1, 1)
-- (0,1)

&gt; moves [Left, Right, Up, Down, Left] (0, 0)
--(-1,0)
</code></pre>

<p><em>data declaration</em> 내에 있는 <em>constructor</em> 는 파라미터를 가질 수 있습니다.</p>

<pre><code class="haskell">data Shape = Circle Float  
           | Rect Float Float

square :: Float -&gt; Shape  
square n = Rect n n

area :: Shape -&gt; Float  
area (Circle r) = pi * r^2  
area (Rect x y) = x * y  
</code></pre>

<p>여기서 <em>constructor</em> 를 함수라 볼 수도 있습니다.</p>

<pre><code class="haskell">Circle :: Float -&gt; Shape  
Rect :: Float Float -&gt; Shape  
</code></pre>

<p><em>constructor</em> 뿐만 아니라 <em>data declaration</em> 그 자체도 파라미터를 가질 수 있습니다.</p>

<pre><code class="haskell">data Maybe a = Nothing | Just a

safediv :: Int -&gt; Int -&gt; Maybe Int  
safediv _ 0 = Nothing  
safediv x y = Just (x `div` y)

safehead :: [a] -&gt; Maybe a  
safehead [] = Nothing  
safehead (x:xs) = Just x  
</code></pre>

<h3 id="recursivetypes">Recursive Types</h3>

<p>재귀적인 타입의 예를 한번 볼까요?</p>

<pre><code class="haskell">data Nat = Zero | Succ Nat  
</code></pre>

<p>여기서 <code>Zero :: Nat</code>, <code>Succ :: Nat -&gt; Nat</code> 라 보면 됩니다. 따라서 다음처럼 확장이 가능하지요.</p>

<pre><code class="haskell">Zero -- 0  
Succ Zero -- 1  
Succ (Succ Zero) -- 2  
</code></pre>

<p>보시면 알겠지만, 우리는 단 한 줄로 자연수를 표현하는 데이터 타입 <code>Nat</code> 를 만들었습니다. 숫자와 <code>Nat</code> 타입을 변환하는 함수를 만들어 봅시다.</p>

<pre><code class="haskell">data Nat = Zero | Succ Nat

nat2int :: Nat -&gt; Int  
nat2int Zero = 0  
nat2int (Succ nat) = 1 + nat2int nat

int2nat :: Int -&gt; Nat  
int2nat 0 = Zero  
int2nat n = Succ (int2nat (n-1))

&gt; nat2int (int2nat 10)
-- 10
</code></pre>

<p>재귀를 이용하면 <code>Nat</code> 간 덧셈을 위에서 만든 변환함수 없이도 만들수 있습니다.</p>

<pre><code class="haskell">add :: Nat -&gt; Nat -&gt; Nat  
add Zero n = n  
add (Succ n) s = Succ (add n s)

&gt; nat2int (add (int2nat 2) (int2nat 3))
-- 5
</code></pre>

<h3 id="list">List</h3>

<p>임의의 타입을 갖는 리스트를 나타내는 <code>List</code> 타입을 만들어 보죠.</p>

<pre><code class="haskell">data List a = Nil | Cons a (List a)

len :: List a -&gt; Int  
len Nil = 0  
len (Cons h t) = 1 + len t

&gt;  len (Cons 4 (Cons 3 Nil))
-- 2

&gt; len Nil
-- 0
</code></pre>

<h3 id="arithmeticexpressions">Arithmetic Expressions</h3>

<p>기본적인 <code>+, *</code> 과 정수와 연산 <em>expression (식)</em> 을 타입으로 만들면 어떻게 될까요?</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Exp-tree-ex-11.svg/375px-Exp-tree-ex-11.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<pre><code class="haskell">data Expr = Val Int  
          | Add Expr Expr
          | Mul Expr Expr          
</code></pre>

<p>이제 <em>expression</em> 의 사이즈와, 계산 결과를 돌려주는 함수 <code>size</code>, <code>eval</code> 을 만듭시다.</p>

<pre><code class="haskell">size :: Expr -&gt; Int  
size (Val n) = 1  
size (Add l r) = size l + size r  
size (Mul l r) = size l + size r

eval :: Expr -&gt; Int  
eval (Val n) = n  
eval (Add l r) = eval l + eval r  
eval (Mul l r) = eval l * eval r

&gt; eval (Add (Val 3) (Val 2))
-- 5

&gt; size (Add (Val 3) (Val 2))
-- 2
</code></pre>

<p>이번엔 이진트리를 표현해 볼까요?</p>

<pre><code class="haskell">data Tree = Leaf Int  
          | Node Tree Int Tree
</code></pre>

<p>이제 트리에서 원하는 숫자가 존재하는지 검사하는 <code>occurs</code> 함수를 만들면</p>

<pre><code class="haskell">occurs :: Int -&gt; Tree -&gt; Bool  
occurs n (Leaf k) = n == k  
occurs n (Node l k r) =  
  (n == k) 
  || occurs n l
  || occurs n r

&gt; occurs 3 (Node (Leaf 3) 4 (Leaf 5))
-- True

&gt; occurs 6 (Node (Leaf 3) 4 (Leaf 5))
-- False  
</code></pre>

<p>트리의 모든 원소를 리스트로 돌려주는 <code>flatten</code> 함수도 만들어 봅시다.</p>

<pre><code class="haskell">flatten :: Tree -&gt; [Int]  
flatten (Leaf k) = [k]  
flatten (Node l k r) = flatten l ++ [k] ++ flatten 

&gt; flatten (Node (Leaf 3) 4 (Leaf 5))
-- [3,4,5]

&gt; flatten (Node (Leaf 6) 4 (Leaf 7))
-- [6,4,7]
</code></pre>

<p>여기서 재미난 결과를 볼 수 있습니다. <code>flatten</code> 함수는 매 재귀마다 왼쪽부터 방문하고, 현재 노드를 방문하고, 마지막으로 오른쪽 노드를 방문합니다. </p>

<p>그래서 <code>flatten</code> 함수의 결과가 <em>ordered</em> 이면 트리는 한 노드를 기준으로 한쪽은 현재 노드보다 작고, 다른쪽은 큰 <em>search-tree</em> 가 됩니다.</p>

<p><em>search-tree</em> 에서는 만약 찾으려는 수가 현재 노드보다 크면 <em>right sub-tree</em> 만, 현재 노드보다 작으면 <em>left sub-tree</em> 만 검색하면 됩니다. 따라서 <code>occurs</code> 함수를 </p>

<pre><code class="haskell">-- occurs for search-ree
occurs' :: Int -&gt; Tree -&gt; Bool  
occurs' n (Leaf k) = k == n  
occurs' n (Node l k r) | n == k = True  
                       | n &lt; k = occurs' n l
                       | otherwise = occurs' n r


&gt; occurs' 3 (Node (Leaf 3) 4 (Leaf 5))
-- True

&gt; occurs' 5 (Node (Leaf 3) 4 (Leaf 5))
-- True
</code></pre>

<p>실제로 트리는 값을 어디에 저장하냐에 따라 다양한 형태가 될 수 있습니다.</p>

<pre><code class="haskell">data Tree a = Leaf a | Node (Tree a) (Tree a)  
data Tree a = Leaf | Node (Tree a) a (Tree a)  
data Tree a b = Leaf a | Node (Tree a b) b (Tree a b)  
data Tree a = Node a [Tree a]  
</code></pre>

<p>위에서 부터</p>

<p>(1) <em>leaf</em> 에만 값을 저장 <br />
(2) <em>node</em> 에만 값을 저장 <br />
(3) <em>leaf</em>, <em>node</em> 에 모두 값을 저장 <br />
(4) 한 <em>node</em> 에 값과 복수개의 트리를 저장  </p>

<h3 id="tautologychecker">Tautology checker</h3>

<p>항상 참인 명제를 <em>tautology</em> 라고 합니다. 논리학에 대해서는 다음 글을 참조해주세요.</p>

<p>(1) <a href='http://imnt.tistory.com/91' >명제논리의 기초 1 : 소개</a> <br />
(2) <a href='http://imnt.tistory.com/91' >명제논리의 기초 2 : 진리표</a> <br />
(3) <a href='http://imnt.tistory.com/91' >명제논리의 기초 3 : tautology, contradiction</a>  </p>

<p><em>tautology</em> 는 여러가지가 있습니다. 한 가지 예를 보면, 참 또는 거짓일 수 있는 명제 <code>p</code>, <code>q</code> 에 대해 <code>p -&gt; q ^ q -&gt; p</code> 는 항상 참입니다.</p>

<p><img src='http://s1.hubimg.com/u/3891828_f520.jpg'  alt="" /></p>

<p align="center">(<a href='http://julieburke.hubpages.com/' >http://julieburke.hubpages.com</a>)</p>

<p>이번에 만들 프로그램에서는 논리학 연산자를 <code>Not</code>, <code>And</code>, <code>Imply</code>, <code>Or</code> 4가지로 제한하겠습니다. <em>proposition (명제)</em> 는 <code>A, ..., Z</code> 이고 각각 <code>True / False</code> 일 수 있습니다.</p>

<pre><code class="haskell">data Prop =  Const Bool  
          | Var Char
          | Not Prop
          | Or Prop
          | And Prop Prop
          | Imply Prop Porp
</code></pre>

<p>검사할 4개의 명제를 만들어 보죠.</p>

<pre><code class="haskell">-- A and ~A
p1 :: Prop  
p1 = And (Var 'A') (Not (Var 'A'))

-- A and B -&gt; A
p2 :: Prop  
p2 = Imply (And (Var 'A') (Var 'B')) (Var 'A')

-- A -&gt; A and B
p3 :: Prop  
p3 = Imply (Var 'A') (And (Var 'A') (Var 'B'))

-- (A and (A -&gt; B)) -&gt; B
p4 :: Prop  
p4 = Imply (And (Var 'A') (Imply (Var 'A') (Var 'B'))) (Var 'B')  
</code></pre>

<p>각 명제가 참인지 거짓인지 알 수 있는 테이블을 나타내는 타입 <code>Subst</code> 를 만듭시다. 진리표라고 생각하면 됩니다. 그리고 여기서 값을 찾는 함수 <code>find</code> 도 만들면</p>

<pre><code class="haskell">type Assoc k v = [(k, v)]  
type Subst = Assoc Char Bool

find :: Eq k =&gt; k -&gt; Assoc k v -&gt; v  
find k t = head [v | (k', v) &lt;- t, k' == k]  
</code></pre>

<p>이제 <code>Prop</code> 를 평가하는 함수 <code>eval</code> 을 만들면</p>

<pre><code class="haskell">eval :: Subst -&gt; Prop -&gt; Bool  
eval _ (Const b) = b  
eval s (Var x) = find x s  
eval s (Not p) = not (eval s p)  
eval s (Or p1 p2) = eval s p1 || eval s p2  
eval s (And p1 p2) = eval s p1 &amp;&amp; eval s p2  
eval s (Imply p1 p2) = eval s p2  
</code></pre>

<p>어떤 명제 <code>Prop</code> 가 <em>tautologt</em> 인지 검사하려면, 명제를 이루는 문장의 모든 참/거짓 경우에 대해 살펴봐야 합니다. 따라서 현재 가진 변수 <code>A, ..., Z</code> 에 대해서 참 / 거짓의 모든 경우를 포함한 테이블이 필요합니다. 이 함수를 만들기 위해 작은 함수부터 차근차근 조립해 갑시다.</p>

<p>먼저 현재 <code>Prop</code> 에서 모든 변수를 찾는 함수 <code>vars</code> 와 중복을 제거하는 함수 <code>uniq</code> 를 만들겠습니다.</p>

<pre><code class="haskel">vars :: Prop -&gt; [Char]  
vars (Const _) = []  
vars (Var x) = [x]  
vars (Not p) = vars p  
vars (And p1 p2) = vars p1 ++ vars p2  
vars (Or p1 p2) = vars p1 ++ vars p2  
vars (Imply p1 p2) = vars p1 ++ vars p2

&gt; vars p1
-- "AA"

&gt; vars p2
-- "AA"

&gt; vars p3
-- "ABA"

&gt; vars p4
--"AAB"

uniq :: Eq a =&gt; [a] -&gt; [a]  
uniq = foldr (\x xs-&gt; if elem x xs then xs else x:xs) []

&gt; uniq (vars p4)
-- "AB"
</code></pre>

<p>길이를 받으면 해당 길이 만큼 <code>True, False</code> 의 모든 조합을 리턴하는 <code>bools</code> 함수도 만들죠. 조합이므로 다음 재귀 단계에, 가능한 모든 경우를 더하면 됩니다.</p>

<pre><code class="haskell">bools :: Int -&gt; [[Bool]]  
bools 0 = [[]]  
bools n = map (False:) prev ++ map (True:) prev  
  where prev = bools (n - 1)
</code></pre>

<p>이제 마지막 퍼즐을 완성하겠습니다. <code>Prop</code> 를 받아, <code>[Subst]</code> 를 돌려주는 함수 <code>substs</code> 와, <code>Prop</code> 를 받아 <em>tautology</em> 인지 검사하는 함수 <code>isTaut</code> 는</p>

<pre><code class="haskell">substs :: Prop -&gt; [Subst]  
substs p = map (zip vs) (bools (length vs))  
  where vs = uniq (vars p)

isTaut :: Prop -&gt; Bool  
isTaut p = and [eval s p | s &lt;- substs p]

&gt; isTaut p1
-- True

&gt; isTaut p2
--False

&gt; isTaut p3
--True

&gt; isTaut p4
--False

&gt; isTaut p5
-- True
</code></pre>

<h3 id="abstractmachine">Abstract Machine</h3>

<p>간단한 수식 계산을 위한 <em>expression</em> 타입을 생각해 봅시다.</p>

<pre><code class="haskell">data Expr = Val Int  
          | Add Expr Expr

value :: Expr -&gt; Int  
value (Val n) = n  
value (Add l r) = value l + value r  
</code></pre>

<p>이제 덧셈을 실제로 해 보면, 계산이 왼쪽부터 이루어지는걸 확인할수 있습니다.</p>

<pre><code class="haskell">-- 2 + 3 + 4
value (Add (Add (Val 2) (Val 3)) (Val 4))  
...
...
(2 + value (Val 3)) + value (Val 4)
</code></pre>

<p>위에서 알 수 있듯이 왼쪽 인자가 오른쪽 인자보다 먼저 평가됩니다. 이건 우리가 지정한게 아니고, 하스켈이 왼쪽 인자부터 평가하기 때문입니다.</p>

<p><em>expression</em> 에서 평가 시점을 결정하는 <em>abstract machine</em> 을 만들어서 해결할 수 있습니다.</p>

<blockquote>
  <p>If desired, however, such control information can be made explicit by defining an abstract machine for expressions,
  which specifies the step-by-step process of their evaluation.</p>
</blockquote>

<p>컨트롤 스택을 위한 타입을 만들고, 값을 평가하는 <code>eval</code> 과 실제로 덧셈을 수행하는 <code>exec</code> 함수를 만들겠습니다.</p>

<pre><code class="haskel">-- expression
data Expr = Val Int  
          | Add Expr Expr

-- control stack
type Cont = [Op]  
data Op = EVAL Expr  
        | ADD Int

eval :: Expr -&gt; Cont -&gt; Int  
eval (Val n) c = exec c n -- eval n  
eval (Add x y) c = eval x (EVAL y : c) -- eval x before y

exec :: Cont -&gt; Int -&gt; Int  
exec [] n = n  
exec (EVAL y : c) n = eval y (ADD n : c)  
exec (ADD n : c)  m = exec c (n + m)

value :: Expr -&gt; Int  
value e = eval e []  
</code></pre>

<p><code>eval (Add x y)</code> 에 대해서 <code>EVAL y</code> 가 먼저 스택에 들어가고, <code>x</code> 가 먼저 평가됩니다. 그 이후에 <code>exec</code> 로 넘어오면서 <code>ADD</code> 명령이 스택에 들어가고, 그 이후에야 <code>y</code> 가 평가됩니다. 마지막으로 컨트롤 스택에 들어간 <code>ADD</code> 명령이 끝납니다.</p>

<p>간단한 예제를 통해 평가되는 과정을 보면</p>

<pre><code class="haskell">eval (Add (Val 3) (Val 5)) []  
eval (Val 3) [EVAL (Val 5)]  
exec [EVAL (Val 5)] 3  
eval (Val 5) [ADD 3]  
exec [ADD 3] 5  
exec [] (3 + 5)  
</code></pre>

<h3 id="classandinstancedeclaration">Class and Instance declaration</h3>

<p>마지막으로 <code>class</code> 대해 알아보겠습니다. 아참 시작하기 전에 먼저 아셔야 할 사실은, 하스켈에선 기술적인 이유로 <code>data</code> 를 이용해 만든 타입만 클래스의 인스턴스가 될 수 있습니다. </p>

<blockquote>
  <p>For technical reasons, only types declared using the data mechanism can be made into instances of classes.</p>
</blockquote>

<p>하스켈에선 <code>Eq</code> 클래스가 있는데요, 이렇게 정의되어 있습니다.</p>

<pre><code class="haskell">class Eq where  
 (==), (/=) :: a -&gt; a -&gt; Bool
 x /= y = not (x == y) 
</code></pre>

<p>이 말은 <code>Eq</code> 의 인스턴스가 되는 <code>a</code> 는 <code>(==)</code> 연산을 지원해야 한다는 뜻입니다. (<code>/=</code> 연산은 디폴트로 정의되어 있습니다.)</p>

<p>그래서 <code>Eq</code> 의 인스턴스인 <code>Bool</code> 의 경우</p>

<pre><code class="haskell">instance Eq Bool where  
  False == False = True
  True == True = True
  _ == _ = False
</code></pre>

<p>물론 기본 연산은 <em>overrided</em> 될 수 있습니다. 어떤 인스턴스의 경우 비교를 위해 <code>==</code> 를 재정의해서 사용할 수 있을겁니다.</p>

<p>클래스는 확장될 수 있습니다. 다른언어의 상속처럼요.</p>

<pre><code class="haskell">class Eq a =&gt; Ord a where  
  (&lt;), (&lt;=), (&gt;), (&gt;=) :: a -&gt; a -&gt; Bool
  min, max :: a -&gt; a -&gt; a

  min x y | x &lt;= y = x
          | otherwise = y

  max x y | x &lt;= y = y
          | otherwise = x
</code></pre>

<p>상대적인 크고 작음을 의미하는 <code>Ord</code> 클래스의 경우 <code>Eq</code> 의 연산에 추가적으로 크기 비교를 위한 연산을 가지고 있습니다. <code>&lt;, &lt;=, &gt;, &gt;=</code> 4개의 연산을 <code>Ord</code> 의 인스턴스는 정의해야 하는데요, 이것만 정의하면 디폴트로 정의된 <code>min, max</code> 도 사용할 수 있습니다.</p>

<p>아까 <code>Imply</code> 구현할 때 <code>p &lt;= q</code> 연산 보셨죠? <code>Bool</code> 은 <code>Ord</code> 의 인스턴스이기도 한데요</p>

<pre><code class="haskell">instance Ord Bool where  
  False &lt; True = True
  _ &lt; _ = False

  b &gt; c = c &lt; b
  b &lt;= c = (b &lt; c) || (b == c)
  b &gt;= c = c &lt;= b
</code></pre>

<h3 id="derivedinstances">Derived instances</h3>

<p>타입을 만들때 <em>built-in</em> 클래스의 인스턴스로 만들기 위해 <code>deriving</code> 키워드를 사용할 수 있습니다. 그래서 <code>Bool</code> 같은 경우 콘솔에 출력도 되고, 문자열에서 변경도 가능하고, 비교도 가능하죠.</p>

<pre><code class="haskell">data Bool = False | True  
          deriving (Eq, Ord, Show, Read)

&gt; False == False
--True

&gt; False &lt; True
-- True

&gt; show False
-- "False"

&gt; read "False"::Bool
--False
</code></pre>

<p>한가지 재밌는 사실은 <code>Bool</code> 의 <em>constructor</em> 중에서 <code>False</code> 가 <code>True</code> 보다 먼저 나오기 때문에 <code>False &lt; True</code> 라는 사실입니다.</p>

<pre><code class="haskell">data Shape = Circle Float | Rect Float Float  
data Maybe a = Nothing | Just a  
</code></pre>

<p>그리고 <code>Float</code> 가 <code>Eq</code> 의 인스턴스이기 때문에 결과적으로 이것을 파라미터로 가지는 <em>constructor</em> <code>Circle</code>, <code>Rect</code> 도 <code>Eq</code> 의 인스턴스입니다.</p>

<pre><code class="haskell">&gt; Rect 1.0 4.0 &lt; Rect 2.0 3.0
True

&gt; Rect 1.0 4.0 &lt; Rect 1.0 3.0
False  
</code></pre>

<p>마찬가지로 <code>Maybe a</code> 가 <code>Eq</code> 의 인스턴스가 되려면 <code>a</code> 가 <code>Eq</code> 의 인스턴스여야 합니다.</p>

<h3 id="examples">Examples</h3>

<p>몇개의 예제들입니다. 참고해보세요</p>

<pre><code class="haskell">import Data.List  
import Data.Char  
import Unsafe.Coerce

data Nat = Zero  
         | Succ Nat
         deriving Show

nat2int :: Nat -&gt; Integer  
nat2int = \n -&gt; genericLength [c | c &lt;- show n, c == 'S']

int2nat 0 = Zero  
int2nat n = Succ (int2nat (n-1))

add :: Nat -&gt; Nat -&gt; Nat  
add n Zero = n  
add n (Succ m) = Succ (add m n)

mult m Zero = Zero  
mult m (Succ n) = add m (mult m n)

-- tree
data Tree1 = Leaf Integer  
          | Node Tree Tree

leaves (Leaf _) = 1  
leaves (Node l r) = leaves l + leaves r  
balanced :: Tree -&gt; Bool  
balanced (Leaf _) = True  
balanced (Node l r) = abs (leaves l - leaves r) &lt;= 1 &amp;&amp; balanced l &amp;&amp; balanced r

balance :: [Integer] -&gt; Tree  
halve xs = splitAt (length xs `div` 2) xs  
balance [x] = Leaf x  
balance xs = Node (balance ys) (balance zs)  
  where (ys, zs) = halve xs
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em> <br />
(3) <a href='http://en.wikipedia.org/wiki/Binary_expression_tree' >Wiki - Binary Expression</a> <br />
(4) <a href='http://imnt.tistory.com/' >http://imnt.tistory.com</a>  </p>]]></description><link>http://1ambda.github.io/haskell-intro6/</link><guid isPermaLink="false">51837e71-0662-427c-b231-b63c47edf5b7</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[type]]></category><category><![CDATA[constructor]]></category><category><![CDATA[class]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 25 Nov 2014 07:56:35 GMT</pubDate></item><item><title><![CDATA[Dijkstra, Heap, Red-Black Tree]]></title><description><![CDATA[<h3 id="dijkstrasshortestpathalgorithm">Dijkstra's Shortest-Path Algorithm</h3>

<p><em>BFS</em> 는 <em>undirected graph</em> 에서 최단 경로를 찾지만, 이건 모든 <em>edge</em> 의 길이가 1일때만 그렇다. </p>

<p>다익스트라(<em>dijkstra</em>, <em>데이크스트라</em>) 알고리즘은 <em>directed graph</em> 에서 <em>non-negative length</em> 에 대한 최단 경로를 찾아낼 수 있다.</p>

<p>각 <em>edge</em> 가 음수라면, 모든 수에 특정 수를 더해 양수로 만들어도, 아니면 음수 그 자체로 다익스트라 알고리즘을 돌려도 최단 경로를 찾지 못한다. 다음의 그래프가 한 예다.</p>

<pre><code>1 -&gt; 2 // length: 1  
2 -&gt; 3 // length: -6  
1 -&gt; 3 // length: -2  
</code></pre>

<p>금융거래를 보면 특정 거래를 <em>edge</em> 라 보고 대해 여기에 대하 이득과 손실을 각각 양수, 음수의 가중치를 가지는 그래프라 생각할 수 있는데, 여기엔 음수 가중치가 있으므로 다익스트라 알고리즘을 쓸 수 없다.</p>

<p><a href='http://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm' >벨만 포드</a> 알고리즘을 써야한다.</p>

<p>길이가 <code>n</code> 인 <em>edge</em> 를 길이가 <code>1</code> 인 <code>n</code> 개의 <em>edge</em> 로 늘려 <em>BFS</em> 를 쓸 수 없느냐 질문할 수도 있겠는데, 가중치가 상당히 크면 연산이 비효율적이 된다. (e.g 150000)</p>

<h4 id="algorithm">Algorithm</h4>

<p>사실 다익스트라 알고리즘은 방문한 점 <code>v</code> 와 방문하지 않은 점 <code>w</code> 에 대해  <em>edge</em> <code>(v -&gt; w)</code> 를 고르는 문제다. <code>l_vw</code> 를 <code>v -&gt; w</code> 의 거리라 하고 <code>A[v]</code> 를 시작점 부터 <code>v</code> 까지의 최단거리라 하면 <code>A[v] + l_vw</code> 를 최소로 하는 <em>edge</em> 를 고르면 된다.</p>

<p>알고리즘은 이렇다. 시작점을 <code>s</code> 라 하면</p>

<pre><code>X = {s} // vertices process so far  
A = [s] // computed shortest path distances

// V is not visited vertices set  

while X != V  
  // v in X, w not in X
  // select the edge minimizing [A]v + l_vw
  pick (v, w) 
  X + w
  A[w] = A[v] + l_vw
</code></pre>

<h4 id="correctness">Correctness</h4>

<p>다익스트라 알고리즘이 <em>non-negative edge length</em> 를 가진 <em>directed graph</em> 에 대해 최단경로를 찾아낸다는 것을 증명하자. </p>

<p><code>A</code> 를 다익스트라 알고리즘이 찾아 낸 경로, <code>L</code> 을 실제 최단거리라 할 때 <code>A[w*] = L[w*]</code> 임을 보이면 된다.</p>

<p>귀납법을 이용해 먼저 가설을 세우면</p>

<blockquote>
  <p>Inductive hypothesis: all previous iterations correct</p>
</blockquote>

<p><em>base case</em> 인 시작점 <code>s</code> 에 대해 참임을 보이면 <code>A[s] = L[s] = 0</code> 이다.</p>

<p>현재 <em>iteration</em> 에서 찾아낸 <em>edge</em> 를 <code>v* -&gt; w*</code> 라 하면, <code>A[w*] = L[v*] + l_v*w*</code> 이다.</p>

<p>이 때 그래프 안에 있는 모든 <code>s -&gt; w*</code> 의 경로의 길이가 <code>L[v*] + l_v*w*</code> 보다 큼을 보이면 된다.</p>

<p>그래프 내에 있는 <code>s -&gt; w*</code> 의 모든 경로 <code>p</code> 는 다음 형태를 가진다.</p>

<p><code>s -&gt; y | -&gt; z -&gt; w*</code>
<br/></p>

<p>여기서 <code>s, y</code> 는 방문한 점이고 <code>z, w*</code> 는 방문하지 않은 점이다. </p>

<p><code>s -&gt; y | -&gt; z -&gt; w*</code> 에 대해 <code>p</code> 의 길이는 다음 3개를 더한 것이다.</p>

<p>(1) <code>l_sy &gt;= A[y] = L[y]</code> (<em>by induction hypothesis</em>) <br />
(2) <code>l_yz</code> <br />
(3) <code>l_zw &gt;= 0</code> </p>

<p>즉, 모든 경로 <code>p</code> 의 길이 <code>l_sy + l_yz + l_zw*</code> 는 <code>L[y] + l_yz</code> 보다 크다. </p>

<p>그런데, 다익스트라 알고리즘으로 고른 경로 <code>A[v*] + l_v*w*</code> 는 <code>L[y] + l_yz</code> 보다 작거나 같다. 왜냐하면 <code>A[v*], L[y], l_v*w*</code> 는 최단경로인데, <code>l_yz</code> 는 최단경로일 수도, 아닐수도 있다. </p>

<p>따라서 우리 알고리즘으로 구한 거리가, 모든 경로 <code>p</code> 의 <em>lower bound</em> 보다 작거나 같다.</p>

<h4 id="runningtime">Running time</h4>

<p><em>naive implementation</em> 의 성능은 <code>O(mn)</code> 이다. <code>n - 1</code> 의 모든 <em>vertex</em> 를 살펴봐야 하고, 루프 내에서 러프하게 모든 <em>edge</em> 를 검사한다고 보면 된다.</p>

<p>다익스트라 알고리즘은 <code>O(n)</code> 정도까지 개선할 수 있다. 알고리즘의 변경이 아니라, 자료구조를 <em>heap</em> 으로 변경함으로써! <em>heap</em> 은 <em>extract-min</em> 연산에 대해 <code>O(log n)</code> 이다.</p>

<p>힙의 구조나 특성은 뒤에서 알아보기로 하고, 여기선 다익스트라 알고리즘에 어떻게 적용할지를 논의하자.</p>

<p>(1) <em>heap</em> 내부 원소들은 방문하지 않은 원소들의 집합 <code>V - X</code> 라 하자. <code>X</code> 는 방문한 원소들의 집합. <br />
(2) <code>V - X</code> 내의 원소 <code>v</code> 에 대해서 <code>key[v]</code> 는 <em>edge</em> <code>(u, v)</code> 에 대한 다익스트라 알고리즘의 스코어다. (<code>u</code> 는 방문한 점)</p>

<p>따라서 <code>v</code> 의 키 값은 <code>X</code> 와 <code>V - X</code> 의 <em>crossing edge</em> <code>u -&gt; v</code> 중에서 가장 작은 <em>edge</em> 길이다.</p>

<p>이때 <code>X</code> 내에 있지 않은 점 <code>v</code> 를 <code>X</code> 로 옮기면서 <code>v -&gt; w</code> 로 새로운 <em>crossing edge</em> 가 생기고, 이로인해 <code>w</code> 의 <em>key</em> 값이 변할 수 있다. 이를 해결하기 위한 <em>key</em> 업데이트 로직은</p>

<pre><code>// v is extracted from heap and added to X
for each edge (v, w)  
  if w in heap
    delete w from heap
    recompute key[w] = min(key[w], A[v] + l_vw)
    reinsert w into heap
</code></pre>

<p><em>running time</em> 은 <em>heap operation</em> 의 수로 결정되는데 각 연산 <code>O(log n)</code> 을</p>

<p>(1) <code>n - 1</code> <em>extract min</em> -> <code>n</code> <br />
(2) 그리고 <em>edge</em> 중심으로 보면, <code>(v, w)</code> 이 <em>edge</em> 가 재 계산될때는 <code>v</code> 가 <code>X</code> 에 추가될때다. 그 이후에는 <code>(v, w)</code> 는 <em>crossing edge</em> 가 되므로 <em>delete, insertion</em> 연산과 관련이 없어진다. 다시 말해 한 <em>edge</em> 당 <em>at most one insertion and deletion</em> 이 있다. -> <code>m</code>  </p>

<p>따라서 <em>heap operation</em> 수는 <code>O(n + m)</code> 이다. 그런데, <em>path</em> 자체는 <em>weakly connected undirected graph</em> 이므로 <code>m ~= n</code> 이고 <code>O(m + n) = O(m)</code> 이라 볼 수 있다.</p>

<p>결국 힙을 이용한 다익스트라 알고리즘은 <code>O(m log n)</code> 이다. 이건 <code>O(m * n)</code> 보다 어마어마하게 빠르다.</p>

<h3 id="whatdatastructureshouldiuse">What data structure should I use?</h3>

<p>위 예제에서도 봤듯이, 적절한 데이터 구조의 사용은 알고리즘의 성능을 개선하는데 도움이 된다.</p>

<p>익히 아는 리스트, 큐 부터 시작해서 <em>bloom filter</em>, <em>union find</em> 등이 있는데, 이렇게 다양한 자료구조가 있는 이유는 우리가 하려는 <em>task</em> 가 다양하기 때문이다.</p>

<p>많은 데이터 구조중 무엇을 선택해야 할까? <em>rule of thumb</em> 는</p>

<blockquote>
  <p><em>Choose the "minimal" data structure that supports all the operations that need.</em></p>
</blockquote>

<p>내게 필요한 것 이상의 과도한 연산을 제공하는 자료구조를 사용할 필욘 없다. 복잡한 연산이 있을수록, 자료구조는 더 복잡해지기 마련이다.</p>

<h3 id="heap">Heap</h3>

<p>자료구조에서 가장 먼저 생각해야 할 것은  <em>"어떤 operation 을 제공하는가?"</em>, <em>"running time 은 얼마인가?"</em> 다.</p>

<p><em>Heap</em> 은 <em>key</em> 를 가진 <em>object</em>를 위한 <em>container</em> 다. <em>employer records</em>, <em>network edges</em>, <em>event manager</em> 등에 이용할 수 있다.</p>

<p>힙의 기본 연산은 <em>insert</em> 와 <em>extract-min (or max)</em> 연산이다. 이 연산의 러닝타임은 <code>O(log n)</code> 이다. <code>n</code> 은 힙 내에 있는 오브젝트의 수다.</p>

<p><code>n</code> 개의 <em>batch insertion</em> 에 대해 <em>heapify</em> 는 <code>O(n)</code>, 임의의 원소를 제거하는 <em>delete</em> 는 <code>O(log n)</code> 이다. 정리하면</p>

<p>(1) <strong>insertion:</strong> <code>O(log n)</code> <br />
(2) <strong>extract-min (or max):</strong> <code>O(log n)</code> <br />
(3) <strong>heapify (batch):</strong> <code>O(n)</code> <br />
(4) <strong>remove (arbitrary):</strong> <code>O(n)</code>  </p>

<h4 id="application">Application</h4>

<p>힙을 어디에 쓸까? 먼저 생각해 볼 수 있는건 <em>min value</em> 가 연속적으로 필요한 작업에 쓸 수 있다. </p>

<p>(1) <em>heap sort</em> 는 힙에서 지속적으로 <em>min-value</em> 를 뽑아내서 정렬하는 방법이다. <code>O(n logn)</code> 의 성능을 보여준다. 이건 <em>merge sort</em> 나 <em>randomized quick-sort</em> 만큼 빠르다.</p>

<p>잠깐 생각해 볼 거리가 있다. <em>quicksort</em> 챕터에서 언급 했듯이 <em>comparison-based sorting</em> 은 <code>O(n logn)</code> 보다 더 빠를 수 없다. 힙 또한 비교를 이용해 정렬을 하므로 이보다 좋은 성능을 내기는 어렵다.</p>

<p>(2) 아까 힙을 <em>event manager</em> 에도 이용할 수 있고 했는데, <em>priority queue</em> 가 바로 그것이다. 각 게임 이벤트가 큐에 들어있다고 하면 여기서 <em>key</em> 는 각 <em>event</em> 의 발생시간이다. 다시 말해 발생시간이 먼저인 이벤트가 먼저 발생되도록 큐를 이용할 수 있다.</p>

<p>(3) <em>median maintanence</em> 에도 힙을 이용할 수 있다. <code>x1, x2, ..., xn</code> 의 배열에 대해 <code>i</code> 번째 스텝에서는 <code>x1, ..., xi</code> 의 중앙값을 돌려주는 문제다. <code>O(i)</code> 로 하면 정말 쉽지만, 조건이 하나 있다. 바로 <code>O(log i)</code> 의 퍼포먼스를 내야하는것. 어떻게 할까?</p>

<p>두개의 힙을 이용하면 쉽게 풀 수 있다. 데이터를 절반씩 나누어 <em>max heap</em>, <em>min heap</em> 각각에 나눠 담으면 된다. 그러면 각 힙의 루트가 중앙값이 될 수 있다.</p>

<p>(4) 마지막으로 힙은 다익스트라 알고리즘의 성능을 개선하는데 사용할 수 있다. 위에서 보았듯이 <code>O(m logn)</code> 의 퍼포먼스를 보여준다.</p>

<h4 id="implementationdetails">Implementation Details</h4>

<p>힙을 배열 또는 트리로 보는 관점이 있는데, 여기선 쉬운 이해를 위해 트리로 설명한다. <em>rooted, binary, as complete as possible tree</em> 로 보면 된다. </p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/6/69/Min-heap.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Binary_heap' >http://en.wikipedia.org/wiki/Binary_heap</a>)</p>

<p><em>min heap</em> 을 예로 들면, 부모는 항상 자식보다 작거나 같다. 따라서 루트는 모든 원소중 가장 작은 값을 가진다.</p>

<p>힙을 배열로 구현한다고 하자. 인덱스가 1부터 시작할때 <code>parent(i)</code> 는 <code>i</code> 가 짝수면 <code>i/2</code>, 홀수면 <code>[i/2]</code> 가 될 것이다. 자식을 구하는건 더 쉽다. <code>i * 2</code> 와 <code>i * 2 + 1</code> 이다.</p>

<p><em>insert</em> 의 구현을 생각해 보자. 힙은 가능한 <em>complete tree</em> 기 때문에, 위 그림에서 새로운 숫자가 입력했을때 새로 생길 노드의 위치는 <code>19</code> 의 왼쪽 자식이다. </p>

<p>이렇게 완전 이진트리를 만드는 위치에 새로운 값을 삽입하고, 부모와 값을 비교해 가면서 값의 위치를 올려간다. 이 방법을 <em>bubble-up</em> 이라 부른다. 
정리하면,</p>

<p>(1) stick <code>k</code> at end of last level <br />
(2) <strong>bubble-up</strong> <code>k</code> until heap property is restored  </p>

<p><em>extract-min</em> 연산은 루트에 있는 수를 뽑아낸다. 이 위치에 마지막 노드를 넣고, <em>bubble-down</em> 함으로써 구현할 수 있다. 새롭게 루트가 된 노드를 내려가는 과정에서 왼쪽 자식, 오른쪽 자식과 모두 비교하여 가장 작은 수를 새로운 부모로 만들면 된다. 정리하면</p>

<p>(1) delete <code>root</code> <br />
(2) move last leaf to be new root <br />
(3) iterlatively <strong>bubble-down</strong> until heap property has been restored  </p>

<p>이 두 연산은 이진트리의 <code>n</code> 번째 깊이까지 내려갈 수 있으므로 퍼포먼스는 <code>O(log_2 n)</code> 이다.</p>

<h3 id="balancedsearchtree">Balanced Search Tree</h3>

<p><strong>sorted array</strong> 에 대한 연산을 먼저 생각해 보자. 이로부터 <em>balanced search tree</em> 로 이끌어 낼 수 있는 연산들이 있을테다. 참고로 <strong>sorted array</strong> 는 <em>static</em> 이기 때문에 <em>insertion, deletion</em> 이 없다.</p>

<p>(1) <strong>Search:</strong> <code>O(logn)</code> <br />
(2) <strong>Select:</strong> <code>O(1)</code> (given order statistic <code>i</code>) <br />
(3) <strong>Min / Max:</strong> <code>O(1)</code> <br />
(4) <strong>Predecessor / Successor:</strong> <code>O(1)</code> <br />
(5) <strong>Rank:</strong> <code>O(logn)</code> <br />
(6) <strong>Output in sorted order:</strong> <code>O(n)</code></p>

<p>여기서 주어진 데이터가 몇 번째 데이터인지를 찾는 <em>rank</em> 는 <em>search</em> 와 똑같은 문제다. <em>binary search</em> 처럼 찾아가면서, 인덱스를 찾아내면 되기 때문이다.</p>

<p>이제 <strong>balanced search tree</strong> 를 생각해보자. </p>

<p>(1) <strong>Search:</strong> <code>O(logn)</code> <br />
(2*) <strong>Select:</strong> <code>O(logn)</code> <br />
(3*) <strong>Min / Max:</strong> <code>O(logn)</code> <br />
(4*) <strong>Predecessor / Successor:</strong> <code>O(logn)</code> <br />
(5) <strong>Rank:</strong> <code>O(logn)</code> <br />
(6) <strong>Output in sorted order:</strong> <code>O(n)</code> <br />
(7+) <strong>Insert:</strong> <code>O(logn)</code> <br />
(8+) <strong>Delete:</strong> <code>O(logn)</code>  </p>

<p><strong>sorted array</strong> 에 비해 <em>select, min or max, pred or succ</em> 연산이 <code>O(logn)</code> 이 되었고 <em>insert, delete</em> 연산이 새롭게 추가됐다. 쉽게 기억하려면 <em>sorted array</em> + <em>logarithmic insert, delete</em> 라 생각하면 된다.</p>

<p>힙과 비교해보면, 두 자료구조 모두 <em>insert, delete</em> 를 <code>O(logn)</code> 이란 빠른 시간에 제공한다. 차이점은, 힙은 <em>min or max</em> 둘 중 하나만 매우 빠르게 제공한다는 것이다. 따라서 <em>priority queue, scheduler</em> 같은 기능을 구현한다면 <em>balanced search tree</em> 보단 힙이 더 좋은 선택이다.</p>

<h3 id="binarysearchtree">Binary Search Tree</h3>

<p><strong>binary search tree</strong> 를 쉽게 기억하는 방법은 <em>dynamic sorted array</em> 라 기억하는 것이다. <strong>sorted array</strong> 가 제공하는 풍부하고 빠른 연산에 <em>insert, delete</em> 를 추가한 것이 바로 <strong>binary search tree, BST</strong> 다.</p>

<p>힙이 <em>vertically sorted</em> 라면 BST 는 <em>horizontally sorted</em> 다. 즉 왼쪽자식은 부모보다 항상 작고, 우측 자식은 부모보다 항상 크다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Binary_search_tree.svg/300px-Binary_search_tree.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org/</a>)</p>

<p>이런 구조적 특성때문에 <em>search (탐색)</em> 을 <code>O(logn)</code> 으로 빠른 시간 내에 해낼 수 있다. 근데, 최악의 경우 노드가 일렬로 주-욱 이어져 있다면 <code>O(n)</code> 의 퍼포먼스를 보여준다.</p>

<p><img src='http://epaperpress.com/sortsearch/images/fig33.gif'  alt="" /></p>

<p align="center">(<a href='http://epaperpress.com/' >http://epaperpress.com</a>)</p>

<h4 id="implementation">Implementation</h4>

<p>이제 연산의 구현을 좀 생각해 보자. </p>

<p>(1) <em>insert, search</em> 는 비슷하다. 자신의 자리를 찾아 내려가다가, 해당 원소가 있으면 돌려주고 아니면 <code>NULL</code> 을 돌려주는 방법으로 <em>search</em> 를 구현할 수 있다. <em>insert</em> 도 값을 비교하면서 내려가다가 적절한 자리에 삽입하면 된다.</p>

<p>(2) <em>max, min</em> 연산은 가장 좌측 노드, 가장 우측 노드를 돌려줌으로써 쉽게 구할 수 있다. </p>

<p>(3) <em>pred, succ</em> 은 자신 다음으로 적거나, 자신 다음으로 큰 원소를 돌려주는 연산인데, 자신 기준으로 왼쪽 부트리에서 가장 우측에 있는 노드, 그리고 자신 기준으로 우측 부트리에서 가장 좌측에 있는 노드를 돌려주면 된다.</p>

<p>(4) <em>in-order traversal</em> 연산은 노드를 오름차순 순서로 방문하는 연산이다. 이것 역시 쉽게 구현할 수 있는데</p>

<pre><code>let r = root of search tree

recurse left sub-tree  
print current node  
recurse right sub-tree  
</code></pre>

<p>노드당 한번만 출력하므로, 퍼포먼스는 <code>O(n)</code> 이다</p>

<p>(5) <em>delete</em> 는 조금 복잡한데 3가지 경우를 고려해야 한다.</p>

<ul>
<li>자식이 없을 경우</li>
<li>왼쪽 또는 오른쪽 자식만 있을 경우</li>
<li>양쪽 자식이 다 있을 경우</li>
</ul>

<p>앞의 두 가지 경우는 어렵지 않은데, 양쪽 자식이 다 있을 경우는 조금 까다롭다. 이 경우는 지우려는 노드의 <em>successor</em> 나 <em>predecessor</em> 을 <code>l</code> 이라 하자. 지우려는 노드와 <code>l</code> 을 뒤 바꾸면, 이전 <code>l</code> 자리에 있던 노드는 <em>left</em> 또는 <em>right</em> 자식이 없으므로 하나의 자식만 있는 알고리즘을 이용해 제거하면 된다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Binary_search_tree_delete_3.svg/620px-Binary_search_tree_delete_3.svg.png'  alt="" /></p>

<p align="center">(<a href='http://commons.wikimedia.org/' >http://commons.wikimedia.org/</a>)</p>

<p>(6) <em>select, rank</em> 연산은 트리에 추가적인 정보를 기록함으로써 쉽게 구할 수 있다.  각 트리마다 자기를 포함한 자식들의 노드 수를 저장하면 된다.</p>

<p><img src='http://www.tcs.auckland.ac.nz/' ~georgy/teaching/1998/98-231FC/231-hand/btr-rank.gif" alt="http://www.tcs.auckland.ac.nz/~georgy/" /></p>

<p align="center">(<a href='http://www.tcs.auckland.ac.nz/' ~georgy/'>http://www.tcs.auckland.ac.nz/~georgy/</a>)</p>

<p>매 삭제와 삽입 연산마다 각 트리의 사이즈를 변경해야 하는데 어렵지 않다. 삽입이나 삭제시 마지막 노드 혹은 <em>predecessor, successor</em> 를 찾아가면서 매번 노드를 방문해야 하므로 이 때 마다 새롭게 값을 변경하면 된다.</p>

<p><em>select, rank</em> 알고리즘은</p>

<pre><code>start at root x  
let y = left sub-tree  
let z = right sub-tree  
let a = size of y

if a = i - 1 return x  
if a &gt;= i, recurse y, i'th statistic  
if a &lt; i, recurse z, (i - a - 1)'th statistic  
</code></pre>

<p>러닝타임은 <code>O(height)</code> 다.</p>

<h3 id="redblacktree">Red-Black Tree</h3>

<p>이진트리는 운이 나쁠경우 <code>O(n)</code> 의 연산 성능이 나오기 나온다. 따라서 트리의 높이를 최대 <code>O(logn)</code> 으로 제한해 연산 성능을 개선할 수 있다.</p>

<p>이렇게 구조적인 제한을 이용해 성능을 개선하는 트리는 <em>red-black tree</em> 이외에도 <em>AVL tree</em>, <em>splay tree</em>, <em>B tree</em> 등이 있다. </p>

<h4 id="invariants">Invariants</h4>

<p><em>red-black tree</em> 는 다음의 제약 조건을 제외하면 이진트리와 동일하다.</p>

<p>(1) each node is red or <code>black</code> <br />
(2) root is <code>black</code> <br />
(3) no 2 <code>reds</code> in a row  -> <code>red</code> node has only <code>black</code> children <br />
(4) every <code>root - NULL</code> path  has same number of black nodes  </p>

<p>여기서 <code>(4)</code> 는 <em>unsuccessful search</em> 를 생각하면 쉽다. 검색이 제대로 되지 않았을 경우 <code>NULL</code> 에서 중단하는데, 그때 까지의 모든 블랙 노드의 수가 다른 <em>unsuccessful search</em> 가 방문한 블랙 노드 수와 동일하다는 것이다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Red-black_tree_example.svg/750px-Red-black_tree_example.svg.png'  alt="http://en.wikipedia.org" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<p>예제를 통해 좀 살펴보자. <code>1 -&gt; 2 -&gt; 3</code> 의 이진트리가 있을 때, <code>2</code> 가 레드 노드라 하자. 그러면 규칙 <code>(4)</code> 를 위반한다. <em>unsuccessful search</em> 의 경우인 <code>0</code> 과 <code>4</code> 를 찾을때 블랙 노드의 개수가 다르다.</p>

<h4 id="heightguarantee">Height Guarantee</h4>

<p>위에서 언급한 제약조건이 실제로는 트리의 높이를 <code>height &lt;= 2 log_2(n + 1)</code> 로 보장한다. </p>

<p>우선 살펴봐야 할 것은, 모든 <code>root-null</code> 경로가 <code>&gt;= k</code> 인 노드를 가지고 있다면, 그 트리는 <code>k</code> 깊이 까지는 완전 이진트리다.</p>

<blockquote>
  <p>If every <code>root-null</code> path has <code>&gt;= k</code> nodes, then tree includes (at the top) a perfectly balanced search tree of depth <code>k - 1</code></p>
</blockquote>

<p>이 것은 레드블랙트리만이 아니라 모든 이진트리에 적용된다. 이제 전체 노드 <code>n</code> 과 관계를 살펴 보자. </p>

<p>이진트리이므로 노드의 수 <code>n &gt;= 2^k - 1</code> 과 <code>k</code> 에 대해 <code>k &lt;= log_2 (n+1)</code> 이다. </p>

<p>아까 <code>k</code> 는 <code>root-null</code> 경로의 노드의 수 라고 했었다. 그리고 레드블랙트리의 (3), (4) 조건을 다시 생각해보면</p>

<blockquote>
  <p>(3) no 2 <code>reds</code> in a row  -> <code>red</code> node has only <code>black</code> children <br />
  (4) every <code>root - NULL</code> path  has same number of black nodes  </p>
</blockquote>

<p>레드 블랙트리에서 모든 노드가 블랙이면, (4) 에 의해서 <code>root-null</code> 경로의 블랙 노드가 최대이므로 블랙 노드의 <em>upper bound</em> 는 <code>&lt;= log_2 (n+1)</code> 이다. 그리고 레드 블랙 트리에서 <code>root-null</code> 경로의 노드수가 깊이가 되므로 이때의 높이는 <code>log_2 (n+1)</code> 이다.</p>

<p>다른 경우를 생각해 보자. 레드블랙트리의 <code>root-null</code> 경로에는 중간 중간 레드 노드가 낄 수 있는데, 레드 노드가 최대로 끼어있을때는 (3) 조건에 의해 블랙노드만큼이다. 이 때 블랙노드는 <em>upper bound</em> 에 의해 <code>&lt;= log_2 (n+1)</code> 이므로, 레드노드도 최대 <code>&lt;= log_2 (n+1)</code> 이다.</p>

<p>따라서 레드블랙트리의 깊이는 최대 <code>&lt;= 2 * log_2 (n + )1</code> 이므로, 연산에 대해 <code>O(log n)</code> 을 보장한다.</p>

<h4 id="rotation">Rotation</h4>

<p>이진트리의 삽입, 삭제 연산은 레드블랙트리에서의 제약조건을 망가트릴 수 있다. 따라서 삭제와 삽입 연산에 부가적으로 구조를 유지하기 위한 작업이 필요하다. </p>

<p>레드블랙트리 뿐만 아니라 <em>AVL tree</em> 나 다른 <em>balanced search tree</em> 도 구조를 유지해야 하는데, 여기에 공통적으로 사용하는 연산이 <em>rotation</em> 이다. 한번 알아보자.</p>

<blockquote>
  <p>Idea: locally rebalance sub-trees at a node in <code>O(1)</code> time.</p>
</blockquote>

<p>먼저 <em>left roation</em> 만 생각하자. 다음 그림에서 우측에 있는 트리를 좌측처럼 변경하는 것이다. <code>P</code> 가 <code>Q</code> 의 자식이 되도록 하는것이다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/2/23/Tree_rotation.png'  alt="http://en.wikipedia.org/wiki/Tree_rotation" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Tree_rotation' >http://en.wikipedia.org/wiki/Tree_rotation</a>)</p>

<p>여기서 <code>B</code> 의 원소는 <code>P</code> 보단 크고 <code>Q</code> 보다 작다. 따라서 <code>Q</code> 와 <code>P</code> 의 위치를 변경하면 <code>B</code> 는 <code>P</code> 의 오른쪽에 와야 한다. 이것이 <em>left rotation</em> 이다. 경로를 따라 왼쪽으로 한칸씩 밀려갔다고 생각하면 기억하기 쉽다.</p>

<p><em>right rotation</em> 은 이것을 정확히 반대로 수행하면 된다. 좌측에 있는 트리에서 <code>P</code>, <code>Q</code> 를 경로를 따라 하나씩 우측으로 밀고, <code>B</code> 는 <code>C</code> 의 왼쪽으로 이동하면 된다.</p>

<p>모든 연산은 포인터 변경으로 끝나므로 <code>O(1)</code> 이다. </p>

<h4 id="insertion">Insertion</h4>

<p>이제 <em>rotation</em> 을 이용해 <em>red-black tree</em> 에서 삽입 연산을 구현해 보자. 삽입과 삭제의 기본적인 아이디어는</p>

<p>(1) 이진트리에서의 <em>insert</em> / <em>remove</em> 연산을 수행 한다. <br />
(2) 레드, 블랙을 다시 색칠한다. <br />
(3) <em>rotation</em> 을 수행한다.</p>

<p>여기 (2) 단계에서 레드블랙트리의 구조가 망가질 수 있다. 새로운 노드를 레드로 만들면, 한 로우 내에 2개의 레드가 있을 수 없다는 규칙을 위반할 수 있고, 블랙으로 칠하면 <code>root-null</code> 경로의 블랙 노드의 수가 같아야 한다는 제약조건에 위배될 수 있다.</p>

<p>두 가지 경우중, 레드로 칠하는 경우가 더 가벼운 작업일 것 같으니</p>

<blockquote>
  <p>새로운 노드가 들어오면 먼저 레드로 칠해본다.</p>
</blockquote>

<p>부모가 블랙이면 문제가 없다.</p>

<blockquote>
  <p>부모가 레드면?</p>
</blockquote>

<p>몇 가지 경우를 생각해봐야 한다. 우선 부모 <code>B</code> 가 레드면, 부모의 부모 <code>C</code> 는 블랙임이 확실하다. 이 때 만약,</p>

<p>(1) <code>C</code> 가 <code>B</code> 말고 다른 자식 <code>D</code> 가 있다면 <code>B, C, D</code> 의 색을 반전시키면 된다. 그리고 새롭게 색을 반전시켰을 때 <code>C</code> 의 부모도 레드일 수 있다. 마찬가지로 <em>recoloring</em> 을 반복하면 된다. 색을 반전시켜도 (3) 또는 (4) 의 규칙을 위반하지 않는다. </p>

<p>아주 만약에, 루트까지 반복해서 루트가 레드가 되었다면 루트를 블랙으로 다시 칠하면 된다. 루트는 모든것의 부모이므로 블랙이 되어도 <code>root-null</code> 경로 조건을 위반하지 않는다.</p>

<p>따라서 연산비용은 <code>O(log n)</code> 이다.</p>

<p><img src='http://cs.lmu.edu/' ~ray/images/rbtrecoloring.png" alt="" /></p>

<p align="center">(<a href='http://cs.lmu.edu/' ~ray/notes/redblacktrees/'>http://cs.lmu.edu/~ray/notes/redblacktrees/</a>)</p>

<p>그런데, 반복해서 이 방법을 사용하다가 <code>C</code> 가 다른 자식 <code>D</code> 를 가지고 있지 않거나, <code>D</code> 가 블랙일 수 있다. 그럴땐 다음 경우로 넘어가야 한다.</p>

<p>(2) <code>C</code> 가 <code>B</code> 말고 다른 자식이 없거나 블랙인 자식을 가지면 <code>A</code> 가 좌측이냐 우측이냐에 따라 <code>right rotation</code>, <code>left-right rotation</code> 으로 해결할 수 있다. 마찬가지로 (3) 또는 (4) 를 위반하지 않는다.</p>

<p><img src='http://cs.lmu.edu/' ~ray/images/rbrestructuring.png" alt="" /></p>

<p align="center">(<a href='http://cs.lmu.edu/' ~ray/notes/redblacktrees/'>http://cs.lmu.edu/~ray/notes/redblacktrees/</a>)</p>

<p>이 경우는 몇번의 로테이션으로 해결할 수 있으므로 <code>O(1)</code> 이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong> <br />
(2) <a href='http://en.wikipedia.org/wiki/Binary_heap' >Wiki - Binary heap</a> <br />
(3) <a href='http://en.wikipedia.org/wiki/Binary_search_tree' >Wiki - Binary search tree</a> <br />
(4) <a href='http://epaperpress.com/sortsearch/bin.html' >http://epaperpress.com</a> <br />
(5) <a href='http://commons.wikimedia.org/wiki/File:Binary_search_tree_delete_3.svg' >http://commons.wikimedia.org/</a> <br />
(6) <a href='http://www.tcs.auckland.ac.nz/' ~georgy/teaching/1998/98-231FC/231-hand/test231.html">http://www.tcs.auckland.ac.nz/~georgy/</a> <br />
(7) <a href='http://en.wikipedia.org/wiki/Red%E2%80%93black_tree' >Wiki - Red-black tree</a> <br />
(8) <a href='http://upload.wikimedia.org/wikipedia/commons/2/23/Tree_rotation.png' >Wiki - Tree rotation</a></p>]]></description><link>http://1ambda.github.io/dijkstra-heap-balanced-tree/</link><guid isPermaLink="false">8d4c00c5-78fc-4a4d-97a1-cf0829c53396</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[heap]]></category><category><![CDATA[dijkstra]]></category><category><![CDATA[red-black tree]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 23 Nov 2014 14:23:37 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 7]]></title><description><![CDATA[<p>이번시간에 <em>Support Vector Machine, SVM</em> 을 배운다.</p>

<h3 id="optimizationobjective">Optimization Objective</h3>

<p>먼저 직관을 얻기 위해 <em>logistic regression</em> 의 <em>sigmoid function</em> 을 좀 보자.</p>

<p><img src='http://my.csdn.net/uploads/201208/09/1344525027_7041.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><code>y = 1</code> 이면 <code>0^Tx &gt;&gt; 0</code> 이어야 <code>h(x)</code> 가 <code>1</code> 에 가까워 진다. </p>

<p>이제 <em>cost function</em> 에 <code>h(x)</code> 를 넣자. 그리고 <code>m = 1</code> 인 트레이닝 셋에 대해서 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360809698_1212.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>파란 그래프에서 볼 수 있듯이 <code>y = 1</code> 일때 <code>0^Tx &gt;&gt; 0</code> 이면 <em>cost</em> 가 상당히 낮아지는걸 볼 수 있다. 이 그래프를 좀 단순화 해서 <em>자주색</em> 그래프를 만들어 보자. 두개의 직선으로 만들었는데, 이 <em>cost function</em> 을 계산하면 상당히 근접한 값을 얻을 수 있고, 동시에 그래프가 단순해져 <em>computational advantage</em> 를 얻을 수 있다.</p>

<p>각각 좌측, 우측에 있는 <em>cost function</em> 을 이렇게 쓴다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5C%20%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29'  alt="" /></p>

<p><em>logistic regression</em> 식 에서 <code>-log h(x)</code> 를 <code>cost_1(z)</code> 로, <code>-log(1 - h(x)))</code> 를 <code>cost_0(z)</code> 로 바꾸면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%20m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7D%28-log%5C%20h_%5Ctheta%28x%5E%7B%28i%29%7D%29%29%5C%20&plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28-log%281%5C%20-%5C%20h_%7B%5Ctheta%7D%28x%5E%7B%28i%29%7D%29%29%29%5D%5C%20&plus;%20%5C%20%7B%5Clambda%20%5Cover%202m%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2%20%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29%20%5C%5C%20min_%5Ctheta%20%5C%20%7B1%20%5Cover%20m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29%5D%5C%20&plus;%20%5C%20%7B%5Clambda%20%5Cover%202m%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2'  alt="" /></p>

<p>이 때, <code>1/m</code> 은 상수이므로 제거해도 어차피 똑같은 <code>0(theta)</code> 를 얻을 수 있다.</p>

<p>그리고 식을 좀 간략히 적어보면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20A%20&plus;%20%5Clambda%20B'  alt="" /></p>

<p>여기서 <code>lambda</code> 가 하는 일은 <em>low cost ('A')</em> 와 <em>small parameter ('B')</em> 를 조절하는 일이다. 식을 좀 변경하면 이렇게도 볼 수 있다. 여기서 <code>C</code> 는 <code>1 / lambda</code> 과 같은 역할이라 보면 된다. </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20&plus;%20%5Clambda%20B'  alt="" /></p>

<p>아주 작은 수의 <code>lambda</code> 를 사용하면 파라미터 <code>B</code> 가 커지는데, 이것은 <code>C</code> 가 커져 <code>A</code> 를 낮추고 <code>B</code> 를 높이는 것과 똑같다. 반대로 <code>C</code> 가 작으면 <code>A</code> 가 커지고, <code>B</code> 가 작아진다.</p>

<p>결국 <code>C</code> 를 쓰느냐 <code>lambda</code> 를 쓰느냐는, 어떤 항을 옵티마이제이션의 중심으로 두느냐다. 최적화된 파라미터를 찾는건 똑같다.</p>

<p>식을 마지막으로 정리하면,</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20%5C%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29%5D%5C%20&plus;%20%5C%20%7B1%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2'  alt="" /></p>

<p>결국 위 식 (<em>cost</em>) 를 최소화 하면, <code>y = 1</code> 일때 <code>0^Tx &gt;&gt; 0</code> 이 되므로 <code>h(x) == 1</code> 이란 뜻이다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360809865_3224.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<h3 id="largeminginintuition">Large Mingin Intuition</h3>

<p><em>SVM</em> 은 <em>large margin classifier</em> 라 부르도 한다. 왜 그런게 한번 살펴보자.</p>

<p>두 집단을 구분하는 초록색, 자주색, 검은색 직선을 생각해 보자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360811170_6003.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>검은색 선이 가장 낫고, 자주색과 초록색은 두 집단을 분리하긴 하는데 썩 만족할만하게는 아니다. 검은 선과 평행하고 각 점까지의 거리가 최소인 파란선을 그리자. 이걸 <em>margin</em> 이라 부른다. 다시 말해서 <em>margin</em> 이 클수록 좋은 <em>classification</em> 이다.</p>

<p><em>large margin</em> 하고 <em>SVM</em> 하고 무슨 상관일까? 그 전에 먼저 <code>C</code> 를 좀 살펴보자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360811018_1834.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><code>z == 0^T x</code>, 의 범위를 생각해 보면 <code>y = 1</code> 일때 <code>z &gt;= 1</code> 이길 바란다. 반대로 <code>y = 0</code> 이면 <code>z &lt;= -1</code> 이면 <code>h(x)</code> 로 충분히 만족할 만한 값을 얻을 수 있다.</p>

<p>이 때 <code>C</code> 가 매우 크면 <code>A</code> 즉, 아래의 식은 굉장히 작아진다. 거의 0 에 가깝게</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360811206_9816.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>두 집단에 대해서 <code>C</code> 가 매우 크면, 다시 말해 <code>A</code> 가 <code>0</code> 에 가까우면 <em>overfitting</em> 된다 볼 수 있으므로 자주색과 비슷한 라인을 찾아낸다. 자주색 선은 모든 샘플에 대해 <em>large margin</em> 을 가지고 있지만 그렇게 썩 좋은 <em>classification</em> 이라 볼 수는 없다.</p>

<p>그러나 <code>C</code> 가 그렇게 크지 않으면 비 정상적인 샘플들은 조금 무시하고 검은색 선을 찾아낸다. 이게 <em>SVM</em> 이 작동하는 방식이다.</p>

<h3 id="mathematicsbehindlargemarginclassification">Mathematics Behind Large Margin Classification</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360893984_1771.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360893988_7434.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>결국 <code>C</code> 가 아주 클 때 <code>A = 0</code> 이므로 <em>SVM</em> <em>cost fucntion</em> 을 최소화 하는 것은 아래 식과 동일하다. 그런데 이 식을 풀어 보면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%20%5Cleft%20%5C%7C%20%5Ctheta%20%5Cright%20%5C%7C%5E2'  alt="" /></p>

<p>그리고 <code>0(theta)</code> 와 <code>x</code> 를 벡터이므로 <code>0^T x^(i) = p^(i) * ||0||</code> 라 볼 수 있다. (여기서 <code>p^(i)</code> 는 <code>x</code> 의 <code>0</code> 로의 <em>projection</em> 된 선의 길이)</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta%5ETx%20%5C%5C%20%5C%5C%20%3D%20p%5E%7B%28i%29%7D%20%5Cleft%20%5C%7C%20%5Ctheta%20%5Cright%20%5C%7C'  alt="" /></p>

<p>이제 이 식을 좀 활용해 보자. <code>C</code> 가 매우 클때는 <code>B</code> 만 최소화 하면 되는데</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2'  alt="" /></p>

<p>이 식 자체가 <em>large margin</em> 을 찾아낸다. 왜 그런가 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360893992_3213.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>왼쪽 그래프의 계산 과정을 보면 <code>x1</code> 을 <code>0</code> 에 <em>projection</em> 해서 얻은 <code>p1</code> 이 매우 작다. 따라서 <code>p1 * ||0|| &gt;= 1</code> 에서 <code>||0||</code> 가 커야 전체 식이 1보다 커지는데, 이러면 식 <code>B</code> 를 최소화 할 수 없다. 마찬가지로 <code>p2</code> 는 매우 작은 음수고, <code>p2 * ||0|| &lt;= -1</code> 에서, <code>||0||</code> 가 매우 큰 음수여야 한다. 이 또한 <code>0</code> 를 크게 만드므로 식 <code>B</code> 가 작아지는 <code>0</code> 를 찾지 못한다. </p>

<p>결국 <code>p</code> 가 커야만 <code>0</code> 가 작아지기 때문에 <code>p</code> 를 크게 하는 <code>0</code> 만 찾고, 이것은 <em>large margin</em> 이다. 따라서 초록색 같은 <em>low margin</em> 의 <code>0</code> 는 선택되지 않는다. </p>

<p>정리하자면 <code>C</code> 가 매우 클때 <em>SVM</em> 은 <em>large magin</em> 을 찾고, 여기서 <code>C</code> 를 낮춤으로써 적당한 수준의 <em>classification</em> 을 얻을 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2'  alt="" /></p>

<h3 id="kernels">Kernels</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895849_6087.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><em>SVM</em> 으로 <em>non-linear decision boundary</em> 를 어떻게 찾아낼까? 단순히 <em>high polynomial features</em> 를 사용하는 것보다 더 나은 방법은 없을까? 고차 다항식은 이미지 처리 예제에서도 봤지만, 계산 비용이 너무 비싸다.</p>

<p><em>kernel</em> 이란 개념이 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895854_4557.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>수동으로 몇몇 <em>landmark</em> <code>l1, l2, ...</code> 을 고른후 이 <em>landmark</em> 사이와의 거리로 새로운 <em>feature</em> <code>f</code> 를 만든다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?f_1%20%3D%20similarity%28x%2C%20l%5E%7B%281%29%7D%29%20%3D%20exp%20%28-%20%7B%7C%7Cx-l%5E%7B%281%29%7D%7C%7C%5E2%20%5Cover%202%5Csigma%5E2%7D%29'  alt="" /></p>

<p>dl <em>similarity function</em> 을 <em>kernel function</em> 특히 여기서 사용한 수식은 <em>gaussian kernel</em> 이라 부른다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895859_5163.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><code>x</code> 와 <code>l</code> 이 상당히 가까우면 <code>f</code> 는 <code>1</code> 에 근접하고, 상당히 멀면 <code>0</code> 에 가까워진다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895862_8544.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>위 그림은 시그마에 따른 <code>f</code> 값의 변화를 보여주는데, 시그마가 작으면 작을수록 조금만 멀어도 <code>f</code> 값은 <code>0</code> 에 가까워진다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895867_6739.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>데이터가 <em>landmark</em> 중 하나에 라도 가까우면 적어도 하나의 <code>f</code> 가 1이 되어, <code>h(x)</code> 가 1 이되고 반면 모든 <em>landmark</em> 에 멀면 모든 <code>f</code> 가 0 이 되어 <code>h(x)</code> 가 0 이된다.</p>

<p>그럼 이제, 문제는 어떻게 <em>landmark</em> 를 정할 것인가?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360899128_1431.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360899133_9301.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><code>l1, ..., lm</code> 을 <code>x1, ..., xm</code> 라 하자. 즉 각 <em>training example</em> 이 <em>landmark</em> 가 된다. 이를 이용해 구한 <em>feature vector</em> <code>f^(i)</code> 중 하나는 <code>sim(x^i, l^i)</code> 이므로 1이 된다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360899136_2691.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>따라서 주어진 <code>x</code> 에 대해 <code>m + 1</code> 의 벡터 <code>f</code> 를 구해 <code>0^Tf &gt;= 0</code> 이면 <code>y = 1</code> 이다. 그리고 이 때 <em>feature</em> 수가 <code>m</code> 이 되므로 </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20%5C%20%5Csum_%7By%3D1%7D%5Emcost_1%28%5Ctheta%5ETf%5E%7B%28i%29%7D%29%20&plus;%20%281-y%5E%7B%28i%29%7D%29cost_0%28%5Ctheta%5ETf%5E%7B%28i%29%7D%29%29%20&plus;%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5Em%5Ctheta_j%5E2'  alt="" /></p>

<p>마지막 항을 좀 자세히 보면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum_%7Bj%3D1%7D%5Ctheta_j%5E2%20%5C%5C%20%5C%5C%20%3D%20%5Ctheta%5ET%20%5Ctheta'  alt="" /></p>

<p>인데 <em>SVM</em> 실제 구현에서는 가운데 <code>M</code> 매트릭스를 삽입해 좀더 효율적으로 돌아가도록 한다. 이 <code>M</code> 은 어떤 <em>kernel</em> 을 사용하는지에 따라 다르다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta%5ET%20M%20%5C%20%5Ctheta'  alt="" /></p>

<p><em>logistic regression</em> 에 <em>kernel</em> 을 사용할 수도 있겠지만, 상당히 느리다. 반면 <em>SVM</em> 에서는 마지막 항을 위 처럼 수정할 수 있기에 빠르게 동작한다.</p>

<h3 id="biasvsvarianceinsvm">Bias vs Variance in SVM</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360899140_2255.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>(1) <code>C</code> 가 크면 <em>low bias</em>, <em>high variance</em>  (== <em>small <code>lambda</code></em>) <br />
(2) <code>C</code> 가 작으면 <em>high bias</em>, <em>low variance</em>  (== <em>large <code>lambda</code></em>)  </p>

<p><code>sigma</code> 가 크면 <code>f</code> 가 적게 변하기 때문에 인풋 <code>x</code> 에 대해서도 <em>high bias</em>, <em>low variance</em> 다.</p>

<h3 id="usingansvm">Using an SVM</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360901245_9359.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>라이브러리를 사용하더라도 <code>C</code> 와 어떤 <em>kernel</em> 을 사용할지는 골라야 한다.</p>

<p><em>feature</em> 가 크고, 트레이닝셋이 작을때는 <em>overfitting</em> 될 수 있으므로 <em>linear kernel</em> 을 사용하는 편이 낫다.</p>

<p>반면 <code>n</code> 이 작고, <code>m</code> 이 클 경우에는 <em>non-linear</em> 가설일 수 있으므로 <em>gaussian kernel</em> 을 사용할 수 있다. 그러면 <code>sigma</code> 를 골라야 한다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360901242_6422.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><em>SVM</em> 라이브러리를 이용할때는 <code>kernel function</code> 을 직접 구현해야 한다. 이걸 이용해서 라이브러리는 <code>x</code> 에 대해 <code>f1, ..., fl</code> 을 계산한다.</p>

<p>만약에 <em>feature</em> 의 스케일이 다르면, <code>x1 = 10000, x2 = 5, ...</code> <code>||x-l||^2</code> 값이 숫자가 큰 항에 의해 좌우될 수 있으므로 <em>feature scailing</em> 을 하는편이 좋다.</p>

<h4 id="otherchoicesofkernel">Other choices of kernel</h4>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360901245_9359.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><em>SVM</em> 구현들이 계산을 최적화 하기위해 다양한 트릭을 이용한다. 이로 인해 모든 <em>similarity function</em> 유효한 커널이 되는건 아니고, <em>"Mercer's Theorem"</em> 을 만족해야만 한다. <del>인용하려 했는데 무슨말인지 모르겠음</del></p>

<p>그렇다고 커널이 <em>linear</em> 와 <em>gaussian</em> 만 있는건 아니고 다양한 커널이 있다. 그림을 참조하자.</p>

<h4 id="multiclassclassification">Multi-class classification</h4>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360901253_5022.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>대부분의 <em>SVM</em> 라이브러리들은 <em>multi-class</em> 에 대한 함수를 제공한다. 그러나 이것들을 사용하는 대신 <em>one-vs-all</em> 방법을 사용할 수도 있다. <code>k</code> 개의 클래스가 있다면 <code>k</code> 개의 <em>SVM</em> 훈련시키면 된다.</p>

<h4 id="logisticregressionvssvm">Logistic regression vs SVM</h4>

<p><img src='http://my.csdn.net/uploads/201208/12/1344759226_6088.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>(1) <code>n &gt;= m</code> 이면 <em>logistic regression</em> 이나 <em>linear kernel</em> 이 낫다. <br />
(2) <code>n</code> 이 작고, <code>m</code> 이 중간 사이즈면 <em>gaussian kernel</em> 을 <br />
(3) <code>n</code> 이 작고 <code>m</code> 이 크면 <em>gaussian</em> 은 상당히 느려진다. <em>feature</em> 를 좀 수정하고, <em>logistic</em> 이나 <em>linear kernel</em> 을 이용한다.</p>

<p><em>SVM</em> 의 장점은 다양한 <em>kernel</em> 을 <em>non-linear function</em> 을 훈련시키기 위해 사용할 수 있다는 점이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>  </p>]]></description><link>http://1ambda.github.io/machine-learning-week-7/</link><guid isPermaLink="false">61eb3656-6495-48e4-a92f-2ba44cf1416d</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine lerning]]></category><category><![CDATA[SVM]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 22 Nov 2014 06:23:25 GMT</pubDate></item><item><title><![CDATA[Intro to Computational Thinking and Data Science 2]]></title><description><![CDATA[<blockquote>
  <p>Computational systems are so very convenient for modeling behaviors of noisier, uncertain systems, <strong>especially in estimating the values of parameters of those systems</strong>.</p>
</blockquote>

<h3 id="montecarlosimulation">Monte Carlo Simulation</h3>

<blockquote>
  <p>Monte Carlo simulation is a method of <strong>estimating the value of an unknown quantity using the principles of inferential statistics</strong></p>
</blockquote>

<p>이전에 잠깐 <em>deterministic model</em> 과 <em>stochastic model</em> 언급 했었는데, 다시 한번 알아보자면</p>

<blockquote>
  <p>In <strong>deterministic models</strong>, the output of the model is  fully determined by the parameter values and the
  initial conditions.</p>
  
  <p><strong>Stochastic models</strong> possess some inherent randomness. The same set of parameter values and initial conditions will lead to an ensemble of different outputs</p>
</blockquote>

<p>때때로 사람들이 <em>deterministic model</em> 은 <em>uncertainty</em> 를 다루지 않는다고 말하곤 하는데 이건 엄밀히 말하면 틀렸다. <em>deterministic model</em> 내부적으로는 <em>randomness</em> 가 없지만, 모델 외부에 <em>uncertainty</em> 가 있을 수 있다.  </p>

<p>몬테 카를로 시뮬레이션이 바로 <em>deterministic model</em> 에 대해 <em>random input</em> 을 이용해 분포를 얻어내는 방법이다. </p>

<blockquote>
  <p>I have heard people say that "a stocahstic model handles uncertainty, a deterministic model doesn't". This is not strictly correct. The correct statement should be: 
  a stochastic model has the capacity to handle then uncertainty in the inputs built into it, for a deterministic model, the uncertainties are extenal to the model. The uncertainties in the inputs to a deterministic model can be handled through use of a Monte Carlo simulation (note that this does not make it a stochastic model). This is computationally inefficient however.</p>
</blockquote>

<h3 id="findingpi">Finding PI</h3>

<pre><code class="python">def stdDev(X):  
    mean = sum(X) / float(len(X))
    total = 0.0
    for x in X:
        total += (x - mean) ** 2
    return (total / len(X)) ** 0.5


def dropNeedles(num):  
    inCircle = 0
    for needles in xrange(1, num + 1, 1):
        x = random.random()
        y = random.random()

        if (x*x + y*y) ** 0.5 &lt;= 1.0:
            inCircle += 1

    return 4 * (inCircle / float(num))


def estimate(numOfNeedles, trials):  
    estimates = []
    for i in range(trials):
        pi = dropNeedles(numOfNeedles)
        estimates.append(pi)

    sd = stdDev(estimates)
    est = sum(estimates) / len(estimates)

    return (est, sd)


def simulate(precision, trials):  
    numOfNeedles = 1000
    sd = precision

    # 95% of the values lie within precision of the mean
    while sd &gt;= (precision / 2.0):
        est, sd = estimate(numOfNeedles, trials)
        print 'PI est =', est, "sd =", round(sd, 6), "needles =", numOfNeedles
        numOfNeedles *= 2

    return est


random.seed(0)  
simulate(0.005, 100)  
</code></pre>

<p>반지름이 1인 원 안에 바늘을 떨어트려, 해당 원 안에 있을 경우와 직사각형에 있을 경우의 비율에 직사각형의 넓이를 곱하면, 원의 넓이 즉 <code>PI</code> 값이 나온다.</p>

<p>실제 돌려보면</p>

<pre><code>PI est = 3.14844 sd = 0.047886 needles = 1000  
PI est = 3.13918 sd = 0.035495 needles = 2000  
PI est = 3.14108 sd = 0.02713 needles = 4000  
PI est = 3.141435 sd = 0.016805 needles = 8000  
PI est = 3.141355 sd = 0.0137 needles = 16000  
PI est = 3.14131375 sd = 0.008476 needles = 32000  
PI est = 3.141171875 sd = 0.007028 needles = 64000  
PI est = 3.1415896875 sd = 0.004035 needles = 128000  
PI est = 3.14174140625 sd = 0.003536 needles = 256000  
PI est = 3.14155671875 sd = 0.002101 needles = 512000  
</code></pre>

<p><code>32000</code> 개와 <code>64000</code> 개의 바늘을 떨어트린 샘플을 보면 실제 샘플도 후자가 많고, 표준편차도 후자가 작음에도 실제 추정값은 더 나쁘게 나왔다.</p>

<p>표준편차가 작으면 실제 값에 근접한 추정값이 나왔다는 뜻이 아닌가? </p>

<blockquote>
  <p>Having the small standard deviation doesn't mean we have a good estimate.</p>
</blockquote>

<p>그렇지 않다. 표준편차가 작다는 것이, 우리가 얻은 추정값이 실제 값과 같다는 뜻은 아니다.</p>

<blockquote>
  <p>All this means is that if we were to draw more samples from the same distribution, we can be reasonably confident that we would get a similar value.</p>
</blockquote>

<p>단지 같은 분포에서 더 많은 샘플을 이용하면 <em>현재 값과 비슷한 값 (!= 실제값)</em> 을 얻을 수 있다는 말이다.</p>

<p>우리가 구한 값이 실제 <code>PI</code> 와 근사하다고 믿기 전에 3가지를 먼저 확인해야한다.</p>

<p>(1) <strong>conceptual model</strong> (이 경우 <code>PI</code> 를 위한 계산) <br />
(2) <strong>implementation</strong> <br />
(3) <strong>enough samples</strong>  </p>

<p>만약에 <code>4 * (inCircle / float(num)</code> 대신에 <code>2 * (inCircle / float(num)</code> 를 사용해 잘못된 <em>conceptual model</em> 을 가진다면 (버그라 볼 수도 있겠다.)</p>

<pre><code>PI est = 1.57422 sd = 0.023943 needles = 1000  
PI est = 1.56959 sd = 0.017748 needles = 2000  
PI est = 1.57054 sd = 0.013565 needles = 4000  
PI est = 1.5707175 sd = 0.008402 needles = 8000  
PI est = 1.5706775 sd = 0.00685 needles = 16000  
PI est = 1.570656875 sd = 0.004238 needles = 32000  
PI est = 1.5705859375 sd = 0.003514 needles = 64000  
PI est = 1.57079484375 sd = 0.002017 needles = 128000  
</code></pre>

<p>보면 알겠지만, 표준편차는 충분히 작음에도 우리가 구한 추정값이 <code>PI</code> 와는 상당히 다르다.</p>

<blockquote>
  <p>Whenever possible, one should attempt to validate results against realilty</p>
</blockquote>

<h3 id="normaldistribution">Normal Distribution</h3>

<blockquote>
  <p>Instead of estimating an unknown parameter by a single value, a <strong>confidence interval</strong> provides a range that is likely to contain the unknown value and a confidence level that the unknown value lays within that range</p>
</blockquote>

<h3 id="commonpatterninscienceandengineering">Common Pattern in Science and Engineering</h3>

<p>보통 두 가지 작업이 있는데,</p>

<p>(1) develop a hypothesis <br />
(2) design an experiment, take measurements <br />
(3) use computation to <br />
- evaluate hypothesis, <br />
- determin values of unknowns, <br />
- predict consequences</p>

<p>두가지는 <code>1 -&gt; 2</code> 순서일 수 있고, 때때로 뒤 바뀔 수도 있다. 예를 한번 살펴보면</p>

<p>먼저 16세기에 <em>Hooke</em> 는 <em>"용수철에 가해진 힘은 그 길이에 비례한다는 가설"</em> 을 세웠다. 이를 증명하기 위해 실험을 고안했는데, 천장에 서로 다른 길이의 스프링을 연결하고 거기에 저울 추를 달았다.</p>

<p>늘어난 길이 <code>x</code> 에 대해 용수철 상수 <code>k</code> 를 <code>kx = mg</code> 를 이용해 계산하면, 얼추 맞는다. 그런데 몇몇 샘플에 대해서는 용수철 상수 <code>k</code> 가 상당히 다르게 나온다. <code>[11.41, 14.49 ...]</code> 왜 그럴까? 용수철 상수가 매번 변한다는걸까? </p>

<p>다음 데이터에 대해 그래프를 그려보면</p>

<pre><code>Distance (m) Mass (kg)  
0.0865 0.1  
0.1015 0.15  
0.1106 0.2  
0.1279 0.25  
0.1892 0.3  
0.2695 0.35  
0.2888 0.4  
0.2425 0.45  
0.3465 0.5  
0.3225 0.55  
0.3764 0.6  
0.4263 0.65  
0.4562 0.7  
0.4502 0.75  
0.4499 0.8  
0.4534 0.85  
0.4416 0.9  
0.4304 0.95  
0.437 1.0  
</code></pre>

<p><em>distance</em> 에 대한 예측 <code>ma / k</code> 와 실제 값이 일치하지 않는다. 이른바 <em>error (오류)</em> 가 있는 것인데, 이들 오류는 <em>small randomness</em> 에 대한 축적의 결과로 이루어 진 것이다.</p>

<p>오류에 대한 <em>probabilty density function</em> 로 <code>y = x - 1 (-1 &lt;= x &lt; 0)</code>, <code>y = -x + 1 (0 &lt; x &lt;= 1)</code> 을 가정했을때 시뮬레이션을 좀 해보자. <code>random.triangular</code> 를 이용하면 <em>triangle distribution</em> 을 얻을 수 있다.</p>

<pre><code class="python">def testErrors(ntrials=10000,npts=100):  
    results = [0] * ntrials
    for i in xrange(ntrials):
        s = 0   # sum of random points
        for j in xrange(npts):
            s += random.triangular(-1,1)
        results[i] =s
    # plot results in a histogram
    pylab.hist(results,bins=50)
    pylab.title('Sum of 100 random points -- Triangular PDF (10,000 trials)')
    pylab.xlabel('Sum')
    pylab.ylabel('Number of trials')

testErrors()  
pylab.show()  
</code></pre>

<p>실행해 보면 에러의 합의 분포가 정규 분포와 비슷하다. 우리가 어떤 에러 분포를 고르든지 간에 <em>finite mean, variance</em> 를 가지고 있다면 에러의 분포는 정규분포다. </p>

<p>실제 그런가 <code>random.triangular</code> 말고 <code>random.uniform</code> 을 이용해 보면 똑같이 정규분포를 얻는다. 이는 <em>central limit theorem (중심극한정리)</em> 를 의미하는데 위키에서 인용하면</p>

<blockquote>
  <p>동일한 확률분포를 가진 독립 확률 변수 n개의 평균값은 n이 적당히 크다면 정규분포에 가까워진다는 정리</p>
</blockquote>

<p>결국 우리가 이전에 스프링을 이용해 봤던 실험에서 발생한 에러는 <em>small random error</em> 의 <em>accumulation</em> 이므로, 우리는 이 에러의 분포를 정규분포라 말할 수 있다는 것이다.</p>

<p><strong>결국 오차 역시 평균 주변에 몰려있는 값이므로, 참값을 상당히 높은 확률로 추측해 낼 수 있다.</strong></p>

<blockquote>
  <p>정규분포는 19세기의 가장 위대한 수학자인 가우스(C. F. Gauss, 1777-1855)에 의해 새롭게 해석된다. 가우스는 관측에 따른 오차의 정도가 대체로 평균값 주변에서 발생한다는 점에 착안하여 정규분포에 따른 확률 밀도 함수와 똑 같은 식을 얻을 수 있었다. 이것은 <strong>관측 오차 역시 정규분포를 따른다는 것으로, 이후 실험으로 구한 관측값에서 참값을 추정해내는 근본적인 원리</strong>로 자리잡게 된다. 이런 점에서 위의 종모양 곡선을 오차곡선(error curve)라고도 부른다.</p>
</blockquote>

<p><em>normal distribution</em> 의 식은 </p>

<p><img src='http://latex.codecogs.com/gif.latex?f%28x%29%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20e%5E%7B-%28x%20-%20%5Cmu%29%5E2%20%5Cover%20%5Csigma%5E2%7D'  alt="" /></p>

<p><code>mu = 0, sigma = 1</code> 인 경우에 <em>standard normal</em> 혹은 <em>unit normal</em> 이라 부른다.</p>

<blockquote>
  <p>So when observation errors are due to the accumlation of many small random perturbations</p>
</blockquote>

<p><img src='http://latex.codecogs.com/gif.latex?f%28x%29%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20e%5E%7B-%28x%29%5E2%20%5Cover%20%5Csigma%5E2%7D'  alt="" /></p>

<p>다시 말해 작은 랜덤의 누적으로 발생한 관측 오차의 경우에는 <code>mu = 0</code> 이다. 그리고 식이 말해주는 바는, 큰 에러의 경우에는 확률이 <em>expnentially less likely</em> 하다는 것이다.</p>

<p>이제 각 에러가 일어날 확률 곱을 다음과 같이 구할 수 있다. </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cprod_%7Bi%20%3D%200%7D%5E%7Blen%28obj%29%20-%201%7D%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29'  alt="" /></p>

<p>이때 이 값을 최대화한다는 것은 각 에러가 나올 확률이 가장 높아야 한다. 다시 말해서 가장 평균적인 에러만 나와야 한다는 뜻이다. 이 값의 최대를 구하는 것은 뒤집은 식의 최소값을 찾는 것과 같으므로</p>

<p><img src='http://latex.codecogs.com/gif.latex?min%20%5C%20%7B1%20%5Cover%20%5Cprod_%7Bi%20%3D%200%7D%5E%7Blen%28obj%29%20-%201%7D%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29%7D'  alt="" /></p>

<p>여기에 자연 로그를 씌우면 확률 변수의 곱이 덧셈으로 변한다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?ln%20%28%7B1%20%5Cover%20%5Cprod%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29%7D%29%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20-%20%5Csum%20ln%20%28L_%7Berr%7D%28obs_i%20-%20pred_i%29%29'  alt="" /></p>

<p>이 값을 최소화 하면 된다. 여기서 <em>pdf</em> 식을 적용하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?min%20-%20%5Csum%20ln%20%28%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20e%5E%7B%28obs_i%20-%20pred_i%29%5E2%20%5Cover%20%5Csigma%5E2%7D%29'  alt="" /></p>

<p>로그를 씌우면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum%20%5Bln%20%7B%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20&plus;%20ln%20%7B%28obs_i%20-%20pred_i%29%5E2%20%5Cover%20%5Csigma%5E2%7D%5D'  alt="" /></p>

<p>이 때 다른 상수를 제외하고 실제 최소화 해야 할 부분만 고려하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?min%20%5Csum%20%28obs_i%20-%20pred_i%29%5E2'  alt="" /></p>

<p>따라서 이 값을 최소화 하면 <em>most likely observations</em> 가 된다. 이런 이유에서 오차 제곱의 합의 최소가 되는 파라미터가 바로 가장 신뢰할만한 파라미터가 된다.</p>

<p><br/> <br />
처음부터 정리하자면, 중심 극한 정리에 따라 에러의 분포가 어떠하든 간에 에러가 확률변수라면 이것의 평균은 정규분포다. 따라서 <em>pdf</em> 식을 적용할 수 있고 이때 <code>mean = 0</code> 이다.</p>

<p>에러가 나올 확률의 곱이 최대이면, 모든 에러에 대해 보편적인 에러를 얻었다는 뜻이므로 이에 대해 식을 정리하면,</p>

<p><em>sum of squared of erros (SSE, least square)</em> 를 최소화 하는 파라미터를 선택하면 가장 신뢰할 만한 관측 결과를 얻어낼 수 있다는 결론을 얻게된다.</p>

<p><br/> <br />
파이선에서는 <code>pylab.plotfit</code> 을 이용해 값을 최소화 하는 파라미터를 뽑아낼 수 있다. 예를 들어서 <code>y = ax + b</code> 의 합을 최소화 하는 <code>a, b</code> 를 찾으려면 </p>

<pre><code class="python">a, b = pylab.ployfir(xvals, yvals, 1)  
</code></pre>

<p><code>y = ax^2 + bx + c</code> 에 대해서는</p>

<pre><code class="python">a, b, c = pylab.polyfit(xvals, yvals, 2)  
</code></pre>

<h3 id="firingarrow">Firing Arrow</h3>

<p>이제 위에서 얻은 개념을 다른 예제에 적용해보면서 가설이 얼마나 <em>잘 맞는가</em> 를 어떻게 측정할건지를 좀 생각해 보자. (<em>Measuring "goodness" of fit</em>)</p>

<p>화살이 날라가는 거리에 따른 높이를 측정한 데이터다.</p>

<pre><code>Distance (yds) height (ins) height height height  
30  0 0 0 0  
29 2.25 3.25 4.5 6.5  
28 5.25 6.5 6.5 8.75  
27 7.5 7.75 8.25 9.25  
26 8.75 9.25 9.5 10.5  
25 12 12.25 12.5 14.75  
24 13.75 16 16 16.5  
23 14.75 15.25 15.5 17.5  
22 15.5 16 16.6 16.75  
21 17 17 17.5 19.25  
20 17.5 18.5 18.5 19  
15 19.5 20 20.25 20.5  
10 18.5 18.5 19 19  
5 13 13 13 13  
0 0 0 0 0  
</code></pre>

<pre><code class="python">def getTrajectoryData(fileName):  
    dataFile = open(fileName, 'r')
    distances = []
    heights1, heights2, heights3, heights4 = [],[],[],[]
    discardHeader = dataFile.readline()
    for line in dataFile:
        d, h1, h2, h3, h4 = line.split()
        distances.append(float(d))
        heights1.append(float(h1))
        heights2.append(float(h2))
        heights3.append(float(h3))
        heights4.append(float(h4))
    dataFile.close()
    return (distances, [heights1, heights2, heights3, heights4])

def tryFits(fName):  
    distances, heights = getTrajectoryData(fName)
    distances = pylab.array(distances)*36 # convert yard to
    totHeights = pylab.array([0]*len(distances))
    for h in heights:
        totHeights = totHeights + pylab.array(h)
    pylab.title('Trajectory of Projectile (Mean of 4 Trials)')
    pylab.xlabel('Inches from Launch Point')
    pylab.ylabel('Inches Above Launch Point')
    meanHeights = totHeights/float(len(heights))
    pylab.plot(distances, meanHeights, 'bo')
    a,b = pylab.polyfit(distances, meanHeights, 1)
    altitudes = a*distances + b
    pylab.plot(distances, altitudes, 'r',
               label = 'Linear Fit')
    a,b,c = pylab.polyfit(distances, meanHeights, 2)
    altitudes = a*(distances**2) + b*distances + c
    pylab.plot(distances, altitudes, 'g',
               label = 'Quadratic Fit')
    pylab.legend()
</code></pre>

<p>위 코드를 돌려보면 이차함수가 일차함수보다 더 <em>fit</em> 한 걸 볼 수 있다. 그럼 문제는 매번 그래프로 그릴수도 없고 어떻게 측정할거냐 하는건데, <em>variabilty</em> 를 이용하는 방법이 있다. 다시 말해 에러가 얼마나 많이 변하냐는 것이다.</p>

<p><em>variability of errors</em> 는 SEE, 즉 관측 데이터와 예측값 간 차이의 제곱의 합으로 구할 수 있다. 그리고 <em>variability of data</em> 는 관측값과 관측값의 평균의 차이의 제곱의 합으로 구할 수 있다. 그리고 이 두 변수간 비율로 모델이 얼마나 잘 맞는지를 판단할 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%7B%5Csigma_%7Berr%7D%5E2%20%5Cover%20%5Csigma_%7Bdata%7D%5E2%7D'  alt="" /></p>

<p>이 값을 <code>R^2</code> 또는 <em>coefficient of determination</em> 이라 부른다. 이 값이 <code>1</code> 에 근접하면 모델이 데이터와 잘 맞고, <code>0</code> 에 가까우면 거의 안맞는다는 뜻이다.</p>

<p>그러나 주의해야 할 점이 하나 있다. <code>R^2</code> 값이 높은 모델이라고 해서 좋은 모델이라는 뜻은 아니다. 지금 현재 가진 데이터에 <em>fit</em> 된다는 거지, 실제 데이터에 적용하면 어떻게 될지 모른다. <em>overfitting</em> 할 수도 있다는 이야기다.</p>

<p>파이썬에서 <code>R^2</code> 를 구하는 함수를 만들면</p>

<pre><code class="python">def rSquare(measured, estimated):  
    """measured: one dimensional array of measured values
       estimate: one dimensional array of predicted values"""
    SEE = ((estimated - measured)**2).sum()
    mMean = measured.sum()/float(len(measured))
    MV = ((mMean - measured)**2).sum()
    return 1 - SEE/MV
</code></pre>

<h3 id="references">References</h3>

<p>(1) <em>MIT 6.00.2 2x</em> in <strong>edx</strong> <br />
(2) <a href='http://ko.wikipedia.org/wiki/%EC%A4%91%EC%8B%AC%EA%B7%B9%ED%95%9C%EC%A0%95%EB%A6%AC' >http://ko.wikipedia.org</a> <br />
(3) <a href='http://www.financedoctor.co.kr/finance/view.php?f_idx=14587&amp;b_code=8&amp;m_code=0&amp;s_code=0' >http://www.financedoctor.co.kr</a> <br />
(4) <a href='http://www.researchgate.net/post/What_is_the_difference_among_Deterministic_model_Stochastic_model_and_Hybrid_model' >www.researchgate.net/</a> <br />
(5) <a href='http://www4.stat.ncsu.edu/' ~gross/BIO560%20webpage/slides/Jan102013.pdf">www4.stat.ncsu.edu</a></p>]]></description><link>http://1ambda.github.io/edx-600-2x-2/</link><guid isPermaLink="false">32cb7752-47f2-4ad2-a5cf-176453e06a7c</guid><category><![CDATA[edx]]></category><category><![CDATA[python]]></category><category><![CDATA[simulation]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 21 Nov 2014 15:43:27 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 5]]></title><description><![CDATA[<p>키보드를 읽거나 화면에 무엇인가 쓰는 <em>intertactive program</em> 은 <em>side-effect</em> 를 만듭니다. 그런데, 하스켈은 <em>side-effect</em> 가 없지요. 그럼 입출력이 불가능한 것일까요? </p>

<p>당연히 그렇지 않습니다. <strong>IO 모나드</strong> 를 사용할겁니다.</p>

<p><em>pure expression</em> 부분과 <em>side-effect</em> 를 만들어내는 <em>impure action</em> 을 구분하여 하스켈에서 입출력을 할 수 있습니다.</p>

<blockquote>
  <p>Interactive program can be written in Haskell using types to distinguish pure expressions from impure actions that may involve side effects</p>
</blockquote>

<p>예를 들어 <code>IO a</code> 는 <code>a</code> 타입을 리턴하는 <em>action</em> 입니다.</p>

<p>몇 가지 예를 보면, <code>IO Char</code> 은 캐릭터를 리턴하는 액션입니다. <code>IO ()</code> 는 <em>unit</em> 을 돌려주는데 이건 절차형 언어에서의 <em>void</em> 와 같다고 보면 됩니다. 다시 말해서 <code>IO ()</code> 는 다른 것엔 아무것도 관심 없고 입출력에만 관심이 있다는 뜻이지요.</p>

<p>지난 시간에 언급 했듯이 <em>IO 모나드</em> 는 사실 <em>State 모나드</em> 입니다.</p>

<pre><code class="haskell">State -&gt; (a, State)  
</code></pre>

<p>스크린이나, 키보드 버퍼등 다양한 State 를 변화시켜 가면서 <code>a</code> 타입의 값을 리턴할 수 있죠. 위에서 본 <code>IO ()</code> 는 <em>purely side-effecting action</em> 입니다.</p>

<h3 id="basicactions">Basic Actions</h3>

<p><code>getChar</code> 는 키보드로부터 글자를 하나 읽어 캐릭터를 리턴합니다. 다른 언어에서는 <code>() -&gt; Char</code> 처럼 정의되었겠죠?</p>

<pre><code class="haskell">getChar :: IO Char  
</code></pre>

<p>다른 <em>action</em> 도 좀 살펴볼까요?</p>

<pre><code class="haskell">puChar :: Char -&gt; IO ()  
return :: a -&gt; IO a  
</code></pre>

<h3 id="sequencing">Sequencing</h3>

<p><em>action</em> 들을 <code>do</code> 로 조합할 수 있습니다.</p>

<pre><code class="haskell">a :: IO (Char, Char)  
a = do x &lt;- getChar  
    getChar
    y &lt;- getChar
    return (x, y)

getLine :: IO String  
getLine = do x &lt;- getChar  
             if x == '\n' then
               return []
             else
               do xs &lt;- getLine
                  return (x:xs)
</code></pre>

<p>몇 가지 더 볼까요?</p>

<pre><code class="haskell">putStr :: String -&gt; IO ()  
putStr [] = return ()  
putStr (x:xs) = do putChar x  
                   putStr xs

putStrLn :: String -&gt; IO ()  
putStrLn xs = do putStr xs  
                 putChar '\n'
</code></pre>

<p>모나드의 산을 넘고 넘어야 IO 의 간결함이 이해가 되니, 아이러니 하죠? 본래 입출력은 정말 기초적인 부분인데 말이지요.</p>

<p>참고로 <em>list comprehension</em> 을 이용하면 <code>putStr</code> 은 이렇게 정의할 수 있습니다.</p>

<pre><code class="haskell">seqn :: [IO a] -&gt; IO ()  
seqn [] = return ()  
seqn (x:xs) = do x  
                 seqn xs

putStr xs = seqn [putChar x | x &lt;- xs]  
</code></pre>

<p>조금 더 블럭을 쌓아봅시다. 문자열을 키보드로 부터 입력받아 화면에 그 길이를 띄워주는 함수를 작성해 봅시다.</p>

<pre><code class="haskell">strlen :: IO ()  
strlen = do putStr "Enter a string: "  
            xs &lt;- getLine
            putStr "The string has "
            putStr (show (length xs))
            putStrLn " characters"

&gt; strlen
-- Enter a string: Hello World!
-- the string has 12 characters
</code></pre>

<p><code>strlen</code> 은 <code>IO ()</code> 타입이니까, 아무것도 돌려주지 않습니다. 입출력에만 관심이 있지요.</p>

<h3 id="hangman">Hangman</h3>

<p>이제까지 배운것을 응용해서 자그마한 행맨 게임을 만들어 봅시다. <em>top down</em> 방식으로 접근할 겁니다.</p>

<pre><code class="haskell">hangman :: IO ()  
hangman = do putStrLn "Think of a word :"  
             word &lt;- sgetLine
             putStrLn "Try to guess it:"
             guess word
</code></pre>

<p>여기서 <code>sgetLine</code> 은 키보드로부터 문자를 입력받아 <code>-</code> 를 화면에 출력합니다.</p>

<pre><code class="haskell">sgetLine :: IO String  
sgetLine = do x &lt;- getCh  
              if x == '\n'
                then do putChar x
                        return []
                else do putChar '-'
                        xs &lt;- sgetLine
                        return (x:xs)
</code></pre>

<p><code>getCh</code> 는 문자열을 키보드로 부터 읽지만 화면에 출력하진 않지요.</p>

<pre><code class="haskell">import System.IO

getCh :: IO Char  
getCh = do hSetEcho stdin False  
           c &lt;- getChar
           hSetCho stdin True
           return c
</code></pre>

<p>여기서 잘 보면 <code>c &lt;- getChar</code> 이 할당(<code>=</code>)처럼 보일텐데, 사실은 그렇지 않습니다. 우린 어떠한 <em>mutable</em> 도 변수도 사용하고 있지 않습니다. 비록 우리가 작성한 코드가 절차형 언어처럼 보일지라도요!</p>

<p>이제 마지막 퍼즐인 <code>guess</code> 함수를 작성해 볼까요?</p>

<pre><code class="haskell">guess :: String -&gt; IO ()  
guess word = do putStr "&gt; "  
                xs &lt;- getLine
                if xs == word
                  then putStrLn "You got it!"
                  else do putStrLn (diff word xs)
                          guess word

diff :: String -&gt; String -&gt; String  
diff xs ys = [if elem x ys then x else '-' | x &lt;- xs]  
</code></pre>

<p><code>diff</code> 를 잠깐 실행해 보면</p>

<pre><code class="haskell">&gt; diff "haskell" "pascal"
-- "-as--ll"
</code></pre>

<h3 id="calculator">Calculator</h3>

<p>시작 전에 몇 가지 보조 함수를 정의하면,</p>

<pre><code class="haskell">getCh :: IO Char  
getCh =  do hSetEcho stdin False  
            c &lt;- getChar
            hSetEcho stdin True
            return c

beep :: IO ()  
beep = putStr "\BEL"

cls :: IO ()  
cls = putStr "\ESC[2J"

type Pos = (Int, Int)

goto :: Pos -&gt; IO ()  
goto (x, y) = putStr ("\ESC["  ++ show y ++ ";" ++ show x ++ "H")

writeAt :: Pos -&gt; String -&gt; IO ()  
writeAt p xs = do goto p  
                  putStr xs
</code></pre>

<p>콘솔 창에서 문자의 위치는 좌표 <code>(Int, Int)</code> 에 의해 결정됩니다. <code>goto</code> 는 그 위치로 커서를 옮기고 <code>writeAt</code> 는 해당 좌표에 입력받은 문자열을 출력합니다.</p>

<p>여기에 <a href='http://1ambda.github.io/haskell-intro4/' >지난번</a>에 만들었던 파서가 <code>-</code>, <code>/</code> 도 처리할 수 있게 조금 업그레이드 하면</p>

<pre><code class="haskell">int :: Parser Int  
int =  do char '-'  
          n &lt;- nat
          return (-n)
        +++ nat

natural :: Parser Int  
natural =  token nat

integer :: Parser Int  
integer =  token int

expr :: Parser Int  
expr = do t &lt;- term  
          do symbol "+"
             e &lt;- expr
             return (t + e)
           +++ do symbol "-"
                  e &lt;- expr
                  return (t - e)
           +++ return t

term :: Parser Int  
term = do f &lt;- factor  
          do symbol "*"
             t &lt;- term
             return (f * t)
           +++ do symbol "/"
                  t &lt;- term
                  return (f `div` t)
           +++ return f

factor :: Parser Int  
factor = do symbol "("  
            e &lt;- expr
            symbol ")"
            return e
          +++ natural
</code></pre>

<p>이제 간단한 계산기를 문자열로 나타내 보면</p>

<pre><code class="haskell">box :: [String]  
box =  ["+---------------+",  
       "|               |",
       "+---+---+---+---+",
       "| q | c | d | = |",
       "+---+---+---+---+",
       "| 1 | 2 | 3 | + |",
       "+---+---+---+---+",
       "| 4 | 5 | 6 | - |",
       "+---+---+---+---+",
       "| 7 | 8 | 9 | * |",
       "+---+---+---+---+",
       "| 0 | ( | ) | / |",
       "+---+---+---+---+"]
</code></pre>

<p><code>q, c, d, =</code> 는 <em>quit</em>, <em>clear</em>, <em>delete</em> <em>evaluation</em> 를 의미합니다. 나머지 버튼은 식을 입력하는데 사용하지요. 이제 박스를화면에 그려주는 <code>showbox</code> 함수를 작성합시다.</p>

<pre><code class="haskell">seqn :: [IO a] -&gt; IO ()  
seqn [] = return ()  
seqn (a:as) = do a  
                 seqn as

buttons :: [Char]  
buttons = standard ++ extra  
          where
            standard = "qcd=123+456-789*0()/"
            extra = "QCD \ESC\BS\DEL\n"

showbox :: IO ()  
showbox =  
  seqn [writeAt (1, y) line | (y, line) &lt;- zip [1..13] box]
</code></pre>

<p><code>buttons</code> 에서 <code>extra</code> 는 좀 더 유연한 버튼 인터페이스를 위해 사용합니다. 무슨 말인고 하니 <code>q</code> 뿐만 아니라 <code>Q</code> 를 눌러도 계산기가 종료되게끔요. </p>

<p>이제 수식을 표현하는 부분을 출력해줄 <code>display</code> 함수를 만듭시다. 입력받은 문자열을, 뒤에서부터 13개만 짤라서 <code>(3, 2)</code> 위치에 출력해줍니다.</p>

<pre><code class="haskell">display :: String -&gt; IO ()  
display xs = do writeAt (3, 2) "             "  
                writeAt (3, 2) (reverse (take 13 (reverse xs)))
</code></pre>

<p>이제 사용자로부터 문자를 입력받아 화면에 출력해주는 로직을 구현한 <code>calc</code> 함수를 보면</p>

<pre><code class="haskell">calc :: String -&gt; IO ()  
calc xs = do display xs  
             c &lt;- getCh
             if elem c buttons
               then process c xs
               else do beep
                       calc xs

process :: Char -&gt; String -&gt; IO ()  
process c xs  
  | elem c "qQ\ESC" = quit
  | elem c "dD\BS\DEL" = delete xs
  | elem c "=\n" = eval xs
  | elem c "cC" = clear
  | otherwise = press c xs
</code></pre>

<p><code>calc</code> 에서는 현재 수식창에 입력된 데이터 <code>xs</code> 와, 사용자로부터 받은 <code>c</code> 를 이용해 작업을 합니다. <code>c</code> 가 만약 <code>buttons</code> 내부에 없다면 다시 <code>calc xs</code> 를 호출해서 새로운 입력을 받습니다.</p>

<p>만약 <code>c</code> 가 <code>buttons</code> 내에 있는 문자들 중 하나라면 <code>process c xs</code> 를 호출하는데, 여기서는 버튼의 종류에 따라 다른 <code>IO ()</code> 를 돌려줍니다.</p>

<pre><code class="haskell">quit :: IO ()  
quit = goto (1, 14)

delete :: String -&gt; IO ()  
delete "" = calc ""  
delete xs = calc (init xs)

eval :: String -&gt; IO ()  
eval xs = case parse expr xs of  
           [(n, "")] -&gt; calc (show n)
           _ -&gt; do beep
                   calc xs

clear :: IO ()  
clear = calc ""

press :: Char -&gt; String -&gt; IO ()  
press c xs = calc (xs ++ [c])  
</code></pre>

<p>(1) <code>quit</code> 는 다시 <code>calc</code> 호출 없이 현재 커서를 14번째 라인으로 이동해 계산기를 종료합니다. <br />
(2) <code>delete</code> 는 현재 <code>xs</code> 에서 마지막 문자를 제거한 <code>init xs</code> 를 <code>calc</code> 에 넘겨줌으로써 수식 입력창에서 마지막 문자를 지웁니다. <br />
(3) <code>eval</code> 는 <code>parse expr xs</code> 의 결과로 올바른 계산 값을 얻으면 <code>calc</code> 에 그 숫자를 문자열로 변환한 결과를 넘겨주어 계산값을 표시합니다. (<code>show n</code>) 아니라면, 계산이 안되므로 비프음을 뿜고 다시 <code>calc xs</code> 를 호출해 새로운 입력을 기다립니다. <br />
(4) <code>clear</code> 는 수식 입력창에 있는 값을 <code>""</code> 를 돌려줌으로써 비웁니다. <br />
(5) <code>press</code> 는 현재 수식 입력창에 있는 데이터 <code>xs</code> 에 <code>c</code> 를 이어 붙입니다.  </p>

<p>잘 보시면 현재 가지고 있는 데이터는 <code>xs</code> 로 표시되고, 이외의 <code>IO ()</code> 를 조합해 가며 화면의 상태(<em>State</em>) 를 변화시킵니다. 이 과정에서 <strong>화면을 변화시키는 부분과, 데이터 <code>xs</code> 가 변하는 부분이 서로 분리</strong> 되어 있습니다.</p>

<p>마지막으로 계산기를 실행시키는 함수 <code>run</code> 을 만들겠습니다.</p>

<pre><code class="haskell">run :: IO ()  
run = do cls  
         showbox
         clear
</code></pre>

<h3 id="gameoflife">Game of Life</h3>

<p><del>인생게임은 아닙니다</del> 세포의 생존게임이라 생각하면 이해하기 쉽습니다. <code>n * m</code> 보드에서 각 칸마다 세포가 위치할 수 있습니다.</p>

<blockquote>
  <ol>
  <li><p>a living cell survives if it has precisely two or three neighbouring squares that contain living cells, and dies (becomes empty) otherwise.</p></li>
  <li><p>an empty square gives birth to a living cell if it has precisely neighbours that contain living cells, and remains empty otherwise.</p></li>
  </ol>
</blockquote>

<p>각 칸마다 균등한 기회를 주기 위해 모서리에 있는 칸 또한 8개의 이웃한 칸을 가졌다고 합시다. <em>torus (3차원의 도넛모양 )</em> 을 생각하심 됩니다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Simple_Torus.svg/310px-Simple_Torus.svg.png'  alt="" /></p>

<p align="center">(<a href='http://commons.wikimedia.org/wiki/File:Simple_Torus.svg' >http://commons.wikimedia.org/wiki/File:Simple_Torus.svg</a>)</p>

<p>초기값에 따라 턴을 반복하면서 다양한 종류의 결과물이 나옵니다. 그 중에서 초기값이 몇번의 턴을 지나면서 지속적으로 대각선으로 움직이는 패턴을 <em>glider</em> 라 부릅니다.</p>

<p><img src='https://camo.githubusercontent.com/f865db6a304d36aa7fef6c060729a2d635cd5c14/687474703a2f2f7777772d726f68616e2e736473752e6564752f7e72636172726574652f7465616368696e672f4d2d3539365f706174742f696d616765732f676c696465722e676966'  alt="" /></p>

<p align="center">(<a href='https://gist.github.com/boggle/10390842' >https://gist.github.com/boggle/10390842</a>)</p>

<p>이제 <em>row</em> 를 <code>x</code>, <em>column</em> 을 <code>y</code> 로 해서 1 부터 시작하는 <code>5 x 5</code> 의 <em>glider</em> 보드를 만들면</p>

<pre><code class="haskell">width :: Int  
width = 5

height :: Int  
height = 5

type Board = [Pos]

glider :: Board  
glider = [(4,2),(2,3),(4,3),(3,4),(4,4)]

showCells :: Board -&gt; IO ()  
showCells b = seqn [writeAt p "O" | p &lt;- b]

isAlive :: Board -&gt; Pos -&gt; Bool  
isAlive b p = elem p b

isEmpty :: Board -&gt; Pos -&gt; Bool  
isEmpty = not (isAlive b p)  
</code></pre>

<p>여기에 해당 칸의 세포가 살았는지 죽었는지 검사하는 <code>isAlive</code>, <code>isEmpty</code> 와 보드를 출력하는 <code>showCells</code> 함수도 만들었습니다.</p>

<p>이제 어떤 <code>(x, y)</code> 를 입력 받아 그 주변 8개의 이웃 세포 좌표를 돌려주는 함수를 만들면</p>

<pre><code class="haskell">neighbs :: Pos -&gt; [Pos]  
neighbs (x,y) =  map wrap [(x-1,y-1), (x,y-1),  
                           (x+1,y-1), (x-1,y),
                           (x+1,y)  , (x-1,y+1),
                           (x,y+1)  , (x+1,y+1)] 

wrap :: Pos -&gt; Pos  
wrap (x,y) =  (((x-1) `mod` width) + 1, ((y-1) `mod` height + 1))  
</code></pre>

<p><code>wrap</code> 은 <code>mod</code> 연산을 이용해서, 판의 범위를 벗어난 이웃 세포의 좌표를 판 내에 있는 이웃으로 만들어 돌려줍니다. 예를 들어 </p>

<pre><code class="haskell">&gt; wrap (0, 1)
-- (5,1)
</code></pre>

<p>이제 살아있는 이웃 세포의 개수를 돌려주는 <code>liveNeighbs</code> 와, 살아있는 세포들(인접한 살아있는 세포가 2, 3개인) 좌표를 돌려주는 <code>survivors</code> 함수를 만듭시다.</p>

<pre><code class="haskell">liveNeighbs :: Board -&gt; Pos -&gt; Int  
liveNeighbs b = length . filter (isAlive b) . neighbs

survivors :: Board -&gt; [Pos]  
survivors b = [p | p &lt;- b, elem (liveNeighbs b p) [2, 3]]  
</code></pre>

<p>그리고 죽은 세포에 대해 인접한 살아있는 세포가 3개일 때만 살아있는 세포로 변경하는 <code>births</code> 함수를 만들면</p>

<pre><code class="haskell">births :: Board  
births :: Board -&gt; [Pos]  
births b = [p | p &lt;- rmdups (concat (map neighbs b)),  
            isEmpty b p,
            liveNeighbs b p == 3]

rmdups :: Eq a =&gt; [a] -&gt; [a]  
rmdups [] = []  
rmdups (x:xs) = x : filter (/= x) xs  
</code></pre>

<p>중복을 제거하기 위해 <code>rmdups</code> 함수를 만들어서 사용했습니다.</p>

<p>이렇게 되면, 다음 턴에서의 <em>board</em> 는 <code>survivors</code> 와 <code>births</code> 의 원소들 이므로</p>

<pre><code class="haskell">nextGen :: Board -&gt; Board  
nextGen b = survivors b ++ births b  
</code></pre>

<p>이제 화면 출력을 위한 몇 가지 함수를 더 만들면</p>

<pre><code class="haskell">life :: Board -&gt; IO ()  
life b = do cls  
            showCells b
            wait 5000
            life (nextGen b)

wait :: Int -&gt; IO ()  
wait n = seqn [return () | _ &lt;- [1..n]]  
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em> <br />
(3) <a href='https://gist.github.com/boggle/10390842' >gist.github.com/boggle</a></p>]]></description><link>http://1ambda.github.io/haskell-intro5/</link><guid isPermaLink="false">2ec0d609-25c4-4cac-bfd7-196899ad001f</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[monad]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 21 Nov 2014 02:20:50 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 4]]></title><description><![CDATA[<p>이번시간엔 모나드를 배웁니다. <del>네. 올것이 왔습니다.</del> 간단한 파서를 구현하는 것 부터 시작해 보겠습니다.</p>

<h3 id="whatisaparser">What is a Parser</h3>

<p><strong>Parser (파서)</strong> 란 텍스트 조각을 분석하여 <em>syntaxtic structure</em> 를 만들어 내는 프로그램(코드)를 말합니다.</p>

<p>많은 프로그램들이 자신만의 파서를 가지고 있습니다. <em>GHC</em> 는 <em>haskell</em> , <em>UNIX</em> 는 <em>shell script</em>, <em>explorer</em> 는 <em>HTML</em> 분석합니다.</p>

<h3 id="theparsertype">The Parser Type</h3>

<pre><code class="haskell">type Parser = String -&gt; Tree  
</code></pre>

<p>하스켈 같은 함수형 언어에서 파서는 함수라 볼 수 있습니다. 문자열을 받아서 <em>Tree (트리)</em> 를 만들어 주는 함수처럼요.</p>

<p>때때로 입력된 문자열이 이상하다면 파서가 제대로 동작하지 않을수도 있습니다. 그럴때 분석되지 않은 문자열을 돌려주려면 이런 형태여야 합니다.</p>

<pre><code class="haskell">type Parser = String -&gt; (Tree, String)  
</code></pre>

<p>어떤 문자열들은 여러가지로 해석될 수도 있겠지요. 그럼 리스트를 돌려줘야겠네요.</p>

<pre><code class="haskell">type Parser = String -&gt; [(Tree, String)]  
</code></pre>

<p>꼭 파서가 트리를 만들 필요는 없지 않을까요? 문자열이 <code>1 + 2</code> 라면 이 값을 더한 <code>3</code> 을 돌려줄 수도 있을겁니다.</p>

<pre><code class="haskell">type Parser a = String -&gt; [(a, String)]  
</code></pre>

<p>이번 강의에서는 복잡한 파서를 구현하기 보다 파서가 무슨일을 하는지에 집중할 것이므로 파서의 타입을 심플하게 가져가겠습니다. 파서가 문자열을 분석하는데 실패하면 <code>[]</code>  성공하면 <em>singleton list</em> 를 돌려주겠습니다.</p>

<h3 id="basicparsers">Basic Parsers</h3>

<p>먼저 문자열에서 첫 번째 원소를 소비하고, 나머지를 돌려주는 간단한 <code>item</code> 파서를 만들어 봅시다. 이 파서는 빈 문자열에 대해서는 <code>[]</code> 를 돌려줍니다.</p>

<pre><code class="haskell">module Lecture7 where

type Parser a = String -&gt; [(a, String)]

item :: Parser Char  
item = \xs -&gt; case xs of  
               [] -&gt; []
               (x:xs) -&gt; [(x, xs)]
</code></pre>

<p>실행하면 이런 결과를 얻습니다.</p>

<pre><code class="haskell">&gt; item "hello world"
-- [('h',"ello world")]

&gt; item ""
-- []
</code></pre>

<p>항상 <code>[]</code> 만 돌려주는 <code>failure</code> 파서와 <code>a -&gt; Parser a</code> 타입의 <code>return</code> 도 만들어 봅시다. 하나는 항상 실패하고, 다른 하나는 항상 성공하는 파서입니다.</p>

<pre><code class="haskell">failure :: Parser a  
failure = \xs -&gt; []

return :: a -&gt; Parser a  
return v = \xs -&gt; [(v, xs)]

&gt; failure "hello world!"
-- []

&gt; (return "hello") " world"
-- [("hello"," world")]

&gt; (return "hello") ""
-- [("hello","")]
</code></pre>

<p>이제 두 개의 파서를 붙이는 함수 <code>(+++)</code> 를 만들어 봅시다. <code>p +++ q</code> 에 대해 파서 <code>p</code> 가 성공하면 <code>p</code> 의 리턴값을, <code>p</code> 가 실패하면 <code>q</code> 가 처리하게 합시다. 위에서 항상 성공하는 파서 <code>return v</code> 와 항상 실패하는 파서 <code>failure</code> 를 여기다 붙이며 어떻게 될지도 한번 생각해 보는것도 좋습니다.</p>

<pre><code class="haskell">(+++) :: Parser a -&gt; Parser a -&gt; Parser a
p +++ q = \xs -&gt; case p xs of  
                  [] -&gt; parse q xs
                  [(y, ys)] -&gt; [(y, ys)]

parse :: Parser a -&gt; String -&gt; [(a, String)]  
parse p xs = p xs  
</code></pre>

<p>여기서 <code>parse</code> 는 그냥 <em>readable</em> 한 코드를 만들기 위해 사용했다고 보면 됩니다. 파서와 텍스트를 받아서 그 적용한 결과를 돌려줍니다.</p>

<pre><code class="haskell">&gt; parse (return '1') "234"
-- [('1',"234")]

&gt; parse failure "abcd"
-- []

&gt; parse (failure +++ (return '1')) "abcd"
-- [('1',"abcd")]

&gt; parse (item +++ return 'd') "abc"
-- [('a', "bc")]
</code></pre>

<h3 id="monad">Monad</h3>

<p>여기서 잠깐 생각해 볼 거리가 있습니다. "<em>parser</em> 가 대체 무슨일을 하고 있는가?"</p>

<p>파서의 타입을 잘 보면 원본 타입 <code>String</code> 을 받아, 여기서 부가적인 작업을 해서 <code>a</code> 타입을 만들고, 다시 본래 타입인 <code>String</code> 더해 튜플로 만들어 돌려줍니다. 다시 말해 파서는 <em>한 타입을 받아 부가적인 정보를 만들어 본래 타입에 붙여주는 함수</em> 라 볼 수 있습니다.</p>

<p>파서의 연결을 도와주는 함수는 <code>(+++)</code> 무엇일까요? <em>부가적인 정보를 붙여주는 파서 를 <strong>합성</em></strong> 해 주는 역할을 합니다.</p>

<p>지금 <code>(+++)</code> 의 규칙은 <code>p</code> 가 실패하면 <code>q</code> 를 적용하지만, 파서 <code>t, u, v</code> 를 받아 모두 적용한 뒤 결과를 돌려주는 연산자도 만들 수 있습니다.</p>

<p><code>(+++)</code> 자체는 하나의 규칙을 의미하지만 자세히 보면 이외에도 다양한 규칙을 가진 합성 함수를 만들 수 있다는 것을 알 수 있습니다. </p>

<p>부가적인 정보를 만들어 내는 함수와(파서), 이 파서간의 합성이 아주 중요한 키 포인트입니다. 그리고 이 파서가 바로 <em>monad</em> 입니다. <del>두둥</del></p>

<blockquote>
  <p>The parser type is a <strong>monad</strong>, a mathematical structure that has proved useful for modeling many different kinds of computations</p>
</blockquote>

<h3 id="sequencing">Sequencing</h3>

<p>위에서는 두개의 파서를 엮어 하나로 만들긴 했지만 둘 중에 하나만 사용했죠. 둘 다 사용하진 않았습니다. 그럼 둘 이상의 파서를 엮어 하나의 파서를 만들려면 어떻게 해야할까요? 일단 생각해 볼 수 있는건 타입이 좀 다릅니다. </p>

<p>서로 다른 두개의 파서 <code>Parser a</code> 와 <code>Parser b</code> 를 고려해 봅시다. </p>

<pre><code class="haskell">type Parser a = String -&gt; [(a, String)]

Parser a  
-- String -&gt; [(a, String)]

Parser b  
-- String -&gt; [(b, String)]
</code></pre>

<p><code>Parser a</code> 의 출력은 <code>[(a, String)]</code>, 이기 때문에 다른 파서 <code>Parser b</code> 의 입력 <code>String</code> 이 될 수 없습니다. </p>

<p>그리고 여기서 한 가지 더 중요한 사실은, <code>Parser a</code> 가 <code>String</code> 을 이용해 만든 타입 <code>a</code> 의 부가정보를 <code>Parser b</code> 에 손실 없이 넘겨줘야 한다는 사실입니다. 그래야만 파서를 조합한 의미가 있지요.</p>

<p>정리하자면 <code>Parser a</code> 를 받아 <code>Parser b</code> 를 돌려주는 <em>파서 조합함수</em> 를 만들 것인데,  부가정보 <code>a</code> 의 보존을 위해 이 함수 내부에서 <code>a -&gt; Parser b</code> 타입의 중간 함수가 필요합니다. <strong>이 중간 함수가 어디에서 어떤 일을 할지가 구현해야 할 부분이자, 가장 중요한 부분</strong>입니다. 파서 종류에 따라 원본 데이터 (여기서는 <code>String</code>) 을 조작하는 방법이 다르기 때문입니다. 거꾸로 말하면 <em>다양한 종류의 파서가 있다는 말</em> 입니다.</p>

<p>함수의 이름은 <code>&gt;&gt;=</code> 라 짓겠습니다. <em>bind</em> 라 읽습니다. 타입은</p>

<pre><code class="haskell">type Parser a = String -&gt; [(a, String)]

parse :: Parser a -&gt; String -&gt; [(a, String)]  
parse p xs = p xs

(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b
</code></pre>

<p>구현은 </p>

<pre><code class="haskell">p &gt;&gt;= q = \xs -&gt; case p xs of  
                  [] -&gt; []
                  (y, ys) -&gt; parse (q y) ys
</code></pre>

<p>즉 <code>&gt;&gt;=</code> 는 <code>Parser a</code> 의 처리 결과가 <code>[]</code> 이면 <code>[]</code> 을 돌려줍니다. 올바르게 처리되었을 경우에는 <code>Parser a</code> 의 결과로 얻어진 부가정보 <code>a</code> 타입에 대해 <code>a -&gt; Parser b</code> 타입의 함수인 <code>y</code> 에게 넘겨 <code>Parser b</code> 를 받고 결과적으로는 <code>\xs -&gt; parse k ys</code> 를 돌려줍니다. (<code>k :: parser b</code>) 그런데, 여기서 <code>parse k ys</code> 의 결과가 <code>[(b, String)]</code> 이기 때문에 <code>\xs -&gt; parse k ys</code> 는 <code>Parser b</code> 라 볼 수 있습니다. </p>

<p>최종적으로는 <code>Parser a</code> 를 이용해 <code>Parser b</code> 를 만들어 냈습니다.</p>

<p>예제를 한번 보시죠. <code>Parser Char</code> 을 이용해 <code>Parser (Char, Char)</code> 을 만들어 볼 수 있습니다.</p>

<pre><code class="haskell">return :: a -&gt; Parser a  
return v = \xs -&gt; [(v, xs)]

(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b
p &gt;&gt;= q = \xs -&gt; case p xs of  
                   [] -&gt; []
                   (y, ys) -&gt; parse (q, y) ys

-- consume only one Char
parseTwice :: Parser (Char, Char)  
parseTwice = item &gt;&gt;= \x -&gt; return (x, x)  
</code></pre>

<pre><code class="haskell">parseTwice "5BEAF"  
-- [((5, 5), "BEAF")] 
</code></pre>

<p><code>item</code> 과 <code>return (x, x)</code> 두개의 파서를 조합해서 <code>parseTwice</code> 라는 새로운 파서를 만들었습니다. 조금 더 붙여볼까요?</p>

<pre><code class="haskell">ignore2 :: Parser (Char, Char)  
ignore2 = item &gt;&gt;= \x -&gt; item &gt;&gt;= \y -&gt; item &gt;&gt;= \z -&gt; return (x, z)

&gt; ignore2 "2A371"
-- [(('2','3'),"71")]
</code></pre>

<h3 id="do">Do</h3>

<p>위에서 보았듯이 같은 원본 타입 <code>String</code> 을 가지는 같은 종류의 파서(모나드)는 계속 연결할 수 있습니다. <code>p1, ..., pn</code> 을 파서라 하고 <code>v1, ..., vn</code> 을 파서가 만드는 부가정보라 할 때 다음과 같이 일반화 할 수 있습니다.</p>

<pre><code class="haskell">p1 &gt;&gt;= \v1 -&gt;  
p2 &gt;&gt;= \v2 -&gt;  
p3 &gt;&gt;= \v3 -&gt;  
...
pn &gt;&gt;= \vn -&gt;  
return (f v1 v2 ... vn)  
</code></pre>

<p>하스켈에선 조금 더 편한 문법을 지원하는데요 바로 <code>do</code> 구문입니다.</p>

<pre><code class="haskell">do v1 &lt;- p1  
   v2 &lt;- p2
   ...
   vn &lt;- pn
   return (f v1 v2 ... vn)
</code></pre>

<h3 id="monadicaxioms">Monadic Axioms</h3>

<p>이 때 <code>do</code> 구문을 활용하는 파서(모나드) <code>pn</code> 에 대해서는 미리 <code>&gt;&gt;=</code> 과 <code>return</code> 이 구현되어 있어야 합니다. 우리도 위에서 두 가지 함수를 사용했습니다. </p>

<p>하스켈에서는 모나드 클래스가 따로 있습니다. 그리고 모든 모나드 클래스의 인스턴스는 최소한 <code>&gt;&gt;=</code> 와 <code>return</code> 을 구현해야 합니다. 우리가 위에서 구현했던 파서를 잠깐 보면</p>

<pre><code class="haskell">type Parser a = String -&gt; [(a, String)]

return :: a -&gt; Parser a  
return v = \xs -&gt; [(v, xs)]

(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b
p &gt;&gt;= q = \xs -&gt; case parse p xs of  
                  [] -&gt; []
                  [(y, ys)] -&gt; parse (q y) ys
</code></pre>

<p><code>return</code> 은 <code>a</code> 를 받아 파서를 돌려줍니다. <code>&gt;&gt;=</code> 는 파서(모나드)를 결합하지요.</p>

<p>아까 다양한 파서(모나드)가 있을 수 있다고 말했던 것 기억 나시죠? 많은 종류의 모나드에 대해  최소한 <code>return</code> 과 <code>&gt;&gt;=</code> 를 구현해야 하는데, 이때 지켜져야 할 <em>axioms (공리)</em> 가 있습니다.</p>

<p>(1) <code>m &gt;&gt;= return</code> == <code>m</code> (<em>right unit</em>) <br />
(2) <code>return x &gt;&gt;= f</code> == <code>f x</code> (<em>left unit</em>) <br />
(3) <code>(m &gt;&gt;= f) &gt;&gt;= g</code> == <code>m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g)</code> (<em>associativity</em>)  </p>

<h3 id="sowhymonad">So, Why Monad?</h3>

<p>근데, 이런 복잡한 모나드가 왜 중요한걸까요? 바로 <em>부가정보</em> 를 만들면서 본래의 타입을 유지하기 때문입니다. </p>

<p>본래 순수 함수형 프로그래밍에선 콘솔 출력 같은 <em>side-effect</em> 를 만들 수 없습니다. 그러나 모나드를 이용하면 <strong>부가정보 (= <em>side-effect</em>)</strong> 와 <strong>연산 부분 (<em>purely functional</em>)</strong> 를 분리할 수 있습니다.</p>

<p>실제 하스켈에서도 <em>IO Monad</em> 를 통해 입출력을 할 수 있죠.</p>

<h3 id="monadagain">Monad, Again</h3>

<p>그러면 실제로 하스켈에서 제공하는 모나드를 클래스를 사용해 봅시다. 코드를 조금 변경해야합니다.</p>

<pre><code class="haskell">module Lecture7 where

import Control.Monad

-- ref: http://www.cs.nott.ac.uk/~gmh/Parsing.lhs
newtype Parser a = P (String -&gt; [(a, String)])

instance Monad Parser where  
  return v = P $ \inp -&gt; [(v, inp)]
  p &gt;&gt;= f = P $ \inp -&gt; case parse p inp of
                         [] -&gt; []
                         [(v, out)] -&gt; parse (f v) out

item :: Parser Char  
item = P $ \inp -&gt; case inp of  
                    [] -&gt; []
                    (x:xs) -&gt; [(x, xs)]

parse                         :: Parser a -&gt; String -&gt; [(a,String)]  
parse (P p) inp               =  p inp

ignore2 :: Parser (Char, Char)  
ignore2 = do x &lt;- item  
             item
             z &lt;- item
             return (x, z)
</code></pre>

<p>실제 돌려보면,</p>

<pre><code class="haskell">&gt; parse ignore2 "7A3BCEF"
-- [(('7','3'),"BCEF")]
</code></pre>

<h3 id="monadplus">MonadPlus</h3>

<p>아까 작성했었던 파서 <code>failure</code>, <code>(+++)</code> 기억 나시나요? <code>failure</code> 는 항상 실패하는 파서를, <code>(+++)</code> 는 첫번째 파서와 두번째 파서를 붙여 둘 중 성공하는 하나의 파서만 선택하는 합성 파서입니다.</p>

<p>하스켈에선 이런 두 가지 특징을 구현한 모나드를 <code>MonadPlus</code> 라 부릅니다. 다시 말해 <code>MonadPlus</code> 에는 기본적인 <code>return</code> 이나 <code>&gt;&gt;=</code> 이외에도 위 두 가지가 더 구현되어 있다는 말이죠. </p>

<p><code>MonadPlus</code> 에서는 <code>failure</code> 대신 <code>mzero</code> 를 <code>(+++)</code> 대신 <code>mplus</code> 란 이름을 사용합니다.</p>

<pre><code class="haskell">instance MonadPlus Parser where  
  mzero = P $ \_ -&gt; []
  p `mplus` q = P $ \inp -&gt; case parse p inp of
                             [] -&gt; parse q inp
                             [(v, out)] -&gt; [(v, out)]

failure :: Parser Char  
failure = mzero

(+++) :: Parser a -&gt; Parser a -&gt; Parser a
p +++ q = p `mplus` q  
</code></pre>

<pre><code class="haskell">&gt; parse (item +++ return 'd') "abc"
-- [('a',"bc")]

&gt; parse (item +++ return 'd') ""
-- [('d',"")]
</code></pre>

<h3 id="derivedprimitives">Derived Primitives</h3>

<p>이제 파서를 엮어서 다양한 파서를 만들어 봅시다.</p>

<pre><code class="haskell">import Data.Char

sat :: (Char -&gt; Bool) -&gt; Parser Char  
sat p = do x &lt;- item  
           if p x then return x else failure

digit :: Parser Char  
digit = sat isDigit

lower :: Parser Char  
lower = sat isLower

upper :: Parser Char  
upper = sat isUpper 

letter :: Parser Char  
letter = sat isAlpha

alphanum :: Parser Char  
alphanum = sat isAlphaNum

char :: Char -&gt; Parser Char  
char x = sat (== x)  
</code></pre>

<p>여기서 <code>char</code> 을 이용하면 지정된 문자열이 있는지 검사하는 파서 <code>string</code> 을 만들 수 있습니다.</p>

<pre><code class="haskell">string :: String -&gt; Parser String  
string [] = return []  
string (x:xs) = do char x  
                   string xs
                   return (x:xs)
</code></pre>

<p><code>string</code> 은 재귀를 이용해 작성했는데, 입력된 문자열이 모두 존재할 경우에만 <code>return</code> 하고 아니면 <code>[]</code> 를 돌려줍니다. (<code>do</code> 매크로는 중간에 <code>[]</code> 가 나오면 <code>[]</code> 를 바로 리턴합니다.)</p>

<pre><code class="haskell">&gt; parse (string "google") "naver google yahoo"
-- []

&gt; parse (string "google") "google yahoo"
-- [("google"," yahoo")]

&gt; parse (string "google") "goo yahoo"
-- []
</code></pre>

<p>그러면, <code>digit</code> 나 <code>letter</code> 같은 파서에 대해 동일한 파서를 여러번 사용하려면 어떻게 해야 할까요? <code>string</code> 처럼 재귀를 이용해 매번 파서를 만들어야 할까요?</p>

<p>그렇지 않습니다. <em>mutual recursion</em> 을 이용해서 파서를 받아 여러번 적용해 주는 <code>many</code> 란 파서를 만들어 봅시다.</p>

<pre><code class="haskell">many :: Parser a -&gt; Parser [a]  
many p = many1 +++ return []

many1 :: parser a -&gt; Parser [a]  
many1 p = do x &lt;- p  
             xs &lt;- many p
             return (x:xs)
</code></pre>

<p><code>many</code> 는 <code>p</code> 을 0번 이상, <code>many1</code> 은 적어도 1번 이상 <code>p</code> 를 적용합니다. </p>

<p><code>many</code> 를 활용하면 변수의 이름도 파싱할 수 있습니다. 변수의 이름은 첫 글자가 소문자로, 나머지는 알파벳 혹은 숫자로 구성되어 있다고 하면 이를 위한 파서 <code>ident</code> 는</p>

<pre><code class="haskell">ident :: Parser String  
ident = do x &lt;- lower  
           xs &lt;- many alphanum
           return (x:xs)

&gt; parse ident "left = 3"
-- [("left"," = 3")]
</code></pre>

<p>이제 뭔가 파서가 좀 쓸만해 보이죠? 자연수를 파싱하는 <code>nat</code> 와 스페이스를 파싱하는 <code>space</code> 를 만들어 보겠습니다.</p>

<pre><code class="haskell">nat :: Parser Int  
nat = do xs &lt;- many1 digit  
         return (read xs)

space :: Parser ()  
space = do many (sat isSpace)  
           return ()

&gt; parse nat "123 abc"
-- [(123," abc")]

&gt; parse space "   abc"
-- [((),"abc")]        
</code></pre>

<p>코드를 분석하는 파서를 만들때 스페이스를 주의해야 합니다. 예를 들어 <code>1+2</code> 와 <code>1 + 2</code> 는 같은 코드입니다. </p>

<p>파서를 받아 앞 뒤로 붙은 스페이스를 제거하는 기능을 덧붙인 파서를 돌려주는 <code>token</code> 이란 함수를 만들어 봅시다. 그리고 나면 <code>token</code> 을 활용해 <code>identifier</code>, <code>natural</code>, <code>symbol</code> 을 만들겁니다.</p>

<pre><code class="haskell">token :: Parser a -&gt; Parser a  
token p = do space  
             v &lt;- p
             space
             return v

identifier :: Parser String  
identifier = token ident

natural :: Parser Int  
natural = token nat

symbol :: String -&gt; Parser String  
symbol xs = token (string xs)  
</code></pre>

<p>이제 이걸 엮어서 숫자 리스트를 분석하는 파서를 만들어 봅시다.</p>

<pre><code class="haskell">nlist :: Parser [Int]  
nlist = do symbol "["  
           n &lt;- natural
           ns &lt;- many (do symbol ","
                          natural)
           symbol "]"
           return (n:ns)


&gt; parse nlist "[1, 2, 3]"
-- [([1,2,3],"")]

&gt; parse nlist "[1, 2]"
-- [([1,2],"")]

&gt; parse nlist "[1, 2"
-- []

&gt; parse nlist "[1 2"
-- []

&gt; parse nlist "[1,"
-- []
</code></pre>

<p><del>모나드의 세계란 참으로 놀랍죠?</del></p>

<h3 id="arithmeticexpressions">Arithmetic Expressions</h3>

<p>이제 단순한 텍스트가 아니라, 코드를 분석해 보죠. 우선 작은 수식을 분석하는 파서를 작성해 봅시다. 우리가 작성할 파서는 정수에 대한 <code>*</code> 과 <code>+</code> 만 처리할 수 있습니다. 간단히 문법을 만들어 보면</p>

<pre><code class="haskell">expr   ::= expr + expr | term  
term   ::= term * term | factor  
factor ::= (expr) | nat  
nat    ::= 0 | 1 | 2 | ...  
</code></pre>

<p>처음보면 난해할 수 있습니다. 이 그림과 비교해가며 보세요. 완벽히 일치하진 않지만 대략적인 설명을 해줍니다.</p>

<p><img src='http://www.csee.umbc.edu/courses/331/fall11/hw/hw2/parsetree.gif'  alt="" /></p>

<p align="center">(<a href='http://www.csee.umbc.edu/' >http://www.csee.umbc.edu</a>)</p>

<p>그런데, 실제로 <code>2 + 3 + 4</code> 에 적용해보면, <code>(2 + 3) + 4</code> 과 <code>2 + (3 + 4)</code> 두 가지 방법으로 해석될 수 있습니다. 따라서 모호함을 제거하기 위해</p>

<pre><code class="haskell">expr   ::= term + expr | term  
term   ::= factor * term | factor  
factor ::= (expr) | nat  
nat    ::= 0 | 1 | 2 | ...  
</code></pre>

<p>이제 <code>2 + 3 + 4</code> 는 확실히 <code>2 + (3 + 4)</code> 입니다. 괴상한 문법을 하스켈로 옮기기 위해 조금  더 다듬어 보도록 하지요.</p>

<p><code>term + expr | term</code> 은 사실 <code>term + (expr | e)</code> 과 동일합니다. (<code>e</code> 는 <strong>비었음</strong> 을 의미) <code>factor * term | factor</code> 도 <code>factor + (term | e)</code> 구요. 따라서</p>

<pre><code class="haskell">expr   ::= term + (expr | e)  
term   ::= factor + (term | e)  
factor ::= (expr) | nat  
nat    ::= 0 | 1 | 2 | ...  
</code></pre>

<p>이제 하스켈 코드로 옮길겁니다. 우리는 트리를 만드는 대신 바로바로 계산할 겁니다. </p>

<pre><code class="haskell">expr :: Parser Int  
expr = do t &lt;- term  
          do symbol "+"
             e &lt;- expr
             return (t + e)
           +++ return t

term :: Parser Int  
term = do f &lt;- factor  
          do symbol "*"
             t &lt;- term
             return (t * f)
           +++ return f

factor :: Parser Int  
factor = do symbol "("  
            e &lt;- expr
            symbol ")"
            return e
          +++ natural          
</code></pre>

<p><code>return t</code> 도 하나의 파서고, <code>+++</code> 로 둘 중 올바르게 작동하는 파서만 택함으로써 문법에서의 <code>|</code> 를 구현했습니다.</p>

<p>이제 파싱된 결과를 해석하는 <code>eval</code> 함수를 만들어 봅시다.</p>

<pre><code class="haskell">eval :: String -&gt; Int  
eval xs = case parse expr xs of  
           [(n, [])] -&gt; n
           [(_, out)] -&gt; error ("ununsed input: " ++ out)
           [] -&gt; error ("invalid input: " ++ xs)


&gt; eval "2 * 3 + 4"
-- 10

&gt; eval "2 * (3 + 4)"
-- 14

&gt; eval "2 * 3 +"
-- *** Exception: ununsed input: +

&gt; eval "2 * 3 - 4"
-- *** Exception: ununsed input: - 4

&gt; eval "-4"
-- *** Exception: invalid input: -4
</code></pre>

<h3 id="programmingwitheffects">Programming With Effects</h3>

<p><a href='http://www.cs.nott.ac.uk/' ~gmh/monads">Programming With Effects</a> 는 <em>Programming in Haskell</em> 의 저자인 <strong>Graham Hutton</strong> 이 작성한 글입니다. 모나드에 대해 이보다 쉽고, 간결하게 설명한 글은 찾기 힘들죠. </p>

<p><em>Programming with Effects</em> 를 참고하여 몇 가지 예제를 더 작성해 보면서 모나드에 더 익숙해져 봅시다.</p>

<pre><code class="haskell">data Expr = Val Int | Div Expr Expr  
</code></pre>

<p>위와 같은 <code>Expr</code> 이 있다고 합시다. 평가하기 위해서 <code>eval</code> 함수를 만들고 실행해 봅시다.</p>

<pre><code class="haskell">eval :: Expr -&gt; Int  
eval (Val n) = n  
eval (Div x y) = eval x `div` eval y

&gt; eval (Val 3)
-- 3

&gt; eval (Div (Val 3) (Val 4))
-- 0

&gt; eval (Div (Val 8) (Val 4))
-- 2

&gt; eval (Div (Val 8) (Val 0))
-- *** Exception: divide by zero
</code></pre>

<p><code>0</code> 으로 나누니 에러가 발생합니다. <code>expr</code> 이 <code>Val 0</code> 인지 아닌지를 판별할 필요가 있습니다. </p>

<p>조금 더 고쳐보면</p>

<pre><code class="haskell">import Prelude hiding (Maybe, Just, Nothing)

data Expr = Val Int | Div Expr Expr  
data Maybe a = Nothing | Just a

safediv :: Int -&gt; Int -&gt; Maybe Int  
safediv n m = if m == 0 then Nothing else Just (n `div` m)

eval :: Expr -&gt; Maybe Int  
eval (Val n) = Just n  
eval (Div x y) = case eval x of  
                  Nothing -&gt; Nothing
                  Just n -&gt; case eval y of
                             Nothing -&gt; Nothing
                             Just m -&gt; safediv n m
</code></pre>

<p>너무 복잡합니다. <code>eval</code> 에서 <code>safediv</code> 에 인자를 넘기는 부분을 추상화하면</p>

<pre><code class="haskell">seqn :: Maybe a -&gt; Maybe b -&gt; Maybe (a, b)  
seqn _ Nothing = Nothing  
seqn Nothing _ = Nothing  
seqn (Just x) (Just y) = Just (x, y)

apply :: (a -&gt; Maybe b) -&gt; Maybe a -&gt; Maybe b  
apply f Nothing = Nothing  
apply f (Just x) = f x

eval :: Expr -&gt; Maybe Int  
eval (Val n) = Just n  
eval (Div x y) = apply f (eval x `seqn` eval y)  
                 where f (n, m) = safediv n m
</code></pre>

<p>조금 더 간편해졌습니다. 그런데 만약 인자가 3개인 연산자에 대해 평가 방법을 정의한다면</p>

<pre><code class="haskell">eval (Op x y z) =  
  apply f (eval x `seqn` (eval y `seqn` eval z))
  where f (a, (b, c)) =                 
</code></pre>

<p>괄호가 점점 중첩됩니다. 모든 것을 나중에 <code>seqn</code> 로 모든 결과를 모아 <code>f</code> 에서 처리하기 보다는 <code>Maybe a</code> 를 받아 <code>a -&gt; Maybe b</code> 를 바로 적용해 <code>Maybe b</code> 를 돌려주고, 이런식으로 순차적으로 처리하는 방식으로 바꿔봅시다.</p>

<pre><code class="haskell">(&gt;&gt;=) :: Maybe a -&gt; (a -&gt; Maybe b) -&gt; Maybe b
m &gt;&gt;= f = case m of  
           Nothing -&gt; Nothing
           Just x -&gt; f x

eval :: Expr -&gt; Maybe Int  
eval (Val x) = Just x  
eval (Div x y) = eval x &gt;&gt;= \n -&gt;  
                 eval y &gt;&gt;= \m -&gt; 
                 safediv n m 
</code></pre>

<p>어디서 많이 보다싶은 식이죠? 바로 하스켈의 <code>do</code> 와 비슷합니다.</p>

<p>하스켈에서 <code>Eq</code> 의 클래스의 정의는 이렇게 되어있습니다.</p>

<pre><code class="haskell">class Eq a where  
  (==) :: a -&gt; a -&gt; Bool
  (/=) :: a -&gt; a -&gt; Bool

  x /= y = not (x == y)
</code></pre>

<p>이 말은 <code>Eq</code> 클래스의 인스턴스가 되는 <code>a</code> 타입은 무조건 <code>==</code> 를 구현해야 한다는 뜻입니다. (<code>/=</code> 는 이미 구현되어 있는거 보이시죠?)</p>

<p>마찬가지로 타입 <code>m</code> 으로 <em>parameterized</em> 된 <code>Monad</code> 클래스의 인스턴스 또한 다음의 두 함수를 구현해야 합니다.</p>

<pre><code class="haskell">class Monad m where  
  return :: a -&gt; m a
  (&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b
</code></pre>

<p>예를 들어 <code>Maybe</code> 같은 경우</p>

<pre><code class="haskell">instance Monad Maybe where  
  return x = Just x

  Nothing &gt;&gt;= _ = Nothing
  (Just x) &gt;&gt;= f = f x
</code></pre>

<h3 id="listmonad">List Monad</h3>

<p><code>Maybe</code> 모나드를 잘 보면 <code>Nothing</code> 은 실패를, <code>Just x</code> 는 성공을 나타내는 연산으로 볼 수 있습니다. </p>

<p>리스트 모나드는 이런 개념을 좀 더 일반화한 것입니다. 복수번의 성공이 있을 수 있죠.</p>

<pre><code class="haskell">instance Monad [] where  
  return x = [x]
  xs &gt;&gt;= f = concat (map f xs)
</code></pre>

<p>이를 이용하면 <code>pairs</code> 와 같은 함수를 만들수 있습니다.</p>

<pre><code class="haskell">pairs :: [a] -&gt; [b] -&gt; [(a, b])  
pairs xs ys = do x &lt;- xs  
                 y &lt;- ys
                 return (x, y)

&gt; pairs [1, 2, 3] [4, 5, 6]
-- [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)]                 
</code></pre>

<p><em>list comprehension</em> 구문과 비슷합니다. 실제로 <code>do</code> 와 <em>list comprehension</em> 모두 리스트의 <code>&gt;&gt;=</code> 를 이용합니다.</p>

<h3 id="statemonad">State Monad</h3>

<p>한 상태(State) 에서 다른 상태로 변환시켜주는 <em>state transformer</em> 의 타입은 이렇게 정의할 수 있을 겁니다.</p>

<pre><code class="haskell">type ST = State -&gt; State  
</code></pre>

<p>그리고 상태가 변하면서 어떤 정보를 남겼을때의 타입을 이렇게 만들어 볼 수 있겠죠.</p>

<pre><code class="haskell">type ST a = State -&gt; (a, State)  
</code></pre>

<p>어디서 많이 본것 같죠? 맞습니다. 위에서 본 <code>Parser</code> 입니다. <code>String -&gt; (a, String)</code> 이였으니까, <code>State</code> 가 <code>String</code> 이었던 거죠.</p>

<pre><code class="haskell">instance Monad ST where  
  return x = \s -&gt; (x, s)

  st &gt;&gt;= f = \s -&gt; let (x, s') = st s
                   in f x s'
</code></pre>

<p>누차 언급했듯이 <code>&gt;&gt;=</code> 는 모나드(연산)간 연결입니다. <code>st</code> 에 <code>s</code> 를 넣은 결과를 <code>(x, s')</code> 라 하면 다시 <code>f x</code> 에 <code>s</code> 를 넣어 연결할 수 있다는 뜻이지요.</p>

<p>위에서는 <code>type</code> 을 사용했지만 실제로 이 키워드를 사용하면 클래스의 인스턴스가 될 수 없습니다. <code>ST</code> 를 <em>monadic type</em> 클래스의 인스턴스로 만들려면 <code>data</code> 나 <code>newtype</code> 을 이용할 수 있습니다. <code>data</code> 의 경우엔 <em>dummy constructor</em> 가 필요합니다. 여기선 <code>S</code> 가 되겠습니다. <em>dummy constructor</em> 의 런타임 오버헤드를 피하려면 <em>newtype</em> 을 이용하면 됩니다.</p>

<p>그리고 이 예제에서는 <em>dummy constructor</em> 를 제거하기 위해 <code>apply</code> 함수를 만들어서 이용하겠습니다. </p>

<p><code>State</code> 는 정수로 표시할겁니다. </p>

<pre><code class="haskell">type State = Int  
data ST a = S (State -&gt; (a, State))

apply :: ST a -&gt; State -&gt; (a, State)  
apply (S f) x = f x

instance Monad ST where  
  return x = S (\s -&gt; (x, s))
  st &gt;&gt;= f = S (\s -&gt; let (x, s') = apply st s in apply (f x) s')
</code></pre>

<p>이제 예제에서 활용할 간단한 이진트리를 정의해 봅시다. 이진트리의 <em>leaf</em> 는 <code>a</code> 타입의 값을 가지고 있습니다.</p>

<pre><code class="haskell">data Tree = Leaf a | Node (Tree a) (Tree b)

-- example
tree :: Tree Char  
tree = Node (Node (Leaf 'a') (Leaf 'b')) (Leaf 'c')  
</code></pre>

<p>이제 <em>State</em> 를 받아 <code>+1</code> 을 더한 다음 <em>State</em> 를 돌려주는 <code>fresh</code> 를 만들어 봅시다.</p>

<pre><code class="haskell">-- data ST a = S (State -&gt; (a, State))

fresh :: ST Int  
fresh = S (\n -&gt; (n, n + 1))  
</code></pre>

<p>즉 <code>fresh</code> 는 <em>State</em> 를 <code>1</code> 만큼 증가시키고 부가정보로 <em>current state</em> <code>n</code> 을 남깁니다. <code>fresh</code> 를 이용하면 위에서 만든 이진트리를 순회하면서 번호를 붙일 수 있습니다. 부가정보로 남는 <code>n</code> 을 <code>Leaf</code> 에다가 붙이는 것이죠. </p>

<p>다음 <code>fresh</code> 의 입력은 이전 <code>fresh</code> 의 아웃풋인 <code>n + 1</code> 이기 때문에 서로 다른 두 노드가 같은 숫자를 가질 일은 없습니다.</p>

<pre><code class="haskell">mlabel :: Tree a -&gt; ST (Tree (a, Int))  
mlabel (Leaf x) = do n &lt;- fresh  
                     return (Leaf (x, n))
mlabel (Node l r) = do l' &lt;- mlabel l  
                       r' &lt;- mlabel r
                       return (Node l' r')

label  :: Tree a -&gt; Tree (a,Int)  
label t = fst (apply (mlabel t) 0)

&gt; label tree
-- Node (Node (Leaf ('a',0)) (Leaf ('b',1))) (Leaf ('c',2))
</code></pre>

<h3 id="iomonad">IO Monad</h3>

<p>하스켈에서 입출력은 IO 모나드를 이용합니다. 무슨말인고 하니, 다음과 같은 <em>axioms</em> 를 구현한 <strong>IO 모나드</strong> 에 대해</p>

<pre><code class="haskell">return  :: a -&gt; IO a  
(&gt;&gt;=)   :: IO a -&gt; (a -&gt; IO b) -&gt; IO b
getChar :: IO Char  
putChar :: Char -&gt; IO ()  
</code></pre>

<p>다음처럼 <code>do</code> 구문을 이용해서 프로그램을 작성할 수 있다는 뜻입니다.</p>

<pre><code class="haskell">getLine :: IO String  
getLine = do x &lt;- getChar  
             if x == '\n' then
               return []
             else
               do xs &lt;- getLine
                  return (x:xs)
</code></pre>

<p>IO 모나드는 <em>State 모나드</em> 라 볼 수 있습니다. <code>IO a</code> 는 타입 <code>a</code> 의 부가정보를 만들면서 <em>State</em> 를 변화시키는 것으로요</p>

<pre><code class="haskell">type World = ...  
type IO a = World -&gt; (a, World)  
</code></pre>

<p>여기서 입/출력이 수행되는 것은 <em>action</em> 에 의해 <code>World</code> 가 변경되는 것이라 볼 수 있습니다.</p>

<h3 id="derivedprimitives">Derived Primitives</h3>

<p>다양한 종류의 모나드에 대해 적용할 수 있는 함수를 만들 수 있습니다. </p>

<p><code>liftM</code> 는 모나드에 대한 <code>map</code> 을 <code>join</code> 은 <code>concat</code> 을, <code>&gt;&gt;</code> 는 첫 번째 결과값을 다 버리고 두번째만 취하는 함수입니다. 마지막으로 <code>sequence</code> 는 모나드 익스프레션 리스트를  하나의 모나드 익스프레션으로 바꾸고, 그 결과를 리스트로 돌려줍니다. 타입을 보시면 이해가 빠를겁니다.</p>

<pre><code class="haskell">liftM :: Monad m =&gt; (a -&gt; b) -&gt; m a -&gt; m b  
liftM f mx = do x &lt;- mx  
             return (f x)

join :: Monad m =&gt; m (m a) -&gt; m a  
join mmx = do mx &lt;- mmx  
              x &lt;- mx
              return x

(&gt;&gt;) :: Monad m =&gt; m a -&gt; m b -&gt; m b
mx &gt;&gt; my = do _ &lt;- mx  
              y &lt;- my
              return y

sequence :: Monad m =&gt; [m a] -&gt; m [a]  
sequence (mx:mxs) = do x &lt;- mx  
                       xs &lt;- sequence mxs
                       return (x:xs)
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <a href='http://stackoverflow.com/questions/2607498/programming-in-haskell-error-in-sat-function' >error in sat function in "Programming in Haskell"</a> <br />
(3) <a href='http://wiki.reeseo.net/Haskell/%EA%B3%B5%EC%8B%9D%20%EC%9E%85%EB%AC%B8%EC%84%9C%20%EB%B2%88%EC%97%AD%EB%AC%B8/9.%20%EB%AA%A8%EB%82%98%EB%93%9C%20' (Monads)">http://wiki.reeseo.net/Haskell</a> <br />
(4) <a href='http://en.wikibooks.org/wiki/Haskell/Understanding_monads' >Understanding Monads</a> <br />
(5) <a href='http://www.csee.umbc.edu/courses/331/fall11/hw/hw2/' >http://www.csee.umbc.edu</a> <br />
(6) <a href='http://www.cs.nott.ac.uk/' ~gmh/monads">Programming With Effects</a> by <em>Graham Hutton</em>  </p>]]></description><link>http://1ambda.github.io/haskell-intro4/</link><guid isPermaLink="false">1b0aad8b-73c3-4f02-9556-e14d8933cae4</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[functional parser]]></category><category><![CDATA[monad]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 19 Nov 2014 04:39:46 GMT</pubDate></item></channel></rss>