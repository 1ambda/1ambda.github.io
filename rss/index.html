<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Old Lisper]]></title><description><![CDATA[Functional Programming]]></description><link>http://1ambda.github.io/</link><generator>Ghost 0.5</generator><lastBuildDate>Sat, 07 Mar 2015 19:45:51 GMT</lastBuildDate><atom:link href="http://1ambda.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Cloud Computing, Paxos]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<p>대부분의 분산 서버 벤더들은 <code>99.99999%</code> 의 <em>reliability</em> 를 보장하지만, <code>100%</code>는 아닙니다. 왜그럴까요? 그들이 못해서가 아니라 <em>consensus</em> 문제 때문입니다.</p>

<blockquote>
  <p>The fault lies in the impossibility of consensus</p>
</blockquote>

<p><em>Consensus</em> 문제가 중요한 이유는, 많은 분산 시스템이 <em>consensus</em> 문제이기 때문입니다. </p>

<ul>
<li>Perfect Failure Detection</li>
<li>Leader Election</li>
<li>Agreement (harder than consensus)</li>
</ul>

<p><br/></p>

<p>일반적으로 서버가 많으면 다음의 일들을 해야합니다.</p>

<ul>
<li><strong>Reliable Multicast:</strong> Make sure that all of them receive the same updates in the same order as each other</li>
<li><strong>Membership/Failure Detection:</strong> To keep their own local lists where they know about each other, and when anyone leaves or fails, everyone is updated simultaneously</li>
<li><strong>Leader Election:</strong> Elect a leader among them, and let everyone in the group know about it</li>
<li><strong>Mutual Exclusion:</strong> To ensure mutually exclusive access to a critical resource like a file</li>
</ul>

<p>이 문제들은 대부분 <em>consensus</em> 와 연관되어 있습니다. 더 직접적으로 연관되어 있는 문제들은</p>

<ul>
<li>The ordering of messages</li>
<li>The up/down status of a suspected failed process</li>
<li>Who the leader is</li>
<li>Who has access to the critical resource</li>
</ul>

<p><br/></p>

<h3 id="consensusproblem">Consensus Problem</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/consensus_problem.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/consensus_problem2.png'  alt="" /></p>

<p>모든 프로세스(노드, 서버)가 같은 <em>value</em> 를 만들도록 해야 하는데, 몇 가지 제약조건이 있습니다.</p>

<ul>
<li><strong>validity:</strong> if everyone propose same value, then that's what's decided</li>
<li><strong>integrity:</strong> decided value must have been proposed by some process</li>
<li><strong>non-triviality:</strong> there is at least one initial system state that leads to each of the all-<code>0</code>'s or all-<code>1</code>'s outcomes</li>
</ul>

<p><em>non-triviality</em> 는 쉽게 말해서, 모두 <code>0</code> 이거나 모두 <code>1</code> 일 수 있는 상태가 있어야 한다는 뜻입니다. 왜냐하면 항상 <code>0</code> 이거나 <code>1</code> 만 나오면 <em>trivial</em> 하기 때문입니다. 별 의미가 없죠.</p>

<p><br/></p>

<h3 id="models">Models</h3>

<p><em>consensus</em> 문제는 분산 시스템 모델에 따라 달라집니다. 모델은 크게 2가지로 나눌 수 있는데</p>

<p>(1) Synchronous Distributed System Model</p>

<ul>
<li>Each message is received within bounded time</li>
<li>Drift of each process' local clock has a known bound</li>
<li>Each step in a process takes <code>lb &lt; time &lt; ub</code></li>
</ul>

<p>동기 시스템 모델에서는 <em>consensus</em> 문제를 풀 수 있습니다.</p>

<p>(2) Asynchronous Distributed System Model</p>

<ul>
<li>Nobounds on process execution</li>
<li>The drift rate of a clock is arbitrary</li>
<li>No bounds on message transmission delay</li>
</ul>

<p>일반적으로 비동기 분산 시스템 모델이 더 일반적입니다, 그리고 더 어렵죠. 비동기를 위한 프로토콜은 동기 모델 위에서 작동할 수도 있으나, 그 역은 잘 성립하지 않습니다.</p>

<p>비동기 분산 시스템 모델에서는 <em>consensus</em> 문제는 풀 수 <strong>없습니다</strong></p>

<ul>
<li>Whatever protocol/algorithm you suggest, there is always a worst-case possible execution with failures and message delays that prevens the system from reaching consensus</li>
<li>Powerful result(see the <strong>FLP</strong> proof)</li>
<li>Subsequently, safe and <strong>probabilistic</strong> solution have become popular (e.g Paxos)</li>
</ul>

<p><br/></p>

<h3 id="paxosinsyncronoussystems">Paxos in Syncronous Systems</h3>

<p>동기 시스템이라 가정합니다. 따라서</p>

<ul>
<li>bounds on message dealy</li>
<li>bounds on upper bound on clock drift rates</li>
<li>bounds on max time for each process step</li>
<li>processes can fail by stopping</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/consensus_in_sync_system.png'  alt="" /></p>

<ul>
<li>아무리 많아야 <code>f</code> 개의 프로세서에서 <em>crash</em> 가 나고</li>
<li>모든 프로세서는 <em>round</em> 단위로 동기화 되고, 동작하며</li>
<li><em>reliable communication</em> 을 통해 서로 통신합니다</li>
</ul>

<p><em>value_i^r</em> 을 <em>round</em> <code>r</code> 의 시작에 <code>P_i</code> 에게 알려진 <em>value</em> 의 집합이라 라 하겠습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/paxos1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/paxos2.png'  alt="" /></p>

<p><code>f+1</code> 라운드 후에 모든 <em>correct</em> 프로세스는 같은 값의 집합을 가지게 되는데, 귀류법으로 쉽게 증명할 수 있습니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/consensus_in_async.png'  alt="" /></p>

<p>비동기 환경에서는, 아주아주아주아주아주 느린 프로세서와 <em>failed</em> 프로세서를 구분할 수 없기 때문에, 나머지 프로세서들이 이것을 결정하기 위해 영원히 기다려야 할지도 모릅니다. 이것이 기본적인 <em>FLP Proof</em> 의 아이디어입니다. 그렇다면, <em>consensus</em> 문제를 정말 풀기는 불가능한걸까요?</p>

<p>풀 수 있습니다. 널리 알려진 <em>consensus-solving</em> 알고리즘이 있습니다. 실제로는 불가능한 <em>consensus</em> 문제를 풀려는 것이 아니라, <em>safety</em> 와 <em>eventual liveness</em> 를 제공합니다. 야후의 <em>zookeeper</em> 나 구글의 <em>chubby</em> 등이 이 알고리즘을 이용합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/yes_we_can_with_paxos.png'  alt="" /></p>

<p><em>safety</em> 는 서로 다른 두개의 프로세서가 다른 값을 제출하지 않는것을 보장하고, (<em>No two non-faulty processes decide different values</em>) <em>eventual liveness</em> 는 운이 좋다면 언젠가는 합의에 도달한다는 것을 말합니다. 근데 실제로는 꽤 빨리 <em>consensus</em> 문제를 풀 수 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/paxos_simple.png'  alt="" /></p>

<p>본래는 최적화때문에 더 복잡한데, 위 슬라이드에서는 간략화된 <em>paxos</em> 가 나와있습니다. <em>paxos</em> 의 <em>round</em> 마다 고유한 <em>ballot id</em> 가 할당되고, 각 <em>round</em> 는 크게 3개의 비동기적인 <em>phase</em> 로 분류할 수 있습니다.</p>

<ul>
<li><strong>election:</strong> a leader is elected</li>
<li><strong>bill:</strong> leader proposes a value, processes ack</li>
<li><strong>law:</strong> leader multicasts final value</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/election.png'  alt="" /></p>

<p>먼저 <em>potential leader</em> 가 <em>unique ballot id</em> 를 고르고, 다른 프로세서들에게 보냅니다. 다른 프로세스들의 반응에 의해서 선출될 수도 있고, 선출되지 않으면 새로운 라운드를 시작합니다. </p>

<ul>
<li>Because becoming a leader requires a majority of votes, and any two majorities intersect in at least one process, and each process can only vote once.</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/bill.png'  alt="" /></p>

<p>리더가 다른 프로세스들에게 <code>v</code> 를 제안하고, 프로세스들은 지난 라운드에 <code>v'</code> 를 결정했었으면 <code>v=v'</code> 를 이용해 값을 결정합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/decision.png'  alt="" /></p>

<p>만약 리더가 <em>majority</em> 의 긍정적인 반응을 얻으면 모두에게 그 결정을 알리고 각 프로세서는 합의된 내용을 전달받고, 로그에 기록하게 됩니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/paxos_no_return.png'  alt="" /></p>

<p>사실 이 과정은 응답을 리더가 받는 단계에서 결정되는 것이 아니라, 프로세서들이 <em>proposed value</em> 를 듣는순간 결정됩니다. 따라서 리더에서 <em>failure</em> 가 일어나도, 이전에 결정되었던 <code>v'</code> 을 이용할 수 있습니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/paxos_safety.png'  alt="" /></p>

<p>이전에도 언급했듯이 <em>safety</em> 는 두개의 서로 다른 프로세서의 의해서 다른 값이 선택되지 않음을 보장합니다. 이는 잠재적 리더가 있다 하더라도 현재 리더와, 잠재적 리더에게 응답하는 <em>majority</em> (반수 이상) 을 교차하면 적어도 하나는 <code>v'</code> 를 응답하기 때문에 <em>bill phase</em> 에서 정의한대로 이전 결과인 <code>v'</code> 가 사용됩니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/paxsos_liveness.png'  alt="" /></p>

<p>그림에서 볼 수 있듯이 영원히 끝나지 않을수도 있지만, 실제로는 꽤 빠른시간 내에 합의에 도달합니다. (eventualy-live in async systems)</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-paxos/</link><guid isPermaLink="false">fa427789-33eb-4728-913a-ab4b1cfbf14e</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[paxos]]></category><category><![CDATA[consensus]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 07 Mar 2015 19:44:32 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, Multicast]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<p><em>multicast</em> 는 클라우드 시스템에서 많이 사용됩니다. <em>Cassandra</em> 같은 분산 스토리지에서는 <em>write/read</em> 메세지를 <em>replica gorup</em> 으로 보내기도 하고, <em>membership</em> 을 관리하기 위해서 사용하기도 합니다</p>

<p>그런데, 이 <em>multicast</em> 는 <em>ordering</em> 에 따라서 <em>correctness</em> 에 영향을 줄 수 있기 때문에 매우 중요합니다. 자주 쓰이는 기법으로 <em>FIFO</em>, <em>Casual</em>, <em>Total</em> 이 있는데 하나씩 살펴보겠습니다.</p>

<p><br/></p>

<h3 id="ordering">Ordering</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Ordering_FIFO.png'  alt="" /></p>

<p><em>FIFO</em> 를 이용한다면, 보낸 순서대로 도착하게 됩니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Ordering_casual.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Ordering_casual_example.png'  alt="" /></p>

<p><em>casual ordering</em> 에서는 반드시 <em>casuality-obeying order</em> 로 전달해야 합니다. 예를 들어 위 그림에서는 <code>M1:1 -&gt; M3:1</code> 이기 때문에 반드시 그 순서대로 받아야 합니다. <em>concurrent event</em> 는 어떤 순서로 받아도 상관 없습니다.</p>

<p><br/></p>

<p><em>casual ordering</em> 이면 <em>FIFO ordering</em> 입니다. 왜냐하면 같은 프로세스에서 보낸 <em>casuality</em> 를 따르면 그게 바로 <em>FIFO</em> 이기 때문입니다. 역은 성립하지 않습니다.</p>

<p>일반적으로는 <em>casual ordering</em> 을 사용합니다. 서로 다른 친구로부터 댓글이 달렸는데, 늦게 달린 친구의 댓글이 먼저 보인다면 당연히 말이 되지 않습니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Ordering_total.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Ordering_total_example.png'  alt="" /></p>

<p><em>total ordering</em> 은 <em>atomic broadcast</em> 라 부르는데, 모든 프로세스가 같은 순서로 메시지를 받는것을 보장합니다.</p>

<ul>
<li>Since <em>FIFO/Casual</em> are orthogonal to <em>Total</em>, can have hybrid ordering protocol too (e.g <em>FIFO-total</em>, <em>Casual-total</em></li>
</ul>

<p><br/></p>

<h3 id="fifoorderingimpl">FIFO Ordering Impl</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/FIFO_impl1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/FIFO_impl2.png'  alt="" /></p>

<ul>
<li>각 프로세스는 <em>seq number</em> 로 구성된 벡터를 유지하고, </li>
<li>프로세스에서 메시지를 보낼때 마다 자신의 <em>seq number</em> 를 하나 증가 시켜서 보냅니다</li>
<li>메시지를 받았을때, <strong>자신의 벡터 내에 있는 값 + 1</strong> 일 경우에만 벡터 값을 +1 한뒤 전달하고, 아니면 +1 인 값이 올 때까지 버퍼에 넣고 기다립니다</li>
</ul>

<p>예제를 보면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/FIFO_impl_example.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/FIFO_impl_example2.png'  alt="" /></p>

<p><br/></p>

<h3 id="totalorderingimpl">Total Ordering Impl</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/total_impl1.png'  alt="" /></p>

<p><em>sequencer-based approach</em> 입니다. 먼저 하나의 프로세스가 <em>sequencer</em> 로 선출된 뒤, 어떤 프로세스가 메세지를 보낼때마다 그룹 뿐만 아니라 <em>sequencer</em> 에게 보내게 됩니다.</p>

<p>이 <em>sequencer</em> 는 글로벌 시퀀스 <code>S</code> 를 유지하면서, 메시지 <code>M</code> 을 받을때마다 <code>S++</code> 해서 <code>&lt;M, S&gt;</code> 로 멀티캐스트를 보냅니다.</p>

<p>각 프로세스에서는 <em>local</em> 에 글로벌 시퀀스 <code>Si</code> 를 유지합니다. 만약 프로세스가 메세지를 받는다면 <code>Si + 1 = S(M)</code> 값을 글로벌 시퀀서로부터 받을때까지 기다리고, 받은 후에야 <code>Si++</code> 하고 전달합니다.</p>

<p><br/></p>

<h3 id="casualorderingimpl">Casual Ordering Impl</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/casual_impl1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/casual_impl2.png'  alt="" /></p>

<p>자료구조 자체는 같으나, <em>casuality</em> 를 검사하기 위해 <em>sender</em> 가 <em>vector</em> 전체를 보냅니다. <em>receiver</em> 는 메세지를 받으면 다음 두 조건을 만족하기 전까지 버퍼에 넣습니다</p>

<ul>
<li><code>M[j]</code> = <code>P_i[j] + 1</code></li>
<li><code>M[k]</code> &lt;= <code>P_i[k]</code>, (<code>k != j</code>)</li>
</ul>

<p>두번째 조건을 해석하면, 자신의 벡터도 다음 프로세스에게 전달해야 하기 때문에 <code>M[k]</code> 이후의 벡터만 가지고 있어야 전달할 수 있다는 뜻입니다. (<code>M[j]</code> 는 제외)</p>

<p>이 두 조건이 만족되야만 <code>P_i[j] = M[j]</code> 로 세팅하고 <code>M</code> 을 전달합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/casual_impl_example1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/casual_impl_example2.png'  alt="" /></p>

<p><br/></p>

<h3 id="reliablemulticast">Reliable Multicast</h3>

<p><em>reliable</em> 이란, 루즈하게 말하자면 모든 <em>receiver</em> 가 메세지를 받는다는 뜻입니다. <em>ordering</em> 과는 <em>orthogonal</em> 하기 때문에 <em>Reliable-FIFO</em>, 등등 구현이 가능합니다. 더 엄밀한 정의는</p>

<ul>
<li>need all <strong>correct</strong> (<em>non-faulty</em>) processes to receive the same set of multicasts as all other correct processes</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/reliable_multicast_impl1.png'  alt="" /></p>

<p>단순히 <em>reliable unicast</em> 를 여러개 보내는것 만으로는 부족합니다. 왜냐하면 <em>sender</em> 에서 <em>failure</em> 가 일어날 수 있기 때문입니다</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/reliable_multicast_impl2.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/reliable_multicast_impl3.png'  alt="" /></p>

<p>비효율적이지만, <em>reliable</em> 합니다.</p>

<p><br/></p>

<h3 id="virtualsynchrony">Virtual Synchrony</h3>

<p><em>virtual sinchrony</em> 혹은 <em>view synchrony</em> 라 불리는데, 이것은 <em>failure</em> 에도 불구하고 <em>multicast ordering</em> 과 <em>reliability</em> 를 얻기 위해 <em>membership protocol</em> 을 <em>multicast protocol</em> 과 같이 사용합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/view.png'  alt="" /></p>

<p>각 프로세스가 관리하는 <em>membership list</em> 를 <em>view</em> 라 부릅니다. <em>virtual synchrony</em> 프로토콜은 이런 <em>view change</em> 가 <em>correct process</em> 에 올바른 순서대로 전달됨을 보장합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/vsync_multicast.png'  alt="" /></p>

<p><em>Virtual Synchrony</em> 프로토콜은 다음을 보장합니다.</p>

<ul>
<li>the set of multicasts delivered in a given view is the same set at all correct processes that were in that view</li>
<li>the sender of the multicast message also belongs to that view</li>
<li>if a process <code>P_i</code> doesn't not deliver a multicast <code>M</code> in view <code>V</code> while other processes in the view <code>V</code> delivered <code>M</code> in <code>V</code>, then <code>P_i</code> will be <strong>forcibly removed</strong> from the next view delivered after <code>V</code> at the other processes</li>
</ul>

<p>다시 말해서, <em>multicast</em> 메세지는 같이 전달된 <em>view</em> 내에 있던 다른 프로세스에서 모두 동일합니다. 그리고 <em>view</em> <code>V</code> 내에 있는 어떤 프로세스가 <code>M</code> 을 전달하지 못할 경우, 다른 프로세스의 <em>next view</em> 에서 제거됩니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/virtual_synchrony_example1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/virtual_synchrony_example2.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/virtual_synchrony_example3.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/virtual_synchrony_example4.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/virtual_synchrony_example5.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/virtual_synchrony_example6.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/virtual_synchrony_example7.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/virtual_synchrony_example8.png'  alt="" /></p>

<p><br/></p>

<ul>
<li>Called <strong>"virtual synchrony"</strong> since in spite of running on an asynchronous network, it gives the appearance of a synchronous network underneath that obeys the same ordering at all processes</li>
</ul>

<p>그러나 <em>consensus</em> 를 구현하는데는 쓸 수 없습니다. <em>partitioning</em> 에 취약하기 때문입니다.</p>

<p>정리하자면 <em>multicast</em> 는 클라우드 시스템에서 중요한 요소입니다. 필요에 따라서 <em>ordering</em>, <em>reliability</em>, <em>virtual synchorny</em> 를 구현할 수 있습니다.</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-multicast/</link><guid isPermaLink="false">1aa1fadb-da2f-4163-af61-a68ed5cef2ac</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[multicast]]></category><category><![CDATA[virtual synchrony]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 07 Mar 2015 17:20:18 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, Snapshots]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<p>이번시간에는 <em>Distributed Snapshot</em> 에 대해서 배웁니다. 클라우드 환경에서 각 어플리케이션(혹은 서비스) 는 여러개의 서버 위에서 돌아갑니다. 각 서버는 <em>concurrent events</em> 를 다루며, 서로 상호작용합니다. 이런 환경에서 <em>global snapshot</em> 을 캡쳐할 수 있다면</p>

<ul>
<li><strong>check pointing:</strong> can restart distributed application on failure</li>
<li><strong>garbage collection of objects:</strong> object at servers that don't have any other objects(ay any servers) with pointers to them</li>
<li><strong>deadlock detection:</strong> useful in database transaction systems</li>
<li><strong>termination of computation:</strong> useful in batch computing systems like Folding@Homes, SETI@Home</li>
</ul>

<p><em>global snapshot</em> 은 두 가지를 포함합니다.</p>

<p>(1) Individual state of each process 
(2) Individual state of each communication channel </p>

<p><em>global snapshot</em> 을 만드는 한가지 방법은 모든 프로세스의 <em>clock</em> 을 동기화 하는 것입니다. 그래서 모든 프로세스에게 <em>time</em> <code>t</code> 에서의 자신의 상태를 기록하도록 요구할 수 있습니다. 그러나</p>

<ul>
<li>Time synchorization always has error</li>
<li>Doesn't not record the state of meesages in the channels</li>
</ul>

<p>지난 시간에 보았듯이, <em>synchronization</em> 이 아니라 <em>casuality</em> 로도 충분합니다. 프로세스가 <strong>명령을 실행하거나</strong>, <strong>메시지를 받거나</strong>, <strong>메시지를 보낼때마다</strong> <em>global system</em> 가 변합니다. 이를 저장하기 위해서 <em>casuality</em> 를 기록하는 방법을 알아보겠습니다.</p>

<p><br/></p>

<h3 id="chandylamportalgorithm">Chandy-Lamport Algorithm</h3>

<p>시작 전에 <em>system model</em> 을 정의하면</p>

<ul>
<li>N Processes in the system</li>
<li>There are two uni-directional communication channels between each ordered process pair <code>P_j -&gt; P_i</code>, <code>P_i -&gt; P_j</code></li>
<li>communication channels are <strong>FIFO</strong> ordered</li>
<li><strong>No failure</strong></li>
<li>All messages arribe intact, and are not duplicated</li>
</ul>

<p><em>requirements</em> 는</p>

<ul>
<li><em>snapshot</em> 때문에 <em>application</em> 의 작업에 방해가 일어나서는 안됩니다</li>
<li>각 프로세스는 자신의 <em>state</em> 를 저장할 수 있어야 합니다</li>
<li><em>global state</em> 는 분산회되어 저장됩니다 (collected in a distributed manner)</li>
<li>어떤 프로세스든지, <em>snapshot</em> 작업을 시작할 수 있습니다</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport1.png'  alt="" /></p>

<ul>
<li>프로세스 <code>P_i</code> 가 <em>market</em> 메세지를 만들고, 자신을 제외한 다른 <code>N-1</code> 개의 프로세스에게 보냅니다</li>
<li>동시에 <code>P_i</code> 는 <em>incoming channel</em> 을 레코딩하기 시작합니다</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport2.png'  alt="" /></p>

<p>(1) 만약 <code>P_i</code> 가 <em>marker</em> 메시지를 처음 받는다면</p>

<ul>
<li>만약메시지를 받은 프로세스 <code>P_i</code> 에서는 자신의 <em>state</em> 를 기록하고</li>
<li>자신을 제외한 프로세스들에게 <em>marker</em> 보내고</li>
<li>는 <em>incoming channel</em> 을 레코딩하기 시작합니다</li>
</ul>

<p>(2) <code>P_i</code> 가 이미 <em>market</em> 메세지를 받은적이 있다면</p>

<ul>
<li>이미 해당 채널의 모든 메세지를 기록중이었으므로, 레코딩을 끝냅니다</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport3.png'  alt="" /></p>

<p>이 알고리즘은 모든 프로세스가 자신의 <em>state</em> 와 모든 <em>channel</em> 을 저장하면 종료됩니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport_Example1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport_Example2.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport_Example3.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport_Example4.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport_Example5.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport_Example6.png'  alt="" /></p>

<p><br/></p>

<h3 id="consistentcuts">Consistent Cuts</h3>

<p><em>Chandy-Lamport</em> 알고리즘은 <em>casuality</em> 를 보장합니다. 이에 대해 증명하기 전에 먼저, <em>consistent cut</em> 이란 개념을 보고 가겠습니다.</p>

<ul>
<li><p><strong>Cut:</strong> time frontier at each process and at each channel. Events at the process/channel that happen before the cut are <strong>in the cut</strong> and happening after the cut are <strong>out of the cut</strong></p></li>
<li><p><strong>Consistent Cut:</strong> a cut that obeys casuality. A cut <code>C</code> is a consistent cut iff for each pair of event <code>e</code> <code>f</code> in the system, such that event <code>e</code> is in the cur <code>C</code> and if <code>f -&gt; e</code></p></li>
</ul>

<p>다시 말해서 <code>e</code> 가 <code>C</code> 내에 있고, <code>f -&gt; e</code> 라면 <code>f</code> 도 <code>C</code> 에 있어야만 <em>consistent cut</em> 이란 뜻입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/consistent_cut1.png'  alt="" /></p>

<p><code>F</code> 가 <em>cut</em> 내에 있지만, 올바르게 캡쳐되어 메시지 큐 내에서 전송중임을 <em>snapshot</em> 에서 보장합니다. 하지만 <code>G -&gt; D</code> 같은 경우는, <code>D</code> 가 <em>cut</em> 내에 있지만 <code>G</code> 가 그렇지 않아 <em>inconsistent cut</em> 입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/consistent_cut2.png'  alt="" /></p>

<p><em>Chandy-Lamport Global Snapshot</em> 알고리즘은 항상 <em>consistent cut</em> 을 만듭니다. 왜 그런가 증명을 보면</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport_Proof1.png'  alt="" /></p>

<p><code>ei -&gt; ej</code> 를 보장한다는 말은 스냅샷 안에 두 이벤트가 있다는 뜻입니다. 따라서 <code>ej -&gt; &lt;P_j records its state&gt;</code> 일때 당연히 <code>ei -&gt; &lt;P_i records its state&gt;</code> 와 같은 말입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/Chandy_Lamport_Proof2.png'  alt="" /></p>

<p>만약 <code>ej -&gt; &lt;P_j records its state&gt;</code> 일때 <code>&lt;P_i records its state&gt; -&gt; ei</code> 라 합시다.</p>

<p>그러면 <code>ei -&gt; ej</code> 로 가는 <em>regular app message</em> 경로를 생각해 봤을때, <code>P_i</code> 가 먼저 자신의 상태를 기록하기 시작했으므로 <em>marker</em> 메세지가 먼저 날라갈겁니다. (FIFO) 그러면 위에서 말한 <code>ei -&gt; ej</code> 경로를 타고 <em>marker</em> 메세지가 먼저 가게되고 <code>P_j</code> 는 자신의 상태를 먼저 기록하게 됩니다. 따라서 <code>P_j</code> 에서 <code>ej</code> 보다 자신의 상태를 기록하는 것이 먼저이므로 <code>ej</code> 는 <em>out of cut</em> 이고, 모순입니다.</p>

<p><br/></p>

<h3 id="safetyandliveness">Safety and Liveness</h3>

<p>분산시스템의 <em>correctness</em> 와 관련해서 <em>safety</em> 와 <em>liveness</em> 란 개념이 있습니다. 이 둘은 주로 혼동되어 사용되는데, 둘을 구별하는 것은 매우 중요합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/liveness.png'  alt="" /></p>

<ul>
<li>distributed computation will terminate eventually </li>
<li>every failure is eventually deteced by some non-faulty process</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/safety.png'  alt="" /></p>

<ul>
<li>there is no deadlock in a distributed transaction system</li>
<li>no object is orphaned</li>
<li><strong>accuracy</strong> in failure detector</li>
<li>no two processes decide on different values</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/liveness_and_safety.png'  alt="" /></p>

<p><em>failure detector</em> 나 <em>concensus</em> 의 경우에서 볼 수 있듯이 <em>completeness</em> 와 <em>accuracy</em> 두 가지를 모두 충족하긴 힘듭니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/language_of_global_state.png'  alt="" /></p>

<p><em>global snapshot</em> 은 한 상태 <code>S</code> 이고, 여기서 다른 스냅샷으로의 이동은 <em>casual step</em> 을 따라 이동하는 것입니다. 따라서 <em>liveness</em> 와, <em>safety</em> 와 관련해 다음과 같은 특징이 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week5/using_global_snapshot.png'  alt="" /></p>

<p><em>Chandy-Lamport</em> 알고리즘은 <em>stable</em> 한지를 검사하기 위해 사용할 수도 있습니다. 여기서 <em>stable</em> 하다는 것은, 한번 참이면 그 이후에는 계속 참인 것을 말합니다. 이는 알고리즘이 <em>casual correctness</em> 를 가지기 때문입니다.</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-snapshot/</link><guid isPermaLink="false">7d51c274-e6e6-41dd-a37e-b548da6e711c</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[snapshot]]></category><category><![CDATA[Chandy-Lamport]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 07 Mar 2015 13:57:56 GMT</pubDate></item><item><title><![CDATA[Coding The Matrix 2, Vector Space]]></title><description><![CDATA[<p><img src='http://th06.deviantart.net/fs71/PRE/i/2012/348/f/a/3d_cube_by_colorsark-d5nztba.jpg'  alt="" /></p>

<h3 id="linearcombinations">Linear Combinations</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/linear_combinations.png'  alt="" /></p>

<p><code>b</code> 와 <code>v1, ..., vn</code> 이 주어졌을때 </p>

<ul>
<li><code>a1, ..., an</code> 을 찾을 수 있을까요? </li>
<li>있다면 <em>unique solution</em> 인지 어떻게 알 수 있을까요?</li>
</ul>

<p><br/></p>

<h3 id="span">Span</h3>

<ul>
<li>The set of all linear combinations of some vectors <code>v1, ..., vn</code> is called <strong>span</strong> of these vector</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/span.png'  alt="" /></p>

<p>이브가 만약 위와 같은식을 만족한다는 사실을 알고 있다면, 패스워드의 모든 <em>span</em> <code>{a1, ..., an}</code> 에 대해서 적절한 <em>response</em> 를 추출할 수 있습니다. 증명은 위처럼 간단합니다.</p>

<p><br/></p>

<p>Let <code>V</code> be a set of vectors if <code>v1, ..., vn</code> are vectors such that <code>V</code> = Span <code>{v1, ..., vn}</code> then</p>

<ul>
<li>we say <code>{v1, ..., vn}</code> is a generating set for <code>V</code></li>
<li>we refer to the vectors <code>v1, ..., vn</code> as generators for <code>V</code></li>
</ul>

<p><code>[x, y, z]</code> = <code>x[1,0,0] + y[0,1,0] + z[0,0,1]</code> 을 <code>R^3</code> 의 <em>standard generator</em> 라 부릅니다. </p>

<p><br/></p>

<h3 id="geometryofsetsofvectors">Geometry of Sets of Vectors</h3>

<ul>
<li><em>Span of the empty set:</em> just the origin, <strong>Zero-dimensional</strong></li>
<li><em>Span</em> <code>{[1,2], [3,4]}</code>: all points in the plane, <strong>Two-dimensional</strong></li>
<li><em>Span</em> <code>{[1,0,1.65], [0,1,1]}</code> is a plain in three dimensions</li>
</ul>

<p><code>k</code> 벡터의 <em>span</em> 은 <em>k-dimensional</em> 일까요? 아닙니다.</p>

<ul>
<li>Span <code>{[0, 0]}</code> 은 <em>zero-dimensional</em> 입니다.</li>
<li>Span <code>{[1,3], [2,6]}</code> 은 <em>one-dimensional</em> 입니다. </li>
<li>Span <code>{[1,0,0], [0,1,0], [1,1,0]}</code> 은 <em>two-dimensional</em> 입니다.</li>
</ul>

<p>그러면 어떤 벡터 <code>v</code> 가 있을때 <em>dimensionality</em> 를 어떻게 알아낼 수 있을까요?</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/geometry_of_sets.png'  alt="" /></p>

<p>위 그림에서 볼 수 있듯이 <em>origin</em> 을 포함하는 <em>geometry object</em> 를 표현하는 방법은 두가지 입니다. 각각은 나름의 쓰임새가 있습니다.</p>

<p>(1) <em>span</em> of some vectors <br />
(2) 우변이 <code>0</code> 인 <em>linear equation system</em> 의 집합</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/two_representation1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/two_representation2.png'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/common_representation1.png'  alt="" /></p>

<p><em>field</em> 의 서브셋은 3가지 속성을 만족합니다. <em>field</em> 를 <code>R</code> 이라 하면</p>

<ul>
<li>subset contains the zero vector</li>
<li>if subset contains <code>v</code> then it contains <code>av</code> for every scala <code>a</code></li>
<li>if subset contains <code>u</code> and <code>v</code> then it contains <code>u+v</code></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/common_representation2.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/common_representation3.png'  alt="" /></p>

<p><code>F^D</code> 의 세가지 속성을 만족하는 <em>subset</em> 을 <strong>vector space</strong> 라 부릅니다. 그리고 <code>U</code> 가 <em>vector space</em> 고 <em>vector space</em> <code>V</code> 의 <em>subset</em> 일때, <code>U</code> 를 <code>V</code> 의 <em>subspace</em> 라 부릅니다.</p>

<p>뒤에서 배울테지만 모든 <code>R^D</code> 의 <em>subspace</em> 는 <em>span</em> <code>{v1, ..., vn}</code> 과 <code>{x: a1 * x = 0, ..., an * x = 0}</code> 의 형태로 쓸 수 있습니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/abstract_vector_space.png'  alt="" /></p>

<p>우리는 벡터에 대해 <em>sequence</em> 나, <em>function</em> 을 정의하지 않았습니다. 단순한 <em>operator</em> 와 공리를 만족하는지, 그리고 <em>property</em> <code>V1, V2, V3</code> 정도만 따졌습니다. 벡터에 대한 이런 추상적 접근은 많은 장점이 있습니다. 그러나 이 수업에서는 사용하지 않겠습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/convex_hull.png'  alt="" /></p>

<p><br/></p>

<h3 id="vectorspace">Vector Space</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/exclude_origin_line.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/exclude_origin_plain.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/affine_space.png'  alt="" /></p>

<p>벡터 <code>c</code> 와 벡터 스페이스 <code>V</code> 에 대해 <code>c + V</code> 와 같은 형태를 <em>affine space</em> 라 부릅니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/affine_combination.png'  alt="" /></p>

<p><code>u1, u2, u3</code> 를 담고있는 <em>plain</em> 을 <code>u1 + V</code> 형태로 표현하고 싶습니다. 어떻게 해야할까요?</p>

<p><code>V</code> 를 <em>span</em> <code>{a, b}</code> 라 하고 <code>a = u2 - u1</code>, <code>b = u3 - u1</code> 라 하면 <code>u1 + V</code> 는 <em>plain</em> 의 변환이지만, 그 자체로서 <em>plain</em> 입니다</p>

<ul>
<li><em>span</em> <code>{a, b}</code> 는 <code>0</code> 을 포함하므로 <code>u1</code> + <em>span</em> <code>{a, b}</code> 는 <code>u1</code> 를</li>
<li><em>span</em> <code>{a, b}</code> 는 <code>u2 - u1</code> 도 을 포함하므로 <code>u1</code> + <em>span</em> <code>{a, b}</code> 는 <code>u2</code> 를</li>
<li><em>span</em> <code>{a, b}</code> 는 <code>u3 - u1</code> 도 을 포함하므로 <code>u1</code> + <em>span</em> <code>{a, b}</code> 는  <code>u3</code> 를 포함합니다.</li>
</ul>

<p>따라서 <code>u1</code> + <em>span</em> <code>{a, b}</code> 는 <code>u1, u2, u3</code> 를 모두 포함하는 평면입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/affine_combination2.png'  alt="" /></p>

<p>더 간단히 <code>ru1 + au2 + bu3</code> (<code>r + a + b = 1</code>) 로 <em>affine combination</em> 을 표현할 수 있습니다. 그리고 더 <em>formal</em> 하게 정의하면,</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/affine_combination3.png'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/affine_equation.png'  alt="" /></p>

<p><em>affine space</em> 를 <em>a solution set of a system of linear equations</em> 으로 표현할 수 있습니다. 그런데, 역으로 이 솔루션이 <em>affine space</em> 일까요?</p>

<p>반례를 하나 들어보면 <code>1x = 1, 2x = 1</code> 일때 솔루션은 없습니다. 그러나 벡터 스페이스 <code>V</code> 는 <em>zero vector</em> 를 가져야 하므로 <em>affine space</em> <code>u + V</code> 는 적어도 하나의 <em>vector</em> 는 가져아합니다. 모순이 발생합니다.</p>

<ul>
<li><strong>Theorem:</strong> <em>solution set of a linear system</em> 은 <em>empty</em> 거나 <em>affine space</em> 입니다. 증명은 아래와 같습니다.</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/affine_combination_proof1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/affine_combination_proof2.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/affine_combination_proof3.png'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/number_of_solutions.png'  alt="" /></p>

<p>지금까지 증명한 것은, <code>u1</code> 이 <em>linear system</em> 의 솔루션일때, <code>u1 + v</code> (<code>v</code> in <code>V</code>) 도 솔루션이란 사실입니다. 여기서 <code>V</code> 는 <em>homogeneous linear system</em> 입니다. (우변이 <code>0</code> 인)</p>

<p>따라서 </p>

<ul>
<li><em>unique solution</em> 을 가질때는 <code>V</code> 가 <code>0</code> 을 해로 가질 때이고</li>
<li><em>GF(2)</em> 의 솔루션 수는 <code>0</code> 이거나, <code>V</code> 와 같습니다.</li>
</ul>

<p><br/></p>

<h3 id="checksumfunction">Checksum function</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/checksum1.png'  alt="" /></p>

<p><em>corrupted</em> 파일이 올바른 파일로 인식될 경우는 오리지널 바이너리 <code>p</code> 에 대해 손상된 파일 <code>p+e</code> 가 위 슬라이드의 방정식을 만족할 경우입니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/2-vector-space/checksum2.png'  alt="" /></p>

<p>이 확률은 모든 가능한 <code>n</code> 벡터에 대해 존재하는 솔루션의 수 이므로 굉장히 낮습니다.</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://colorsark.deviantart.com/art/3D-Cube-342632998' >Title image</a> <br />
(2) <strong>Coding the Matrix</strong> by <em>Philip Klein</em>  </p>]]></description><link>http://1ambda.github.io/coding-the-matrix-2/</link><guid isPermaLink="false">5f630834-a38f-4833-a4a3-8d465a1c0b31</guid><category><![CDATA[coursera]]></category><category><![CDATA[linear algebra]]></category><category><![CDATA[vector space]]></category><category><![CDATA[span]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 04 Mar 2015 16:28:24 GMT</pubDate></item><item><title><![CDATA[Pattern Discovery 3]]></title><description><![CDATA[<p><img src='https://m1.behance.net/rendition/modules/7116731/disp/d18c13cd5b49bf40b41e6ef0610b26d3.png'  alt="" /></p>

<p>이번 시간에 배울 주제는 <em>Sequential Pattern Mining</em> 입니다.</p>

<ul>
<li>GSP (Generalized Sequential Patterns)</li>
<li>Vertical Format-Based Mining: <strong>SPADE</strong></li>
<li>Pattern-Growth Methods: <strong>PrefixSpan</strong></li>
<li>Mining Closed Sequential Patterns: <strong>CloSpan</strong>
Constrain-Based Sequential Pattern Mining</li>
</ul>

<p><em>sequential pattern mining</em> 은 다양한 곳에 사용됩니다.</p>

<ul>
<li>customer shopping sequences</li>
<li>medial treatments</li>
<li>web click streams, calling patterns</li>
<li>program execution sequences (software engineering)</li>
<li>biological sequences (DNA)</li>
</ul>

<p><em>time-series DB</em> 와는 다릅니다. 이건 일정 간격으로 로그가 저장된 것이고, <em>sequential pattern</em> 은 <em>time stamp</em> 가 붙은 것이라 보면 됩니다. 어찌 보면 [Process Mining][http://1ambda.github.io/process-mining-week1/] 이라 볼 수도 있겠습니다.</p>

<p><em>sequential pattern</em> 은 크게 <em>gapped</em> 와 <em>non-gapped</em> 로 나누어집니다. 전자는 패턴 사이의 <em>gap</em> 을 허용하고, 후자는 허용하지 않습니다. 모든 시퀀스가 중요하다는 뜻입니다. 예를 들어 웹사이트에서 <em>click stream</em> 사이의 <em>gap</em> 은 정말 중요할 수 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/sequential_pattern_mining.png'  alt="" /></p>

<p><em>sequential pattern mining</em> 은 주어진 시퀀스에서 빈번한 서브시퀀스의 집합을 찾아냅니다. <em>element</em> (<code>()</code>) 또는 <em>event</em> 라 부르는 단위가 <em>items</em> 를 담고 있습니다. 그리고 <code>()</code> 로 묶인 <em>item</em> 의 순서는 중요하지 않습니다.</p>

<p><br/></p>

<h3 id="gsp">GSP</h3>

<p><em>GSP</em> 는 <em>apriori-based sequential pattern mining</em> 기법입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/GSP.png'  alt="" /></p>

<p><em>singleton</em> 시퀀스를 기반으로 <em>length 1, 2</em> 의 <em>candidates</em> 를 만들고, <em>apriori pruning</em> 을 적용합니다. 그러면, <code>36 + 15 = 51</code> 의 <em>candidates</em> 를 얻을 수 있습니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/GSP2.png'  alt="" /></p>

<p>데이터베이스를 지속적으로 스캔해가면서 <em>minimum support</em> 를 통과하지 못하는 것들을 제거하고 위 과정을 반복하는 것이 <em>GSP Mining</em> 입니다.</p>

<p><br/></p>

<h3 id="spade">SPADE</h3>

<p><em>SPADE (Sequential Pattern Mining in Vertical Data)</em></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/SPADE.png'  alt="" /></p>

<p><em>SID</em> 뿐만 아니라 <em>element ID, EID</em> 를 이용해서 테이블을 좌측처럼 하나 만듭니다. 그리고 이 테이블을 이용해서 우측 상단 테이블처럼 <code>a</code>, <code>b</code> 등이 어느 <em>SID, EID</em> 셋에서 나타나는지를 파악합니다. 패턴의 길이를 늘려가면서, 즉 테이블을 계속 조인해 나가면 패턴의 <em>support</em> 를 구할 수 있습니다.</p>

<p><br/></p>

<h3 id="prefixspan">PrefixSpan</h3>

<p><em>Pattern-Growth</em> 기반의 알고리즘인 <em>PrefixSpan</em> 을 살펴보겠습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/prefix_span1.png'  alt="" /></p>

<p>먼저 <em>length-1</em> 패턴을 찾고 이를 기반으로 <em>projected DB</em> 를 만들어가며 마이닝을 진행합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/prefix_span2.png'  alt="" /></p>

<p>단계가 지나면 지날수록 <em>candidate</em> 가 생겨나는 비율이 줄고, <em>projected DB</em> 자체도 줄어든다는 장점이 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/prefix_span3.png'  alt="" /></p>

<p>다만 <em>projected DB</em> 에서 많은 중복이 발생하기 때문에 이를 해결하기 위해 <em>pseudo projection</em> 을 이용할 수 있습니다. </p>

<p><br/></p>

<h3 id="clospan">CloSpan</h3>

<p><em>CloSpan</em> 은 <em>closed sequential pattern</em> 을 마이닝하는 알고리즘입니다.</p>

<p><em>closed pattern</em> 을 다시 복습해 보면</p>

<blockquote>
  <p>closed pattern: A pattern(itemset) <code>X</code> is closed if <code>X</code> is frequent, and there exists no super pattern <code>Y</code> ⊃ <code>X</code>, with the same support as <code>X</code></p>
</blockquote>

<p>예를 들어 <code>&lt;abc&gt;:20, &lt;abcd&gt;:20, &lt;abcde&gt;:15</code> 라면 <code>&lt;abcd&gt;</code> <code>&lt;abcde&gt;</code> 는 <em>closed pattern</em> 입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/clo_span.png'  alt="" /></p>

<p><em>closed pattern</em> 을 마이닝하는 이유는 이전에도 말했듯이 중복된 패턴을 피하기 위함입니다. 위 그림처럼 <em>redundant search space</em> 를 <em>pruning</em> 할 수 있습니다.</p>

<p><br/></p>

<h3 id="constraintbased">Constraint-Based</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/constraint_based_mining.png'  alt="" /></p>

<ul>
<li><strong>Data anti monotonic:</strong> <code>S</code> 가 제약조건 <code>c</code> 를 위반했을때, 나머지 부분인 <code>s</code> 를 더해도 여전히 위반이라면 <code>s</code> 를 제거할 수 있습니다.</li>
<li><strong>Sunccint:</strong> 제약조건 <code>c</code> 를 기준으로 데이터를 직접 조작합니다. 예를 들어 <code>S</code> 가 <code>{i-phone, MacAir}</code> 를 반드시 포함해야 한다고 할때, 그렇지 못하면 <code>S</code> 를 제거할 수 있습니다</li>
<li><strong>Convertible:</strong> 아이템을 정렬해서 제약조건을 <em>anti-monotonic</em> 이나 <em>monotonic</em> 등으로 바꿉니다. </li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/time_based_constraints.png'  alt="" /></p>

<ul>
<li><em>order constaint</em> 는 <em>anti-monotonic</em> 입니다</li>
<li><em>min, max gap</em> 제약조건은 <em>succinct</em> 입니다.</li>
<li><em>max span</em> 제약조건은 처음과 마지막 <em>element</em> 의 시간 간격입니다. 이것도 <em>succinct</em> 입니다</li>
<li><em>window size</em> 제약조건은 한 <em>element</em> 내부에서 <em>event</em> 발생 회수를 제한하는 조건입니다.</li>
</ul>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/episode_pattern_mining.png'  alt="" /></p>

<p>정규표현식과 <em>episode</em> 는 <em>sequential pattern</em> 의 다른 표현 방법입니다.</p>

<p><br/></p>

<h3 id="graphpatternmining">Graph Pattern Mining</h3>

<p>이번 시간에 배울 내용은 다음과 같습니다.</p>

<ul>
<li>Apriori-Based Graph Pattern Mining</li>
<li><strong>gSpan:</strong> A Pattern-Growth-Based Method</li>
<li><strong>CloseGraph:</strong> Mining Closed Graph Pattern</li>
<li>Graph Indexing</li>
<li>Top-K Large Structural Patterns in a Massive Network</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/graph_support.png'  alt="" /></p>

<p><em>Graph</em> 에서 <em>support</em> 란 <em>subgraph</em> 가 나타나는 수 입니다. </p>

<p>그래프 패턴 마이닝을 위해서 다양한 방법을 이용할 수 있습니다.</p>

<p>(1) Generation of candidate subgraphs</p>

<ul>
<li>Apriori (<strong>FSG</strong>) vs Pattern Growth(<strong>gSpan</strong>)</li>
</ul>

<p>(2) Search Order</p>

<ul>
<li>Breadth vs Depth</li>
</ul>

<p>(3) Elimination of duplicate subgraphs</p>

<ul>
<li>Passive vs Active (e.g <strong>gSpan</strong>)</li>
</ul>

<p>(4) Support calculation</p>

<ul>
<li>Store embeddings (e.g <strong>GASTON, FFSM, MoFA</strong>)</li>
</ul>

<p>(5) Order of Pattern Discovery</p>

<ul>
<li>Path -> Tree -> Graph (<strong>GASTON</strong>)</li>
</ul>

<p><br/></p>

<h3 id="aprioribasedapproach">Apriori-Based Approach</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/apriori_based_approache.png'  alt="" /></p>

<p><em>Apriori Property</em> 에 의해서, 어떤 그래프가 <code>G</code> 가 빈번한 경우는, <em>*모든 *</em>서브그래프들도 빈번할 경우뿐입니다. </p>

<p>따라서 <code>k</code> 개의 <em>edge, vertex</em> 를 가진 <em>frequent</em> 서브그래프에서 공통된 엣지가 많은 그래프를 골라 <code>k+1</code> 개의 <em>edge, vertex</em> 그래프를 만듭니다. 그리고 여기서 이 그래프의 <strong>모든 서브 그래프가</strong> <em>frequent</em> 한지 검사하여 <em>pruning</em> 을 진행할 수 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/vertex_edge_growing.png'  alt="" /></p>

<p><em>vertex</em> 기반으로 확장해 나가는 알고리즘으로 <em>AGM (Apriori-based Graph Mining)</em> 이 있습니다. <em>edge</em> 를 확장해 나가는 알고리즘으로는 <em>FSG (Frequent Sub Graphs)</em> 가 있는데, 일반적으로 더 작은 컴포넌트인 <em>edge</em> 를 확장시켜 나가는 방법이 더 효율적이라고 알려져 있습니다.</p>

<p><br/></p>

<h3 id="gspanapatterngrowthapproach">gSpan: A Pattern Growth Approach</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/pattern_growth_approach_gSpan.png'  alt="" /></p>

<p>먼저 <code>k</code>-<em>edge</em> 그래프를 보고, 여기에 하나의 <em>edge</em> 를 더해 <code>k+1</code> <em>edge</em> 그래프도 빈번하다면 이 과정을 계속 반복해 나아갑니다. 이 방법은 많은 수의 <em>subgraph</em> 가 중복된다는 단점이 있습니다. </p>

<p>이 문제를 해결하기 위해 <em>gSpan</em> 에서는 생성할 <em>subgraph</em> 의 순서를 미리 정의해 놓고 <em>depth-first search</em> 를 이용해서 <em>graph</em> 를 <em>sequence</em> 처럼 펼칩니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/gspan_example.png'  alt="" /></p>

<p>위 그림에서는 가장 작은 인덱스를 먼저 선택하는 <em>DFS</em> 를 이용해서 우측처럼 시퀀스를 만들었습니다. </p>

<p><br/></p>

<h3 id="closegraph">CloseGraph</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/closed_graph.png'  alt="" /></p>

<p><code>n</code> 개의 <em>edge</em> 를 가진 그래프에는 <code>2^n</code> 개의 서브그래프가 존재합니다. 정말 어마어마한 숫자입니다. 이런 <em>explosion</em> 문제를 해결하기 위해 <em>closed frequent subgraph</em> 를 이용합니다.</p>

<ul>
<li>A frequent graph <code>G</code> is <strong>closed</strong> if there exists no supergraph of <code>G</code> that carries the same support as <code>G</code>'</li>
</ul>

<p><em>loseless compression</em> 이기 때문에 결과는 <em>complete</em> 합니다. 따라서 <em>closed graph pattern</em> 을 마이닝 하면 좀 더 효율적입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/close_graph_algorithm.png'  alt="" /></p>

<p><code>G</code> 가 있을 때마다 <code>G1</code> 이 존재한다면 다른 <em>supergraph</em> 를 살펴볼 필요가 없습니다. 이는 <code>G1</code> 이 <code>G</code> 를 커버할 수 있기 때문입니다. 아래는 다른 알고리즘과의 성능 비교입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/close_graph_performance.png'  alt="" /></p>

<p><br/></p>

<h3 id="graphindex">Graph Index</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/graph_indexing.png'  alt="" /></p>

<p>그림에서 볼 수 있듯이 <em>path index</em> 는 <code>(a)</code> <code>(b)</code> 를 쿼리 <code>Q</code> 에 대해 필터링 하지 못할 수 있습니다. 따라서 그래프를 직접 인덱싱하는 것이 필요한데, 문제는 그래프를 인덱싱할때 서브그래프가 너무 많다는 것입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/gIndex.png'  alt="" /></p>

<p>따라서 <em>frequent substructure</em> 만 인덱스 하되, <em>size-increasing support threshold</em> 를 이용하면 됩니다. 즉 사이즈가 증가할수록 <em>min support</em> 도 올리는 것인데, 이는 큰 그래프일수록 작은 그래프에서 이미 <em>indexed</em> 되었을 수 있기 때문입니다.</p>

<p>그리고 <em>discriminative substructure</em> 를 인덱싱해야합니다. 이는 기존과 비슷한 그래프를 인덱싱 할 필요는 없기 때문이지요. <em>discriminative</em> 그래프를 선택하기 위해서 슬라이드처럼 새로운 그래프 <code>x</code> 가 기존의 인덱싱된 그래프 <code>f1, f2, ...,</code> 을 얼마나 커버하는지를 계산하여 작으면 인덱싱합니다.</p>

<p><br/></p>

<h3 id="spidermine">Spider Mine</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/spider_mine1.png'  alt="" /></p>

<p><em>pattern fusion</em> 과 비슷하게, 작은 컴포넌트인 <em>spider</em> 가 모여 결국에는 큰 컴포넌트를 만든다는 기본적인 아이디어로부터 시작합니다.</p>

<p><em>r-Spider</em> 는 <em>vertex</em> <code>u</code> 로부터 <code>r</code> 홉 안에 도달할 수 있는 <em>frequent</em> 패턴입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/spider_mine2.png'  alt="" /></p>

<p>알고리즘이 수행되는 동안 <em>spider mine</em> 알고리즘은 <em>large pattern</em> 을 유지하고 <em>small pattern</em> 을 <em>pruning</em> 합니다. 그 이유는 작은 패턴일수록 <em>random draw</em> 에서 <em>hit</em> 할 확률이 낮고, 했다 하더라도 여러번 <em>hit</em> 할 확률은 더 낮기 때문입니다. </p>

<p><br/></p>

<h3 id="patternbasedclassification">Pattern-Based Classification</h3>

<p>이번 챕터에서 배울 내용은 다음과 같습니다.</p>

<ul>
<li>Pattern-Based Classification</li>
<li>Associative Classification</li>
<li>Discriminative Pattern-Based Classification</li>
<li>Direct Mining of Discriminative Patterns</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/pattern_based_why.png'  alt="" /></p>

<p><em>frequent pattern mining</em> 과 <em>classification</em> 을 조합하면 더 심도있고, 다양한 데이터에 대한 분석이 가능합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/pattern_based_example.png'  alt="" /></p>

<p><br/></p>

<h3 id="associativeclassificationcbacmar">Associative Classification: CBA, CMAR</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/classification_CBA.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/CMAR.png'  alt="" /></p>

<p><br/></p>

<h3 id="discriminativeclassification">Discriminative Classification</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/discriminative1.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/discriminative2.png'  alt="" /></p>

<p>당연한 이야기지만 <em>single item</em> 보다는 <code>k</code> 개의 아이템셋이 더 많은 <em>information gain</em> 을 만듭니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/discriminative3.png'  alt="" /></p>

<p>그리고 위 슬라이드에서 볼 수 있듯이, <em>frequent, but not too frequent</em>  한 패턴이 <em>discriminative</em> 하게 적용됨을 알 수 있습니다. (<em>info gain</em> 이 더 많다는 뜻)</p>

<p><br/></p>

<h3 id="ddpmine">DDP Mine</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/DDPMine1.png'  alt="" /></p>

<p><em>frequent pattern mining</em> 후에 <em>discriminative pattern</em> 을 얻는 것은 계산적으로 비쌉니다. 따라서 바로 <em>discriminative pattern</em> 을 얻을 수 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/DDPMine2.png'  alt="" /></p>

<p>알고리즘은 이렇습니다. 매 이터레이션마다 가장 <em>discriminative power</em> 가 큰 <em>feature</em> <code>f</code> 를 고르고, <code>D</code> 에서 <code>f</code> 에 의해 커버 되는 인스턴스 <code>D</code> 를 제거합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week3/DDPMine3.png'  alt="" /></p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='https://www.behance.net/gallery/625042/Icon-and-pattern-with-a-marketing-theme' >Title image</a> <br />
(2) <strong>Pattern Discovery</strong> by <em>Jiawei Han</em> </p>]]></description><link>http://1ambda.github.io/pattern-discovery-3/</link><guid isPermaLink="false">9d993973-15d9-4611-bb12-119343656a18</guid><category><![CDATA[coursera]]></category><category><![CDATA[pattern discovery]]></category><category><![CDATA[gSpan]]></category><category><![CDATA[closeGraph]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 03 Mar 2015 16:02:54 GMT</pubDate></item><item><title><![CDATA[Articles]]></title><description><![CDATA[<h3 id="scala">Scala</h3>

<p><strong>Functional Programming in Scala</strong> by <em>Martin Odersky</em></p>

<p><a href='http://1ambda.github.io/functional-programming-in-scala-chapter-1/' >Chapter 1</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-2/' >Chapter 2</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-3/' >Chapter 3</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-4/' >Chapter 4</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-5/' >Chapter 5</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-6/' >Chapter 6</a> <br />
<a href='http://1ambda.github.io/functional-programming-in-scala-chapter-7/' >Chapter 7</a>  </p>

<p><strong>Reactive Programming</strong> by <em>Martin Odersky</em></p>

<p><a href='http://1ambda.github.io/reactive-programming-1/' >Chapter 1</a> - Monads, Random Generators <br />
<a href='http://1ambda.github.io/reactive-programming-2/' >Chapter 2</a> - Stateful Object <br />
<a href='http://1ambda.github.io/reactive-programming-3/' >Chapter 3</a> - Try, Future, Promise <br />
<a href='http://1ambda.github.io/reactive-programming-4/' >Chapter 4</a> - Observable, Rx, Scheduler <br />
<a href='http://1ambda.github.io/reactive-programming-5/' >Chapter 5</a> - Actor   </p>

<p><strong>Articles</strong></p>

<p><a href='http://1ambda.github.io/new-to-play-framework-2/' >new to Play Framework2</a> <br />
<a href='http://1ambda.github.io/partial-functions-scala/' >Partial Functions, Scala</a>  </p>

<h3 id="haskell">Haskell</h3>

<p><strong>Introduction to Functional Programming using Haskell</strong></p>

<p><a href='http://1ambda.github.io/haskell-intro1' >Chapter 1</a> - Basics <br />
<a href='http://1ambda.github.io/haskell-intro2' >Chapter 2</a> - List Comprehension <br />
<a href='http://1ambda.github.io/haskell-intro3' >Chapter 3</a> - Recursion, Higher Order Function <br />
<a href='http://1ambda.github.io/haskell-intro4' >Chapter 4</a> - Monad <br />
<a href='http://1ambda.github.io/haskell-intro5' >Chapter 5</a> - IO Monad <br />
<a href='http://1ambda.github.io/haskell-intro6' >Chapter 6</a> - Type and Class <br />
<a href='http://1ambda.github.io/haskell-intro7' >Chapter 7</a> - The Countdown Problem <br />
<a href='http://1ambda.github.io/haskell-intro8' >Chapter 8</a> - Lazy Evaluation, Strict <br />
<a href='http://1ambda.github.io/haskell-intro9' >Chapter 9</a> - Induction <br />
<a href='http://1ambda.github.io/a-poor-mans-concurrency-monad' >Poor Man's Concurrency Monad</a></p>

<h3 id="machinelearning">Machine Learning</h3>

<p><strong>Machine Learning</strong> by <em>Andrew Ng</em>, Coursera</p>

<p><a href='http://1ambda.github.io/machine-learning-week-1/' >Chapter 1</a> - Linear Regression <br />
<a href='http://1ambda.github.io/machine-learning-week-2/' >Chapter 2</a> - Gradient Descent <br />
<a href='http://1ambda.github.io/machine-learning-week-3/' >Chapter 3</a> - Logistic Regression <br />
<a href='http://1ambda.github.io/machine-learning-week-4/' >Chapter 4</a> - Neural Network <br />
<a href='http://1ambda.github.io/machine-learning-week-5/' >Chapter 5</a> - Back Propagation <br />
<a href='http://1ambda.github.io/machine-learning-week-6/' >Chapter 6</a> - Practical Advices <br />
<a href='http://1ambda.github.io/machine-learning-week-7/' >Chapter 7</a> - Support Vector Machine <br />
<a href='http://1ambda.github.io/machine-learning-week-8/' >Chapter 8</a> - K-means, PCA Details <br />
<a href='http://1ambda.github.io/machine-learning-week-9/' >Chapter 9</a> - Anomaly Detection, Recommender System <br />
<a href='http://1ambda.github.io/machine-learning-week-10/' >Chapter 10</a> - Stochastic Gradient, Synthetic Data, Ceiling Analysis  </p>

<h3 id="algorithm">Algorithm</h3>

<p><strong>Algorithm: Design and Analysis Part 1</strong> by <em>Tim Roughgarden</em></p>

<p>(1) <a href='http://1ambda.github.io/divide-and-conquer/' >Divide and Conquer</a> <br />
(2) <a href='http://1ambda.github.io/randomized-selection/' >Randomized Selection</a> <br />
(3) <a href='http://1ambda.github.io/graphs-the-contraction-algorithm/' >Graphs, The Contraction Algorithm</a> <br />
(4) <a href='http://1ambda.github.io/graph-search-and-connectivity/' >Graph Search and Connectivity</a> <br />
(5) <a href='http://1ambda.github.io/dijkstra-heap-balanced-tree/' >Dijkstra, Heap, Red-Black Tree</a> <br />
(6) <a href='http://1ambda.github.io/hash-table-universal-hashing-bloom-filters/' >Hash Table, Universal Hashing, Bloom filters</a>  </p>

<p><strong>Algorithms, Part 1</strong> by <em>Robert Sedgewick</em></p>

<p>(1) <a href='http://1ambda.github.io/union-find-algorithms-week-1/' >Union Find</a> <br />
(2) <a href='http://1ambda.github.io/analysis-of-algorithms/' >Analysis of Algorithms</a> </p>

<p><strong>Algorithms, Part 2</strong> by <em>Robert Sedgewick</em></p>

<p>(1) <a href='http://1ambda.github.io/graph-challenges-minimum-spanning-trees' >Spanning Tree, Shortest Paths</a> <br />
(2) <a href='http://1ambda.github.io/radix-sort-suffix-sort' >Radix Sort, Suffix Sort</a> <br />
(3) <a href='http://1ambda.github.io/r-way-ternary-search-tries/' >R-way, Ternary Tries</a> <br />
(4) <a href='http://1ambda.github.io/substring-search/' >KMP, Boyer-Moore, Rabin-Karp</a> <br />
(5) <a href='http://1ambda.github.io/maximum-flow/' >Maximum Flow (Ford-Fulkerson)</a> <br />
(6) <a href='http://1ambda.github.io/algorithm-data-compression/' >Data Compression, Huffman, LZW</a>   </p>

<h3 id="artificialintelligence">Artificial Intelligence</h3>

<p><strong>Artificial Intelligence (CS188)</strong> by <em>Dan Klein, Pieter Abbeel</em></p>

<p>(1) <a href='http://1ambda.github.io/artificial-intelligence-1' >Intro</a> <br />
(2) <a href='http://1ambda.github.io/artificial-intelligence-2' >Search</a>  </p>

<p><strong>Artificial Intelligence Planning</strong> by <em>Dr.Gerhard Wickler</em>, <em>Prof. Austin Tate</em></p>

<p>(1) <a href='http://1ambda.github.io/ai-planning-1' >Intro</a> <br />
(2) <a href='http://1ambda.github.io/ai-planning-2' >A*, STRIPS, forward and backward search</a> <br />
(3) <a href='http://1ambda.github.io/ai-planning-3' >PSP, PoP</a> <br />
(4) <a href='http://1ambda.github.io/ai-planning-4' >STN, HTN</a>  </p>

<h3 id="cloudcomputing">Cloud Computing</h3>

<p><strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera</p>

<p>(1) <a href='http://1ambda.github.io/cloud-computing-1-1/' >MapReduce</a> <br />
(2) <a href='http://1ambda.github.io/cloud-computing-gossip-protocol/' >Gossip Protocol</a> <br />
(3) <a href='http://1ambda.github.io/cloud-computing-membership-protocol/' >Membership Protocol</a> <br />
(4) <a href='http://1ambda.github.io/cloud-computing-p2p-systems/' >P2P Systems</a>  </p>

<h3 id="dataanalysis">Data Analysis</h3>

<p><strong>Pattern Discovery</strong> by <em>Jiawei Han</em>, Coursera</p>

<p><a href='http://1ambda.github.io/pattern-discovery-1/' >Chapter 1</a> - Apriori, FP Growth <br />
<a href='http://1ambda.github.io/pattern-discovery-2/' >Chapter 2</a> - Null-invariant, Pattern-Fusion, Constaint   </p>

<p><strong>Intro to Computational Thinking and Data Science</strong>, edx</p>

<p><a href='http://1ambda.github.io/edx-600-2x-1/' >Chapter 1</a> - Modeling <br />
<a href='http://1ambda.github.io/edx-600-2x-2/' >Chapter 2</a> - Monte Carlo Simulation <br />
<a href='http://1ambda.github.io/edx-600-2x-3/' >Chapter 3</a> - Optimization Problem <br />
<a href='http://1ambda.github.io/edx-600-2x-4/' >Chapter 4</a> - State Modeling, Hierarchical Clustering   </p>

<p><strong>Coding The Matrix</strong> by <em>Philip Klein</em>, Coursera</p>

<p><a href='http://1ambda.github.io/coding-the-matrix-1/' >Chapter 1</a> - Function, Field, Vector</p>

<h3 id="processmining">Process Mining</h3>

<p><strong>Process Mining</strong> by <em>Wil Van der Alast</em>, Coursera</p>

<p><a href='http://1ambda.github.io/process-mining-week1/' >Week 1</a> - Process Mining Intro <br />
<a href='http://1ambda.github.io/process-mining-week2/' >Week 2</a> - Alpha Algorithm <br />
<a href='http://1ambda.github.io/process-mining-week3/' >Week 3</a> - Metric, C-nets <br />
<a href='http://1ambda.github.io/process-mining-week4/' >Week 4</a> - Conformance Checking, Dotted Chart <br />
<a href='http://1ambda.github.io/process-mining-week5/' >Week 5</a> - Decision, Social, Organization Mining  </p>

<h3 id="java">Java</h3>

<p><strong>Articles</strong></p>

<p><a href='http://1ambda.github.io/java-interview-questions-collection-framework/' >Java Interview Questions - Collection Framework</a>  </p>]]></description><link>http://1ambda.github.io/articles/</link><guid isPermaLink="false">9666f26e-e434-403f-95b1-8e667199693c</guid><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 28 Feb 2015 16:50:51 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, P2P Systems]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<p>P2P 시스템의 기술들은 <em>cloud computing</em> 의 많은 분야에서 활용됩니다. 뒤에서 배울 <em>Chord P2P hashing</em> 같은 경우는 <em>Cassandra</em>, <em>Voldmort</em> 등의 <em>key-value store</em> 에서 쓰이고 있습니다. </p>

<p><br/></p>

<h3 id="napster">Napster</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/napster.png'  alt="" /></p>

<p>최초에 <em>peer</em> 는 서버에게 메세지를 보내 P2P 시스템에 가입했다는 사실을 알립니다.</p>

<p><em>Napster</em> 에서는 중앙에 서버를 두어, 파일이 저장된 <em>peer</em> 를 기록합니다. 각 <em>peer</em> 는 파일이 어디있는지 검색하기 위해 중앙 서버에 질의해야 합니다. 그림에서 볼 수 있듯이, 각 파일은 서버가 아니라 <strong>클라이언트</strong> 에 저장되어 있습니다. 파일이 어느 클라이언트(<em>peer</em>) 에 저장되어있는지 알게되면, <em>ping</em> 을 날려 살아있는지 확인 후 파일을 다운 받습니다. </p>

<p><em>Napster</em> 의 문제점은</p>

<ul>
<li>중앙 서버로의 요청이 너무나 많습니다.</li>
<li><p>서버가 다운되면, 시스템이 멈춥니다.</p>

<p><br/></p></li>
</ul>

<h3 id="gnutella">Gnutella</h3>

<p><em>Gnutella</em> 는 <em>Napster</em> 시스템에서 <strong>서버</strong>를 제거했습니다. 각 클라이언트 (<em>peer</em>) 는 파일이 어디 저장되어있는지 파악하기 위해 서로 통신하지요. 이처럼 클라이언트가 서버처럼 행동하기때문에 <em>servent</em> 라 부르기도 합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella.png'  alt="" /></p>

<p>위 슬라이드에서 알 수 있듯이, 각 피어는 근처에 있는 피어로의 링크를 가지고 있습니다. 이 링크는 <em>overlay graph</em> 라 부르기도 합니다.</p>

<p><em>gnutella</em> 에서 피어간 통신에 사용되는 주요 메세지 타입은</p>

<ul>
<li><strong>Query:</strong> search</li>
<li><strong>QueryHit:</strong> reponse to query</li>
<li><strong>Ping:</strong> to probe network for other peers</li>
<li><strong>Pong:</strong> reply to ping, contains address of another peer</li>
<li><strong>Push:</strong> used to initiate file transfer</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella_header.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella_search_ttl.png'  alt="" /></p>

<p>위 그림에서 <code>TTL = 2</code> 이기 때문에 <em>query</em> 메세지는 <em>2-hop</em> 까지만 전파됩니다. 그리고 <em>gnutella</em> 에서는 각 피어가 최근에 퍼트린 <em>query</em> 메세지 리스트를 유지하고 있기 때문에 같은 메세지를 다시 전파하지 않습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella_queryhit_msg.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/gnutella_queryhit_msg_ex.png'  alt="" /></p>

<p>피어가 보낸 <em>query</em> 에 대해 해당하는 파일을 가지고 있다는 응답은 <em>query hit</em> 메세지를 통해 전달됩니다.</p>

<p><em>gnutella</em> 에서는 과도한 트래픽을 방지하기 위해 다음의 방법을 사용합니다.</p>

<ul>
<li>to avoid duplicate transmissions, each peer maintains a list of recently received messages</li>
<li>query forwarded to all neighbors except peer from which received</li>
<li>each query (identified by <code>DescriptorID</code>) forwarded only once</li>
<li><em>QueryHit</em> routed back only to peer from which <em>Query</em> received with same <code>DescriptorID</code></li>
<li>for flooded messages, duplicates with same <code>DescriptorID</code> and <em>Payload descriptor</em> are dropped</li>
<li><em>QueryHit</em> with <code>DescriptorID</code> for which <em>Query</em> not seen is dropped</li>
</ul>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/after_receiving_queryhit.png'  alt="" /></p>

<p><em>QueryHit</em> 메세지를 <em>requestor</em> 가 받으면 최적의 <em>responder</em> 를 고르고,  <strong>HTTP</strong> 를 이용해서 몇번의 통신을 한 뒤 파일을 전송받습니다. 여기서 <em>gnutella</em> 가 <em>HTTP</em> 를 이용하는 이유는, HTTP 가 <em>standard</em>, <em>well-debugged</em>, <em>widely used</em> 이기 때문입니다.</p>

<p>그런데 만약, <em>responder</em> 가 방화벽(<em>firewall</em>) 뒤에 있으면 어떻게 될까요? 일반적으로 방화벽은 <em>incomming message</em> 를 필터링 합니다. <em>gnutella</em> 는 이럴 경우 대비해 <em>push</em> 를 만들어 놓았습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/dealing_with_firewalls.png'  alt="" /></p>

<p><em>query hit</em> 메세지를 받은 후에 <em>requestor</em> 가 보내는 <em>HTTP</em> 메세지에 <em>responder</em> 가 응답하지 않으면 <em>overlay link</em> (이미 연결되어있는) 을 통해서 <em>push</em> 메세지를 <em>requestor</em> 가 보냅니다. <em>responder</em> 는 방화벽 뒤에 있어도, <em>overlay link</em> 를 통해 받은 <em>push</em> 메세지를 확인하고 파일 전송을 시작합니다.</p>

<p>만약 <em>requestor</em> 가 방화벽 뒤에 있다면, <em>gnutella</em> 프로토콜로는 파일을 전송 받을 수 없습니다.</p>

<p><br/></p>

<p><em>gnutella</em> 에서 생기는 문제점은 </p>

<ul>
<li><em>ping/pong</em> constituted 50% traffic: use multiplex, cache and reduce freq of <em>ping/pong</em></li>
<li>modem-conncted hosts do not have enough bandwidth for passing gnutella traffic: use a central server to act as proxy for such peers. or use <strong>FastTrack System</strong></li>
<li>large number of <em>free loaders</em></li>
<li>flooding causes excessive traffic: use <strong>Structured P2P system</strong> e.g <strong>Chord System</strong></li>
</ul>

<p><br/></p>

<h3 id="fasttrac">FastTrac</h3>

<p><em>FastTrac</em> 은 <em>Kazza</em>, <em>KazzaLite</em>, <em>Grokster</em> 라는 기술을 기반으로 한 <em>Napster</em> <em>Gnutella</em> 의 하이브리드입니다. </p>

<p><em>healthier participants</em> 를 이용하겠다는 기본적인 아이디어로부터 출발했습니다. <em>gnutella</em> 와 비슷하지만 노드중 일부가 <em>supernode</em> 가 되어, 특별한 역할을 수행합니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/fast_trac.jpg'  alt="" /></p>

<ul>
<li><em>supernode</em>는 <em>Napster server</em> 와 비슷하게 근처에 있는 노드의 <code>&lt;file name, peer point&gt;</code> 리스트를 저장합니다</li>
<li><em>supernode</em> 의 멤버십은 시간이 지나면서 변합니다</li>
<li>어떤 노드도 <em>supernode</em> 가 될 수 있습니다. 그러기 위해서는 <em>reputation</em> 을 얻어야 합니다</li>
<li>각 노드는 데이터를 탐색하기 위해 <em>supernode</em> 에 질의합니다</li>
</ul>

<p>이 <em>reputation system</em> 은 <em>Kazaalite</em> 처럼 <em>upload</em> 한 파일의 양으로 결정할 수도 있고, 경제학적인 원리를 적용한 방법도 있습니다</p>

<p><br/></p>

<h3 id="bittorrent">BitTorrent</h3>

<p>이전에 언급했듯이 <strong>다운만 받는 peer</strong> 도 존재할 수 있습니다. <em>BitTorrent</em> 는 업로드 하는 <em>peer</em> 에게 보상을 해 주어, <em>peer</em> 들의 업로드를 더 이끌어 낼 수 있습니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/bit_torrent_network.jpg'  alt="" /></p>

<p><em>BitTorrent</em> 네트워크 구성은 위 슬라이드와 같습니다.</p>

<ul>
<li><strong>Tracker:</strong> 파일당 하나씩 존재하며 <em>heartbeat</em> 를 받아 <em>peer</em> 의 <em>join</em>, <em>leave</em> 를 관리합니다.</li>
<li><strong>Seed:</strong> 전체 파일을 가지고 있는 <em>peer</em> </li>
<li><strong>Leecher:</strong> 파일의 일부분을 가지고 있는 <em>peer</em> </li>
</ul>

<p><em>BitTorrent</em> 에서는 블럭단위로 파일을 전송하는데, 이 때 사용하는 몇 가지 규칙이 있습니다.</p>

<ul>
<li><em>Local Rarest First:</em> 파일을 다운받을때, 귀한 블럭부터 먼저 받습니다</li>
<li><em>Tit for tat:</em> 업로드 하는 만큼, 다운로드 <em>bandwidth</em> 를 할당받습니다. 다시 말해서 업로드를 많이해야 빠르게 받을 수 있습니다</li>
<li><em>Choking:</em> 동시에 업로드하는 <em>neighbor</em> 수를 제한해서 <em>bandwidth</em> 가 너무 많이 사용되지 않도록 합니다. <em>best neighbor</em> 를 선택하여 <em>unchoked set</em> 을 유지하고, 주기적으로 이 집합을 재평가합니다. 이외의 다른 <em>peer</em> 는 <em>choked set</em> 입니다. </li>
</ul>

<p><em>optimistic unchoke</em> 기법은 주기적으로 랜덤한 <em>neighbor</em> 를 <em>unchoke</em> 해서, <em>unchoked set</em> 을 <em>fresh</em> 하게 유지합니다. 여기서 <em>random choice choking</em> 을 쓰는 이유는</p>

<ul>
<li>To avoid the sysem from getting stuck where only a few peers receive service</li>
</ul>

<p><br/></p>

<h3 id="dht">DHT</h3>

<p>지금까지 본 <em>Napster</em>, <em>Gnutella</em>, <em>FastTrac</em> 은 일종의 <em>DHT, Distribute Hash Table</em> 입니다.</p>

<p><em>DHT</em> 에서의 <em>performance concerns</em> 는</p>

<ul>
<li>load balancing</li>
<li>fault-tolerance</li>
<li>efficiency of lookup and inserts</li>
<li>locality</li>
</ul>

<p>우리가 배울 <em>Chord</em> 는 이런 구조가 적용된 <em>structured peer to peer system</em> 입니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/performance_comparison_nap_gnu.jpg'  alt="" /></p>

<p><em>Napster</em> 는 <em>peer</em> 의 경우 파일을 저장하지 않기 때문에 메모리가 많이 들지 않지만, <em>server</em> 에서 많은 메모리를 요구합니다. 서버로 질의가 가기때문에 <em>lookup latency</em> 나 <em>lookup</em> 을 위한 메세지 수 자체는 많지 않지만, 서버의 부하가 상당히 심할 수 있습니다.</p>

<p>반면 <em>Gnutella</em> 에서는 서버가 없습니다. 그렇기 때문에 피어는 파일이 저장되어있는 주변 피어의 목록을 가지고 있어야 하는데, <code>N</code> 만큼의 이웃이 주변에 있을 수 있습니다. 따라서 한 피어에서 필요한 메모리 양은 <code>O(N)</code> 입니다.</p>

<p>그리고 네트워크가 직선으로 구성되어 있다고 할때, <em>lookup latency</em> 는 <code>O(N)</code> (<code>N-1</code>) 이고 룩업을 위한 메세지 수도 <code>O(N)</code> (<code>2(N-1)</code>) 입니다.</p>

<p>반면 <em>Chord</em> 는 모두 <code>O(log N)</code> 입니다. 이론적으로 <em>constant</em> 는 아니지만, <em>real world</em> 에서는 상당히 낮은 수가 될 수 있습니다.</p>

<p><br/></p>

<h3 id="chord">Chord</h3>

<p><em>Chord</em> 는 <em>Berkeley</em> 와 <em>MIT</em> 에서 개발된 <em>P2P</em> 프로토콜입니다.<em>latency</em> 와 <em>message cost of routing</em> (<em>lookups</em>/<em>inserts</em>) 를 줄이기 위해 지능적으로 <em>neighbor</em> 를 선택하고 <em>Consistent Hashing</em> 기법을 사용합니다.</p>

<p><em>Consistent Hasing</em> 값은 <em>peer</em> 에 부여되는 주소값으로</p>

<ul>
<li>IP 와 Port로 <em>SHA1</em> 로 해싱해서 160 비트 스트링을 만들고 </li>
<li><code>m</code> 비트로 절단해서 사용합니다</li>
<li><em>peer</em> 의 <em>ID</em> 라 불리기도 하는데, 이 값은 당연히 최대 <code>2^m - 1</code> 입니다</li>
<li>해싱값이므로 <em>unique</em> 하진 않지만 충돌이 일어날 확률은 굉장히 적습니다</li>
<li>그리고 이 값이 <code>2^m</code> 개의 점이 되어 하나의 원을 구성합니다</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/ring_of_peers.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_finger_table.png'  alt="" /></p>

<p>각 노드는 (반) 시계방향으로의 <em>successor</em> 를 가지고 있고, 다른 노드를 가리키기 위한 <em>finger table</em> 을 가지고 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_file_saving.png'  alt="" /></p>

<p>파일도 마찬가지로 <em>SHA-1</em> 으로 해싱해서, 160 비트로 짜른 뒤 <code>mod 2^m</code> 연산해서, 같은 값이거나 그보다 큰 값을 가지는 <em>peer</em> 에 저장합니다.</p>

<p>만약 균일하게 해싱된다면 <code>K</code> 개의 키, <code>N</code> 개의 피어에서 파일은 각 피어당 <code>K/N</code> 개씩 저장되므로 피어당 걸리는 부하는 <code>O(K/N)</code> 입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_search_process.png'  alt="" /></p>

<p>위 그림에서 <code>N80</code> 피어가 <code>K42</code> 파일을 찾을때, </p>

<ul>
<li><em>finger table</em> 에 <code>42</code> 가 없으므로 최대한 먼 <code>N16</code> 에 질의하고, </li>
<li><code>N16</code> 은 <code>N32</code> 와 <code>N80</code> 밖에 모르므로 <code>N32</code> 를 거쳐 <code>N45</code> 로 질의합니다.</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_search_analysis.png'  alt="" /></p>

<p><em>chrod search</em> 는 <code>O(log N)</code> 의 시간이 듭니다. 증명에 대한 <em>intuition</em> 은 쉽습니다.</p>

<p>만약 현재 <code>Here</code> 에서 <code>Key</code> 를 모른다고 합시다. 그러면 그 거리의 <code>1/2</code> 만큼은 점프를 해야합니다. 그것보다 더 적게 점프하면 거리를 <code>d</code> 라 합시다. <em>finger table entry</em> 값은 2배씩 증가하기 때문에, <code>2d</code> 만큼 점프할 수 있는 엔트리가 있어야 하고, 그럼 애초부터 <code>2d</code> 만큼 점프했어야 했기 때문에 모순입니다.</p>

<p><code>log(N)</code> 만큼의 점프 뒤에는 <em>key</em> 까지의 거리는 아무리 멀어봐야 <code>2^m / N</code> 입니다. 균일하게 분포되는 해싱을 쓴다 가정하면, 이 사이에는 적은 수의 노드만 있습니다. 따라서 <code>O(logN)</code> 만큼만 더 점프한다면 높은 확률로 <em>key</em> 를 찾을 수 있습니다. <code>O(logN) + O(logN) = O(logN)</code> 이므로, <em>search</em> 는 <code>O(logN)</code> 입니다.</p>

<p><em>insertion</em> 도 <em>searching</em> 과 마찬가지로 <code>O(logN)</code> 입니다. 그러나 이 성능은 <em>finger table</em> 과 <em>successor</em> 가 잘못되지 않았을 경우에만 참입니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_multiple_successor.png'  alt="" /></p>

<p><em>chrod</em> 는 <em>successor</em> 한개만 가질땐 <em>failure</em> 에 취약하기 때문에, 위 그림처럼 다수개의 <em>successor</em> 를 가질 수 있습니다. 이 경우 성능은 어떻게될까요?</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/multiple_successor_analysis.png'  alt="" /></p>

<p><code>2log(N)</code> 개의 <em>successor</em> 를 유지할 경우를 한번 생각해 봅시다. <code>50%</code> 씩 <em>failure</em> 가 발생하면</p>

<ul>
<li>하나의 노드에서 유지하는 <em>successor</em> 중, 적어도 하나의 <em>successor</em> 가 살아있을 확률은</li>
</ul>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%28%7B1%20%5Cover%202%7D%29%5E%7B2logN%7D%20%3D%201%20-%20%7B1%20%5Cover%20N%5E2%7D'  alt="" /></p>

<ul>
<li>위 확률은 모든 살아있는 노드(<code>50%</code>) 에서 참일때, 다시 말해서 모든 노드에서 적어도 하나의 <em>successor</em> 가 존재할 확률은 <code>N</code> 이 매우 클때</li>
</ul>

<p><img src='http://latex.codecogs.com/gif.latex?%281%20-%20%7B1%20%5Cover%20N%5E2%7D%29%5E%7BN/2%7D%20%3D%20e%5E%7B-%7B1%5Cover%202N%7D%7D%20%5Capprox%201'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_joining.png'  alt="" /></p>

<ul>
<li>a new peer affects <code>O(logN)</code> other finger entires in the system, on average</li>
<li>number of messages per peer join <code>O(logN * logN)</code></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/chord_stabilization_protocol.png'  alt="" /></p>

<p><em>join</em>, <em>leave</em>, <em>failure</em> 등 <em>churn</em> 이 자주 일어나므로 <em>loop</em> 가 있는지 없는지 검사하기 위해 주기적으로 <em>stabilization protocol</em> 를 사용합니다.</p>

<p><br/></p>

<h3 id="pastry">Pastry</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/pastry_routing.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/pastry_locality.png'  alt="" /></p>

<p><em>Pastry</em> 는 <em>chord</em> 처럼 <em>node</em> 에 <em>id</em> 를 부여합니다. <em>routing table</em> 은 <em>prefix matching</em> 에 기반하기 때문에 <code>log(N)</code> 의 성능을 보여줍니다. 그리고 짧은 <em>prefix</em> 일 수록 가까이에 있을 확률이 높습니다.</p>

<p><br/></p>

<h3 id="kelips">Kelips</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/kelips.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/kelips2.png'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/kelips3.png'  alt="" /></p>

<p><em>Kelips</em> 는 <em>1-hop lookup</em> 을 보여줍니다. 이럴 수 있는 이유는 위 그림에서 보듯이 <em>affinity group</em> 이란걸 사용하기 때문입니다. 루트 <code>N</code> 에 가까운 숫자 <code>k</code> 를 정하고, 이 수로 <code>mod</code> 연산을 해, 그룹을 만듭니다. 각각의 그룹은 내에 있는 모든 노드는 서로 어떤 파일을 저장하는지 알고 있습니다. 그리고 각 노드는 다른 그룹으로의 링크를 하나씩 가지고 있습니다. 따라서 어딜가든 거의 1번 혹은 2번 내에 <em>lookup</em> 이 가능합니다.</p>

<p><em>chord</em> 에 비해 메모리를 더 잡아먹긴 합니다. <code>O(logN)</code> 보단 많은 양이지만, 그렇게 많지도 않습니다. 메모리가 귀하다면 <em>chord</em> 나 <em>pastry</em> 를, 그렇지 않고 <em>lookup</em> 속도가 중요하다면 <em>kelips</em> 를 사용하면 됩니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week3/kelips4.png'  alt="" /></p>

<p><em>membership</em> 은 <em>gossip-based</em> 프로토콜로 관리할 수 있습니다. </p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-p2p-systems/</link><guid isPermaLink="false">6e527ab7-0598-4177-b199-dd4ef466f537</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[P2P]]></category><category><![CDATA[Napster]]></category><category><![CDATA[Gnutella]]></category><category><![CDATA[BitTorrent]]></category><category><![CDATA[FastTrack]]></category><category><![CDATA[Chord]]></category><category><![CDATA[Pastry]]></category><category><![CDATA[Kelips]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 28 Feb 2015 16:18:25 GMT</pubDate></item><item><title><![CDATA[Java Interview Questions, Collection Framework]]></title><description><![CDATA[<p><img src='http://4.bp.blogspot.com/_b6abT-2H2yE/TSTixbyU8GI/AAAAAAAAAUU/LcqDidb_liw/s1600/screen-capture-1.png'  alt="" /></p>

<p><br/></p>

<h3 id="general">General</h3>

<p>(1) <strong>Explain Collections Hierarchy?</strong></p>

<p><img src='http://2.bp.blogspot.com/-M0M8nv5s2lQ/U3BcbRQcRvI/AAAAAAAAAec/oBBmQCPDm9Y/s1600/Collection-Classes.tif'  alt="" /></p>

<p><img src='http://4.bp.blogspot.com/-o9Jk4Z4Tohs/U3Be46CxGTI/AAAAAAAAAeo/Wq8-hhZ8dCA/s1600/Collection-Classes_Map.tif'  alt="" /></p>

<p align="center">(<a href='http://www.java-redefined.com/' >http://www.java-redefined.com</a>)</p>

<p>크게 보면 <em>Collection</em> 과 <em>Map</em> 인터페이스로 구분되어 있습니다. </p>

<ul>
<li><code>Map</code> 은 <em>key-value pair</em> 컨테이너이기 때문에 단일 원소에 대한 컨테이너인 <code>Collection</code> 과 호환되지 않습니다.</li>
<li><code>Set</code> 은 중복된 원소를 허용하지 않습니다.</li>
<li><code>Set</code> 과 <code>Map</code> 에 정렬 기능이 필요하면 <code>SortedSet</code>,  <code>SortedMap</code> 인터페이스 구현체인 <code>TreeMap</code>, <code>TreeSet</code> 등을 이용할 수 있습니다.</li>
</ul>

<p>(2) How do you remove an entry from a collection? and subsequently what is difference between <code>Collection.remove()</code> and <code>Iterator.remove()</code>, which one you will use, while removing elements during iteration?</p>

<p>아래에서 언급하겠지만 <em>fail-fast</em> 와 관련된 문제입니다. 만약 순회하고 있지 않다면 <code>Collection.remove()</code> 를 사용해도 상관 없지만</p>

<p><em>iterator</em> 를 이용해서 순회하는 동안 컬렉션의 <code>remove()</code> 메소드를 이용하면 <code>ConcurrentModificationException</code> 예외가 발생합니다.  따라서 <code>Iterator.remove()</code> 를 이용해야 합니다. <a href='http://stackoverflow.com/questions/14200489/collection-iterator-remove-vs-collection-remove' >SO 답변</a>에서도 그 이유를 찾을 수 있습니다.</p>

<pre><code class="java">// invalid
List&lt;Integer&gt; l = new ArrayList&lt;Integer&gt;(Arrays.asList(1, 2, 3, 4));  
for (int el : l) {  
  if (el &lt; 3) {
      l.remove(el);
  }
}

// correct way
Iterator&lt;Integer&gt; it = l.iterator();  
while (it.hasNext()) {  
  int el = it.next();
  if (el &lt; 3) {
      it.remove();
  }
}
</code></pre>

<p><br/></p>

<h3 id="listinterfacerelated">List interface related</h3>

<ul>
<li><code>List</code> 는 중복된 원소를 허용하며 <em>ordered elements</em> 를 담는 컨테이너입니다. 때때로 <em>Sequence</em> 라 불리기도 합니다. </li>
</ul>

<p>(1) <code>Vector</code> vs <code>ArrayList</code> vs <code>LinkedList</code></p>

<ul>
<li><code>Vector</code> 의 모든 메소드는 <em>동기화 (synchronized)</em> 됩니다. <code>ArrayList</code> 는 <em>thread-unsafe</em> 합니다.</li>
<li><code>Vector</code> 는 <em>JDK</em> 첫 릴리즈부터 포함되어있던 레거시 클래스고, <code>ArrayList</code> 는 <em>JDK 1.2</em> 에서 컬렉션 프레임워크 도입과 함께 추가되었습니다.</li>
<li><em>default</em> 로 <code>Vector</code> 는 두배씩 사이즈가 커지는 반면, <code>ArrayList</code> 는 <em>50%</em> 씩 증가합니다.</li>
<li><code>LinkedList</code> 도 <em>thread-unsafe</em> 하기 때문에 대신 <a href='http://docs.oracle.com/javase/6/docs/api/java/util/concurrent/ConcurrentLinkedQueue.html' >ConcurrentLinkedQueue</a> 나 <a href='http://docs.oracle.com/javase/6/docs/api/java/util/concurrent/LinkedBlockingDeque.html' >LinkedBlockingDeque</a> 를 이용할 수 있습니다.</li>
</ul>

<p>(2) What is different between <code>Iterator</code> and <code>ListIterator</code></p>

<ul>
<li><code>Iterator</code> 를 이용해 <code>Set</code> 등 컬렉션을 순회할 수 있지만 <code>ListIterator</code> 는 <code>List</code> 밖에 못 합니다</li>
<li><code>Iterator</code> 는 <em>forward-only</em> 지만, <code>ListIterator</code> 는 양방향 순회가 가능합니다</li>
<li><code>ListIterator</code> 는 <em>add</em>, <em>replace</em>, <em>getting index position</em> 등의 기능이 더 있습니다. </li>
</ul>

<p>참고로 <em>iterator</em> 를 이용해 리스트를 순회하는 방법은</p>

<pre><code class="java">List&lt;String&gt; strList = new ArrayList&lt;&gt;();  
Iterator&lt;String&gt; it = strList.iterator();

while(it.hasNext()){  
  String obj = it.next();
  System.out.println(obj);
}
</code></pre>

<p><br/></p>

<h3 id="setinterfacerelated">Set interface related</h3>

<p><code>Set</code> 은 <em>uniqueness of elements</em> 를 보장합니다. 따라서 중복된 원소를 허용하지 않습니다. 만약 <em>ordering</em> 이 있는 <code>Set</code> 을 사용하고 싶다면 구현체로 <code>TreeSet</code> 을 선택하면 됩니다.</p>

<p>(1) <strong>How HashSet store elements?</strong></p>

<p><code>HashSet</code> 은 <em>uniqueness</em> 를 보장하기 위해 내부적으로 <code>Map</code> 을 이용합니다. <em>key-value</em> 를 저장하나, 모든 <em>value</em> 를 같게끔 하죠.</p>

<pre><code class="java">private transient HashMap&lt;E, Object&gt; map;  
// This is added as value for each key
private static final Object PRESENT = new Object();

public boolean add(E e) {  
  return map.put(e, PRESENT) == null;
}
</code></pre>

<p>(2) Can a null element added to a <code>TreeSet</code> or <code>HashSet</code>?</p>

<p><code>HashMap</code>, <code>HashSet</code> 은 하나의 <em>null-key</em> 를 허용하지만, <code>TreeSet</code>, <code>TreeMap</code> 은 <em>null-key</em> 를 허용하지 않습니다. </p>

<p><code>TreeMap</code> 은 <code>NavigableMap</code> 의 구현이고, <code>TreeSet</code> 은 내부적으로 <code>NavigableMap</code> 을 사용합니다. 그런데 <code>NavigableMap</code> 이 <em>null-key</em> 를 허용하지 않기 때문에, <code>TreeSet</code>, <code>TreeMap</code> 도 그렇습니다.</p>

<p><br/></p>

<h3 id="mapinterfacerelated">Map interface related</h3>

<p><code>Map</code> 은 <em>key-value pair</em> 를 저장하기 위해 사용합니다. <code>Map</code> 인터페이스 구현체로 <code>HashMap</code>, <code>LinkedHashMap</code>, <code>HashTable</code>, <code>EnumMap</code>, <code>IdentityHashMap</code>, <code>Properties</code> 가 있습니다.</p>

<p>(1) Difference between <code>HashMap</code> and <code>HashTable</code></p>

<ul>
<li><code>HashTable</code> 은 <em>동기화 (synchronized)</em> 되지만, <code>HashMap</code> 은 그렇지 않습니다.</li>
<li><code>HashTable</code> 은 <em>null-key</em> 나 <em>null-value</em> 를 허용하지 않습니다.</li>
<li><code>HashMap</code> 의 <em>iterator</em> 는 <strong>fail-fast</strong> 인 반면 <code>HashTable</code> 의 <em>enumerator</em> 는 그렇지 않습니다.</li>
</ul>

<p>참고로, <em>iterator</em> 는 <em>iteration</em> 동안 <em>caller</em> 가 <code>remove</code> 메소드를 이용해서 원소를 제거할 수 있지만, <em>enumerator</em> 를 이용할때는 원소를 추가하거나 제거할 수 없습니다. 이런 기능 차이 때문에 <em>enumerator</em> 가 기본적인 기능만 가지고 있고 더 빠릅니다. 또 다른 차이점은 <em>enumerator</em> 는 <code>Stack</code>, <code>Vector</code> 처럼 레거시 클래스에 대해 사용합니다.</p>

<p>(2) What are <code>IdentityHashMap</code> and <code>WeakHashMap</code>?</p>

<p>이부분은 <a href='http://howtodoinjava.com/2013/07/09/useful-java-collection-interview-questions/' #identityHashMap_weakHashMap_differences">원문</a>을 첨부합니다.</p>

<blockquote>
  <p><strong>IdentityHashMap</strong> is similar to HashMap except that <strong>it uses reference equality when comparing elements</strong>. IdentityHashMap class is not a widely used Map implementation. While this class implements the Map interface, it intentionally violates Map’s general contract, which mandates the use of the equals() method when comparing objects. IdentityHashMap is designed for use only in the rare cases wherein reference-equality semantics are required.</p>
  
  <p><strong>WeakHashMap</strong> is an implementation of the Map interface that <strong>stores only weak references to its keys</strong>. Storing only weak references allows a key-value pair to be garbage collected when its key is no longer referenced outside of the WeakHashMap. This class is intended primarily for use with key objects whose equals methods test for object identity using the == operator. Once such a key is discarded it can never be recreated, so it is impossible to do a look-up of that key in a WeakHashMap at some later time and be surprised that its entry has been removed.</p>
</blockquote>

<p><br/></p>

<h3 id="morequestions">More Questions</h3>

<p>(1) What do you understand by iterator <strong>fail-fast</strong> property?</p>

<p><strong>fail-fast iterator</strong> 는 <em>iteration</em> 이 시작된 이후로 <em>collection</em> 이 변경되는걸 알아채는 순간 <code>ConcurrentModificationException</code> 을 던지면서 멈춥니다. 여기서 <em>변경</em> 이란 한 스레드가 컬렉션을 순회하는 동안, 컬렉션에 있는 원소의 삭제, 변경 혹은 추가가 일어나는 것을 말합니다.</p>

<p><em>fail-fast</em> 는 <em>modification count</em> 란 것을 유지하고 있다가, <em>iteration thread</em> 가 <em>modification count</em> 의 변경을 알아채면 예외를 던지는 방식으로 구현됩니다.</p>

<p>(2) What is difference between <strong>fail-fast</strong> and <strong>fail-safe</strong></p>

<p><strong>fail-safe iterator</strong> 는 복사본에 대해 컬렉션 순회를 진행하기 때문에 원본에 변경이 일어나도 멈추지 않습니다. 일반적으로 <code>java.util.concurrent</code> 에 있는 클래스들의 (e.g <code>ConcurrentHashMap</code> 이나 <code>CopyOnWriteArrayList</code>) <em>iterator</em> 가 <em>fail-safe</em> 입니다.</p>

<p>(3) How to avoid <code>ConcurrentModificationException</code> while iterating a collection?</p>

<ul>
<li>먼저 <em>fail-safe iterator</em> 를 사용할 수 있는지 확인합니다 <em>JDK 1.5</em> 이상을 사용한다면, <code>ConcurrentHashMap</code> 이나 <code>CopyOnWriteArrayList</code> 를 사용할 수 있습니다.</li>
</ul>

<p>위 방법이 불가능하면 다음을 고려할 수 있으나, 퍼포먼스가 떨어질 수 있다는 점을 유의해야 합니다. </p>

<ul>
<li><em>list</em> 를 <em>array</em> 로 바꾸어, 순회합니다</li>
<li><em>list</em> 를 순회하는 동안 <em>synchronized block</em> 을 이용해 <em>lock</em> 을 겁니다.</li>
</ul>

<p>(4) What is difference between Synchronized Collection and Concurrent Collection?</p>

<p><em>Java 5</em> 와 함께 <code>ConcurrentHashMap</code>, <code>CopyOnWriteArrayList</code>, <code>BlockingQueue</code> 등의 <em>concurrent collection</em> 클래스들이 추가 되었습니다. 이 클래스들은 <em>synchronized collection</em> 보다 성능이 더 나은데, 이는 일부분에만 <em>lock</em> 을 걸기 때문입니다. 더 자세한 내용은 <a href='http://javarevisited.blogspot.kr/2011/04/difference-between-concurrenthashmap.html' >여기로</a></p>

<p>(5) What is <code>Comparable</code> and <code>Comparator</code>?</p>

<p>자바에서 <code>TreeSet</code> 이나 <code>TreeMap</code> 처럼 <em>automatic sorting</em> 기능이 있는 모든 컬렉션은 <code>compare</code> 메소드를 사용합니다. </p>

<p>이 때 <em>element class</em> 는 정렬을 위해 <code>Comparator</code> <strong>또는</strong> <code>Comparable</code> 인터페이스를 반드시 구현해야 합니다. <em>wrapper class</em> 인 <code>Integer</code>, <code>Double</code> 등이 <code>Comparable</code> 인터페이스를 구현하는 이유가 바로 이것입니다.</p>

<p><code>Comparable</code> 은 원소가 컬렉션에 추가될때 자동적으로 정렬되도록 (<em>natural sorting</em>) 하기 위해 사용하고, <code>Comparator</code> 는 추가적인 정렬방법을 이용하기 위해 정의할 수 있습니다. <a href='http://www.java2blog.com/2013/02/difference-between-comparator-and.html' >여기</a>서 가져온 예제를 보면</p>

<pre><code class="java">// Comparable
public class Country implements Comparable&lt;Country&gt;{  
       @Override
    public int compareTo(Country country) {
        return (this.countryId &lt; country.countryId ) ? -1: (this.countryId &gt; country.countryId ) ? 1:0 ;
}} 

// Comparator

Country indiaCountry=new Country(1, "India");  
Country chinaCountry=new Country(4, "China");  
Country nepalCountry=new Country(3, "Nepal");  
Country bhutanCountry=new Country(2, "Bhutan");  
        
List&lt;Country&gt; listOfCountries = new ArrayList&lt;Country&gt;();  
listOfCountries.add(indiaCountry);  
listOfCountries.add(chinaCountry);  
listOfCountries.add(nepalCountry);  
listOfCountries.add(bhutanCountry); 

Collections.sort(listOfCountries,new Comparator&lt;Country&gt;() {  
  @Override
  public int compare(Country o1, Country o2) {
    return o1.getCountryName().compareTo(o2.getCountryName());
  }
});
</code></pre>

<p><br/></p>

<h3 id="references">References</h3>

<p>(1) <a href='http://howtodoinjava.com/2013/07/09/useful-java-collection-interview-questions/' #why_map_not_extend_collection">Useful Java Collection Interview Questions</a> <br />
(2) <a href='http://websphereemerge.blogspot.kr/' >Title Image</a> <br />
(3) <a href='http://www.java-redefined.com/2014/05/java-collection-interview-questions.html' >http://www.java-redefined.com</a> <br />
(4) <a href='http://www.java2blog.com/2013/02/difference-between-comparator-and.html' >http://www.java2blog.com/</a> <br />
(5) <a href='http://www.javatpoint.com/java-collections-interview-questions' >http://www.javatpoint.com</a> <br />
(6) <a href='http://stackoverflow.com/questions/14200489/collection-iterator-remove-vs-collection-remove' >SO:  Iterator.remove() vs Collection.remove()</a></p>]]></description><link>http://1ambda.github.io/java-interview-questions-collection-framework/</link><guid isPermaLink="false">617c586a-498c-458f-aad2-67156cb56b52</guid><category><![CDATA[collection]]></category><category><![CDATA[java]]></category><category><![CDATA[interview]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 22 Feb 2015 16:27:11 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, Membership Protocol]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<p>왜 <em>membership</em> 이란 개념이 클라우드 컴퓨팅에 필요할까요? </p>

<p>한 노드가 <em>OS</em>, <em>Disk</em>, <em>Network</em> 등 때문에 10년 (120개월) 마다 한 번씩 고장난다고 합시다. 그러면 120개의 노드를 가지고 있다면 1개월마다  한 번씩입니다. 이정도는 참을만하죠? 그런데, 12,000 개의 서버를 가지고 있다면 <em>MTTF (mean time to failure)</em> 는 7.2 시간마다 한번씩입니다. 이건 큰 문제입니다. </p>

<p>따라서 머신이 멀쩡한지 아닌지를 수동이 아니라 자동으로 판단하고 보고해줄 시스템이 필요합니다. <em>membership</em> 이 필요한 것이죠. 이 대상은</p>

<p>(1) Process <em>group</em>-based systems</p>

<ul>
<li>Clouds / Datacenters</li>
<li>Replicated servers</li>
<li>Distributed databases</li>
</ul>

<p>(2) Cash-stop / Fail stop process failures</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/membership1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/membership2.jpg'  alt="" /></p>

<p>멤버십 프로토콜은 다음처럼 구성되어 있습니다.</p>

<ul>
<li>멤버쉽 리스트 (<em>complete</em>, <em>almost-complete</em>, <em>partial-random</em>)</li>
<li><em>dissemination</em> mechanism to inform about joins, leavs, and failures of processes</li>
<li><em>failure detector</em></li>
</ul>

<p><br/></p>

<h3 id="failuredetector">Failure Detector</h3>

<p><em>distributed failure detector</em> 를 평가할 수 있는 지표는</p>

<ul>
<li><strong>Completeness:</strong> each failure is detected</li>
<li><strong>Accuracy:</strong> there is no mistaken detection</li>
<li><strong>Speed:</strong> time to first detection of a failure</li>
<li><strong>Scale:</strong> equal load on each member. network message load</li>
</ul>

<p>안타깝게도 <em>completeness</em> 와 <em>accuracy</em> 를 <em>lossy network</em> 에서 동시에 추구할 수 없다는 사실이 밝혀졌습니다. (<em>Chandra and Toueg</em>) </p>

<p>현실적으로는</p>

<ul>
<li><em>completeness:</em> 100% guaranteed</li>
<li><em>accuracy:</em> partial / probabilistic guarantee</li>
</ul>

<p><br></p>

<p>(1) Centralized Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/centralized_heartbeating.jpg'  alt="" /></p>

<p>중앙 집중형이기 때문에 <em>load</em> 가 한쪽으로만 쏠린다는 단점이 있습니다.</p>

<p>(2) Ring Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/ring_heartbeating.jpg'  alt="" /></p>

<p>링 형태로 구성되었기때문에 동시에 발생하는 다수개의 <em>failure</em> 를 탐지하지 못합니다.</p>

<p>(3) All To All Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/all2all_heartbeating.jpg'  alt="" /></p>

<p>우선 <em>equal load</em> 라는 장점이 있습니다. 개별 노드당 오버헤드가 큰 것처럼 보이는데, 뒤에서 다시 한번 보겠지만 사실 그렇게 크지 않습니다. </p>

<p>(4) Gossip-Style Membership</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_heartbeating1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_heartbeating2.jpg'  alt="" /></p>

<p><em>accuracy</em> 가 높다는 장점이 있습니다.</p>

<p>동작 방식은 이렇습니다. <em>hearbeat</em> 가 <code>T_fail</code> 초 후에도 증가하지 않으면, 해당 멤버는 <em>failure</em> 를 일으킨 것으로 판별됩니다. 그리고 멤버 리스트에서는 <code>T_cleanup</code> 초 후에 제거됩니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/why_cleanup_time1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/why_cleanup_time2.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/why_cleanup_time3.jpg'  alt="" /></p>

<p>왜 바로 제거하지 않고, <code>T_cleanup</code> 초 후에 제거할까요? 이는 위 슬라이드에서 볼 수 있듯이 <code>3</code> 번 노드가 <em>failure</em> 를 일으켰을때, <code>2</code> 번 노드의 멤버 리스트에서 바로 제거한다면 <code>1</code> 번 노드로부터 업데이트를 받아 멤버 리스트에 <em>failure</em> 가 발생하지 않은것처럼 추가될 수 있기 때문입니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_membership_analysis.jpg'  alt="" /></p>

<p><code>T_gossip</code> 이 줄면, <em>bandwidth</em> 를 많이 잡아먹는 대신, <em>detection time</em> 이 줄어듭니다. <em>trade-off</em> 라 보면 되겠습니다.</p>

<p>그리고 <code>T_fail, T_cleanup</code> 이 증가하면 <em>false positive rate</em> 는 줄어드는 대신, 당연히 <em>detection time</em> 이 늘어납니다.</p>

<p><br/></p>

<p>그러면 위에 나온 것 중 어느것이 가장 좋은 <em>failure detector</em> 일까요? 앞서 언급했던 기준들을 이용해서 살펴보겠습니다.</p>

<ul>
<li><em>Completeness:</em> guarantee always</li>
<li><em>Accuracy:</em> a prob of mstake in time T <code>PM(T)</code></li>
<li><em>Speed:</em> <code>T</code> time units</li>
<li><em>Scale:</em> <code>N*L</code> Compare this across protocols</li>
</ul>

<p>(1) All-To-All Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/performance_all2all.jpg'  alt="" /></p>

<p><em>work load</em> 가 <code>N</code> 에 비례합니다.</p>

<p>(2) Gossip-Style Heartbeating</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/performance_gossip.jpg'  alt="" /></p>

<p><code>tg</code> 를 <code>O(n)</code> 의 <em>gossip message</em> 를 보내는데 걸리는 <em>gossip period</em> 라 했을때, 한 <em>round</em> 에서의 전파 시간인 <code>logN</code> 을 곱해 <code>T = logN * tg</code> 입니다. 이때 오버헤드 <code>L = N/tg</code> 이므로, <code>L = N * logN / T</code> 입니다. </p>

<p>오버헤드가 <em>all-to-all heartbeating</em> 보다 훨씬 높죠? 이는 <em>accuracy</em> 가 더 높기 때문입니다. 앞에서 <em>all-to-all</em> 가 더 비용이 많이 들것 같지만 실제로는 그렇지 않다고 했었는데, 이런 이유에서입니다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/suboptimal_worstcase.jpg'  alt="" /></p>

<ul>
<li><em>worst case load per member</em> <code>L*</code> 라 하고</li>
<li><code>P_ml</code> 을 독립적인 메시지 손실양 이라고 했을때, </li>
</ul>

<p><code>L*</code> 을 <code>T, PM(T), P_ml</code> 의 함수로 표시하면 </p>

<p><img src='http://latex.numberempire.com/render?L%2A%20%3D%20%7B%20log%28PM%28T%29%29%20%5Cover%20log%28P_ml%29%20%7D%20%2A%20%7B1%20%5Cover%20T%20%7D&amp;sig=b21744720873bd544c3b394bd827b158'  alt="" /></p>

<p>메시지 손실 <code>P_ml</code> 이 높을수록, 오버헤드 <code>L*</code> 는 당연히 작아져야 하고, <code>PM(T)</code> 가 높을수록 <em>false-positive</em> 가 많으므로 오버헤드가 높습니다. 수식을 보면 변수 <code>N</code> 이 없는데, 이는 <em>scale-free</em> 함을 보여줍니다.</p>

<p>그리고 <em>all-to-all</em> 이나 <em>gossip-based</em> 는 <strong>suboptimal</strong> 입니다. 왜냐하면 </p>

<ul>
<li><code>L = O(N/T)</code></li>
<li>try to achieve simultaneous detection at all processes</li>
<li>fail to distinguish <strong>failure detection</strong> and <strong>dissemination components</strong></li>
</ul>

<p>따라서 두개의 컴포넌트를 분리하고, <em>non heatbeat-based failure detection</em> 을 이용하면 됩니다.</p>

<p><br/></p>

<h3 id="swimfailuredetector">SWIM Failure Detector</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_intro.jpg'  alt="" /></p>

<p><em>SWIM</em> 은 <em>probabilistic failure detector protocol</em> 입니다. </p>

<p><em>period</em> <code>T</code> 동안 프로세스(노드) <code>pi</code> 는 <code>pj</code> 를 랜덤하게 골라 <em>ping</em> 을 보냅니다. <em>ack</em> 가 오면, 남은 <em>period</em> 동안 아무것도 하지 않습니다. 그러나 위 슬라이드에서 볼 수 있듯이 <code>pj</code> 가 응답하지 않으면 랜덤하게 <code>K</code> 개의 프로세스를 선택해서, <em>ping</em> 을 날리고, 이를 통해 <em>indirect</em> 한 방법으로 <code>pj</code> 의 응답을 검사합니다.</p>

<p><em>SWIM</em> 의 퍼포먼스는 <em>heartbeat</em> 와 비교했을때 어떨까요?</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_vs_heartbeating.jpg'  alt="" /></p>

<p><code>X</code> 축은 <strong>process load</strong>, <code>Y</code> 축은 <em>first detection time</em> 입니다. <em>false-positive rate</em> 와 <em>message loss rate</em> 는 고정되어있다고 가정합니다.</p>

<p><em>heartbeat</em> 의 경우에는 앞서 봤듯이 <em>detection time</em> 읖 높이면 <em>work load</em> 가 낮아지고 (= <em>low bound on the bandwidth</em>), 반대로 <em>detection time</em> 을 낮추면, <em>work load</em> 가 높아집니다. 반면 <em>SWIM</em> 은 둘다 적죠.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_parameters.jpg'  alt="" /></p>

<p>슬라이드에서 볼 수있듯이 <em>first detection time</em>, <em>process load</em> 는 <em>constant</em> 입니다. <em>process load</em> 의 경우에는 <em>15% packet loss</em> 가 있을때 <em>optimal</em> 의 8배인 <code>8L*</code> 보다 적습니다.</p>

<p><em>false positive rate</em> 는 <code>K</code> 를 증가시켜서 줄일 수 있습니다. <code>K</code> 가 증가함에 따라 <em>false positive rate</em> 는 지수적으로 감소합니다. </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_accuracy_load.jpg'  alt="" /></p>

<p><del>쿨하게 페이퍼를 보시라는 교수님</del></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/SWIM_detection_time.jpg'  alt="" /></p>

<p>어째서 <em>expected detection time</em> 이 <code>1 / e-1</code> 일까요? 하나의 프로세스가 죽었을때, 핑 되려면 다른 프로세스의 멤버쉽 리스트에 있어야 하고, 랜덤하게 선택되야 합니다. </p>

<p>랜덤하게 선택될 확률은 <code>1/N</code> 이고, 선택되지 않을 확률은 <code>1 - 1/N</code> 입니다. 다른 <code>N-1</code> 개의 프로세스에 의해 모두 선택되지 않을 확률은 <code>(1-1/N)^N-1</code> 이고, <code>1</code> 에서 이 값을 빼면 선택될 확률입니다. 그리고 익히 알려진 바대로 <del>응?</del> <code>N</code> 이 매우 커지면 이 값은 <code>1-e^-1</code> 과 같습니다.</p>

<p>그리고 확률론을 잘 안다면 <del>응?</del> 이 값에 기대값을 취하면 <code>e / e-1</code> 이 됩니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/time_bounded_completeness.jpg'  alt="" /></p>

<p>여기에 간단한 트릭을 이용하면 <em>worst case</em> 로 <code>O(N)</code>, 정확히는 <code>2N-1</code> <em>period</em> 내에 <em>failure</em> 가 발견되도록 할 수 있습니다. <em>membership list</em> 를 순회하다가, 마지막에 도달하면 랜덤하게 재배열 하는 것입니다. </p>

<p>그러면 최악의 경우 2번째 멤버에 대해 <em>ping</em> 을 날릴때 첫번째 멤버에 <em>failure</em> 가 발생하고, 재 배열했을때 첫번째 멤버가 마지막에 있다면 <code>(N-1) + (N)</code> 의 <em>period</em> 가 걸립니다. 그리고 이것은 <em>accuracy</em> 등 다른 <em>failure detector</em> 의 속성들을 그대로 유지한채 <em>worst case</em> 시간을 줄이는 결과를 만듭니다.</p>

<p><br/></p>

<h4 id="disseminationandsuspicion">Dissemination and Suspicion</h4>

<p><em>dissemiantion</em> 방법으로</p>

<p>(1) <strong>Multicast</strong> (Hardware / IP)</p>

<ul>
<li>unreliable</li>
<li>multiple simultaneous multicasts</li>
</ul>

<p>(2) <strong>Point-To-Point</strong> (TCP / UDP)</p>

<ul>
<li>expensive</li>
</ul>

<p>(3) <strong>Zero extra message:</strong> Piggyback on Failure Detector messages</p>

<ul>
<li>Infection-style Dissemination (like <em>SWIM</em>)</li>
</ul>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/infection_style_dissemination.jpg'  alt="" /></p>

<p>슬라이드에서 볼 수 있듯이 <em>infection style dissemination</em> 은 <code>λ log(N)</code> <em>protocol periods</em> 후에 <code>N^-(2λ-2)</code> 개의 프로세스만 업데이트되지 않습니다. 바꿔말하면 <code>O(logN)</code> 후에 대부분의 프로세스는 발견돈 <em>failure</em> 정보를 업데이트 한다는 뜻입니다. </p>

<p>여기서 <code>λ</code> 는 <em>consistency level</em> 을 결정하는 상수입니다. 어떤 경우에도 <em>SWIM detector</em> 는 <em>failure</em> 를 <code>2N-1</code> 내에 발견하기 때문에 <em>completeness</em> 100% 가 보장됩니다.</p>

<p><br/></p>

<h3 id="suspicionmechanism">Suspicion Mechanism</h3>

<p><em>false positive</em> 가 발생하는 이유는</p>

<ul>
<li>perturbed processes</li>
<li>package losses (e.g from congestion)</li>
</ul>

<p><em>SWIM</em> 에서 사용했던 <em>indirect pinging</em> 도 이 문제를 해결하지 못할 수 있습니다. (e.g <em>correlated message losses near pinged host</em>)</p>

<p>먼저 <em>failure</em> 가 발견되었을때 다른 노드들에게 알리기 전에 먼저 <em>suspect</em> 한다면 <em>false positive</em> 비율을 줄일 수 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/suspicon_mechanism_state_machine.jpg'  alt="" /></p>

<p>그림이 좀 복잡한데, 프로세스(노드) <code>pi</code> 기준으로 <em>state</em> 가 어떻게 변하는지를 나타낸 그림이라고 보면 됩니다. <code>pj</code> 에게 핑을 날려 응답하지 않으면 <em>suspected</em> 상태로 변하고, 여기서 <em>timeout</em> 되면 <em>failed</em> 되어 <code>pj</code> 가 <em>failure</em> 라고 <em>dissemination</em> 하는 상태가 됩니다.</p>

<p>한 가지 발생할 수 있는 문제점은 <em>suspected</em> 상태에서 <em>alive</em> 상태로 반복적으로 전환될 수 있다는 점입니다. 이러한 혼란을 피하기 위해 <em>incarnation number</em> 를 사용할 수 있습니다.</p>

<p>프로세스 <code>pj</code> 가 <em>suspected</em> 메세지를 받았을때, <em>incarnation number</em> 를 증가시킬 수 있는 것은 <code>pj</code> 만 가능합니다. 그리고 <em>increase incarnation number</em> 메시지를 받은 다른 프로세스들은 <em>alive</em> <code>pj</code> 메시지를 전달합니다.</p>

<p>높은 숫자의 <em>incarnation number</em> 가 더 우선합니다. 그리고 <em>suspect</em> 와 <em>alive</em> 같은 값이라면 <em>suspect</em> 메시지로 처리됩니다. 그리고 <em>failed</em> 메시지는 다른 어떤 메시지보다 더 높은 우선순위를 가지고 있습니다.</p>

<p><br/></p>

<h3 id="summary">Summary</h3>

<ul>
<li>failures the norm, not the exception in datacenters</li>
<li>every distributed system uses a failure detector</li>
<li>many distributed systems use a membership service</li>
<li>ring failure detection underlies <em>IBM SP2</em> and many other similar clusters</li>
<li>Gossip-style failure detection underlies AWS EC2/S3 (rumored)</li>
</ul>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-membership-protocol/</link><guid isPermaLink="false">146da27a-1df0-44d0-a8e1-3020c05f0d22</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[membership]]></category><category><![CDATA[SWIM]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 22 Feb 2015 07:02:52 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, Gossip Protocol]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<h3 id="multicast">Multicast</h3>

<p>이번시간에 배울 내용은 <em>Gossip Protocol</em> (혹은 <em>Epidemic Protocol</em>) 입니다.</p>

<p>기존에는 특정 그룹에게 메세지를 보내기 위해 <em>multicast</em> 를 이용했지만, 클라우드 컴퓨티 환경에서는</p>

<ul>
<li>프로세스가 죽어 노드가 크래쉬를 일으킬수도</li>
<li>네트워크 문제때문에 패킷이 딜레이되거나, 드랍될 수 있고</li>
<li>노드가 빠르게 증가합니다.</li>
</ul>

<p>그러나 멀티캐스트는 <em>fault-tolerance</em> 와 <em>scalability</em> 측면에서 부족한 부분이 많았습니다. 이런 문제를 해결하기 위해 다양한 방법이 도입되었는데</p>

<p>(1) <strong>Centralized:</strong> 중앙 서버에서 <em>TCP, UDP</em> 패킷을 날립니다. 간단한 구현이지만 중앙서버의 오버헤드가 높고, 수천개의 노드가 있을때 <em>latency</em> 가 생깁니다. 노드의 수를 <code>N</code> 이라 했을때, 모든 노드에 메시지가 전달되는데 <code>O(N)</code> 시간이 걸리지요.</p>

<p>(2) <strong>Tree-Based:</strong> 전달 받은 노드에서, 다시 패킷을 전달하여 경로가 <em>tree</em> 형태로 구성됩니다. <em>balanced tree</em> 라면 어떤 그룹에 패킷이 전달되는데 <code>O(logN)</code> 의 시간이 걸립니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/tree_based_multicast.jpg'  alt="" /></p>

<p>이 방법의 단점은 </p>

<ul>
<li><em>tree</em> 를 구성하고 유지하는데 필요한 오버헤드</li>
<li><em>root</em> 에 가까운 곳에서 <em>failure</em> 가 발생했을때의 파급력</li>
</ul>

<p>일반적으로 <em>tree-based multicast</em> 프로토콜에서는 <em>spanning tree</em> 를 구성해서 최단비용으로 패킷을 전달합니다. 그리고 메시지가 올바르게 전달되었는지 <em>ACK</em> 또는 <em>NAK</em> 를 이용하는데 <em>SRM</em> 이던 <em>RMTP</em> 던 여전히 <code>O(N)</code> 만큼의 <em>ACK/NAK</em> 오버헤드가 발생합니다.</p>

<p><br/></p>

<h3 id="gossip">Gossip</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_example1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/gossip_example2.jpg'  alt="" /></p>

<p>가십 프로토콜은 위 그림처럼 작동합니다.</p>

<ul>
<li>주기적으로 랜덤한 타겟을 골라 <em>gossip message</em> 를 전송합니다</li>
<li>그리고 이것을 받아 <em>infected</em> 상태가 된 노드도 똑같이 행동합니다.</li>
</ul>

<p>이걸 <em>Push gossip</em> 이라 부릅니다. <em>multiple message</em> 를 가십하기 위해 랜덤 서브셋을 선택하거나, <em>recently-received</em> 메시지를 를 선택하거나, <em>higher priority one</em> 을 고를 수 있습니다.</p>

<p>어떤 가십 메시지에 대해 대부분의 노드가 <em>infected</em> 되었을때 <em>push gossip</em> 은 비효율적입니다. 이때는 <em>uninfected</em> 노드가, 새로운 가십메시지가 있는지 주변 노드에게 물어보는 <strong>pull gossip</strong> 이 오버헤드가 더 적습니다.</p>

<ul>
<li><strong>Pull gossip:</strong> Periodically poll a few random selected processes for new multicast meesages that you haven't received</li>
</ul>

<p><br/></p>

<h3 id="gossipanalysis">Gossip Analysis</h3>

<p>가십프로토콜은 다음의 특징을 가집니다.</p>

<ul>
<li><strong>lightweight</strong> in large groups</li>
<li>spreads a multicast quickly</li>
<li>highly <em>fault-tolerant</em></li>
</ul>

<p>이를 위해 간단한 증명을 해보도록 하겠습니다.</p>

<ul>
<li>전체 <code>n+1</code> 의 <em>population</em> 에 대해 </li>
<li><em>uninfected individuals</em> 의 수를 <code>x</code></li>
<li><em>infected individuals</em> 의 수를 <code>y</code> </li>
<li><em>individual pair</em> 간의 <em>contract rate</em> 를 <code>β</code> 라 하면</li>
</ul>

<p>항상 <code>x + y = n + 1</code> 이고, 시작상태에서는 <code>x_0 = n, y_0 = 1</code> 입니다. 그리고 시간이 지날때마다 <em>uninfected</em> <code>y</code> 는 다음처럼 감소합니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cfrac%7B%5Cmathrm%7Bd%7D%20x%7D%7B%5Cmathrm%7Bd%7D%20t%7D%20%3D%20-%5Cbeta%20xy'  alt="" /></p>

<p>그러면 이 수식으로부터 다음을 이끌어 낼 수 있습니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?x%20%3D%20%7B%20n%28n&plus;1%29%20%5Cover%20%7Bn%20&plus;%20e%5E%7B%5Cbeta%28n&plus;1%29t%7D%7D%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?y%20%3D%20%7B%20%28n&plus;1%29%20%5Cover%20%7B1%20&plus;%20ne%5E%7B-%5Cbeta%28n&plus;1%29t%7D%7D%7D'  alt="" /></p>

<p>그리고 <em>infected node</em> 가 랜덤하게 <code>b</code> 개의 노드를 고른다 하면 <code>β</code> 는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cbeta%20%3D%20%7Bb%20%5Cover%20b%7D'  alt="" /></p>

<p>그리고 시간 <code>t</code> 를 가십이 진행되는 <em>round</em> 라 보고 <code>t = clog(n)</code> 이라 치환하겠습니다. 다음을 이끌어낼 수 있습니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?y%20%5Capprox%20%28n&plus;1%29%20-%20%7B1%20%5Cover%20n%5E%7Bcb-2%7D%7D'  alt="" /></p>

<p>이 식으로부터 <em>gossip protocol</em> 이 <em>low latency</em>, <em>reliability</em>, <em>lightweight</em> 하다는 것을 알 수 있습니다.</p>

<p>(1) <strong>low latency</strong></p>

<p><code>c, b</code> 를 <code>n</code> 과 독립적으로 아주 작은 숫자로 세팅하면 <code>clog(n)</code> <em>round</em> 이므로 적은 시간 내에 메시지가 전파됩니다.</p>

<p>(2) <strong>reliability</strong></p>

<p><code>n</code> 이 매우 크면 <code>1 / n^{cb-2}</code> 가 <code>0</code> 에 가까워지므로, <code>1 / n^{cb-2}</code> 만큼의 노드를 제외한 모든 노드가 <em>infected</em> 된다는 것을 알 수 있습니다.</p>

<p>(3) <strong>lightweight</strong></p>

<p>각 노드는 <code>cb log(n)</code> 만큼의 <em>gossip message</em> 만 전파합니다. 이론적으로는 <code>log(N)</code> 은 상수가 아니지만, 실제로는 아주 천천히 증가하는 숫자기에 작은 숫자처럼 생각할 수 있습니다.</p>

<p><br/></p>

<h3 id="faulttolerance">Fault-Tolerance</h3>

<p><em>50% packet loss</em> 를 생각해 봅시다. <code>b</code> 를 <code>2/b</code> 로 치환하면 됩니다. 그러면 이전과 같은 <em>reliability</em> <em>0% packet loss</em> 를 위하 두배의 <em>round</em> 만큼만 더 진행하면 됩니다.</p>

<p><em>node failure</em> 는 어떨까요? 50% 노드에서 <em>failure</em> 가 발생한다면 <code>n, b</code> 을 <code>2/n, 2/b</code> 으로 치환하면 됩니다. 이는 <em>contract rate</em> 에서 가십 메시지를 전달하는 <code>n</code> 중 <code>2/n</code> 의 노드만 살아있고, 선택되는 <code>b</code> 중 <code>b/2</code> 노드만 살아있기 때문입니다. 이 경우에도 상수만 곱하면 이전과 같은 <em>reliability</em> 를 얻을 수 있습니다.</p>

<p><em>failure</em> 와 관련해서 한 가지 생각해 볼 문제가 있습니다. 모든 노드가 죽는것이 가능할까요? 물론 가능합니다 초기에 모든 노드가 죽으면요. 그러나 <em>improbable</em> 입니다. 일단 몇개의 노드가 <em>infected</em> 되면, 이후에는 퍼지는 속도가 훨씬 더 빠르기 때문입니다. 루머나 바이러스가 퍼질 수 있는 이유를 생각하면 이해하기 쉽습니다.</p>

<p><br/></p>

<h3 id="pullgossip">Pull Gossip</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/pull_gossip_analysis.jpg'  alt="" /></p>

<p>그림에서 볼 수 있듯이, 어떤 형태의 가십 프로토콜이던 <code>2/N</code> 까지 전달할때는 <code>O(logN)</code> 만큼의 시간이 걸립니다. 그 이후에는 <em>pull gossip</em> 이 훨씬 빠르죠.</p>

<p><code>i</code> <em>round</em> 후에 남아있는 <em>uninfected node</em> 의 수를 <code>p_i</code> 라 합시다. <em>pull gossip</em> 을 이용할때 다음 단계에서도 <em>uninfected</em> 일 확률은 </p>

<p><img src='http://latex.codecogs.com/gif.latex?p_%7Bi&plus;1%7D%20%3D%20p_i%5E%7Bk&plus;1%7D'  alt="" /></p>

<p>이는 <code>p_i</code> 자체가 <em>uninfected</em> 여야 하고, 이 노드가 선택하는 <code>k = b</code> 만큼의 노드도 <em>uninfected</em> 여야 하는데, 이 확률은 극히 낮습니다. 슬라이드에서 보듯이 <em>super-exponential</em> 하고, 그렇기 때문에 <em>second half</em> 부터는 <em>pull gossip</em> 이 <code>O(log(logN))</code> 입니다.</p>

<p><br/></p>

<h3 id="topologyawaregossip">Topology-Aware Gossip</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week2/topology_aware_gossip.jpg'  alt="" /></p>

<p>만약 <em>uninfected node</em> 를 <em>uniformly random</em> 하게 고른다면 위 그림에서 라우터의 오버헤드는 <code>O(N)</code> 이 됩니다. 더 정확하게는 <em>round</em> 마다 <code>b * (2/n)</code> 이 될겁니다. </p>

<p>이를 해결하기 위해, 서브넷에 <code>n_i</code> 개의 노드가 있을때 자신이 속한 서브넷에 있는 <em>uninfected node</em> 를 더 자주 고르게, 확률을 <code>1 - (1/n_i)</code> 가 되도록 합니다. 그러면, 현재 서브넷에 있는 노드를 선택할 확률이 1 에 가까우므로 <code>O(logN)</code> 시간 내에 전파되고, 라우터의 오버헤드는 <code>(n_i) / (n_i)</code> 가 되어, <code>O(1)</code> 이 됩니다. </p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera  </p>]]></description><link>http://1ambda.github.io/cloud-computing-gossip-protocol/</link><guid isPermaLink="false">791b3276-2b13-469d-96ff-21b0b279bfd2</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[gossip]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 21 Feb 2015 05:41:54 GMT</pubDate></item><item><title><![CDATA[Pattern Discovery 2]]></title><description><![CDATA[<p><img src='https://m1.behance.net/rendition/modules/7116731/disp/d18c13cd5b49bf40b41e6ef0610b26d3.png'  alt="" /></p>

<p>패턴 마이닝을 통해 만들어지는 수많은 <em>pattern</em>, <em>rule</em> 이 모두 유용한 것은 아닙니다. 따라서 <em>interestingness measure</em> 을 위해 객관적이거나, 주관적인 평가방법을 이용할 수 있습니다.</p>

<p>(1) <strong>Objective interestingness measures</strong></p>

<ul>
<li>support, confidence, correlation</li>
</ul>

<p>(2) <strong>Subjective interestingness measures</strong></p>

<ul>
<li><em>Query-based:</em> relevant to a user's particular request</li>
<li><em>Against one's knowledge-base:</em> unexpected, freshness, timeliness</li>
<li><em>Visualization tools:</em> Multi-dimensional, interactive examination</li>
</ul>

<p>이 방법중, 먼저 객관적인 방법에 대해 좀 더 알아보겠습니다.</p>

<p><br/></p>

<h3 id="liftchisquared">Lift, χ²(Chi-squared)</h3>

<p><em>confidence</em> 는 두 변수가 관련있는지 말해주지만, <em>positive</em> 혹은 <em>negative</em> 관계인지 말해주지 않습니다. 이를 판별하기 위해 <em>lift</em> 를 이용할 수 있죠</p>

<p><img src='http://latex.codecogs.com/gif.latex?lift%28B%2C%20C%29%20%5C%5C%20%5C%5C%20%3D%20%7Bc%28B%20-%3E%20C%29%20%5Cover%20s%28C%29%7D%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20%7Bs%28B%20%5Ccup%20C%29%20%5Cover%20%7Bs%28B%29%20%5Ctimes%20s%28C%29%7D%7D'  alt="" /></p>

<p><code>Lift(B, C)</code> 는 <code>B</code> 와 <code>C</code> 가 얼마나 관련있는지를 말해줍니다. 수식을 보면 알겠지만</p>

<ul>
<li><code>Lift(B, C) = 1</code> 이면 <code>B</code> 와 <code>C</code> 는 <em>independent</em></li>
<li><code>&gt; 1</code> 이면 <em>positive correlated</em></li>
<li><code>&lt; 1</code> 이면 <em>negative correlated</em></li>
</ul>

<p><br/></p>

<p><em>correlated events</em> 를 판별하는 다른 방법은 <code>χ²</code> 를 이용하는 것입니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cchi%5E2%20%3D%20%5Csum%20%7B%28observed%20-%20expected%29%5E2%20%5Cover%20expected%7D'  alt="" /></p>

<ul>
<li><code>χ² = 0</code> 이면 <em>independent</em></li>
<li><code>χ² &gt; 1</code> 이면 <em>correlated</em> 이며 <em>positive</em> 인지 <em>negative</em> 인지는 <em>expected</em> 값과 비교하면 알 수 있습니다.</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/null_transaction.jpg'  alt="" /></p>

<p>그러나 <em>lift</em> 와 <em>chi-squared</em> 가 항상 좋은 평가지표는 아닙니다. 위 테이블을 보면 <code>Lift(B, C) = 8.44</code> 입니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?lift%28B%2C%20C%29%20%5C%5C%20%5C%5C%20%3D%20%7B%28100/102100%29%20%5Cover%20%7B%281100/102100%29%20' *%20%281100/102100%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%208.4380" alt="" /></p>

<p>이는 <code>~B and ~C</code> 부분의 숫자가 <code>B, C</code> 보다 월등히 높아서 그런데, 이런 영역을 <em>null transaction</em> 이라 부릅니다. </p>

<p><code>B, C</code> 는 같이 일어날 확률이 상당히 낮지만, <em>null transaction</em> 때문에 높은것처럼 보입니다.</p>

<p><br/></p>

<h3 id="nullinvariantmeasures">Null Invariant Measures</h3>

<p><em>lift</em> 와 <em>chi-squared</em> 는 많은 수의 <em>null transaction</em> 이 있을 때 좋은 평가 지표가 될 수 없습니다. </p>

<p>이를 해결하기 위해 <em>null transaction</em> 에 영향을 받지 않는 <em>null-invaraint measures</em> 를 사람들이 만들어 두었습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/null_invariant_measures.jpg'  alt="" /></p>

<p><em>null invariance</em> 는 <em>massive transaction data</em> 를 마이닝할때 아주 중요합니다. <em>null transaction</em> 이 아주 많을 수 있기 때문이죠. </p>

<p>그러면 이 많은 <em>measures</em> 중 어떤것이 가장 나을까요? 예제 데이터로 한번 비교해 봅시다. <code>m</code> 은 <em>milk</em>, <code>c</code> 는 <em>coffee</em> 입니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/comparison_of_measures.jpg'  alt="" /></p>

<blockquote>
  <p>Kulc holds firm and is in balance of both directional implications</p>
</blockquote>

<p>여기에 <em>imbalance ratio</em> 라는 개념을 도입할 수 있습니다.</p>

<ul>
<li><strong>imbalance ratio:</strong> measure the imbalance of two itemsets <code>A</code> and <code>B</code> in rule implications</li>
</ul>

<p><img src='http://latex.codecogs.com/gif.latex?IR%28A%2C%20B%29%20%5C%5C%20%5C%5C%20%3D%20%7B%7B%7Cs%28A%29%20-%20s%28B%29%7D%20%5Cover%20s%28A%29%20&plus;%20s%28B%29%20-%20s%28A%5Ccup%20B%29%7D'  alt="" /></p>

<p><em>Kulc</em> 와 <em>IR</em> 을 이용하면 조금 더 데이터를 자세히 살펴볼 수 있죠.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/IR.jpg'  alt="" /></p>

<ul>
<li>D4 is <em>neutral</em>, <em>balanced</em></li>
<li>D5 is <em>neutral</em>, but <em>imbalanced</em></li>
<li>D6 is <em>neutral</em>, but very <em>imbalanced</em></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/DBLP_example.jpg'  alt="" /></p>

<p><code>ID 5</code> 를 보면, <em>Kulc</em> 는 아이템 <code>A, B</code> 가 상당한 연관성이 있지만, <em>imbalance</em> 하므로 <code>0.562</code> 의 값을 돌려주는 것을 볼 수 있습니다.</p>

<p><br/></p>

<h2 id="5miningdiversepatterns">5. Mining Diverse Patterns</h2>

<p>이번 시간에 배울 주제들은 다음과 같습니다.</p>

<ul>
<li>Mining Multiple-Level Associations</li>
<li>Mining Multi-Dimensional Associations</li>
<li>Mining Quantitative Associations</li>
<li>Mining Negative Correlations</li>
<li>Mining Compressed and Redundancy-Aware Patterns</li>
<li>Mining Long/Colossal Patterns</li>
</ul>

<p><br/></p>

<h3 id="multilevelassociations">Multi-Level Associations</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/multi_level_items.jpg'  alt="" /></p>

<p><em>item</em> 은 하위 계층으로 다시 분류될 수 있습니다. 이럴때는 단순히 <em>uniform min support</em> 를 이용하는 것보다, 아래 계층으로 내려갈수록 <em>reduced min support</em> 를 이용하는 편이 더 낫습니다.</p>

<p>그리고 한번의 여러 단계(<em>multi-level</em>) 을 마이닝하기 위해 <em>shared multi-level mining</em> 이란 기법을 이용할 수 있습니다.  이건 뒷부분에서 더 살펴보겠습니다.</p>

<p><em>multi-level association</em> 마이닝의 문제점은 <em>redundant rules</em> 을 만들 수 있다는 점입니다. 따라서 필터링 기법이 필요합니다. <code>level 1</code> 에서 발견된 룰을, <code>level 2</code> 에서 다시 검사하지 않는것 처럼요</p>

<ul>
<li><code>milk -&gt; wheat bread [s=8%, c=70%]</code></li>
<li><code>2% milk -&gt; wheat breadk [s=2%, c=72%]</code></li>
</ul>

<p>아이템에 따라서 <em>customized min support</em> 가 필요한 경우도 있습니다. 우유나 빵은 그렇지 않아도 상관 없지만, <em>diamond</em>, <em>watch</em> 등은 커스터마이징이 꼭 필요합니다. 고가의 아이템이니까요. 이 경우 <em>group-based individualized min-support</em> 를 이용하면 됩니다.</p>

<ul>
<li><code>{diamon, watch}: 0.05%; {bread, milk}: 5%;, ...</code></li>
</ul>

<p><br/></p>

<h3 id="multidimensionalassociations">Multi-Dimensional Associations</h3>

<p><em>multi-dimensional</em> 의 예는</p>

<p>(1) <strong>inter-dimension association rules</strong> (no repeated pred)</p>

<p><code>age(X, "18-25") ∩ occupation(X, "student") =&gt; buys(X, "coke")</code></p>

<p>(2) <strong>hybrid-dimension association rules</strong> (repeated pred)</p>

<p><code>age(X, "18-25") ∩ buys(X, "popcorn") =&gt; buys(X, "coke")</code></p>

<p><em>attribute</em> 는 <em>categorical</em> 이거나 <em>quantitative</em> 일 수 있습니다. </p>

<p><br/></p>

<h3 id="quantitativeassociations">Quantitative Associations</h3>

<p><em>numerical attribute</em> (e.g <em>age, salary</em>) 를 마이닝 하기 위해 다양한 <em>method</em> 를 사용할 수 있습니다.</p>

<p>(1) static discretization based on prefefined concept hierarchies. data cube-based aggregation</p>

<p>(2) dynamic discretization based on data distribution</p>

<p>(3) clustering: distance-based association. first one-dimensional clustering, then association</p>

<p>(4) deviation analysis</p>

<p><br/></p>

<h3 id="negativecorrelations">Negative Correlations</h3>

<p><em>rare pattern</em> 과 <em>negative pattern</em> 은 다릅니다.</p>

<p>(1) <strong>Rare patterns</strong></p>

<ul>
<li>아주 낮은 <em>support</em> 지만, 롤렉스 시계를 사는 행위처럼 중요할 수 있습니다</li>
<li><em>individualized</em>, <em>group-based min support</em> 를 다양한 아이템 그룹에 설정해서 마이닝합니다.</li>
</ul>

<p>(2) <strong>Negative patterns</strong></p>

<ul>
<li>자동차를 동시에 2개 사는것처럼, 같이 일어나는 경우가 드뭅니다 (<em>unlikely to happen together</em>)</li>
</ul>

<p><br/></p>

<p><em>negative pattern</em> 은 어떻게 마이닝할까요? 한가지 방법은 <em>lift</em> 에서 사용했던 <em>support-based definition</em> 을 이용하는 것입니다.</p>

<ul>
<li><code>s(A ∪ B) &lt;&lt; s(A) X s(B)</code></li>
</ul>

<p>이 정의는 작은 <em>transaction dataset</em> 에서는 통하지만, 데이터 크기가 커지면 적용되지 않습니다.</p>

<p>(1) 전체 200개의 트랜잭션에 대해</p>

<ul>
<li><code>s(A∪B) = 0.005, s(A) x s(B) = 0.25, s(A∪B) &lt;&lt; s(A) X s(B)</code></li>
</ul>

<p>(2) 전체 10^5 개의 트랜잭션에 대해</p>

<ul>
<li><code>s(A∪B) = 1/10^5, s(A) x s(B) = 1/10^3 X 1/10^3, s(A∪B) &gt;&gt; s(A) X s(B)</code></li>
</ul>

<p>이전에 봤었던 <em>null transaction</em> 때문입니다. <em>support-based definition</em> 은 <em>not null-invariant</em> 입니다.</p>

<p>이를 해결하기 위해 <em>Kulczynski measure-based definition</em> 을 이용하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%28P%28A%7CB%29%20&plus;%20P%28B%7CA%29%29%20/%202%20%3C%20%5Cepsilon'  alt="" /></p>

<p>여기서 <code>ɛ</code> 는 <em>negative pattern threshold</em> 를 의미합니다. 만약 위 수식이 <code>ɛ</code> 보다 작으면 <em>negatively correlated</em> 란 뜻이지요. </p>

<p><br/></p>

<h3 id="compressedpatterns">Compressed Patterns</h3>

<p>때로는 너무 많아 의미가 없는 <em>scattered pattern</em> 때문에 <em>compressed pattern</em> 을 마이닝 할 필요가 있습니다. </p>

<p><em>compressed pattern</em> 인 <em>closed pattern</em> 과 <em>max pattern</em> 의 정의를 복습해보면</p>

<ul>
<li><strong>closed pattern:</strong> A pattern <code>x</code> is <strong>closed</strong> if <code>x</code> is frequent, and there exists no super pattern <code>Y ⊃ X</code> with the same support as <code>X</code></li>
<li><strong>max pattern:</strong> A pattern <code>X</code> is a <strong>max pattern</strong>. if <code>X</code> is frequent and there exists no frequent super-pattern <code>Y ⊃ X</code></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/compressed_pattern.jpg'  alt="" /></p>

<p>예를 들어 위 그림에서 <code>P1, 2, 3, 4, 5</code>는 모두 <em>closed</em> 고, <code>P3</code> 는 <em>max pattern</em> 입니다. <em>P3</em> 만 남기자니 <em>information loss</em> 가 너무 많고, 다 남기자니 엣지가 없습니다. <code>P2, P3, P4</code> 정도면 적당할 것 같습니다.</p>

<p>이 적당한 정도를 결정하기 위해 <em>pattern distance measure</em> 을 사용할 수 있습니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?Dist%28P_1%2C%20P_2%29%20%3D%201%20-%20%7B%7CT%28P_1%29%20%5Ccap%20T%28P_2%29%7C%20%5Cover%20%7CT%28P_1%29%20%5Ccup%20T%28P_2%29%7C%7D'  alt="" /></p>

<p>그리고 이 <em>distance</em> 값을 이용해 <em>δ-cluserting</em> 을 합니다. </p>

<ul>
<li><strong>δ-clustering:</strong> For each pattern <code>P</code>, find all patterns which can be expressed by <code>P</code> and whose distance to within <code>δ</code> (<em>δ-cover</em>)</li>
</ul>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/redundancy_aware_top_k.jpg'  alt="" /></p>

<p><em>Redundancy-Aware Top-k pattern</em> 이란 기법도 있습니다.</p>

<p><code>(a)</code> 가 본래 패턴이고, <em>traditional top-k</em> 기법으로는 가장 컴팩트한(진한) 3개의 패턴만 남깁니다. 따라서 우측 클러스터는 버려지죠.</p>

<p>이를 막기 위해 클러스터별로 하나씩 남기는 <code>(d)</code> <em>summarization</em> 을 이용할 수도 있으나, 이건 중요한 것만을 돌려주지 않습니다. </p>

<p>따라서 두 방법을 조합한 <code>(b)</code>, 중복을 허용하는 <em>redundancy-aware top-k</em> 를 이용하면 적절한 패턴을 남기고, 나머지는 버릴 수 있습니다.</p>

<p>이를 위해 <em>MMS (Maximal Marginal Significance)</em> 메소드를 사용할 수 있습니다.</p>

<p><br/></p>

<h3 id="colossalpatterns">Colossal Patterns</h3>

<p><em>long pattern mining</em> 은 소셜 네트워크 분석이나, 바이오인포메틱스, 소프트웨어 엔지니어링등 다양한 분야에서 필요로 합니다. 그러나, 지금까지 우리가 본건 길이가 10 보다 적은 패턴을 마이닝하는 기법들이었습니다.</p>

<p><em>long pattern</em> 을 분석하기 어려운 이유는 지난시간에 봤듯이 <em>downward closure property</em> 때문입니다. <em>frequent pattern</em> 의 <em>sub-pattern</em> 은 적어도 그만큼은 빈번하기 때문에, 패턴의 길이가 길고 <em>frequent</em> 하다면, 그 수많은 서브패턴을 분석해야 하는 것이지요.</p>

<p><em>BFS (e.g Apriori)</em>, <em>DFS (e.g FPgrowth)</em> 등 무엇을 이용하든 수 많은 패턴을 검색해야 하고, <em>combinatorial explosion</em> 과 마주할 수 밖에 없습니다.</p>

<p><code>40C20</code> 컴비네이션의 경우 기존에 존재하는 가장 빠른 마이닝 알고리즘들(e.g FP-Close, LCM)도 계산을 완료하지 못하는 경우가 많습니다. 그러나 놀랍게도 <em>pattern-fusion</em> 알고리즘은 1초만에 결과를 돌려줍니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/pattern_fusion1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/pattern_fusion2.jpg'  alt="" /></p>

<p>즉, 작은 <em>core pattern</em> 을 모아 <em>colossal pattern</em> 을 만들어 낸다는 것이지요.</p>

<ul>
<li><strong>core patterns</strong> of a colossal pattern <code>α</code>: A set of subpatterns of <code>α</code> that cluster around <code>α</code> by sharing a similar support</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/robustness_of_colossal_pattern.jpg'  alt="" /></p>

<p><em>core pattern</em> 에 대한 더 엄밀한 정의는 위와 같습니다.</p>

<p><em>frequent pattern</em> <code>α</code> 에 대해, <em>sub-pattern</em> 인 <code>β</code> 는  다음을 만족하면 <em>τ-core pattern</em> 입니다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B%7CD_%5Calpha%7C%20%5Cover%20%7CD_%5Cbeta%7C%7D%20%5Cgeq%20%5Ctau%5C%20%28where%5C%20%5Ctau%5C%20is%5C%20core%5C%20ratio%29'  alt="" /></p>

<p>그리고 패턴 <code>α</code> 에서 <code>d</code> 만큼의 아이템을 제거해도, 여전히 <em>τ-core pattern of α</em> 이면 <code>α</code> 를 <em>(d, τ)-robust</em> 라 부릅니다. 따라서 <code>d</code> 만큼의 아이템이 있거나 없어도, 코어패턴이므로 전체 숫자는 <code>2^d</code> 만큼의 코어패턴을 만들 수 있습니다.</p>

<p>그러므로 <em>colossal pattern</em> 이라면, 정말 많은 수의 <em>core pattern</em> 을 만들 수 있습니다. 그리고 이런 <em>core pattern</em> 은  <em>distance</em> 가 충분히 작으므로 <em>dense ball</em> 형태로 뭉칩니다. 결과적으로 <em>random pattern space</em> 에서 패턴을 뽑으면, <em>dense ball</em> 내의 패턴일 확률이 굉장히 높습니다.</p>

<p>이를 기반으로한 <em>Pattern-Fusion Algorithm</em> 은</p>

<ol>
<li><p><strong>Initialize (creating initial pool)</strong>: </p></li>
<li><p>Use an existing algorithm to min all frequent patterns up to a small size (e.g 3)</p></li>
<li><p><strong>Iteration (iterative pattern fusion):</strong> </p></li>
<li><p>At each iteration, <code>K</code> seed patterns are randomly picked from the current pattern pool</p></li>
<li>For each seed pattern thus picked, we find all the patterns within a bounding ball centered at the seed pattern</li>
<li>All these patterns found are fused tohether to generate a set of super-patterns</li>
<li><p>All the super-patterns thus generated form a new pool for the next iteration</p></li>
<li><p><strong>Termination:</strong></p></li>
<li><p>when the current poll contains no more than <code>K</code> patterns at the beginning of an iteration</p></li>
</ol>

<p><br/></p>

<h2 id="6constraintbasedmining">6. Constraint-Based Mining</h2>

<p>이번시간에 배울 내용은 다음과 같습니다.</p>

<ul>
<li>Different Pruning Strategies</li>
<li>Constrainted Mining with Pattern Anti-Monotonicity</li>
<li>Constrainted Mining with Pattern Monotonicity</li>
<li>Constrainted Mining with Data Anti-Monotonicity</li>
<li>Constrainted Mining with Succinct Constraints</li>
<li>Constrainted Mining with Convertible Constraints</li>
<li>Hanlding Multiple Constraints</li>
</ul>

<p>왜 <em>Constraint-Based Mining</em> 이 필요할까요? 데이터셋에 있는 <strong>all</strong> 패턴을 <strong>autonomously</strong> 하게 찾는것은 불가능합니다. 이는 <em>compressed pattern mining</em> 에서 언급했듯이, 너무 많은 패턴이 있기 때문이지요. 특히 데이터셋이 커지면 사용자가 관심 없는 데이터가 기하급수적으로 늘어납니다.</p>

<p>따라서 패턴 마이닝은 사용자가 무엇을 원하는지 <em>data mining query language</em> 나 <em>GUI</em> 를 통해서 직접 명령을 내리는 <em>interactive</em> 한 과정이 되야 합니다.</p>

<p><em>constraints</em> 를 이용하면 다음과 같은 장점이 있습니다.</p>

<ul>
<li><strong>user flexibility:</strong> provides <strong>constraints</strong> on what to be mined</li>
<li><strong>optimization:</strong> explores such constraints for efficient mining</li>
</ul>

<p><br/></p>

<h3 id="differentpruning">Different Pruning</h3>

<p><em>constraints</em> 에 따라 <em>pruning strategy</em> 달라집니다.</p>

<p>(1) <strong>pattern space pruning constraints</strong></p>

<ul>
<li><em>anti-monotonic:</em> if constraint <code>c</code> is violated, its further mining can be terminated</li>
<li><em>monotonic:</em> if <code>c</code> is satisfied, no need to check <code>c</code> agina</li>
<li><em>succinct:</em> <code>c</code> can be enforced by directly manipulating the data</li>
<li><em>convertible:</em> <code>c</code> can be converted to monotonic or anti-monotonic if items can be propery ordered in processing</li>
</ul>

<p>(2) <strong>data space pruning constraints</strong></p>

<ul>
<li><em>data succinct:</em> data space can be pruned at the initial pattern mining process</li>
<li><em>data anti-monotonic:</em> if a transaction <code>t</code> doesn't satisfy <code>c</code>, then <code>t</code> can be pruned to reduce data processing effort</li>
</ul>

<p><br/></p>

<h3 id="antimonotonicity">Anti-Monotonicity</h3>

<p><em>constaint</em> <code>C</code> 는 다음의 경우에 <em>anti-monotone</em> 이라고 말합니다.</p>

<ul>
<li>If an itemset <code>S</code> <strong>violates</strong> constraint <code>C</code>, so does any of its superset</li>
<li>That is, mining on itemset <code>S</code> can be terminated</li>
</ul>

<p>예를 들어서 다음의 제약조건은 <em>anti-monotone</em> 입니다</p>

<ul>
<li><code>sum(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &lt;= 15</code> </li>
<li><code>support(S) &gt;= k</code></li>
</ul>

<p>따라서 <em>Apriori pruning</em> 은 본질적으론 <em>anti-monotonic constaint</em> 에 기반합니다.</p>

<p>반대로 <code>sum(S.price) &gt;= v</code> 는 <em>not anti-monotone</em> 입니다.</p>

<p><br/></p>

<h3 id="monotonicity">Monotonicity</h3>

<p><em>itemset</em> <code>S</code> 가 <em>constaint</em> <code>c</code> 를 만족할때, <code>S</code> 의 <em>superset</em> 도 그러하다면 <code>c</code> 는 <em>monotone</em> 이라 부릅니다. 다음은 모두 <em>monotone</em> 입니다.</p>

<ul>
<li><code>sum(S.price) &gt;= v</code></li>
<li><code>min(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &gt;= 15</code></li>
</ul>

<p><br/></p>

<h3 id="dataantimonotonicity">Data Anti-Monotonicity</h3>

<p><em>data anti-monotone</em> 는 <em>transaction</em> 기반으로 <em>pruning</em> 을 진행해 나아갑니다. 정의는 이렇습니다.</p>

<ul>
<li>In the mining process, if a data entry <code>t</code> cannot satisfy a pattern <code>p</code> under <code>c</code>, <code>t</code> cannot satisfy <code>p</code>'s superset either</li>
</ul>

<p>다음은 모두 <em>data anti-monotone</em> 입니다.</p>

<ul>
<li><code>sum(S.price) &gt;= v</code> </li>
<li><code>min(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &gt;= 25</code></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/data_anti_monotone.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="succinctconstaints">Succinct Constaints</h3>

<p><em>succintness</em> 는 <em>data space</em> 와 <em>pattern space</em> 를 모두 <em>pruning</em> 합니다.</p>

<blockquote>
  <p>if the constaint <code>c</code> can be enforced by directly manipulating the data</p>
</blockquote>

<p>(1) To find those patterns without item <code>i</code></p>

<p><em>pattern space pruning</em> 처럼 <code>i</code> 을 DB 에서 제거합니다.</p>

<p>(2) To find those patterns containing item <code>i</code></p>

<p><em>data space pruning</em> 처럼 <em>i-projected</em> DB 만 마이닝 합니다.</p>

<p>(3) <code>min(S.price) &lt;= v</code> is succinct</p>

<p><code>price &lt;= v</code> 에서 시작해서, <em>high-price item</em> 을 제거해 나가기 때문에 <em>pattern + data space pruning</em> 입니다.</p>

<p>(4) <code>sum(S.price) &gt;= v</code> is not succinct</p>

<p><em>itemset</em> <code>S</code> 의 <em>sum</em> 이 점점 크기때문에, 미리 제거할 수 없습니다.</p>

<p><br/></p>

<h3 id="convertibleconstaints">Convertible Constaints</h3>

<blockquote>
  <p>Convert tough constaints into (anti-) monotone by proper ordering of items in transactions</p>
</blockquote>

<p><code>avg(S.profit) &gt; 20</code> 같은 경우는 <em>anti-monotone</em> 도 <em>monotone</em> 도 아닙니다. </p>

<ul>
<li>만약 현재 만족한다고 했을때, 아주 작은 <code>profit*</code> 을 가지는 아이템을 추가하면 <em>violation</em> 이고,</li>
<li>만약 현재 위반한다고 했을때, 아주 큰 값을 추가하면 <em>satisfaction</em> 이기 때문입니다.</li>
</ul>

<p>이런 <em>constaint</em> 에 대해서도 <em>pruning advantage</em> 를 얻고자 하는것이 바로 <em>convertible constaints</em> 의 목적입니다. 가능하면 <em>anti-monotone</em> 이 더 선호되는데, 이는 <em>monotone</em> 일 경우 검사만 하지 않고, <em>anti-monotone</em> 일 경우 <em>super-pattern</em> 을 날려버릴 수 있기 때문입니다.</p>

<ul>
<li>만약 <code>c: avg(S.profit &gt; 20)</code> 에 대해서 </li>
<li><em>itemset</em> 을 내림차순으로 <code>S: {a, g, f, b, h, d, c, e}</code> 정렬하고 </li>
<li><code>avg(ab) = 20</code>, <code>g = 20</code> 이면</li>
</ul>

<p><em>constaint</em> <code>C</code> 는 <em>anti-monotone</em> 이라 할 수 있습니다. 왜냐하면 패턴 내부가 <code>profit</code> 을 기준으로 내림차순으로 되어서, 어떤 <em>item entry</em> 를 뽑아도 <code>c</code> 를 만족할 수 없기 때문입니다.</p>

<p>아쉽게도 이 방법은 <em>level-wise candidate generation</em> 을 하는 <em>Apriori</em> 알고리즘엔 적용되지 않습니다.</p>

<p><br/></p>

<h3 id="hanldingmultipleconstaints">Hanlding Multiple Constaints</h3>

<p>다수개의 <em>constaints</em> 를 사용하는것은 좋으나, <em>item ordering</em> 에서 충돌이 생길 수 있습니다. 이럴땐 먼저 하나의 <em>constaint</em> 기준으로 정렬하고, 나머지는 <em>projected databases</em> 를 마이닝할때 하면 좋습니다.</p>

<p>예를 들어 다음 두개의 <em>constaints</em> 가 있을때</p>

<ul>
<li><code>c1: avg(S.profit) &gt; 20</code></li>
<li><code>c2: avg(S.price) &lt; 50</code></li>
</ul>

<p><code>c1</code> 이 더 강력한 <em>pruning power</em> 가 있다고 생각하고, <code>c1</code> 먼저  <em>anti-monotone</em> 으로 변경 한 후, 각 <em>projected-DB</em> 에서 트랜잭션을 오름차순으로 정렬해 <code>c2</code> 를 마이닝에 이용합니다.    </p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='https://www.behance.net/gallery/625042/Icon-and-pattern-with-a-marketing-theme' >Title image</a> <br />
(2) <strong>Pattern Discovery</strong> by <em>Jiawei Han</em> </p>]]></description><link>http://1ambda.github.io/pattern-discovery-2/</link><guid isPermaLink="false">eae33e61-9556-4292-99f1-9b45d93ceb62</guid><category><![CDATA[coursera]]></category><category><![CDATA[pattern discovery]]></category><category><![CDATA[data mining]]></category><category><![CDATA[lift]]></category><category><![CDATA[pattern-fusion]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 20 Feb 2015 02:49:15 GMT</pubDate></item><item><title><![CDATA[Artificial Intelligence 2, Search]]></title><description><![CDATA[<p><img src='http://picm.yourswallpaper.com/other/box-robot_18407.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="agents">Agents</h3>

<p><em>agent</em> 가 <em>good decision</em> 을 내릴려면 <em>planning</em> 을 해야합니다. 그러기 위해선 어떤 <em>action</em> 이 좋을지 <em>search (탐색)</em> 해 보아야 하고 결국 풀어야 할 문제는 <em>search problem</em> 이 됩니다.</p>

<p>(1) <strong>reflex agent</strong></p>

<ul>
<li>Choose action based on current percept (and maybe memory)</li>
<li>May have memory or a model of the world's current state</li>
<li>Do not consider the future consequences of their action</li>
<li>Consider how the world <strong>IS</strong></li>
</ul>

<p>자신이 인지하는 <em>environment</em> 에 기반하여 어떤 <em>action</em> 을 취할지 결정하나, <em>action</em> 의 결과를 고려하지 않고 결정을 내리기에 문제가 생길 수 있습니다. <em>reflext agent</em> 가 <em>rational</em> 할 수 있을까요?</p>

<blockquote>
  <p>Of course. Rationality is a function of the actions you take, not the computation. So if you had a big enough, good enough lookup table, and you're taking the right actions. <strong>Rationality doesn't care what process led to them.</strong> Reflex is a comment on the thought process</p>
</blockquote>

<p>(2) <strong>planning agents</strong></p>

<p><em>planning agent</em> 는 <em>reflex agent</em> 와는 다르게 <strong>what if</strong> 를 질문합니다. 따라서</p>

<ul>
<li>Decisions based on (hypothesized) consequences of actions</li>
<li>Must have a model of how the world evolves in response to actinos</li>
<li>Must formulate a goal(test)</li>
<li>Consider how the world <strong>WOULD BE</strong></li>
</ul>

<p><em>planning agent</em> 는 <em>action</em> 을 선택할때 <em>real world</em> 에서 실제로 실행해보진 않습니다. 대신 <em>model</em> 을 이용해 <em>simulation</em> 을 해봅니다. 따라서 <em>planning agent</em> 에서는 <em>real world</em> 를 반드시 모델링 해야 합니다.</p>

<blockquote>
  <p>In order to have a planning agent, you must have <strong>a model of the world</strong></p>
</blockquote>

<p>그렇기 때문에 모델상에서 <em>goal</em> 인지 테스트 할 수 있는 방법도 필요합니다. </p>

<p><em>planning</em> 과 관련해서 <em>complete planning</em> 과 <em>optimal planning</em> 이 있습니다. <em>complete planning</em> 은 <em>solution</em> 을 찾아내고, <em>optimal planning</em> 은 <em>best solution</em> 을 찾아냅니다.</p>

<p>또한 <em>planning agent</em> 는 한번에 <em>plan</em> 을 세워 실행할 수도 있지만, 매 실행 후 다시 <em>re-planning</em> 할 수도 있습니다. </p>

<p><br/></p>

<h3 id="searchproblem">Search Problem</h3>

<p><em>search problem</em> 은 다음처럼 구성됩니다.</p>

<ul>
<li><strong>A state space:</strong> models how the world is</li>
<li><strong>A successor function (with actions, costs):</strong> models how it evolves in response to your actions</li>
<li><strong>A start state</strong> and <strong>a goal test</strong></li>
</ul>

<p>그리고 <em>solution</em> 은 <em>start state</em> 를 <em>goal state</em> 로 변환하는 <em>a sequence of actions (a plan)</em> 입니다.</p>

<p>다시 정리하자면, <em>state</em> 는 <em>world</em> 를 어떻게 모델링 하는지를 나타내고, <em>successor function</em> 은 <em>action</em> 에 <em>world</em> 가 어떻게 반응할지를 나타냅니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/searchprbs_are_models.jpg'  alt="" /></p>

<blockquote>
  <p>Search problems are just models</p>
</blockquote>

<p>실제로 현실세계를 그대로 시뮬레이션하기엔 복잡하기때문에, 이를 계산하기 위해 <em>rough</em> 한 모델이 필요합니다. 이 <em>model</em> 적절하다면 <em>search problem</em> 의 결과도 정확합니다.</p>

<p>모델을 너무 추상화 해서 만들면 (<em>abstract too much</em>) 문제를 풀 수 없고, 그 반대라면 현실세계의 복잡함을 모두 다뤄야 하기 때문에 계산이 어려울 수 있습니다. 따라서 적절한 정도의 <em>abstraction</em> 이 필요합니다.</p>

<p>예를 들어 모든 <em>dot</em> 을 먹는 팩맨 에이전트를 만든다고 할때, <em>state</em> 에 문제를 풀기에 필요 이상의 정보를 넣으면 <em>search space</em> 가 너무 커져 계산이 어렵고, 너무 추상화해서 문제를 풀기에 필요한 정보가 부족하면 <em>solution</em> 을 찾는다 해도 올바른 <em>solution</em> 이 아닐 수 있습니다.</p>

<p><br/></p>

<h3 id="searchstategraph">Search State Graph</h3>

<p><em>state space graph</em> 는 <em>search problem</em> 의 <em>mathematical representation</em> 입니다.</p>

<ul>
<li>Nodes are (abstracted) world configurations</li>
<li>Arcs represent successors (action results)</li>
<li>The goal test is a set of goal nodes (maybe only one)</li>
<li>In a search graph, each state occurs only once</li>
</ul>

<h3 id="searchstatetree">Search State Tree</h3>

<p><em>search tree</em> 는 <em>plan</em> 이 어떠할지를 나타내는 일종의 <em>what if tree</em> 입니다. </p>

<ul>
<li>The start state is the root node</li>
<li>Children correspond to successors</li>
<li>Nodes show states, but correspond to <strong>PLANS</strong> that achieve those states</li>
<li>For most problems, we can never actually build the whole tree</li>
</ul>

<p><em>general tree search</em> 알고리즘은</p>

<pre><code>function TREE-SEARCH(problem, strategy) returns a solution, or failure

  initialize the search tree using the initial state of problem

  loop do
    if there are no candidates for expansion 
      then return failure

    choose a leaf node for expansion according to strategy

    if the node contains a goal state
      then return the corresponding solution
      else expand the node and 
           add the resulting nodes to the search tree

  end
</code></pre>

<p>여기서 중요한 요소는 <em>fringe (현재 고려중인 nodes)</em>, <em>expansion</em>, <em>exploration strategy</em> 다. 특히 어떤 <em>fringe nodes</em> 를 선택할 것인가가 중요한 질문이 됩니다.</p>

<p>널리 알려진 방법으로 <em>Depth-First Serach</em>, <em>Breadth-First Search</em> 등이 있습니다. 이들 <em>search algorithm</em> 의 성능을 평가하기 위해 다음 요소를 고려할 수 있습니다. </p>

<ul>
<li><strong>complete:</strong> guaranteed to find a solution if one exists</li>
<li><strong>optimal:</strong> guaranteed to find the least cost path</li>
<li>time complexity</li>
<li>space complexity</li>
</ul>

<p>그리고 <em>DFS</em> 은 <em>branching factor</em> <code>b</code>, <em>depth</em> <code>m</code> 이라 했을때 </p>

<ul>
<li>At any given time during the search, the number of nodes on the fringe can be no larger than <code>b*m</code></li>
<li>The number of nodes expanded throughout the entire search can be as large as <code>b^m</code></li>
</ul>

<p><em>BFS</em> 알고리즘에서 <em>branching factor</em> <code>b</code>, <em>depth</em> <code>s</code> 라 했을때 </p>

<ul>
<li>At any given time during the search, the number of nodes on the fringe can be large as <code>b^s</code></li>
<li>The number of nodes expanded throughout the entire search can be as large as <code>b^s</code></li>
</ul>

<p>두 방법을 섞은 <em>iterative deepening</em> 이란 알고리즘도 있습니다. <em>limit 1</em> 까지는 <em>DFS</em> 를 돌려보고, 실패하면 <em>limit2</em> 까지 <em>DFS</em> 를 돌려보는 방식입니다. </p>

<p><em>Uniform Cost Search (UCS)</em> 란 것도 있는데 <em>priority queue</em> 를 이용해서 더 낮은 <em>cost</em> 부터 탐색하는 방식입니다. <em>UCS</em> 는 <em>complete</em>, <em>optimal search</em> 입니다. 단점으로는 </p>

<ul>
<li>Explores options in every direction</li>
<li>No information about goal location</li>
</ul>

<p><br/></p>

<p>지금까지 배운 <em>search algorithm</em> 은 모두 <em>uninformed search</em> 입니다. 간단히 정리하면</p>

<ul>
<li>search operates <strong>over models of the world</strong></li>
<li>the agent doesn't actually try all the plans out in the real world</li>
<li>planning in all <strong>"in simulation"</strong></li>
<li><strong>your search is only as good as your models</strong></li>
</ul>

<p>위에서 본 <em>search algorithm</em> 은 <em>fringe strategies</em> 만 다르고 모두 동일합니다. 개념상으로는 모든 <em>fringes</em> 는 <em>priority queue</em>  입니다. <em>DFS</em> 와 <em>BFS</em> 의 경우에는 각각 <em>stack</em>, <em>queue</em> 를 이용해서 <em>priority queue</em> 의 <em>log(n)</em> 오버헤드를 피할 수 있습니다.</p>

<p><br/></p>

<h3 id="informedsearch">Informed Search</h3>

<p>이번시간에는 <em>state</em> 의 정보를 이용하는 <em>informed search</em> 와 <em>graph search</em> 를 배웁니다. <em>informed search</em> 의 기본적인 아이디어는 <em>direction</em> 을 결정할때, <em>goal</em> 에 가까운 방향인지를 알 수 있는 정보를 이용하는 것입니다.</p>

<p>(1) <strong>informed search</strong></p>

<ul>
<li>heuristics</li>
<li>greedy search</li>
<li>A* search</li>
</ul>

<p>(2) <strong>Graph Search</strong></p>

<p><br/></p>

<h3 id="searchheuristics">Search Heuristics</h3>

<p><em>A heuristic is:</em></p>

<ul>
<li>A function that <strong>estimatees</strong> how close a state is to a goal</li>
<li>Designed for a particular search problem</li>
</ul>

<p>문제에 따라 <em>heuristics</em> 는 다릅니다. 루마니아 투어 문제의 경우 <em>직선거리</em> 가 될 수 있고, 팬케잌 문제(하노이탑) 의 경우 잘못 올려진 팬케잌의 수가 <em>heuristic function</em> 이 될 수 있습니다.</p>

<p>이런 <em>heuristics</em> 을 어떻게 알고리즘에 적용할까요? 하나는 <em>DFS</em> 처럼 같은 <em>sibling</em> 사이에서 더 낮은 <em>heuristics</em> 값을 가지는 <em>fringe</em> 를 선택하는 방법이 있습니다. 이걸 <em>greedy search</em> 라 부릅니다.</p>

<p>반면 <em>BFS</em> 처럼 같은 <em>heuristics</em> 값을 가지는 모든 <em>fringe</em> 를 탐색할 수도 있습니다. 이걸 <em>A* search</em> 라 부릅니다.</p>

<p><br/></p>

<h3 id="greedysearch">Greedy Search</h3>

<p><em>greedy search</em> 는 <em>heuristic</em> <em>(estimate of distance to nearest goal for each state)</em> 을 이용해서 <em>fringe</em> 를 선택하지만, <em>DFS</em> 처럼 <em>badly-guided</em> 될 수 있습니다. 항상 <em>optimal</em> 한 솔루션을 찾아주진 않는다는 이야기입니다.</p>

<p></br></p>

<h3 id="asearch">A* Search</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/ucs_plus_greedy.jpg'  alt="" /></p>

<p><em>A* Search</em> 는 <code>f(n) = g(n) + h(n)</code> 을 이용합니다. 즉, 지금까지 온 거리 <code>g(n)</code> 과 앞으로 남은 (예측) 거리 <code>h(n)</code> 을 더한 값을 이용해서 어떤 <em>fringe</em> 를 선택할지 결정합니다. </p>

<p><em>A*</em> 와 관련해서 생각해 볼 한가지는 <em>goal fringe</em> 를 <em>enqueue</em> 할 때가 아니라 <em>dequeue</em> 할때 <em>stop</em> 해야한다는 것 입니다. 이는 현재 <em>queue</em> 에 있는 것중 <em>goal</em> 까지 더 작은 <code>g(n)</code> 을 가진 <em>fringe</em> 가 존재할 수 있기 때문이죠.</p>

<p><em>A* search</em> 는 <em>admissible</em> 하면 <em>optimal</em> 입니다. 여기서 <em>admissible (optimistic)</em> 하다는 뜻은 <em>heuristics</em> 값 <code>h(n)</code>이 절대로 실제 <em>cost</em> <code>h*(n)</code> 보다 높지 않다는 뜻입니다. (always underestimate)</p>

<p><code>0 &lt;= h(n) &lt;= h*(n)</code></p>

<ul>
<li><strong>Inadmissible (pessimistic)</strong> heuristics <strong>break</strong> optimality by trapping good plans on the fringe</li>
<li><strong>Admissible (optimistic)</strong> heuristics slow down bad plans but never outweigh true costs</li>
</ul>

<p><br/></p>

<p><em>uniform-cost search</em> 와 <em>A* search</em> 를 기하학적으로 비교해보면, <em>UCS</em> 는 정원의 등고선을 그리며 <em>goal</em> 을 탐색하지만 <em>A*</em> 는 <em>goal</em> 쪽으로 기운 타원형태의 등고선이 만들어집니다.</p>

<p>정리하자면</p>

<ul>
<li><strong>DFS, BFS:</strong> uninformed search, don't consider cost</li>
<li><strong>UCS:</strong> uninformed search, only consider cost</li>
<li><strong>Greedy search:</strong> informed search, only consider heuristic</li>
<li><strong>A* search:</strong> informed search which uses both cost and heuristic</li>
</ul>

<p><br/></p>

<h3 id="admissibleheuristics">Admissible Heuristics</h3>

<p>어려운 <em>search problem</em> 을 최적으로 풀어내려면 <em>admissible heuristics</em> 를 만들어야 하는데, 이 <em>admissible heuristics</em> 은  본래 문제에서 <em>constaints</em> 가 조금 줄어들어 새로운 <em>action</em> 을 사용할 수 있는 <em>relaxed problem</em> 의 솔루션이 될 수 있습니다. </p>

<p>그리고 <em>inadmissible heuristic</em> 도 때로는 유용할 수 있습니다. <em>optimal solution</em> 이 꼭 필요하지 않다면요. </p>

<p>그러나 이번에는 <em>admissible heuristics</em> 을 만드는 연습을 해보겠습니다. <em>8 puzzle</em> 을 <em>search problem</em> 으로 해서요. 먼저 해야 할 질문은</p>

<ul>
<li>What are the states?</li>
<li>How many states?</li>
<li>What are actions?</li>
<li>How many successor from the start state?</li>
<li>What should the costs be?</li>
</ul>

<p>(1) 만약 <em>heuristic</em> 을 <em>number of tiles misplaced</em> 로 한다면, 이건 <em>admissible</em> 일까요? </p>

<p>당연히 <em>admissible heuristic</em> 입니다. 왜냐하면 어느 <em>action</em> 도 한번에 <code>1</code> 개 이상의 타일을 옮길 수 없으니까요. 그런데 이건 <em>relaxed problem heuristic</em> 입니다. 최대 <code>8</code> 번만에 문제를 풀려면 타일을 직접 정확한 위치에 붙여야 합니다. 부직포 붙이듯이요.</p>

<p>(2) 만약 타일을 직접 목적지로 한번에 움직이진 않지만, 다른 타일을 무시하고 움직일 수 있다면 어떨까요? 아까보단 <em>less relaxed</em> 하다고 생각해봅시다. 이 경우 <em>manhattan distance</em> 를 이용할 수 있습니다.   이것도 마찬가지로 <em>relaxed heuristic</em> 이지만 아까보단 좀 덜 루즈합니다. </p>

<p>아까보다는 <em>heuristic</em> <code>h</code> 값이 더 커졌으니까, 가장 정확한 <em>heuristic</em> (actual cost) 값은 이것보다는 적어도 크다고 생각할 수 있습니다. 일종의 <em>lower bound</em> 라고 보면 쉽습니다. </p>

<p>그리고 <em>heuristic</em> 이 더 정확해졌기 때문에, <em>expanded nodes</em> 수도 이전보다 훨씬 줄어들게 됩니다.</p>

<p>(3) <em>actual cost</em> 를 <em>heuristic</em> 으로 사용하면 어떨까요? 이 값은 당연히 <em>admissible</em> 합니다. <code>h(n) = h*(n)</code> 이니까요. 게다가 <em>expanded nodes</em> 수도 가장 적습니다. </p>

<p>다만 문제는, 가장 정확한 <em>heuristic</em> 이기 때문에 매 턴마다 이 값을 계산하기 위한 연산 비용이 비쌉니다. 이것이 <em>A*</em> 알고리즘이 가진 <em>trade-off</em> 입니다. <em>quality of estimate</em> 와 <em>work per node</em>  를 적절히 조절해서 <em>heuristic</em> 을 만들어야 합니다.</p>

<blockquote>
  <p>As heuristics get closer to the true cost, you will expand fewer nodes but usually do more work per node to compute the heuristic itself</p>
</blockquote>

<p>나침반을 보고 길을 찾을때, <em>loose heuristic</em> 은 좀 더 넓은 범위에서 맞다고 알려주어 이용하기 쉽다면, <em>actual cost</em> 의 경우에는 나침반이 제시하는 올바른 방향이 너무나 작기때문에 자세히 보고, 여러번봐야 하는것과 비슷합니다.</p>

<p>정리하자면 <em>heuristic</em> 이 <em>actual cost</em> 에 가깝다고 해서 반드시 좋은건 아닙니다. 연산시간을 고려하면 적정 수준의 <em>loose heuristic</em> 을 사용할 필요가 있습니다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/heuristic_dominance.jpg'  alt="" /></p>

<p>모든 <em>heuristic</em> 값이 더 크면 <em>dominance</em> 라고 말합니다. 다시 말해 더 정확한, <em>actual cost</em> 에 가깝다는 뜻입니다. 그리고 <em>admissible</em> 한 두 <em>heuristics</em> 에 대해 그 <em>max</em> 값도 당연히 <em>admissible</em> 합니다.</p>

<p><em>bottom lattice</em> 를 <em>zero heuristic</em>, <em>top</em> 을 <em>exact</em> 라 부릅니다. 만약 <em>zero heuristic</em> 을 이용하면 <em>uniform-cost search</em> 와 동일합니다.</p>

<h3 id="graphsearch">Graph Search</h3>

<p><em>tree search</em> 는 중복되는 부분에 대해 다시 탐색하므로 비효율적입니다. 이 부분을 개선하기 위해 <strong>모든 state 를 단 한번만</strong> <em>expand</em> 할 수 있습니다. <em>set of expanded states</em> 를 유지하고, <em>state</em> 를 탐색하기 전에 이미 <em>expanded</em> 되었는지 검사하면 됩니다.</p>

<p><em>graph search</em> 는 <em>completeness</em> 엔 문제가 없으나 <em>not-optimal</em> 일 수 있습니다. 아래 예제를 보면 <em>sub-optimal solution</em> 을 리턴합니다. <em>admissible heuristic</em> 임에도 불구하고요.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/a_star_graph_suboptimal.jpg'  alt="" /></p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/artificial-intelligence/search/consistency.jpg'  alt="" /></p>

<p>이건 <em>consistency</em> 속성이 만족되지 않아서 그렇습니다. <em>goal</em> 까지의 <em>admissibility</em> 뿐만 아니라, 각 <em>arc</em> 마다도 <code>h &lt;= actual cost</code> 를 만족하면 <em>consistent</em> 하다고 말합니다. 만약 <em>heuristic</em> 이 <em>consistent</em> 하면 <em>f value</em> 가 절대로 줄지 않기 때문에 결과적으로 <em>graph search</em> 를 통한 결과도 <em>optimal</em> 이 됩니다.</p>

<ul>
<li><em>Fact 1:</em> In tree search, A* expands nodes in increasing total <em>f value</em> (<strong>f-contours</strong>)</li>
<li><em>Fact 2:</em> For every state <code>s</code>, nodes that reach <code>s</code> optimally are expanded before nodes that reach <code>s</code> suboptimally</li>
</ul>

<p><br/></p>

<h3 id="optimality">Optimality</h3>

<p>(1) Tree Search</p>

<ul>
<li>만약 <em>heuristic</em> 이 <em>admissible</em> 이면 A* 는 <em>optimal</em> 입니다</li>
<li><em>UCS</em> 는 <code>h = 0</code> 인 <em>special case</em> 입니다</li>
</ul>

<p>(2) Graph Search</p>

<ul>
<li>만약 <em>heuristic</em> 이 <em>consistent</em> 이면, A* 는 <em>optimal</em> 입니다.</li>
<li><em>UCS</em> 도 <code>h = 0</code> 이어서 <em>consistent heuristic</em> 이므로 <em>optimal</em></li>
</ul>

<blockquote>
  <p>Consistency implies admissibility</p>
</blockquote>

<p>일반적으로 대부분의 <em>natural admissible heuristic</em> 는 <em>consistent</em> 합니다. 특히 <em>relaxed problems</em> 에서 나왔다면 더더욱요</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <strong>Artificial Integelligence (CS 188)</strong> by <em>Dan Klein, Pieter Abbeel</em> <br />
(2) <a href='http://imgkid.com/cute-box-robot-tumblr.shtml' >Title Image</a>  </p>]]></description><link>http://1ambda.github.io/artificial-intelligence-2/</link><guid isPermaLink="false">82a14f90-2790-4df3-bef8-a080f0141d64</guid><category><![CDATA[edx]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[CS188]]></category><category><![CDATA[search]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 19 Feb 2015 06:59:46 GMT</pubDate></item><item><title><![CDATA[Artificial Intelligence 1, Intro]]></title><description><![CDATA[<p><img src='http://www.land-of-web.com/wp-content/uploads/2012/08/w30.jpg'  alt="" /></p>

<h3 id="ai"> AI</h3>

<p>사람처럼 행동하는것? 사람처럼 생각하는것? 무엇이 <em>AI</em> 일까?</p>

<blockquote>
  <p>Act Rationally</p>
</blockquote>

<p>여기서 <em>rational</em> 은</p>

<ul>
<li>Maximally achieving pre-defined goals</li>
<li>Rationality only concerns what decisions are made. not the thought process begind them</li>
<li>Goals are expressed in terms of the utility of outcomes</li>
</ul>

<p>따라서 <em>rational</em> 의 의미는 <strong>maximizing your expected utility</strong> </p>

<p><br/></p>

<h3 id="brain">Brain</h3>

<p>인간의 뇌는 <em>rational decision</em> 을 내리는데 상당히 뛰어나지만, 완벽하지는 않다. 이런 <em>brain</em> 를 모방해서 인공지능을 만들어보려 했지만 뇌는 <em>software</em> 만큼 <em>modular</em> 하지 않기 때문에 <em>reverse engineering</em> 해서 인공지능을 만들긴 어려웠다.</p>

<p>과학자들이 뇌를 분석하는 과정에서 얻은 <em>lessons learned</em> 는 <strong>memory</strong> 와 <strong>simuation</strong> 이 <em>decision making</em> 에서 아주 중요한 요소라는 것이다.</p>

<p><br/></p>

<h3 id="whatcanaido">What Can AI Do?</h3>

<p>(1) <strong>Language</strong></p>

<ul>
<li>Translation</li>
</ul>

<p>(2) <strong>Vision (Perception)</strong></p>

<ul>
<li>Object and face recognition</li>
<li>Scene segmentation</li>
<li>Image classification</li>
</ul>

<p>(3) <strong>Robotics</strong></p>

<ul>
<li>Vehicles</li>
<li>Rescure</li>
<li>Soccer!</li>
<li>Lots of automations</li>
</ul>

<p>(4) <strong>Logic</strong></p>

<ul>
<li>Theorem provers</li>
<li>NASA fault diagnosis</li>
<li>Question answering</li>
</ul>

<p>(5) <strong>Game Playing</strong></p>

<p>(6) <strong>Decision Making</strong></p>

<ul>
<li>Scheduling (e.g airline routing)</li>
<li>Route Planning (e.g Google maps)</li>
<li>Medical diagnosis</li>
<li>Web search engines</li>
<li>Spam classifiers</li>
<li>Automated help desks</li>
<li>Fraud dections</li>
<li>Productrecommendations</li>
<li>Lots more!</li>
</ul>

<p><br/></p>

<h3 id="designingrationalagents">Designing Rational Agents</h3>

<p>CS188 에서는 <em>rational agent</em> 를 디자인하는 방법을 배운다. <em>rational agent</em> 란 <em>행동(act)</em> 과 <em>인지 (perceive)</em> 를 할 수 있는 <em>개체 (entity)</em> 다. 즉, <em>환경 (environment)</em> 를 인식해서 그에 맞는 판단을 내린 후 행동하는 소프트웨어로 볼 수 있다. </p>

<ul>
<li>A <strong>rational agent</strong> selects actions that maximize its (expected) <strong>utility</strong></li>
<li>Characteristics of the <strong>percepts</strong>, <strong>environment</strong>, and <strong>action space</strong> dictate techniques for selecting rational actions</li>
</ul>

<p>이 수업에서 배우는 것은 어떤 <em>environment</em> 와 어떤 <em>percept</em> 를  가지고 있는지를 파악한 후, 이와 관련된 기존의 테크닉을 이용해서 <em>언제</em>, <em>어떻게</em> 문제를 풀 수 있는지를 배운다.</p>

<p><br/></p>

<h3 id="coursetopics">Course Topics</h3>

<p>Part 1: <strong>Making Decisions</strong></p>

<ul>
<li>Fast search / planning</li>
<li>Constraint satisfaction</li>
<li>Adversarial and uncertain search</li>
</ul>

<p>Part 2: <strong>Reasoning under Uncertainty</strong></p>

<ul>
<li>Bayer' nets</li>
<li>Decision theory</li>
<li>Machine learning</li>
</ul>

<p>Throughout: <strong>Applications</strong></p>

<ul>
<li>Natural language processing</li>
<li>Vision</li>
<li>Robotics</li>
<li>Games</li>
</ul>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <strong>Artificial Integelligence (CS 188)</strong> by <em>Dan Klein, Pieter Abbeel</em> <br />
(2) <a href='http://www.land-of-web.com/inspiration/photography/meet-the-danbo-cute-little-cardboard-robot-photos.html' >Title Image</a>  </p>]]></description><link>http://1ambda.github.io/artificial-intelligence-1/</link><guid isPermaLink="false">a5116bfa-3786-420b-860a-a78024e945aa</guid><category><![CDATA[edx]]></category><category><![CDATA[artificial intelligence]]></category><category><![CDATA[CS188]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 19 Feb 2015 04:51:28 GMT</pubDate></item><item><title><![CDATA[Cloud Computing, MapReduce]]></title><description><![CDATA[<p><img src='http://ook.co/wp-content/uploads/cloudcomputing.png'  alt="" /></p>

<h3 id="intro">Intro</h3>

<p><em>map</em> 과 <em>reduce</em> 라는 단어는 <em>functional language</em> 에서 왔다.</p>

<ul>
<li><em>map:</em> processes each record sequentially and independently</li>
<li><em>reduce:</em> processes set of all records in batches</li>
</ul>

<pre><code class="lisp">(map square '(1 2 3 4))
;; (1 4 9 16)

(reduce + '(1 4 9 16))
;; (+16 (+9 (+4 1)))
;; 30
</code></pre>

<p><br/></p>

<h3 id="mapreduce">MapReduce</h3>

<p><img src='http://webmapreduce.sourceforge.net/docs/User_Guide/images/map-reduce.png'  alt="" /></p>

<p align="center">(<a href='http://webmapreduce.sourceforge.net/' >http://webmapreduce.sourceforge.net/</a>)</p>

<blockquote>
  <p><em>Map:</em> <strong>Parallelly</strong> process <strong>a large number</strong> of individual records to generate intermediate key/value pairs
  <br/> <br />
  <em>Reduce:</em> processes and merges all intermediate values associated per key</p>
</blockquote>

<p>각 키는 하나의 <em>reducer</em> 에 할당되고, <em>partitioning keys</em> 에 의해 <em>reduce</em> 가 진행된다. 자주 쓰이는 기법으로 <em>hash partitioning</em> 이 있다. <code>hash(key) % # of reduce servers</code></p>

<pre><code class="java">public static class MapClass extends MapReduceBase  
            implements Mapper&lt;LongWriteable, Text, Text, IntWritable&gt; {

  private final static IntWritable one = new IntWritable(1);
  private Text word = new Text();

  public void map(LongWritable key, Text value, 
                  OutputCollector&lt;Text, IntWritable&gt; output,
                  Reporter reporter) throws IOException {

    String line = value.toString();
    StringTokenizer itr = new StringTokenizer(line);

    while (itr.hasMoreTokens()) {
      word.set(itr.nextToken());
      output.collect(word, one);
    }
  }
}

public static class ReduceClass extends MapReduceBase  
            implements Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {

  public void reduce(Text key, Iterator&lt;IntWritable&gt; values,
                     OutputCollector&lt;Text, IntWritable&gt; output,
                     Reporter reporter) throw IOException {

    int sum = 0;
    while (values.hasNext()) {
      sum += values.next().get();
    }

    output.collect(key, new IntWritable(sum));
  }                     
}

public void run(String inputPath, String outputPath) throw Exception {

  // The job
  JobConf conf = new JobConf(WordCount.class);
  conf.setJobName("mywordcount");

  // The keys are words
  (srings) conf.setOutputKeyClass(Text.class);

  // The values are counts (ints)
  conf.setOutputValueClass(IntWritable.class);
  conf.setMapperClass(MapClass.class);
  conf.setReducerClass(ReduceClass.class);

  FileInputFormat.addInputPat(conf, new Path(inputPath);
  FileOutputFormat.setOutputPath(conf, new Path(outputPath));

  JobClient.runJob(conf);
}
</code></pre>

<p><br/></p>

<h3 id="mapreduceapplication">MapReduce Application</h3>

<p>(1) <strong>Distributed Grep</strong> </p>

<ul>
<li><em>input:</em> large set of files</li>
<li><em>output:</em> lines that match pattern</li>
<li><em>map:</em> emits a line if it matches the supplied pattern</li>
<li><em>reduce:</em> copies the intermediate data to output</li>
</ul>

<p>(2) <strong>Reverse Web-Link Graph</strong></p>

<ul>
<li><em>input:</em> web graph(tuple <code>(a,b)</code> where page <code>a</code> -> page <code>b</code>)</li>
<li><em>output:</em> for each page, list of pages that link to it</li>
<li><em>map:</em> process we log and for each input <code>&lt;source, target&gt;</code>, it outputs <code>&lt;target, source&gt;</code></li>
<li><em>reduce:</em> emits <code>&lt;target, list(source)&gt;</code></li>
</ul>

<p>(3) <strong>Count of URL Access Frequency</strong></p>

<ul>
<li><em>input:</em> log of accessed URLs</li>
<li><p><em>output:</em> for each URL, the number of total accesses for that URL</p></li>
<li><p><em>map:</em> process web log and outputs <code>&lt;URL, 1&gt;</code></p></li>
<li><em>multiple reducers:</em> emits `<URL, URL_count></li>
<li><strong>chain another MapReduce job to calculate</strong> <code>overall_count</code></li>
</ul>

<p>(4) <em>Sort</em></p>

<ul>
<li><em>map</em> task's output is sorted (e.g., <em>quicksort</em>)</li>
<li><em>reduce</em> task's input is osrted (e.g., <em>mergesort</em>)</li>
</ul>

<p>따라서 정렬을 하기 위해</p>

<ul>
<li><em>map:</em> <code>&lt;key, value&gt;</code> -> <code>&lt;value, _&gt;</code> (identity)</li>
<li><em>reduce:</em> <code>&lt;key, value&gt;</code> -> <code>&lt;key, value&gt;</code> (identity)</li>
</ul>

<p>이 때 <em>parttition key</em> 로 <em>range</em> 를 사용하는 것이 가능하다. 다만, 특정 구간에 <em>data</em> 가 몰려있을 수 있으므로 <em>dstiribution</em> 을 고려해 <em>reducer</em> 에게 할당해주면 된다.</p>

<p><br/></p>

<h3 id="scheduling">Scheduling</h3>

<p>일반 <em>user</em> 는</p>

<ul>
<li>Write a Map program, write a Reduce program</li>
<li>Submit job; wait for result</li>
<li>Need to know nothing about parallel/distributed programming</li>
</ul>

<p>그러나 내부적으로는</p>

<ul>
<li>Parallelize Map</li>
<li>Transfer data from Map to Reduce</li>
<li>Parallelize Reduce</li>
<li>Implement Stroage for Map input, Map output, Reduce input, Reduce output</li>
</ul>

<p>그리고 <em>reduce</em> 가 시작되기 전에 반드시 <em>map</em> 이 끝나야 한다. 다시 말해서 <em>map phase</em> 와 <em>reduce phase</em> 사이에는 <em>barrier</em> 가 있어야 한다. 그렇지 않으면 결과가 부정확할 수 있다.</p>

<p>이제 하나하나씩 살펴보자.</p>

<p>(1) <em>Parallelize Map:</em> Easy. Each map task is independent of the other</p>

<p>(2) <em>Transfer data from Map to Reduce:</em> All map output records with same key assigned to same Reduce task. Use <strong>Partitionning Function</strong></p>

<p>(3) <em>Parallelize Reduce:</em> Easy. Each reduce task is independent of the other</p>

<p>(4) <em>Implement Storage for Map input, Map output, Reduce input and Reduce output:</em></p>

<ul>
<li>Map input: from <strong>distributed file system</strong></li>
<li>Map output: to local disk at Map node; Use <strong>local file systems</strong></li>
<li>Reduce input: from (multiple) remote disks; Uses local file systems</li>
<li>Reduce output: to <strong>distributed file system</strong></li>
</ul>

<p>DFS 의 예로 <em>Google File System</em>, <em>HDFS</em> 등이 있다.</p>

<p><br/></p>

<p>하둡은 스케쥴러로 <em>YARN, Yet Another Resouce Negotiator</em>를 사용한다. <em>YARN</em> 은 각 서버를 <em>a collection of containers</em> 로 취급한다. 여기서 <em>container = some CPU + some Memory</em> 다.</p>

<p><em>YARN</em> 은 크게 3파트로 나눌 수 있는데</p>

<ul>
<li><em>Global Resource Manager(RM):</em> scheduling</li>
<li><em>Per-server Node Manager(NM):</em> Daemon and server-specific functions</li>
<li><em>Per-application(job) Application Master(AM):</em> Container negotiation with RM and NMs, Detecting task failures of that job</li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/cloud-computing-concept-1/week1/YARN.jpg'  alt="" /></p>

<p><em>container</em> 가 필요하면 <em>AM1</em> 이 <em>RM</em> 에게 알리고, <em>Node B</em> 의 <em>NM2</em> 에서 <em>Task</em> 가 끝나면, <em>RM</em> 이 <em>Node A</em> 의 <em>AM1</em> 에게 사용 가능한 컨테이너가 있다는 사실을 알려 <em>AM1</em> 이 <em>NM2</em> 에게 컨테이너를 사용하겠다는 요청을 보내는 식이다.</p>

<p><br/></p>

<h3 id="faulttolerance">Fault-Tolerance</h3>

<p>(1) Server Failure</p>

<ul>
<li><em>NM</em> hearbeats to <em>RM</em>. If server fails <em>RM</em> lets all affected <em>AMs</em> know, and <em>AMs</em> take action</li>
<li><em>NM</em> keeps track of each task running at its server. If task fails while in-progress, mark the task as idle and restart it</li>
<li><em>AM</em> heartbeats to <em>RM</em>. On failure, <em>RM</em> restarts <em>AM</em>, which then syncs up with its running tasks</li>
</ul>

<p>(2) RM Failure</p>

<ul>
<li>Use old checkpoints and bring up secondary <em>RM</em></li>
<li>Heartbeats also used to piggyback container requests. Avoids extra mesages</li>
</ul>

<p>요약하자면, <em>NM</em>, <em>AM</em> 은 <em>RM</em> 에게 <em>heartbeat</em> 를 보낸다. <em>NM</em> 에서 오류가 나면 <em>RM</em> 이 영향을 받는 <em>AM</em> 에게 알리고, 해당 <em>AM</em> 이 적절히 처리한다. 또한 <em>NM</em> 은 <em>task</em> 를 유지하면서, <em>task</em> 에러가 발생하면 재시작한다. <em>AM</em> 에서 오류가 나면 <em>RM</em> 이 재시작하고, 해당 <em>AM</em> 의 태스크와 싱크를 맞춘다. <em>RM</em> 에서 오류가 날 경우엔 <em>secondary RM</em> 을 이용한다.</p>

<h3 id="stragglers">Stragglers</h3>

<p><em>slow nodes</em> 를 부르는 다른말이다. <em>speculative execution</em> 으로 해결할 수 있다. 보통 느린 이유는 <em>disk</em>, <em>network bandwidth</em>, <em>CPU</em>, <em>memory</em> 등 때문인데 <em>task</em> 를 복제해서 다른 <em>node</em> 에서 돌린 뒤 먼저 완료되는 노드의 결과를 이용하는 방식이다.</p>

<blockquote>
  <p>Perform backup (replicated) execution of straggler task: task considered done when first replica completed</p>
</blockquote>

<h3 id="locality">Locality</h3>

<p><em>cloud</em> 의 <em>hierarchical topology</em> 때문에 <em>GFS</em>, <em>HDFS</em> 등은 각 <em>chunk</em> 를 3군데에 복제한다. 이때 같은 <em>rack</em> 에 위치할수도 아닐수도 있다.</p>

<p><em>MapReduce</em> 연산에서는 <em>map task</em> 를 스케쥴링할때 가능하면 다음의 순서로 배치한다.</p>

<p>(1) <em>chunk</em> 가 있는 머신에 or failing that <br />
(2) 아니면 같은 <em>rack</em> 에 or failing that <br />
(3) Anywhere  </p>

<p><br/></p>

<h3 id="summary">Summary</h3>

<p>(1) MapReduce uses parallelization + aggregation to schedule applications across clusters.</p>

<p>(2) Need to deal with failure</p>

<p>(3) Plenty of ongoing research work in scheduling and fault-tolerance for Mapreduce and Hadoop</p>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://ook.co/solutions/cloud-computing/' >Title Image</a> <br />
(2) <strong>Cloud Computing Concept 1</strong> by <em>Indranil Gupta</em>, Coursera <br />
(3) <a href='http://webmapreduce.sourceforge.net/docs/User_Guide/sect-User_Guide-Introduction-What_is_Map_Reduce.html' >MapReduce Image</a>  </p>]]></description><link>http://1ambda.github.io/cloud-computing-1-1/</link><guid isPermaLink="false">663ff3ef-8d2f-4c15-8897-90acbda32548</guid><category><![CDATA[coursera]]></category><category><![CDATA[cloud computing]]></category><category><![CDATA[MapReduce]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 13 Feb 2015 12:34:11 GMT</pubDate></item><item><title><![CDATA[Coding The Matrix 1, Function, Field and Vector]]></title><description><![CDATA[<p><img src='http://th06.deviantart.net/fs71/PRE/i/2012/348/f/a/3d_cube_by_colorsark-d5nztba.jpg'  alt="" /></p>

<h3 id="thefunction">The Function</h3>

<blockquote>
  <p><strong>Function Invertibility Theorem:</strong> A function <code>f</code> is invertible if and only if it is <strong>one-to-one</strong> and <strong>onto</strong></p>
</blockquote>

<p><br/></p>

<h3 id="thefield">The Field</h3>

<pre><code class="pyhon">In [6]: 1+3j + (10+20j)  
Out[6]: (11+23j)

In [7]: x = 1+3j

In [8]: (x-1)**2  
Out[8]: (-9+0j)

In [9]: x.real  
Out[9]: 1.0

In [10]: x.imag  
Out[10]: 3.0

In [11]: type(1+2j)  
Out[11]: complex  
</code></pre>

<blockquote>
  <p>Such a collection of "numbers" with <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code> is called a <strong>field</strong>. Different fields are like different classes obeying the same interface</p>
</blockquote>

<p><em>field</em> <code>C</code> 는 <em>complex numbers</em> 다. 이걸 공부해야 하는 이유는</p>

<ul>
<li><code>C</code> is similar enough to <code>R</code> to be familiar but different enough to illustrate the idea of a filed</li>
<li>Complex numbers are intellectual ancestors of vectors</li>
<li>In more advanced parts of linear algebra, complex numbers play an important role</li>
</ul>

<p><br/></p>

<h3 id="playingwithc">Playing with C</h3>

<p><em>complex numbers</em> <code>C</code> 상에서는 한 축이 <em>real number</em>, 다른 축이 <em>imagenary number</em> (<em>python</em> 에선 <code>j</code> 로 표시) 다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/c_function_composition.jpg'  alt="" /></p>

<p>이 때 <em>translation</em> <code>f = z + z0</code> 를 <em>arrow</em> 처럼 볼 수 있다. <code>z0</code> 에서 시작해서 <code>z + z0</code> 를 향하는 화살표로</p>

<p>따라서 <code>f1(z) = z + z1</code>, <code>f2(z) = z + z2</code> 가 있을때 <em>function composition</em> <code>(f1 * f2)(z)</code> 는, <em>adding arrow</em> 처럼 생각할 수 있다.</p>

<p><a href='http://resources.codingthematrix.com/' >http://resources.codingthematrix.com/</a> 여기서 준비물을 구하고 아래 코드를 실행해 보자.</p>

<pre><code>In [1]: from plotting import plot

In [2]: L = [2+2j, 3+2j, 1.75+1j, 2+1j, 2.25+1j, 2.5+1j, 2.75+1j, 3+1j, 3.25+1j]

In [3]: plot(L)

In [4]: plot({z/2 for z in L})  
</code></pre>

<p>벡터와 비슷하게 스케일링은 양수를 곱하면 된다. <em>arrow</em> 를 뒤집고 싶으면 <code>-1</code> 을 곱하면 되고, </p>

<p>반시계방향으로 90도 <em>rotation</em> 을 원하면 <code>f(z) = iz</code> <em>translation</em> 을 사용하면 된다. <code>x+yi</code> 가 <code>-y+xi</code> 가 된다.</p>

<p><em>complex number</em> 에서는 <code>z</code> 와 <code>1 + 0i</code> 의 각도를 <em>argument</em> 라 부르는데, 이를 구하기 위한 공식을 오일러가 만들어 두었다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/argument_def.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/euler_argument.jpg'  alt="" /></p>

<p>어느 <em>real number</em> <code>θ</code> 에 대해서, <code>e^(θi)</code> 가 단위 원 위의 <em>argument</em> <code>θ</code> 를 가진 점 <code>z</code> 가 된다.</p>

<p>따라서 <code>θ = π</code> 일때, <code>e^(πi) = -1</code> 이다.</p>

<pre><code class="python">In [1]: from plotting import plot  
In [2]: from math import e, pi  
In [3]: plot([e**(t*2*pi*1j/20) for t in range(20)])  
</code></pre>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/rotation.jpg'  alt="" /></p>

<p>따라서 기존 <code>z</code> 값에 원하는 라디안 값 <code>k</code> 만큼 <code>e^(ki)</code> 를 곱해주면 <em>exponentiation law</em> 에 의해서, 그만큼 회전한다.</p>

<pre><code class="python">In [11]: plot([e**(pi*1j/4) * z for z in L])  
</code></pre>

<p><br/></p>

<h3 id="playingwithgf2">Playing with GF(2)</h3>

<p><em>Galois Field 2</em> has just two elements <code>0</code> and <code>1</code></p>

<p><em>GF(2)</em> 에서는 특이하게도 <em>addition</em> 이 <em>XOR</em> 과 같다. <em>multiplication</em> 나 <em>usual algebraic laws</em> (e.g multiplication distribution) 는 기존과 동일하다.</p>

<pre><code class="python">In [1]: from GF2 import one

In [2]: def encrypt(p, k): return p+k

In [3]: k = one

In [4]: p = one

In [5]: c = en  
%env       encrypt    enumerate

In [5]: c = encrypt(p, k)

In [6]: c  
Out[6]: 0  
</code></pre>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/encryption.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/encryption2.jpg'  alt="" /></p>

<p>더 자세히는, <code>p</code> 를 어떻게 선택하는지는 <code>c</code> 의 <em>probability distribution</em> 에 영향을 주지 않기때문에 <em>Eve</em> 가 <code>c</code> 를 관찰한다 할지라도 <code>p</code> 에 대해 정보를 얻을 수 없다.</p>

<p>왜 이 <em>cryptosystem</em> 이 <em>perfect secrecy</em> 를 만드는걸까? </p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/perfect_secrecy1.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/perfect_secrecy2.jpg'  alt="" /></p>

<p><code>p = 0</code> 에 대해 <code>k</code> 를 받아 <code>c</code> 를 돌려주는 함수를 <code>f0</code> 이라 하면, <code>f0</code> 은 <em>one-to-one,  onto function</em> 이다. 따라서 <code>k</code> 를 선택하는 확률이 균일하다면 <code>c</code> 의 확률도 <em>uniformly distribution</em> 이다. <code>f1</code> 도 마찬가지다.</p>

<p>이 아이디어가 <em>one-time pad</em> 라는 <em>cryptosystem</em> 의 근간이다.</p>

<blockquote>
  <p>If each bit is encrypted with its own one-bit key, the cryptosystem is <strong>unbreakable</strong></p>
</blockquote>

<p><br/></p>

<p><em>GF(2)</em> 를 <em>network coding</em> 에도 사용할 수 있다. 커스터머 <code>c</code>, <code>d</code> 에게 동시에 <em>video streaming</em> 을 하면 중간지점에서 병목이 발생할 수 있는데 <code>b1 + b2</code> 를 더해 나중에 <code>c</code> 와 <code>d</code> 에서 <em>substraction</em> 을 이용해 원래 비트를 구하면 된다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/network_coding.jpg'  alt="" /></p>

<p><br/></p>

<h3 id="vector">Vector</h3>

<p><em>quaternions</em> (4원수) 에 관한 이야기부터 시작한다.</p>

<blockquote>
  <p>해밀턴은 복소수가 2차원 평면상의 점으로 표현될 수 있다는 사실로부터, 3차원 공간에서 점을 표현하는 같은 방법을 찾으려 하였다. 3차원 공간에서의 정점은 3개의 수로 이루어지며, 해밀턴은 그 3개의 수들을 어떻게 더하고 곱할 수 있는지에 관해 생각해왔다. 그러나 그는 두개의 정점간의 나누기를 어떻게 정의할지 알지 못했고, 난관에 부딪히고 말았다.</p>
  
  <p>1843년 10월 16일, 해밀턴은 그의 아내와 더블린의 로열 운하(영어: Royal Canal, 아일랜드어: An Chanáil Ríoga)을 걷고 있었다. 브로엄 다리(Brougham Bridge, 현재는 브룸 다리 Broom Bridge)를 걷고 있을 때, 나누기에 관한 해답이 그의 뇌리를 스쳤다. 그는 3개의 요소(Triples)를 나누지는 못하지만, 4개의 요소(quadruples)를 나눌 수 있다는 걸 생각했다. 4개의 요소 중, 3요소를 이용해 3차원 공간의 정점을 표현 할 수 있다. 해밀턴은 3차원 공간상의 정점에 대한 그의 새로운 수체계를 표현할 수 있었다. 그는 이 수체계의 기본 규칙을 다리에 새겨놓았다.</p>
  
  <p><code>i^2 = j^2 = k^2 = ijk = -1</code></p>
  
  <p>해밀턴은 위의 기본적인 규칙을 적용한 4개의 요소를 "사원수"라고 명명했다. 그 후 그는 사원수를 연구하고 알리는데 그의 남은 여생을 바쳤다. 그는 "사원수론자"(Quaternionists)라는 학파를 창시하고, 몇권의 책을 출판하여 사원수를 전파시켰다. 그의 마지막 책 《사원수 원론》(Elements of Quaternions)는 800여 쪽으로 구성되어 있고, 해밀턴 사망 직후에 출판되었다.</p>
  
  <p>해밀턴의 죽음 이후, 그의 제자인 피터 거스리 테이트는 사원수의 연구를 계속하였다. 당시 더블린에서는 사원수가 의무적인 시험의 하나였다. 현재는 공간 운동학, 맥스월 방정식 등의 벡터를 이용하여 설명하는 물리와 기하학의 논제들은 그 당시에는 모두 사원수를 이용하여 설명되었다. 또한 사원수에 관한 전문적인 연구학회인 사원수 학회(영어: The Quaternion Society)도 존재하였다.</p>
  
  <p>1880년대 중반부터 조사이어 윌러드 기브스와 올리버 헤비사이드가 제안한 벡터 해석학이 사원수 표현을 대신하기 시작했다. 벡터는 사원수와 같은 현상을 설명하였기 때문에, 고전 사원수 연구에서 많은 아이디어와 용어 등을 빌려왔다. 그러나 벡터 해석이 보다 간결한 개념과 표기법을 가지고 있었기에 사원수는 수학과 물리에서 비주류가 되었다. 이는 해밀턴의 사원수가 이해하기 난해하고, 표기가 친숙하지 않았으며, 그의 저작물에 길고 불분명한 표현이 많았기 때문이다.</p>
  
  <p>그러나 사원수는 20세기 말에 공간상에서의 회전에 관한 사원수의 유용성에 의해서 다시 주목받기 시작했다. 사원수를 이용한 회전의 표현은 행렬을 사용하는 표현에 비해 더욱 간결했고 계산이 빨랐다. 이런 이유로, 사원수는 컴퓨터 그래픽, 제어이론, 신호처리, 자세제어(attitue control), 물리학, 생물정보학, 분자동역학, 컴퓨터 시뮬레이션, 궤도역학(orbital mechanics)등에 사용되고 있다. </p>
</blockquote>

<p></br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/vectors_are_functions.jpg'  alt="" /></p>

<p><em>vector</em> 를 정의역(<em>domain</em>) 에서 치역(<em>image</em>) 로 대응되는 일종의 <em>function</em> 이라 볼 수 있다. <em>python</em> 에서는 <em>dictionary</em> 로 쉽게 나타낼 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/sparsity.jpg'  alt="" /></p>

<p><em>vector</em> 에서 <code>0</code> 이 많으면 <em>sparse vector</em> 라 부르고, <code>k</code> 개 만큼만 <code>0</code> 이 아닌 원소가 있으면 <em>k-sparse</em> 라 부른다. <em>vector</em> 의 몇번째 원소가 <code>0</code>이 아닌지를 나타내야되기 때문에 <em>k-sparse vector</em> 는 <em>k proportional space</em>  가 필요하다. </p>

<p><em>physical sensors</em> 로 얻어지는 <em>signal</em> 은 대부분 <em>sparse vector</em> 가 아니기 때문에 공간을 아끼기 위해, <em>signal</em> 을 <em>lossy compression</em> 으로 압축해서 보내는 법을 강의 후반부에서 배울 것이다.</p>

<p><br/></p>

<h3 id="additionmultiplication">Addition, Multiplication</h3>

<pre><code class="python">In [1]: from plotting import plot  
In [2]: v = [3, 2]  
In [3]: def scalar_vector_mult(alpha, v): return [alpha * x for x in v]  
In [4]: plot([scalar_vector_mult(i/10, v) for i in range(11)])  
</code></pre>

<p><img src='http://latex.codecogs.com/gif.latex?%5Calpha%5B3%2C%202%5D%20&plus;%20%5B0.5%2C%201%5D%20%5C%5C%20%3D%20%5Calpha%28%5B3.5%2C%203%5D%20-%20%5B0.5%2C%201%5D%29%20&plus;%20%5B0.5%2C%201%5D%20%5C%5C%20%3D%20%5Calpha%5B3.5%2C%203%5D%20-%20%5Calpha%5B0.5%2C%201%5D%20&plus;%20%5B0.5%2C%201%5D%20%5C%5C%20%3D%20%5Calpha%5B3.5%2C%203%5D%20-%20%281%20-%20%5Calpha%29%5B0.5%2C%201%5D%20%5C%5C%20%3D%20%5Calpha%5B3.5%2C%203%5D%20-%20%5Cbeta%5B0.5%2C%201%5D%20%5C%5C%20%5C%5C%20%28where%5C%20%5Calpha%2C%20%5Cbeta%20%3E%200%2C%20%5C%20%5Calpha%20&plus;%20%5Cbeta%20%3D%201%29'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/convex_comb.jpg'  alt="" /></p>

<p><em>arbitrary line segment</em> 를 <em>addition</em>, <em>multiplication</em> 을 이용해 <code>a[3, 2] + [0.5, 1]</code> 처럼 표현할 수 있는데, 여기서 식을 좀 더 변형해 <em>convex combination</em> 을 만들 수 있다. 이걸 이용하면 <code>u, v</code> 의 비중이 얼마냐에 따라 <em>output</em> 이 어떻게 달라지는지를 쉽게 표현할 수 있다.</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/convex_comb_ex.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/affine_comb.jpg'  alt="" /></p>

<p><code>[0.5, 1]</code> 부터 <code>[3.5, 3]</code> 까지 <em>infinite line</em> 을 표현하기 위해 <em>affine combination</em> 을 이용할 수 있다. 더 자세한 내용은 <a href='http://en.wikipedia.org/wiki/Linear_combination' >Wiki: line combination</a> 을 참고하자</p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/line_comb.jpg'  alt="" /></p>

<p></br></p>

<h3 id="dictionarybasedrepresentation">Dictionary-based Representation</h3>

<p>앞서 언급했듯이 <em>vector</em> 는 <em>domain</em> <code>D</code> 로 부터 어떤 <em>field</em> 로 <em>mapping</em> 하는 <em>function</em> 이다. 파이썬에서는 이런 <em>function</em> 을 <em>dictionary</em> 로 표현할 수 있다.</p>

<pre><code class="python">class Vec:  
    def __init__(self, domain, function):
        self.D = domain
        self.f = function


def zero_vec(D):  
    return Vec(D, {d: 0 for d in D})


def setItem(v, d, val):  
    v.f[d] = val


def getItem(v, d):  
    return v.f[d] if d in v.f else 0


def list2vec(L):  
    return Vec(set(range(len(L))), {k:v for k, v in enumerate(L)})

# vec test
v = Vec({'A', 'B', 'C'}, {'A': 1})  
for d in v.D:  
    if d in v.f:
        print(v.F[d])

# zero_vec test
D = {'A', 'B', 'C'}  
v = zero_vec(D)  
for d in v.D:  
    print v.f[d]

# list2vec test
L = [1, 2, 3, 4]  
V = list2vec(L)

for d in V.D:  
    print(d)
    print(V.f[d])
</code></pre>

<p><br/></p>

<h3 id="vectorsovergf2">Vectors over GF(2)</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/GF2_perfect_secrecy.jpg'  alt="" /></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/all_or_nothing_secret.jpg'  alt="" /></p>

<p>두명에게 나누어 <code>v</code> 를 전송하기 위해 <em>uniform distribution</em> 으로 <code>vA</code> 를 얻어 <code>vB = v - vA</code> 를 만든 뒤 각 한명씩에게 <code>vA</code>, <code>vB</code> 를 전송하는 것이다.</p>

<p><code>vA</code> 는 랜덤 <em>n-vector</em> 고 <code>vB</code> 는 <code>f(x) = v - x</code> 의 <em>output</em> 인데, 이 함수의 <em>input</em> 이 랜덤하게 골라졌으므로 이것만으로는 어떤것도 얻을 수 없다.</p>

<p><img src='http://cdn.phys.org/newman/gfx/news/2012/jhygjfvjgv.jpg'  alt="" /></p>

<p><em>RSA</em> 가 이 테크닉을 사용한다고 한다.</p>

<ul>
<li>Split each password into two parts</li>
<li>Store the two parts on two separate servers</li>
</ul>

<p><br/></p>

<h3 id="dotproduct">Dot-Product</h3>

<p><em>inner product</em> (내적) 이라 부른다. <em>scalar</em> 값을 돌려주고 두 벡터가 이루는 각을 알 수 있다. 외적과 내적에 관한 자세한 내용은 <a href='http://mrw0119.tistory.com/12' >프로그래밍에 미치다 - 외적, 내적 분해</a> 를 참고하자.</p>

<p>내적은 <em>linear equation</em> 에 사용할 수 있다.</p>

<pre><code class="python">D = {"radio", "sensor", "CPU", "memory"}  
duration = {"radio": 0.1, "sensor": 0.5, "CPU": 1, "memory": 0.5} # second  
rate = {"radio": 500, "sensor": 20, "CPU": 1000, "memory": 200} # mA

duration * rate  
</code></pre>

<p><em>linear equation</em> 과 관련해서 중요한 질문들을 던져보자.</p>

<ul>
<li>Is there an algorithm for solving a system of linear equations?</li>
<li>How can we know whether there is only one solution</li>
<li>What if our data are slightly inaccurate</li>
</ul>

<p>이후의 강의들에서 위에서 던진 질문들을 해결할 것이다.</p>

<p><br/></p>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/dot_product_measuring_similarity.jpg'  alt="" /></p>

<p>두 음성이 비슷한지 <em>dot-product</em> 로 비교할 수 있다. 매 부분마다 음성이 비슷한지 비교해야 하므로 연산이 느릴 수 있지만 <em>Fast Fourier Transform</em> 을 이용하면 계산을 빠르게 수행할 수 있다.</p>

<p><br/></p>

<h3 id="dotproductovergf2">Dot-Product over GF(2)</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/dot_product_auth.jpg'  alt="" /></p>

<p>몇번의 질문을 컴퓨터가 던지는것과 비슷하게 <em>n-vector password</em> <code>x</code> 에 대해 컴퓨터가 <em>random n-vector</em> <code>a</code> 를 보내고, 사람이 <em>dot-product</em> 값 <code>a * x = b</code>  를 보낸다.</p>

<p><em>eavesdropper</em> 가 <code>a1, ..., an</code> <code>b1, ..., bn</code> 값을 도청한다면 패스워드를 알기 위해선 다음의 질문을 반드시 해결해야 한다</p>

<ul>
<li><strong>How many solutions for that linear equation?</strong></li>
<li><strong>How to compute them?</strong></li>
</ul>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/attacking_simple_auth.jpg'  alt="" /></p>

<p>만약 <em>Eve</em> 가 <code>01011</code> 과 <code>11110</code> 을 관찰했다면 <code>01011 + 11110</code> 에 대해서는   그림에서 보듯이 해킹이 가능하다. 따라서 추가적으로 던져야 할 질문은</p>

<ul>
<li><strong>If a vector satisfies the equations, then what other equations does the vector satisfy?</strong></li>
</ul>

<p><br/></p>

<h3 id="triangularsystem">Triangular System</h3>

<p><img src='https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/coding-the-matrix/1-vector/triangular_system.jpg'  alt="" /></p>

<ul>
<li>If <code>rowlist[i][i]</code> is zero procedure will raise <code>ZeroDivisionError</code></li>
<li>If this never happens, solution found is the only solution to the system</li>
</ul>

<p>위의 코드는 <code>D = {0, 1, ..., n-1}</code> <em>domain</em> 에 대해서만 작동하기 때문에 다른 도메인에서 돌아갈 수 있도록 코드를 수정하면</p>

<pre><code class="python">def trianuglar_solve(rowlist, domain, b):  
    x = zero_vec(set(label_list))

    for r in reversed(range(len(rowlist))):
        c = label_list[r]
        x[c] = (b[r] - x * rowlist[r]) / rowlist[r][c]

    return x
</code></pre>

<p><br/></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href='http://colorsark.deviantart.com/art/3D-Cube-342632998' >Title image</a> <br />
(2) <strong>Coding the Matrix</strong> by <em>Philip Klein</em> <br />
(3) <a href='http://ko.wikipedia.org/wiki/%EC%82%AC%EC%9B%90%EC%88%98' >Wiki: 4원수</a> <br />
(4) <a href='http://wiki.mathnt.net/index.php?title=%ED%95%B4%EB%B0%80%ED%84%B4%EC%9D%98_%EC%82%AC%EC%9B%90%EC%88%98' (quarternions)">Math Wiki: 4원수</a> <br />
(5) <a href='http://en.wikipedia.org/wiki/Linear_combination' >Wiki: line combination</a> <br />
(6) <a href='http://mrw0119.tistory.com/12' >프로그래밍에 미치다 - 외적, 내적 분해</a>  </p>]]></description><link>http://1ambda.github.io/coding-the-matrix-1/</link><guid isPermaLink="false">46c525c5-23be-4306-9722-8ec9f3f90112</guid><category><![CDATA[coursera]]></category><category><![CDATA[linear algebra]]></category><category><![CDATA[vector]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 12 Feb 2015 11:00:01 GMT</pubDate></item></channel></rss>