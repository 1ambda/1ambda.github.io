<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Old Lisper]]></title><description><![CDATA[Lisp, Emacs, Scala]]></description><link>http://1ambda.github.io/</link><generator>Ghost 0.5</generator><lastBuildDate>Tue, 18 Nov 2014 11:24:31 GMT</lastBuildDate><atom:link href="http://1ambda.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Process Mining, Week1]]></title><description><![CDATA[<p>매 10분마다 새롭게 생성되는 데이터의 양은 2003년까지의 모든 데이터를 합한 것보다 더 많다고 한다. 이 데이터 속에는 무궁무진한 가치가 있다고 하여 어떤 사람들은 데이터를 기름이라 비유하기도 한다.</p>

<p><img src='https://farm9.staticflickr.com/8037/8008798697_d36feb328d_h_d.jpg'  alt="" /></p>

<h3 id="datascienceandbigdata">Data Science and Big Data</h3>

<p>우리가 들고 다니는 핸드폰에는 14개 이상의 센서가 달려있는데, 이렇게 다양한 이벤트로부터 데이터가 무수히 많이 발생하는걸 볼 수 있다. <em>Internet of Events</em> 시대다.</p>

<p><em>Internet of Events</em> 에는 크게 4개의 <em>source</em> 가 있는데</p>

<p>(1) <em>Internet of Content</em> (e.g Google, Wiki) <br />
(2) <em>Internet of People</em> (e.g Twitter, Facebook) <br />
(3) <em>Internet of Things</em> (e.g home appliances) <br />
(4) <em>Internet of Places</em> (e.g Smart phones)</p>

<p>왜 이렇게 데이터가 많이 증가할까? 데이터를 만드는 도구들이 널리 퍼졌기도 하지만 기본적으로 디바이스들이 어마어마하게 좋아졌기 때문이다. (가격도 물론). </p>

<p>매 2년마다 같은 범위에 집약할 수 있는 트랜지스터가 2배씩 늘어난다는 무어의 법칙을 일상생활에 적용하면 어떻게 될까? 40년전에는 비행기로 7시간 걸리던 거리가, 매 2년마다 1/2씩 줄어든다면 24 milliseconds 가 된다. 이건 정말 어마어마하게 줄어든 것이다. </p>

<p>이렇게 디바이스들의 처리, 저장 능력이 급속도로 늘었기 때문에 사람들은 이제 <em>Big Data</em> 를 이야기 하게 되었다. 그리고 문제는 여전히</p>

<blockquote>
  <p>How to extract real value from big data?</p>
</blockquote>

<p>기존의 데이터에 비해서 <em>Big data</em> 가 다른점은 무엇일까? 사람들은 빅데이터에 대해 이야기 할때 <em>4V</em> 를 말하곤 하는데</p>

<p>(1) <strong>Variety:</strong> Different froms of data sources <br />
(2) <strong>Veracity:</strong> Uncertainty of data <br />
(3) <strong>Volumn:</strong> Data size <br />
(4) <strong>Velocity:</strong> Speed of change</p>

<p><em>Veracity</em> 가 묻고자 하는것은 이런 것들이다. <em>"다량의 면도기 사용 데이터를 수집했는데, 이 면도기를 사용한 사람이, 실제로 그 면도기를 구매한 사람인가?"</em></p>

<p>이런 성격을 가진 빅데이터를 포함해서 일반적인 데이터를 분석할때 데이터 사이언티스트가 하는 4가지 질문이 있다.</p>

<ol>
<li>What happened?  </li>
<li>Why did it happen?  </li>
<li>What will happen?  </li>
<li>What is the best that can happen?</li>
</ol>

<p>예를 들어 병원에서는 <em>"왜 이 환자가 이렇게 오래 기다렸나?</em>", <em>"의사가 가이드라인을 따랐나?"</em>, <em>"그럼 대기 시간을 예측할 수 있을까?"</em>, <em>"내일은 얼마나 많은 스태프가 더 필요할까?"</em>, <em>"비용을 얼마나 줄일 수 있을까?"</em> 와 같은 질문을 할 수 있다.</p>

<p>이런 질문에 답하기 위해 다양한 스킬을 이용할 수 있다.</p>

<p><img src='http://blog.zhaw.ch/datascience/files/2014/06/SkillSet-1024x751.png'  alt="" /></p>

<p align="center">(<a href='http://blog.zhaw.ch/datascience' >http://blog.zhaw.ch/datascience</a>)</p>

<p>지금까지 빅데이터에 대해 했지만 이 강의에서는 특별히 <em>process</em> 에 집중한다. 이유는</p>

<blockquote>
  <p>In the end, It is the process that matters (and no the data or the software)    </p>
  
  <p>Not just patterns and decisions, but end-to-end processes</p>
</blockquote>

<p>간단히 말하면 프로세스 마이닝은 <em>process-centric view on data science</em> 라 할 수 있다.</p>

<p>즉 프로세스 마이닝은 <em>event data</em> 와 <em>processes</em>, <em>process models</em> 간의 관계를 파악하는 것이다. 어떤 사람들은 <em>Business process intelligence</em> 라 부르기도 한다.</p>

<p>프로세스 마이닝의 <em>use cases</em> 는</p>

<blockquote>
  <ol>
  <li>What is the process that people really follow?</li>
  <li>Where are the bottlenecks in my process?  </li>
  <li>Where do people (or machines) deiate from the expected or idealized processes?</li>
  </ol>
</blockquote>

<p>결국 프로세스 마이닝은 <em>Data science in Action</em> 이다.</p>

<blockquote>
  <p>Not just data processes matter</p>
</blockquote>

<h3 id="differencetypesofprocessmining">Difference Types of Process Mining</h3>

<p>프로세스 마이닝의 포지션은 <em>process model analysis</em> 와 <em>data-oriented analysis</em> 의 중간이다. </p>

<p><img src='http://fluxicon.com/blog/wp-content/uploads/2014/02/Overview-ProcessMining.jpg'  alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog' >http://fluxicon.com/blog</a>)</p>

<p>기존의 데이터마이닝은 데이터만을 보고 프로세스에 집중하지 않았다면, 프로세스 마이닝은 <em>end-to-end</em> 를 포함한 프로세스 자체에 집중한다. </p>

<p>왜 이런 프로세스에 집중할까? 그 이유는 <em>performance-oriented questions</em>, <em>comliance-oriented questions</em> 에 답하기 위해서다.</p>

<p>프로세스 마이닝의 시작은 <em>event data</em> 를 분석하는 것 부터다. <em>event log</em> 는 3가지 컬럼을 기본적으로 가지고 있는데 <em>case id</em>, <em>activity name</em>, <em>time stamp</em> 다.</p>

<p><img src='http://fluxicon.com/blog/wp-content/uploads/2012/02/PM-Example_small.png'  alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog' >http://fluxicon.com/blog</a>)</p>

<p><em>model</em> 과 <em>event data</em> 사이에는 3가지 관계가 있다.</p>

<p>(1) <strong>Play-Out:</strong> 단순히 <em>model</em> 을 <em>simulation</em> 하면 다양한 시나리오 (<em>event logs</em>) 를 만들 수 있다. <br />
(2) <strong>Play-In:</strong> 다양한 <em>event logs</em> 로 부터 <em>model</em> 을 추론하는 것이다. (<em>No modeling is needed</em>) <br />
(3) <strong>Replay:</strong> <em>event data</em> 를 <em>model</em> 에서 재현함으로써 어떤 요소가 부족한지, 혹은 병목 지점등을 파악할 수 있다. (<em>conformance checking</em>)  </p>

<p><img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-20-728.jpg?cb=1305062721'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-21-728.jpg?cb=1305062721'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-22-728.jpg?cb=1305062721'  alt="" /></p>

<p><br/> <br />
<em>play-in</em> 은 좀 신선하다. 단순히 <em>event logs</em> 만으로 실제로 사람들이 따르는 프로세스를 추론할 수 있다는 이야기다.</p>

<p>그리고 이런 모델에 대해 <em>real data</em> 를 <em>repaly</em> 함으로써 병목 지점을 발견하여 개선함으로써 <em>performance</em> 를 늘릴 수 있다는 것이다.</p>

<p><br/> <br />
<img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-17-728.jpg?cb=1305062721'  alt="" /></p>

<p>요약하자면 <em>event logs</em> 로 부터 <em>play-in</em> 을 통해 <em>model</em> 을 이끌어 내고 여기에 대해 <em>replay</em> 를 통해 <em>conformance checking</em> 을 할 수 있다. 그리고 <em>enchanced model</em> 을 실제 적용하는 과정이 <em>play-out</em> 이라 볼 수 있다.</p>

<h3 id="howprocessminingrelatestodatamining">How process Mining Relates to Data Mining</h3>

<p><br/> <br />
<img src='http://fluxicon.com/blog/wp-content/uploads/2011/08/Version2.png'  alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog' >http://fluxicon.com/blog</a>)</p>

<p>기존의 <em>BI</em> 는 실제 <em>reality</em> 를 단순히 <em>KPI</em> 를 요약하는데 그쳤었다. 그러나 <em>anscombe's quartet</em> 를 보면 알 수 있듯이 똑같은 통계치를 가졌더라도 시각화 하면 전혀 다른 양상일 수 있다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/638px-Anscombe%27s_quartet_3.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Anscombe' s_quartet'>http://en.wikipedia.org/wiki/Anscombe's_quartet</a>)</p>

<p>따라서 <em>event data</em> 를 단순히 값으로 요약하는건 <em>reality</em> 를 반영하지 못할 수도 있다. 값도 중요하지만 <em>process</em> 를 봐야한다.</p>

<p>더 깊이 들어가기전에 데이터마이닝에 대해서 좀 알고 가자.</p>

<h4 id="variables">Variables</h4>

<p>두 타입의 <em>variable</em> 이 있는데 </p>

<p>(1) <strong>categorical variables:</strong> <em>ordinal</em>, <em>nominal</em> <br />
(2) <strong>numerical varaibles:</strong> ordered, cannot be enumerated easily  </p>

<p><em>yes / no</em> 같은건 <em>nominal</em> 이다.</p>

<h4 id="supervisedlearning">Supervised Learning</h4>

<p><em>supervised learning</em> 의 목표는 <em>labeled data</em> 를 이용하여</p>

<blockquote>
  <p>Explain <strong>response variable (dependent variable)</strong> in terms of <strong>predictor variable (independent variables)</strong></p>
</blockquote>

<p>여기에는 크게 나누면 두 가지 테크닉이 쓰인다. 하나는 <em>categorial response variable</em> 에 대해 사용하는 <em>classification</em> 이고 다른 하나는 <em>numerical response variable</em> 에 대해 쓸 수 있는 <em>regression</em> 이다.</p>

<h4 id="unsupervisedlearning">Unsupervised Learning</h4>

<p><em>unsupervised learning</em> 은 <em>unlabeled data</em> 를 가지고 <em>clustering</em> 이나 <em>pattern discovert</em> 등을 하는 것이다.</p>

<p><em>k-means</em>, <em>agglomerative hierarchical</em>, <em>association rules</em> 등 다양한 알고리즘을 이용한다.</p>

<h4 id="processminingvsdatamining">Process Mining vs Data Mining</h4>

<ul>
<li>둘 다 데이터로부터 시작한다.  </li>
<li>데이터마이닝은 <em>process-centric</em> 이 아니다.  </li>
<li><em>process discovery</em>, <em>conformance checking</em>, <em>bottleneck analysis</em> 는 전통적인 데이터마이닝으로 풀기 어렵다.  </li>
<li>프로세스 마이닝은 <em>end-to-end process models</em>, <em>concurrency</em> 중심이다.  </li>
<li>프로세스 마이닝의 <em>event log</em> 는 <em>timestamp</em> 와 <em>case</em> 컬럼이 있다.  </li>
<li>프로세스 마이닝과 데이터마이닝은 복잡한 문제를 풀기 위해 같이 사용될 수 있다.  </li>
</ul>

<h3 id="learningdecisiontree">Learning Decision Tree</h3>

<p><em>decision tree</em> 는 <em>supervised learning</em> 에서 사용되는 기법이다. <em>decision tree</em> 에 놓여있는 아이디어는 처음의 <em>*high entropy (uncertain)</em> 상태에서 <em>attribute</em> 에 따라 <em>subset</em> 으로 쪼개면서 복잡도를 낮춤으로써 <em>low entropy</em> 를 만들 수 있다.</p>

<p><em>entropy</em> 는 <em>degree of uncertainty</em>, <em>inverse of compressibility</em> 다. 만약 데이터에서 <em>entropy</em> 가 매우 적다면 데이터를 압축할 수 있다. 그러나 대부분의 경우 <em>high entropy</em> 이기 때문에</p>

<blockquote>
  <p><strong>Goal:</strong> reduce entropy in leaves of tree to improve predictability  </p>
</blockquote>

<p>엔트로피를 계산하기 위해 로그를 이용하면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?E%20%3D%20-%20%5Csum_%7Bi%20%3D%201%7D%5Ek%20P_i%20%5C%20log_2%28P_i%29'  alt="" /></p>

<p><em>intuition</em> 은 초록공과 빨간공이 1:1 로 섞여있을땐 <code>E = 1</code> 이고, 빨간공이나 초록공만 있을때는 <code>E = 0</code> 이다. 따라서 <em>decision tree</em> 가 깊어지면 깊어질수록 전체 <code>E</code> 가 낮아진다. </p>

<p><img src='http://cfile26.uf.tistory.com/image/2023334B5153F4EE27D112'  alt="http://frontjang.tistory.com/" /></p>

<p align="center">(<a href='http://frontjang.tistory.com/' >http://frontjang.tistory.com</a>)</p>

<p>그리고 이렇게 얻어진 <em>overall entropy</em> 의 차이를 <em>information gain</em> 이라 부른다. <em>classification</em> 에는 변화가 없어도 <em>information gain</em> 이 있을 수 있다. 반대로 한단계 더 분리 되었어도 <em>information gain</em> 이 <code>0</code> 일 수 있다.</p>

<p>따라서 선택 가능한 모든 <em>attribute</em> 에 대해 <em>information gain</em> 을 비교하여 가장 큰 <em>attribute</em> 를 선택하고 더 이상의 커다란 변화가 없을때 까지 반복하면 <em>decision tree</em> 를 만들 수 있다.</p>

<p><em>minimal gain</em>, <em>maximum depth</em> 등을 세팅할 수도 있고, <em>overfitting</em> (모든 경우를 다 분리하는것) 을 막기 위해 최소 노드 사이즈를 정할 수 있다. <em>post pruning</em> 등 다양한 기술이 있다.</p>

<p>프로세스 마이닝에 적용해 보면 모델에서 분기 될 때 <em>"What is driving these decisions?"</em>, 등을 파악할 수 있고 <em>"most likely path"</em> 같은 문제도 해결할 수 있다.</p>

<h3 id="associationrule">Association Rule</h3>

<p><em>unsupervised learning</em> 도구인 <em>association rule</em> 을 이용해 패턴을 찾아보자.</p>

<p><em>association rule</em> 은 <code>X =&gt; Y</code> 형태다. 시작 전에 몇가지 개념을 보고 넘어가자.</p>

<h4 id="support">Support</h4>

<p><em>support</em> 는 <code>0 ~ 1</code> 사이의 값을 가지는데, <code>1</code> 이면 <em>good</em>, <code>0</code> 로 갈수록 <em>bad</em> 를 의미한다. </p>

<p><img src='http://latex.codecogs.com/gif.latex?support%28X%5CRightarrow%20Y%29%20%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%20%5Cover%20N%20%7D'  alt="" /></p>

<p>즉 전체 데이터 중 <code>X</code>, <code>Y</code> 가 같이 있는 <em>instance</em> 의 비율을 의미한다.</p>

<h4 id="confidence">Confidence</h4>

<p><em>support</em> 와 마찬가지로 <code>0 ~ 1</code> 값을 가지며 높은 값일수록 더 연관성 있음을 의미한다.</p>

<p><a href='http://latex.codecogs.com/gif.latex?confidence%28X%5CRightarrow%20Y%29%20%3D%20%7BN' >http://latex.codecogs.com/gif.latex?confidence%28X%5CRightarrow%20Y%29%20%3D%20%7BN</a><em>%7BX%20%5Ccup%20Y%7D%20%5Cover%20N</em>X%20%7D</p>

<p>전체 <code>X</code> 인스턴스 중 <code>X</code>, <code>Y</code> 가 같이 있는 <em>instance</em> 의 비율을 의미한다.</p>

<h4 id="lift">Lift</h4>

<p><img src='http://latex.codecogs.com/gif.latex?lift%28X%5CRightarrow%20Y%29%20%5C%5C%20%5C%5C%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%5C%20/%5C%20N%20%5Cover%20%7B%28N_X%20/%20N%29%20%28N_Y%20/%20N%29%7D%20%7D%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%5C%20N%20%5Cover%20%7BN_X%20%5C%20N_Y%7D%20%7D'  alt="" /></p>

<p><em>lift</em> 는 <em>실제 같이 나타나는 비율 / 기대했던 비율</em> 이다. 식을 보면 알겠지만 각 아이템이 나타나는 비율을 독립이라 가정한 것을 분모로 실제 나타나는 비율을 나눈 것이다. 따라서 <code>lift &gt; 1</code> 이면 <code>X</code> 는 <code>Y</code> 가 나타나는데 긍정적인 영향을 미치거나 혹은 <code>Y</code> 가 <code>X</code> 에 대해 긍정적인 영향을 미친것이다. 반면 <code>lift &lt; 1</code> 이면 반대고, <code>lift = 1</code> 이면 서로 관계가 없다 볼 수 있다.</p>

<p><a href='http://analyticstrainings.com/?p=151' >여기</a>를 인용하면</p>

<blockquote>
  <p><strong>A lift value greater than 1</strong> indicates that X and Y appear more often together than expected; this means that the occurrence of X has a positive effect on the occurrence of Y or that X is positively correlated with Y.</p>
  
  <p><strong>A lift smaller than 1</strong> indicates that X and Y appear less often together than expected, this means that the occurrence of X has a negative effect on the occurrence of Y or that X is negatively correlated with Y</p>
  
  <p><strong>A lift value near 1</strong> indicates that X and Y appear almost as often together as expected; this means that the occurrence of X has almost no effect on the occurrence of Y or that X and Y have Zero Correlation.</p>
</blockquote>

<p><em>class</em> 가 많으면 <em>rule</em> 또한 엄청나게 많아지기 때문에 <em>support</em>, <em>confidence</em>, <em>lift</em> 를 이용해서 룰을 필터링하거나 정렬할 수 있다.</p>

<p>일반적으로 이 3가지에 대해</p>

<p>(1) <em>support</em> 는 높을수록 좋다. <br />
(2) <em>confidence</em> 는 1에 가까워야 한다. <br />
(3) <em>lift</em> 는 1보다 커야한다.  </p>

<p>다음의 조건이 있을때 각 룰에 대해 <em>support</em>, <em>confidence</em>, <em>lift</em> 를 계산해 보자.</p>

<blockquote>
  <p>100 customers buy diapers and / or beer: <br />
  - 9 customers buy just Hoegaarden <br />
  - 40 customers buy just Pampers <br />
  - 50 customers buy just Pampers and Dommelsch <br />
  - 1 customer buys just Pampers, Hoegaarden and Dommelsch  </p>
</blockquote>

<p>먼저 <code>{Pampers} =&gt; {Dommelsch}</code> 는</p>

<p><code>s = 51 / 100 = 0.51</code>, <code>c = 51 / 91 = 0.56</code>, <code>l = 51 * 100 / (91 * 51) = 1.1</code> </p>

<p>다음으로 <code>{Dommelsch} =&gt; {Pampers}</code> 는</p>

<p><code>s = 0.51, c = 1, l = 1.1</code> 이다.</p>

<p>값을 보면 이 두 가지 룰은 상당히 신빙성이 있다고 볼 수 있다. 그리고 나머지 룰들을 살펴봐도 <code>supoort, confidence, lift</code> 값 이 상당히 낮다.</p>

<p>계산 방법은 간단한데, <em>class</em> 가 많으면 계산해야 할 <em>rule</em> 자체가 어마어마하게 많아진다. 이 문제를 해결하기 위해 몇 가지 방법이 있다.</p>

<h4 id="apriorialgorithm">Apriori Algorithm</h4>

<p><img src='http://latex.codecogs.com/gif.latex?Y%20%5Csubset%20X%5C%20%3D%3E%5C%20%28N_Y%20/%20N%29%20%5Cgeq%20%28N_X%20/%20N%29'  alt="" /></p>

<p><code>X</code> 의 부분집합인 <code>Y</code> 에 대해서, <code>X</code> 의 <em>support</em> 가 높으면 <code>X</code> 의 부분집합도 충분히 빈번해야 한다. 그래서 <code>X</code> 의 부분집합인 <code>Y</code> 의 <em>support</em> 가 낮으면 <code>Y</code> 의 부분집합을 살펴볼 필요가 없어 연산 수를 줄일 수 있다.</p>

<h4 id="patternmining">Pattern Mining</h4>

<p>여기서 본 연관 분석은 <em>process</em> 를 고려하지 않지만, 이 기법을 잘 활용하면 <em>sequence mining</em> 이나 <em>episode mining</em> 등등에 활용 될 수 있다.</p>

<h3 id="clusteranalysis">Cluster Analysis</h3>

<p><em>unsupervised learning</em> 기법인 <em>clustering</em> 도 간단히 살펴보자.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/SLINK-Gaussian-data.svg/186px-SLINK-Gaussian-data.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Cluster_analysis' >http://en.wikipedia.org/wiki/Cluster_analysis</a>)</p>

<h4 id="kmeansclustering">k-means clustering</h4>

<p>여기서 <code>k</code> 는 몇개의 집단으로 나눌건지를 의미하는 숫자다. 알고리즘 자체는 굉장히 직관적이다.</p>

<p>(1) 먼저 <em>centroid</em> 라 부르는 점들을 <em>attribute</em> 에 랜덤하게 혹은 레귤러 하게 <code>k</code> 개 배치한다. <br />
(2) 각 점에서 <em>centroid</em> 까지 거리가 가장 짧은 <em>centroid</em> 를 선택하고, 이 집단 내부에서 가운데 점을 계산해 <em>centroid</em> 로 다시 정한다. <br />
(3) <em>centroid</em> 에 변화가 없을 때 까지 계속 반복한다.  </p>

<p><img src='http://datavisualization.blog.com/files/2011/08/kmeansclustering.jpg'  alt="" /></p>

<p align="center">(<a href='http://datavisualization.blog.com/' >http://datavisualization.blog.com</a>)</p>

<pre><code>// ref: http://datavisualization.blog.com/visible-data/cluster-analysis/

Select K points as the initial Centroids  
REPEAT  
   Form K clusters by assigning all points to the closest Centroid
   recompute the Centroid for each cluster
UNTIL Centroids don’t change // or less than thresahold”  
</code></pre>

<p>초기에 <em>centroid</em> 가 랜덤하게 선택되기 때문에 <em>non-deterministic</em> 이어서 여러번 계산 후에 가장 좋은 <em>clustering</em> 을 골라야 한다. </p>

<p>그리고 <code>k</code> 값에 따라 클러스터가 달라질 수 있으므로 변화시켜가면서 좋은 <code>k</code> 값을 찾아야 한다.</p>

<p><img src='http://datavisualization.blog.com/files/2011/08/howmanyclusters.jpg'  alt="" /></p>

<p align="center">(<a href='http://datavisualization.blog.com/' >http://datavisualization.blog.com</a>)</p>

<h4 id="agglomerativehierarchicalclustring">Agglomerative hierarchical clustring</h4>

<p><em>k-means</em> 이외에도 다양한 클러스터링 알고리즘이 있다.</p>

<p><img src='http://www.cs.umd.edu/hcil/hce/hce3-manual/dendrogram.png'  alt="" /></p>

<p align="center">(<a href='http://www.cs.umd.edu/' >http://www.cs.umd.edu</a>)</p>

<h4 id="applyingprocessmining">Applying Process Mining</h4>

<p>클러스터링은 <em>event-log</em> 를 분할하는데 쓸 수 있다. 그러면 특징이 다른 <em>event-log</em> 를 뽑아낼 수 있고 각각의 클러스터에 대해 모델을 만드는데 유용하다.</p>

<h3 id="evaluatingminingresult">Evaluating Mining Result</h3>

<p>마이닝으로 모델을 만들거나, 결과를 얻었다고 하자. 어떻게 평가할까?</p>

<h4 id="confusionmatrix">Confusion Matrix</h4>

<p><em>confusion matrix</em> 는 <em>predict class</em> 와 <em>actual class</em> 를 기반으로 테이블을 만든 것이다.</p>

<p><img src='http://lh3.ggpht.com/_qIDcOEX659I/SzjW6wGbmyI/AAAAAAAAAtY/Nls9tSN6DgU/contingency_thumb%5B3%5D.png?imgmax=800'  alt="" /></p>

<p align="center">(<a href='http://crsouza.blogspot.kr/' >http://crsouza.blogspot.kr</a>)</p>

<p><br/> <br />
여기에 대해 <em>error</em>, <em>accuracy</em>, <em>precision</em>, <em>recall</em>, <em>F1-score</em> 등을 계산할 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/08classbasic-140913212207-phpapp02/95/data-miningconcepts-and-techniques-chapter-8-classification-basic-concepts-51-638.jpg?cb=1410662460'  alt="" /></p>

<p align="center">(<a href='http://www.slideshare.net/salahecom/08-classbasic' >http://www.slideshare.net/salahecom/08-classbasic</a>)</p>

<h4 id="crossvalidation">Cross Validation</h4>

<p>가지고 있는 데이터로 모델을 만들면, 모델에는 잘 맞지만 실제 데이터에는 안맞을 수 있다.</p>

<blockquote>
  <p><em>*Overfitting: *</em> the model is too specific for the data set used to learn the model and performs poorly on new instances</p>
  
  <p><strong>Underfitting :</strong> the model is too general and does not exploit the data</p>
</blockquote>

<p>그래서 데이터셋을 <em>training set</em> 과 <em>test set</em> 으로 분리해서 각각 훈련, 퍼포먼스 테스트를 위해 사용한다.</p>

<h3 id="summary">Summary</h3>

<p>이번 주차엔 데이터마이닝에 대해서 논했는데, 다음 시간부터는 <em>process discovery</em>, <em>conformance checking</em> 등에 대해 이야기 한다. <del>어째 오토마타의 향연이 될 것 같기도</del></p>

<h3 id="references">References</h3>

<p>(1) <strong>Process Mining: Data science in Action</strong> by Wil van der Aalst <br />
(2) <a href='http://1ambda.github.io/www.processmining.org' >www.processmining.org</a> <br />
(3) <a href='http://blog.zhaw.ch/datascience/the-data-science-skill-set/' >http://blog.zhaw.ch/datascience/the-data-science-skill-set/</a> <br />
(4) <a href='http://fluxicon.com/blog/2014/02/how-is-process-mining-different-from/' >http://fluxicon.com/blog</a> <br />
(5) <a href='http://www.slideshare.net/wvdaalst/process-mining-chapter01introduction?related=1' >Process Mining Chapter 1</a> <br />
(6) <a href='http://en.wikipedia.org/wiki/Anscombe' s_quartet">Anscombe's quartet</a> <br />
(7) <a href='http://frontjang.tistory.com/category/Computer/MachineLearning' >http://frontjang.tistory.com</a> <br />
(8) <a href='http://analyticstrainings.com/?p=151' >http://analyticstrainings.com/?p=151</a> <br />
(9) <a href='http://datavisualization.blog.com/visible-data/cluster-analysis/' >http://datavisualization.blog.com</a> <br />
(10) <a href='http://www.cs.umd.edu/hcil/hce/hce3-manual/hce3_manual.html' >http://www.cs.umd.edu</a> <br />
(11) <a href='http://crsouza.blogspot.kr/2009/12/performing-discriminant-power-analysis.html' >http://crsouza.blogspot.kr</a> <br />
(12) <a href='http://www.slideshare.net/salahecom/08-classbasic' >http://www.slideshare.net/salahecom/08-classbasic</a></p>]]></description><link>http://1ambda.github.io/process-mining-week1/</link><guid isPermaLink="false">6b0990d6-e516-4154-9e40-4b7b7244bdbf</guid><category><![CDATA[coursera]]></category><category><![CDATA[process mining]]></category><category><![CDATA[decision tree]]></category><category><![CDATA[association rule]]></category><category><![CDATA[k-means clustering]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 18 Nov 2014 03:51:30 GMT</pubDate></item><item><title><![CDATA[Graph Search and Connectivity￼]]></title><description><![CDATA[<p>기본적인 그래프 탐색 방법 <em>DFS</em>, <em>BFS</em> 에 대해 배우고 약간씩 응용하여 <em>shortest path</em>, <em>conncected components</em>, <em>topological order</em>, <em>strongly connected components</em> 등을 찾는 방법을 배운다. </p>

<p>마지막 부분에선 웹이 어떻게 생겼을까 잠깐 고민해 본다.</p>

<h3 id="graphsearch">Graph Search</h3>

<p>그래프 탐색은 다양하게 활용할 수 있다.</p>

<p>(1) check if a network is connected <br />
(2) driving directoin (shortest path) <br />
(3) formulate a plan (e.g how to fill in a sudoku puzzle) <br />
(4) compute the <em>"pieces"</em> of a graph (e.g clustering)</p>

<p>그래프를 탐색하는데는 <em>"재 방문하지 않는다"</em> 등 여러 조건이 붙으면서 다양한 방법이 있을 수 있겠지만 여기서는 단순히 모든 <em>vertex</em> 를 방문하는 일반적인 그래프 탐색 알고리즘 (<em>generic algorithm</em>) 에 대해 먼저 이야기 해 보자.</p>

<p>이렇게 먼저 일반적인 알고리즘을 정의해 보는 이유는, <em>BFS</em> 와 <em>DFS</em> 를 증명할때 먼저 정의한 일반적인 알고리즘의 특수한 경우임을 파악하여 이미 증명된 결과를 활용할 수 있기 때문이다.</p>

<blockquote>
  <p>Goals: <strong>find everything findable from a given start vertex</strong>, <code>O(m + n)</code></p>
</blockquote>

<p>여기서 <em>findable</em> 이란 말은 두 점 <code>(s, e)</code> 사이에 <em>path (경로)</em> 가 있냐는 질문과 동일하다. 경로가 없으면 <em>findable</em> 이 아니다.</p>

<p>목표로 하는 복잡도가 <code>O(m + n)</code> 인데, 이것은 정점의 수 <code>n</code> 이나 엣지수 <code>m</code> 중 더 큰 수를 따라간다고 이해하면 된다. 알고리즘은 이렇다.</p>

<pre><code>initially `s` explored, all other vertices are unexplored  
while possible:  
  choose an edge `(u, v)` with `u` explored and `v` unexplored  
  mark `v` explored  
</code></pre>

<p><em>generic graph search algorithm</em> 이 끝났을때 <code>v</code> 가 <em>explored</em> 라면 그래프 <code>G</code> 가 <code>s -&gt; v</code> 인 <em>path</em> 가 존재한다. 이를 귀납법으로 증명해 보자.</p>

<p>귀납법이므로 먼저 증명하려는 바를 부정하여 알고리즘이 종료 되었을 때 <code>G</code> 에서 <code>(s -&gt; v)</code> 로 가는 경로가 없다고 하자. </p>

<p>알고리즘 초기 단계에서 <code>s</code> 만 <em>explored</em> 고 나머지는 <em>unexplored</em> 다. 매 탐색마다 <code>(u, w)</code> 를 찾아내며 <em>unexplored</em> <code>w</code> 를 <em>explored</em> 로 마킹한다. </p>

<p><code>(s, v)</code> 사이 경로가 없다면, 어떤 <code>w</code> 가 <em>unexplored</em> 인 <code>(u, w)</code> 가 알고리즘이 끝났을때 존재해야 한다. <code>w</code> 가 <code>v</code> 일수도, <code>u</code> 가 <code>s</code> 일수도 있다.</p>

<p>그러나 이 경우 <em>unexplored</em> <code>w</code> 가 존재하면 알고리즘이 절대 종료될 수 없다. 결국 모순이므로 <code>s -&gt; v</code> <em>path</em> 가 없다는 것이 잘못되었다.</p>

<h3 id="bfsvsdfs">BFS vs DFS</h3>

<p>사실 그래프 탐색 문제는 <em>crossing edge</em> 문제와 같다. 한쪽을 <em>explored</em>, 다른쪽을 <em>unexplored</em> 라 놓고 각 <em>vertex</em> 들을 잇는 <em>crossing edge</em> 를 고르는 문제다.</p>

<p><em>BFS</em> 는 기본적으로 <em>queue</em> 를 사용하면 <code>O(m + n)</code> 이다. 그리고</p>

<p>(1) explore nodes in <em>"layers"</em> <br />
(2) can compute <em>"shortest path"</em> <br />
(3) can compute connected components of an undirected graph  </p>

<p><em>DFS</em> 는 <em>stack</em> 을 이용하면 <code>O(m + n)</code> 이다. 그리고</p>

<p>(1) explore aggressively like a maze, backtrack only when necessary <br />
(2) compute topological ordering of directed acyclic graph <br />
(3) compute connected components in directed graphs</p>

<h3 id="breadthfirstsearch">Breadth-First Search</h3>

<p><em>BFS</em> 는 <em>shortest path</em> 를 계산할 수 있고 <em>undirected graph</em> 의 <em>connected components</em> 를 구할 수 있다. 그리고 복잡도는 <code>O(m + n)</code> 이다.</p>

<p>함수를 <code>BFS(graph G, start-vertex s)</code> 라 하면 시작단계에서는 모든 그래프 노드가 <em>unexplored</em> 다.</p>

<p>(1) mark <code>s</code> as explored <br />
(2) Let <code>Q</code> - queue data structure <strong>(FIFO)</strong>, initialied with <code>s</code> <br />
(3) while <code>Q</code> is not empty: <br />
- remove the first node of <code>Q</code>, call it <code>v</code> <br />
- for each edge <code>(v, w)</code>, if <code>w</code> unexplored mark <code>w</code> as explored and add <code>w</code> to Q</p>

<p>시작 점 <code>s</code> 를 <em>layer 0</em> 이라 부르면 <em>layer 1</em> 은 <em>layer 0</em> 에서 갈 수 있는 지점이다. 모두 저장하고, 큐에서 하나 꺼내 <em>layer 2</em> 를 계산해서 다시 집어넣고, 이 과정을 반복한다. 알고리즘 중에 이미 방문했는지를 검사하기 때문에 같은 노드를 두번 이상 방문하지 않는다.</p>

<p>알고리즘이 종료되었을때 <code>v</code> 가 <em>explored</em> 라면 <code>s -&gt; v</code> 인 <em>path</em> 가 존재한다. 증명은 간단한데 <em>BFS</em> 가 <em>generic search algorithm</em> 의 <em>spcial case</em> 이기 때문이다. </p>

<p><em>BFS</em> 알고리즘을 잘 보면 <em>generic algorithm</em> 처럼 <code>(u, w)</code>, <code>w</code> 는 <em>unexplored</em> 인 <em>edge</em> 를 찾는데, 이 때 <em>BFS</em> 는 한 레이어에서 다음 레이어로 갈 수 있는 <em>edge</em> 만 찾는다는 점이 다르다.</p>

<p><em>running time</em> 은 <code>O(n_s + m_s)</code> 다. 여기서 <code>n_s</code> 는 <code>s</code> 에서 갈 수 있는 <em>node</em> 의 숫자고 <code>m_s</code> 는 <code>s</code> 에서 갈 수 있는 <em>edge</em> 수다.</p>

<p><code>while</code> 루프 알고리즘을 다시 보면</p>

<pre><code>while `Q` is not empty:  
  remove the first node of `Q`, call it `v`  
  for each edge `(v, w)`:
    if `w` is unexplored:
      mark `w` as explored
      add `w` to Q
</code></pre>

<p>한 <em>vertex</em> 는 아무리 많아봐야 큐에 한번 들어가고,  이 때마다 이 <em>vertex</em> 에서 갈 수 있는 <em>edge</em> 를 검사하지만, 결국 아무리 많아봐야 한 <em>edge</em> 당 두번씩만 검사되고, 검사하는 <code>for</code> 구문은 <code>O(1)</code> 이기 때문에 <code>O(m + n)</code> 이다.</p>

<h3 id="shortestpath">Shortest Path</h3>

<p>생각해보면 굉장히 쉽다. <code>s</code> 부터 시작해서 <code>v</code> 까지의 거리를 찾는 경우 <code>s = v</code> 면 각 노드의 <code>dist</code> 값을 <code>0</code> 으로, 아니면 무한히 큰 값으로 한다. </p>

<p><em>BFS</em> 에서 레이어마다 하나씩 넘어갈때 마다 <code>dist</code> 값을 1씩 증가시키는데, 이때 이미 <code>dist</code> 값이 있는 경우 그 값보다 적으면 새로운 <code>dist</code> 값을 기록하고, 아니면 기록하지 않는다.</p>

<p>따라서 알고리즘이 종료되었을때 <code>dist(v) = i</code> 라면 <code>v</code> 는 <code>i</code> 번째 레이어에 있다. 바꿔말하면 <em>shortest path <code>(s, v)</code></em> 는 <code>i</code> 개의 <em>edge</em> 를 가지고 있다는 뜻이다.</p>

<h3 id="undirectedconnectivity">Undirected Connectivity</h3>

<p><em>undirected connectivity</em> 는 그래프에서 서로 연결된 부분 집합을 찾는 문제다. 용어부터 정의하고 가자면</p>

<blockquote>
  <p>equivalence classes of the relation <code>u ~ v</code> &lt;=> <code>E(u, v)</code> path in <code>G</code></p>
</blockquote>

<p><em>equivalence class</em> 는 처음봤는데 위키에 보니 다음의 3 가지 속성을 만족한다고 한다.</p>

<blockquote>
  <p>For every element <code>a</code> in X, <code>a ~ a</code> <strong>(reflexivity)</strong> <br />
  For every two elements <code>a</code> and <code>b</code> in X, if <code>a ~ b</code>, then <code>b ~ a</code> <strong>(symmetry)</strong> <br />
  For every three elements <code>a</code>, <code>b</code>, and <code>c</code> in X, if <code>a ~ b</code> and <code>b ~ c</code>, then <code>a ~ c</code> <strong>(transitivity)</strong></p>
</blockquote>

<p><em>connected component</em> 를 어디다 쓸 수 있을까? </p>

<p>네트워크에 대해 적용해 보면, 네트워크가 끊어졌는지를 <em>connected component</em> 를 구해서 두개 이상이 나오는지로 판단할 수 있다.</p>

<p><em>clustering</em> 에도 쓸 수 있다. 만약 두 유전자나, 웹페이지가 비슷한지를 비교해서 <em>connected component</em> 로 만들면 구별되는 특징을 가진 집단을 만들 수 있다.</p>

<p><em>clustering</em> 하는 다른 알고리즘이 많음에도 <em>BFS</em> 는 <em>linear time</em> 이기 때문에 <em>clustering</em> 에 충분히 쓸만하다.</p>

<p><em>undirected</em> 그래프에서 <em>BFS</em> 를 이용하면 <em>conncected component</em> 를 구하는 알고리즘은 이렇다.</p>

<pre><code>all node unexplored // assume labelled 1 to n

for i = 1 to n  
  if i not yet explored
    BFS(G, i)
</code></pre>

<p>따라서 <code>BFS</code> 를 수행할 때 마다 <em>connected component</em> 가 하나씩 나온다고 말할 수 있다. </p>

<p>성능은 마찬가지로 <code>O(m + n)</code> 이다. 왜냐하면 부의 <code>if</code> 나 <code>for</code> 그리고 모든 노드를 <em>unexplored</em> 로 초기화 하는 부분도 <code>O(n)</code> 이고, 각 노드 하나씩에 대해서 방문하지 않았을 때만 <em>BFS</em> 를 수행하는데 <em>BFS</em> 는 <em>edge</em> 에 대해서는 <code>O(1)</code> 이고, 모든 <em>edge</em> 를 검사하므로 <em>BFS</em> 의 전체 성능은 <code>O(m)</code> 이다. 따라서 <code>O(m + n)</code></p>

<h3 id="depthfirstsearch">Depth-First Search</h3>

<blockquote>
  <p>explore aggressively, and backtrack when necessary</p>
</blockquote>

<p><em>BFS</em> 로도 <code>O(m +n)</code> 시간 내에 탐색하고 <em>shortest path</em>, <em>connected component</em> 를 찾는데 왜 <em>DFS</em> 가 필요할까?</p>

<p>(1) can computes a topological ordering of a directed acyclic graph <br />
(2) strongly conncected components of directed graphs</p>

<p><em>BFS</em> 는 못하는 이 두 가지 문제를 <code>O(m + n)</code> 으로 해결할 수 있다.</p>

<p>코드는 비슷한데 <em>queue</em> 대신 <em>stack</em> 을 쓰도록 하고, 재귀버전으로 작성해 보자.</p>

<pre><code>DFS(graph G, start-vertex s)

mark s as explored

for every edge (s, v):  
  if v is unexplored
    DFS(G, v)
</code></pre>

<p><em>DFS</em> 가 종료 됐을때 <code>v</code> 가 <em>explored</em> 라면 <code>s -&gt; v</code> 인 <em>path</em> 가 있다. 이는 <em>DFS</em> 가 위에서 본 <em>generic search algorithm</em> 의 특별한 케이스임을 생각하면 쉽게 알 수 있다.     </p>

<p>성능은 <em>BFS</em> 와 같이 <code>O(n_s  m_s)</code> 인데, 각 <em>vertex</em> 는 아무리 많아봐야 한번, <em>edge</em> 는 아무리 많아봐야 두번씩 체크하고 <em>edge</em> 내부에서의 연산은 <code>O(1)</code> 이기 때문이다.</p>

<h3 id="topologicalsort">Topological Sort</h3>

<p>정의부터 보면</p>

<blockquote>
  <p>A <strong>toplogical ordering</strong> of a <em>directed graph</em> <code>G</code> is a labelling <code>f</code> of <code>G</code>'s nodes such that <br />
  1. the <code>f(v)</code>'s are the set <code>{1, 2, 3, ..., n}</code> <br />
  2. <code>(u, v)</code> in <code>G</code> => <code>f(u)</code> &lt; <code>f(v)</code></p>
</blockquote>

<p>이미지로 보면 더 이해하기 쉽다.</p>

<p><img src='http://www.stoimen.com/blog/wp-content/uploads/2012/12/3.-Topological-Sort-Order.png'  alt="" /></p>

<p align="center">(<a href='http://www.stoimen.com/' >http://www.stoimen.com</a>)</p>

<p>왜 <em>topological sort</em> 가 필요할까? <em>precedence constraints</em> 가 있는 <em>sequence</em> 에서 나올 수 있는 모든 경우의 수를 파악하기에 좋다. 예를 들어 선수과목이 있을때 이수 가능한 스케쥴이라던가, 일정이라던가.</p>

<blockquote>
  <p>Sequence taks while respecting all precedence constraints</p>
</blockquote>

<p>단, <em>topological sort</em> 를 하기 위한 조건이 하나 있는데 <em>directed cycle</em> 이 없어야 한다. 다시 말해 <em>acyclic</em> 이어야 한다.</p>

<blockquote>
  <p>If <code>G</code> has directed cycle, then no topological ordering</p>
</blockquote>

<p><em>directed graph</em> 에서 <em>outgoing edge</em> 가 없는 것을 <em>sink vertex</em> 라 하자. 그러면 <em>directed acyclic graph, DAG</em> 는 최소한 하나의 <em>sink vertex</em> 를 가지고 있다.</p>

<p>증명은 <em>contradiction</em> 을 이용하자. <em>sink vertex</em> 가 없다고 하면, 쭈욱 방문하다 보면 하나의 <em>vertex</em> 를 두번 이상 방문하게 되고, 그건 <em>cyclic</em> 이므로 <em>acyclic</em> 이란 조건에 위배되므로 모순이다. 따라서 <em>DAG</em> 에서는 최소한 하나의 <em>sink vertex</em> 가 있다.</p>

<p><em>topological sort</em> 의 알고리즘은 </p>

<pre><code>let v be a sink vertex of G  
set f(v) = n  
recurse on G - {v}  
</code></pre>

<p><code>G - {v}</code> 도 <em>DAG</em> 이다. 왜냐하면 <em>DAG</em> 에서 <em>sink vertex</em> 를 제거해도 <em>DAG</em> 이기 때문에 매 재귀마다 <code>G</code> 는 <em>DAG</em> 가 된다. 이 때 제거하는 <em>sink vertex</em> 에 전체 노드 수 <code>n</code> 을 매기기 때문에 최종적으로는 <code>1, .., n</code> 을 가진 <em>toplogical order</em> 을 계산할 수 있다.</p>

<p>이제 <em>DFS</em> 를 이용해 <em>toplogical sort (위상 정렬)</em> 을 해보자.</p>

<pre><code>DFS(graph G, start-vertex s)  
- mark s explored  
- for every edge (s, v):
    if v not yet explored:
      DFS(G, v)
- set f(s) = current_label // sink vertex
- current_label--

DFS-Loop(graph G)  
- mark all nodes unexplored
- current_label = n // to keep track of ordering
- for each vertex v in G:
    if v not yet explored:
      DFS(G, v)
</code></pre>

<p><em>running time</em> 은 <code>O(m + n)</code> 이다. <em>node</em> 마다 <code>O(1)</code>, <em>edge</em> 마다 <code>O(1)</code> 이고 <em>node</em> 나 <em>edge</em> 는 두번 방문하지 않기 때문에 (<em>directed graph</em>) <code>O(m + n)</code></p>

<p>위상정렬을 하는지는 <code>(u, v)</code> 가 <em>edge</em> 라면 <code>f(u) &lt; f(v)</code> 임을 보이면 된다.</p>

<p><code>u</code> 먼저 방문되었을 경우에는 <code>v</code> 가 먼저 끝나 <code>n</code> 이 할당되기 때문에 <code>f(u) &lt; f(v)</code> 다.</p>

<p>만약에 <code>v</code> 가 <code>u</code> 보다 먼저 방문되면 <code>u</code> 가 방문되기도 전에 <code>v</code> 에 대한 방문이 끝나므로 <code>f(u) &lt; f(v)</code> 다.</p>

<h3 id="stronglyconnectedcomponents">Strongly Connected Components</h3>

<p>먼저 정의부터 보면 </p>

<blockquote>
  <p><strong>Strongly conncected components (SCCs)</strong> of a directed graph <code>G</code> are the equivalence classes of the relation. <code>u ~ v</code> means path <code>u -&gt; v</code> and <code>v -&gt; u</code> in G</p>
</blockquote>

<p><em>directed graph</em> 는 방향성이 있기 때문에 단순히 <em>component</em> 를 구한다고 해서 <em>equivalence classes</em> 가 되지 않는다. 서로 순환이 될 수 있는, cyclic  인 <em>component</em> 를 찾아야 한다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/5/5c/Scc.png'  alt="" /></p>

<p align="center">(<a href='http://commons.wikimedia.org/' >http://commons.wikimedia.org</a>)</p>

<p><em>SCC</em> 는 <em>cycle</em> 이기 때문에 <em>DFS</em> 만 돌려도 나올 <strong>수</strong> 있다. 그런데, 만약 전체로 갈 수 있는 노드에서 <em>DFS</em> 를 돌려버리면 모든 <em>SCC</em> 가 합쳐진 형태가 나온다. 다시 말해서 단순 DFS 를 모든 노드에 대해 돌리는 것으로는 <em>SCC</em> 를 얻을 수도, 못 얻을 수도 있다는 소리다. <em>Kosaraju's Two-Pass Algorithm</em> 으로 해결할 수 있다.</p>

<h3 id="kosarajus2passalgorithm">Kosaraju's 2-pass algorithm</h3>

<p><code>O(m + n)</code> 으로 <em>SCC</em> 를 구하는 것을 보장한다. 어떻게 그럴까? <em>SCC</em> 를 찾을 때 <em>DFS</em> 를 돌릴려면 <strong>특정 노드의 순서</strong>로 <em>DFS</em> 를 돌려야 한다. 그렇지 않으면 <em>SCC</em> 가 나오지 않는다. <em>Kosaraju algorithm</em> 은 이 순서를 찾아준다. </p>

<pre><code>Let G_rev = G with all arcs reversed  
run DFS-Loop on G_rev // compute "magical ordering"  
run DFS-Loop on G // discover SCCs  
</code></pre>

<p>좀 더 자세히 보면 <code>f(v)</code> 를 각 <em>vertex</em> 에 대해 <em>finishing time</em> 이라 보면, 두번째 <code>DFS-Loop</code> 에서 <code>f(v)</code> 의 <em>decreasing order</em> 로 <code>DFS</code> 를 여러번 돌리면 <em>SCC</em> 를 찾아준다. 각 함수의 구현을 보면</p>

<pre><code>DFS-Loop(graph G)

global variable t = 0 // # of nodes processed so far  
global variable s = NULL // current source vertex

// assume nodes labelled 1 to n
for i = n to 1 by -1:  
  if i not yet explored:
    s := i
    DFS(G, i)
</code></pre>

<pre><code>DFS(graph G, node i)

mark i as explored  
set leader(i) := node s

for each arc (i, j) in G:  
  if j not yet explored:
    DFS(G, j)

t++  
set f(i) := t  
</code></pre>

<p>첫번째 <code>DFS-Loop</code> 에서는 <em>edge</em> 가 뒤집어져 있다. 함수가 끝나면 각 노드마다 <code>f(t)</code> 를 계산 해 주는데, 이게 사실 <em>SCC</em> 기준으로 보면 같은 <em>SCC</em> 내에서는 외부와의 연결고리가 없는 내부 노드가 가장 낮은 <code>f(t)</code> 를 가지게 된다. </p>

<p>이제 두번째 <code>DFS-Loop</code> 를 돌리기 위해 <em>edge</em> 를 다시 뒤집어서 보면 가장 높은 <code>f(t)</code> 값을 가지는 노드가 가장 먼저 <em>DFS</em> 를 돌려야 할 노드가 된다. 그리고 <em>leader</em> 는 각 <em>SCC</em> 를 얻기 위해 <em>DFS</em> 를 시작해야 할 지점이 된다.</p>

<p><em>running time</em> 은 <code>2 x DFS</code> 기 때문에 <code>O(m + n)</code> 이다. 첫 번째 노드에서 얻은 <em>finisihing time</em> <code>f(t)</code> 를 정렬하면 <code>O(n logn)</code> 이기 때문에 정렬 없이 <em>decreasing</em> 순서로 <em>DFS</em> 를 돌게 해줘야 한다.</p>

<h3 id="analysis">Analysis</h3>

<p>분석에 앞서서 간단한 성질을 먼저 이끌어 내자. 그래프를 변형해 <em>node</em> 각각을 <em>SCC</em> 로 만든 <em>meta-graph</em> 를 생각 해 보자. 이 <em>meta graph</em> 는 <em>DAG</em> 다. 왜냐하면 모든 <em>cycle</em> 있는 그래프는 <em>SCC</em> 로 포함되었기 때문이다.</p>

<p>따라서 <code>G</code> 나, 여기서 <em>edge, arc</em> 를 뒤집은 <code>G_rev</code> 나 같은 <em>SCC</em> 를 가지고 있다.</p>

<p>이 때 <code>G</code> 에서 서로 인접한 <em>SCC</em> <code>C1 -&gt; C2</code> 에 대해서 <em>edge</em> <code>(i, j)</code> 가 있다고 해 보자. (<code>i -&gt; j</code>)</p>

<p>그러면 <code>G_rev</code> 로 계산한 <code>max f(C1) &lt; max f(C2)</code> 임을 알 수 있다. 다시 말해 <code>C2</code> 가 먼저 <em>DFS</em> 를 돌려야 하는 <em>SCC</em> 인데, 먼저 돌려야 할 수록 더 높은 <em>finishing time</em> <code>f(t)</code> 를 가진다. </p>

<p>이건 쉽게 보일 수 있는데, <code>G_rev</code> 에서는 <em>arc</em> 가 반대 방향이 되므로 더 큰 <em>SCC</em> <code>C1</code> 이, 다시 말해 더 나중에 계산해야 할 <em>SCC</em> 가 더 작은 <em>SCC</em> 가 되므로 먼저 계산이 끝나 더 작은 <code>max f(t)</code> 를 가지게 된다. </p>

<p>증명은 <code>C1 union C2</code> 의 첫번째 노드가 <code>C1</code> 에 있을 때 <code>C2</code> 에 있을때로 각각 나눠서 참임을 보이면 쉽다.</p>

<p>알고리즘을 다시 보면</p>

<pre><code>DFS-Loop(graph G)

global variable t = 0 // # of nodes processed so far  
global variable s = NULL // current source vertex

// assume nodes labelled 1 to n
for i = n to 1 by -1:  
  if i not yet explored:
    s := i
    DFS(G, i)
</code></pre>

<pre><code>DFS(graph G, node i)

mark i as explored  
set leader(i) := node s

for each arc (i, j) in G:  
  if j not yet explored:
    DFS(G, j)

t++  
set f(i) := t  
</code></pre>

<p><code>DFS</code> 를 한번 돌릴 때 마다 <em>SCC</em> 가 하나씩 발견된다. 우선 <em>sink SCC</em> 가 가장 높은 <code>f(t)</code> 값을 가지게 되므로 가장 먼저 <em>DFS</em> 를 돌게 된다. 그리고 <em>SCC</em> 는 <em>cyclic</em> 이므로 하나의 <em>SCC</em> 만 찾고 끝남을 보장한다. 다음으로 높은 <code>f(t)</code> 값을 가지는 <em>SCC</em> 를 찾고, 더이상 <em>SCC</em> 를 찾지 못할 때 까지 반복하고 알고리즘이 끝나는걸 확인할 수 있다.</p>

<p>처음엔 잘 몰랐는데 <em>leader</em> 가 해당 <em>SCC</em> 에서 가장 높은 <code>f(t)</code> 값을 가지는 <em>node</em> 다.</p>

<h3 id="structureoftheweb">Structure of the Web</h3>

<p><em>vertices</em> 를 웹페이지라 보고 <em>edges</em> 를 하이퍼링크라 보면 웹을 <em>directed graph</em> 이해할 수 있다.</p>

<p>그럼 웹은 어떻게 생겼을까? 사람들이 첫번째로 웹이 어떻게 생겼는지 확인하기 위해 시도한 방법은 <em>crawling</em>, 즉 링크를 따라가며 모든 웹페이지를 긁는 방식이었다.</p>

<p>그래서 실제로 해보니 2000 년도에는 <em>200 milions</em> 의 <em>node</em>, <em>1 bilion</em> 의 <em>edge</em> 가 있었다고 한다.</p>

<p>그럼 이게 어떻게 생겼을까? <em>one big scc</em> 일거라 보는 관점이 있다. 한쪽에선 오래된 웹페이지들이 있고, 더 뻗어나가지 않는다. 이쪽을 <em>out</em> 이라 보면 반대편에서는 새로운 웹페이지들이 생겨 기존의 웹페이지에 <em>edge</em> 를 붙여 나가는 <em>in</em> 부분이 있다고 할 수 있다. 몇몇 부분에는 전혀 연결이 되지 않은 부분이 있을 수 있다.</p>

<p><img src='http://bparsia.files.wordpress.com/2009/11/bowtieweb.png?w=600&amp;h=364'  alt="" /></p>

<p align="center">(<a href='http://bparsia.wordpress.com/' >http://bparsia.wordpress.com</a>)</p>

<p>웹의 <em>core</em> 부분은 <em>well connected</em> 되어 있는데 <em>small world property</em> 를 가지고 있다. 무슨말이냐면 모든 노드가 각각 서로 연결되어 있진 않지만 연결을 많이 가지고 있는 특정 몇몇 노드에 의해 모든 노드가 연결된다는 뜻이다. 결국 서로 연결되는데 몇 <em>hop</em> 안걸린다 볼 수 있다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Small-world-network-example.png/330px-Small-world-network-example.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Small-world_network' >http://en.wikipedia.org/wiki/Small-world_network</a>)</p>  

<p><img src='http://web.mit.edu/9.29/www/neville_jen/connectivity/MEA2_files/image002.jpg'  alt="" /></p>

<p align="center">(<a href='http://web.mit.edu/' >http://web.mit.edu</a>  
)</p>

<p>요즘의 연구들은 웹 그래프가 어떤식으로 진화하는지, 정보들이 어떤식으로 전파되는지 등을 중점으로 하고 있다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong> <br />
(2) <a href='http://en.wikipedia.org/wiki/Equivalence_class' >Equivalence class</a> <br />
(3) <a href='http://www.stoimen.com/blog/2012/12/10/computer-algorithms-topological-sort-revisited/' >http://www.stoimen.com</a> <br />
(4) <a href='http://commons.wikimedia.org/wiki/File:Scc.png' >http://commons.wikimedia.org/wiki/File:Scc.png</a> <br />
(5) <a href='http://bparsia.wordpress.com/2009/11/24/does-rest-explain-the-bowtie-gross-structure-of-the-web/' >http://bparsia.wordpress.com</a> <br />
(6) <a href='http://web.mit.edu/9.29/www/neville_jen/connectivity/MEA2.htm' >http://web.mit.edu</a> <br />
(7) <a href='http://en.wikipedia.org/wiki/Small-world_network' >http://en.wikipedia.org/wiki/Small-world_network</a></p>]]></description><link>http://1ambda.github.io/graph-search-and-connectivity/</link><guid isPermaLink="false">dcb3c85a-c903-4dab-bb88-b408099fb092</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[graph]]></category><category><![CDATA[BFS]]></category><category><![CDATA[DFS]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 15 Nov 2014 04:29:52 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 6]]></title><description><![CDATA[<p>지난시간엔 <em>back propagation</em> 구현해 보고 여기에 적용할 수 있는 소소한 것들 <em>random initialization</em> 과 <em>gradient checking</em> 등도 알아 보았다.</p>

<p>머신러닝을 단순히 아는것과, 실전에서 사용할 수 있다는 건 큰 차이가 있다. 이번 시간에는 실전에서 필요한 여러가지 팁들에 대해 설명한다. 후반부에서는 스팸 분류기를 통해 간단한 머신러닝 시스템을 설계해 본다.</p>

<h3 id="diagnostics">Diagnostics</h3>

<p><img src='http://chart.apis.google.com/chart?cht=tx&amp;chl=J' (%5Ctheta)%20%3D%20%7B1%20%5Cover%202m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20(h_%5Ctheta(x%5E%7B(i)%7D%20-%20y%5E%7B(i)%7D)%5E2%20%2B%20%5Clambda%5Csum_%7Bj%3D1%7D%5Em%20%5C%20%5Ctheta_j%5E2%5D" alt="" /></p>

<p>집 가격에 대한 <em>linear regression</em> 가설을 세웠는데 <em>error</em> 가 좀 큰 것을 발견했다. 어떻게 해야할까?</p>

<p>(1) Get more training examples <br />
(2) Try smaller sets of features <br />
(3) Try getting additional features <br />
(4) Try adding polynomial features <br />
(5) Try decreasing <em>lambda</em> <br />
(5) Try increasing <em>lambda</em>  </p>

<p>이중에서 더 많은 트레이닝 셋을 추가하는 것은 별로 도움이 안 될 수도 있다. (이유는 뒷 부분에서 논의한다.)</p>

<p>알고리즘의 정상 동작여부를 파악할 수 있는 몇 가지 판별법을 알아보자. <em>gradient checking</em> 이 그랬던 것처럼, 구현하는데는 좀 시간이 걸려도 디버깅에 드는 시간을 많이 줄여준다.</p>

<blockquote>
  <p>A diagnostic can sometimes rule out certain courses of action (changes to your learning algorithm) as being unlikely to improve its performance significantly</p>
</blockquote>

<h3 id="evaluatingahypothesis">Evaluating a hypothesis</h3>

<p><em>low training error</em> 를 갖는 <em>hypothesis (가설)</em> 이 항상 좋은 건 아니다. <em>overfitting</em> 이 발생할 수 있기 때문이다.</p>

<p>그리고 <em>feature</em> 가 많을 수록 <em>plotting</em> 하기 힘들기 가설을 평가할 다른 방법을 찾아야 한다. 단순히 그리는 것 만으로 모든 가설을 평가하긴 어렵다.</p>

<p>한가지 평가 방법으로 전체 <em>training set</em> 을 <code>70% / 30%</code> 로 분리해 <code>70%</code> 은 <em>training set</em> 으로 나머지 <code>30%</code> 는 <em>test set</em> 으로 활용할 수 있다. (<em>참고로 테스트셋과 트레이닝셋은 랜덤하게 분리하는 편이 좋다.</em>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360378105_8286.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>linear regressoin</em> 에 트레이닝 셋과 테스트셋을 분리하는 과정을 알아 보면</p>

<p>(1) <code>0(theta)</code> 를 트레이닝 셋에 대해 학습시켜 트레이닝 에러를 최소화 하는 <code>J(0)</code> 를 찾는다. <br />
(2) 학습된 <code>0(theta)</code> 에 대해 테스트 셋을 돌려 <em>test error</em> 를 찾는다.</p>

<p>그럼 <em>linear regression</em> 말고 <em>classification</em> 에는 어떻게 적용할까?</p>

<p>마찬가지로 <code>0(theta)</code> 에 대해 <code>J(0)</code> 를 찾고, 여기에 <code>J_test(0)</code> 를 돌려 테스트 에러를 찾는다.</p>

<p>아니면 아래 그림에서 볼 수 있듯이 <em>misclassification error</em> 를 이용해도 된다. 보면 알겠지만 같은 정의다. <code>y = 0</code> 일때 <code>h(x) &lt; 0.5</code> 이어야 하고, <code>y = 1</code> 일때 <code>h(x) =&gt; 0.5</code> 이어야 하기 때문에 엇갈리게 나온 경우 <code>err</code> 함수에서 <code>1</code> 을 리턴해, 이 값을 모두 합한 뒤 전체 테스트 셋의 숫자로 나누면 테스트 에러값을 구할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360378588_2059.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h3 id="modelselection">Model Selection</h3>

<p>당연한 이야기지만 <em>training set</em> 에 가설이 <em>well fit</em> 되어있기 때문에 트레이닝셋에 포함되지 않은 새로운 경향의 데이터를 만나면 에러가 많이 생길 수 있다.</p>

<blockquote>
  <p>Once parameters were fir to some set of data (training set), the error of the parameters as measured on that data (the training error <code>J(0)</code>) is likely to be lower than the actual generalization error.</p>
</blockquote>

<p><code>d</code> 를 <em>degree of polynomial (가설의 다항식 차수)</em> 이라 하자. 그럼 <code>d = 1, 2, .. , 10</code> 중에 어떤 걸 택하는 게 좋을까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360380082_1392.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>각각에서 나오는 파라미터 벡터를 <code>0^(1), 0^(2), ...</code> 이라 하자. 그리고 여기서 나오는 테스트 셋의 에러를 <code>J_test(0^(1))</code>, <code>J_test(0^(2))</code> 등이라 하면 이 값을 모두 조사해 최소로 나오는 <code>d</code> 를 가진 모델을 택한다. </p>

<p>그러나 문제는 이렇게 선택한 모델이 <em>optimistic estimate of generalization error</em> 라는 점이다. 테스트 셋에 대해서 가장 적은 에러를 모델이 보여준다 해도 실제 데이터에 대해 똑같이 적은 에러를 보여주리라고 확신할 수 없다.</p>

<h3 id="trainvalidationtestsets">Train / Validation / Test Sets</h3>

<p>이 문제를 해결하기 위해 <em>training set</em> 을 <em>60%/20%/20%</em> 로 나누어 각각을 <em>training set</em>, <em>cross validation set (CV)</em>, <em>test set</em> 이라 하자. 그리하여 각각의 에러를 구할 수 있다. </p>

<p>여기서 <em>CV</em> 에 대한 <em>error</em> 가 최저인 모델을 택하면 이 모델은 <em>test set</em> 에 대해서는 <em>fit</em> 되어 있지 않기 때문에 <em>test error</em> 가 <em>estimate generalization error</em> 라 볼 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360459807_7333.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>다시 정리해 보면 먼저 <code>0</code> 를 <em>training set</em> 에 대해 학습 시켜 <code>0</code> 값을 얻은 뒤, <em>cross validation (CV)</em> 에 대해 <em>error</em> 를 구해 가장 작은 값을 갖는 모델을 고른다.</p>

<p>이제 이 모델에 대해서 <em>test error</em> 를 구하면 이 모델은 테스트 셋에 대해서 <em>fit</em> 되지도, 가장 적은 에러를 가지는지 검사되지도 않은 데이터이므로 일반적인 에러값에 대한 추정치라 볼 수 있다.</p>

<p>일반적으로 <em>CV error</em> 는 <em>test error</em> 보다 더 작은 값을 가지는데, 이는 선택한 모델의 <code>0</code> 가 <em>CV set</em> 에 대해 최저치를 갖도록 <em>fit</em> 되어있기 때문이다.</p>

<h3 id="diagnosingbiasvsvariance">Diagnosing Bias vs Variance</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360461366_4352.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>그림에서 볼 수 있듯이 <code>d=1</code> 인 경우엔 <em>underfit</em>, <code>d=4</code> 인 경우엔 <em>overfit</em> 이 발생한다. 다른말로 각각 <em>high bias</em>, <em>high variance</em> 라 부른다.</p>

<p>아래와 같이 가로 축을 <code>d</code>, 세로 축을 <code>error</code> 라 하면 <code>d</code> 가 증가할 수록 <em>training error</em> 는 0 에 가까워진다. 반면 <em>CV set</em> 에 대해서는 하나의 <code>d</code> 만 최저치를 가지고 나머지는 그 보다 높기 때문에 아래와 같은 그래프를 그릴 수 있다.</p>

<p><img src='http://my.csdn.net/uploads/201207/28/1343484056_3257.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>이 그래프가 시사하는 바는, </p>

<p>(1) <em>underfit</em> 할 경우 <code>d</code> 가 작으므로 <code>J_train(0)</code> 는 매우 크고, <code>J_cv(0)</code> 는 그의 거의 비슷한 값을 가지게 된다. (<em>bias problem</em>) <br />
(2) <em>overfit</em> 할 경우 <code>d</code> 가 크므로 <code>J_train(0)</code> 는 매우 작고, <code>J_cv(0)</code> 는 그보다는 훨씬 크다. (<em>variance problem</em>)  </p>

<p>따라서 <code>J_train(0)</code> 값이 <code>J_cv(0)</code> 과 얼마나 비슷한지 비교함으로써 <em>overfit</em> 혹은 <em>underfit</em> 되는지 판단할 수 있다.</p>

<p><img src='http://my.csdn.net/uploads/201207/28/1343484595_6134.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><a href='http://www.4four.us/article/2010/11/bias-variance-tradeoff' >여기</a> 서 <em>bias vs varance</em> 의 이해를 위해 인용을 좀 하자면,</p>

<blockquote>
  <p>Bias, 즉 선입관이 크면, (좋게 말해서) 줏대가 있고 (나쁘게 말해서) 고집이 세기 때문에 새로운 경험을 해도 거기에 크게 휘둘리지 않는다. 평소 믿음과 다른 결과가 관찰되더라도 한두 번 갖고는 콧방귀도 안 뀌며 생각의 일관성을 중시한다. (High Bias, Low Variance) 반대로 선입관이 작으면, (좋게 말하면) 사고가 유연하고 (나쁘게 말하면) 귀가 얇기 때문에 개별 경험이나 관찰 결과에 크게 의존한다. 새로운 사실이 발견되면 최대한 그걸 받아들이려고 하는 것이다. 그래서 어떤 경험을 했느냐에 따라서 최종 형태가 왔다갔다한다. (High Variance, Low Bias)</p>
</blockquote>

<h3 id="regularizationandbiasvariance">Regularization and Bias / Variance</h3>

<p><em>regularization</em> 이 끼어들면 <code>lambda</code> 를 <em>bias vs variance</em> 문제에서 고려해야 한다. 아래 그림을 보자.</p>

<p><img src='http://my.csdn.net/uploads/201207/28/1343485336_9809.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><em>lambda</em> 가 크면 당연히 <em>high bias</em>, 매우 작으면 <em>high variance</em> 다. 그러면 중간 값을 찾아야 한다는건 알겠는데, 어느정도가 적당한 값일까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360461577_6101.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>이 전과 비교했을때 <code>J(0)</code> 에 <em>regularization term</em> 이 추가되었지만 <code>J_train(0)</code> 이나 <code>J_cv(0)</code>, <code>J_test(0)</code> 에는 <em>regularization term</em> 이 없다는 점에 유의하자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360461899_5163.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>모델을 선택했다면 <em>lambda</em> 를 천천히 증가시켜가면서 각각에 대해 <code>0(theta)</code> 를 구한다. 그리고 이 값을 이용해 구한 <code>J_cv(0)</code> 가 가장 적은 에러 값을 가지는 <em>lambda</em> 를 구하면 된다. <em>model selection</em> 과 비슷하다.</p>

<p><em>lambda</em> 과 <em>CV error</em>, <em>training error</em> 간 관계를 알아보자면 아래와 같다. 위에서 언급 했듯이 <em>lambda</em> 가 크면 <em>bias</em>, 0 에 가까우면 <em>variance</em> 임을 확인할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360462458_2256.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>bias</em> 와 <em>variance</em>, 그리고 <em>lambda</em> 의 관계는 아래 그래프에서도 확인할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201210/12/1350026192_9384.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<h3 id="learningcurves">Learning Curves</h3>

<p>전체 트레이닝 셋의 사이즈 <code>m</code> 이 커질때 에러는 어떻게 되는가 그래프로 한번 보자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552101_5795.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>간단히 생각해 보면 <code>m</code> 의 사이즈가 클수록 <em>training set</em> 의 에러는 점점 늘어나고, <code>m</code> 이 커지면 커질수록 <em>generalize</em> 가 가능하므로 <em>CV error</em> 는 점점 줄어든다.</p>

<p><em>high bias</em> 인 경우 처음엔 <em>training error</em> 이 매우 크다가, <code>m</code> 이 클수록 <em>training error</em> 의 증가율이 작아지므로</p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552417_8655.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>이 그림이 시사하는 바는 </p>

<blockquote>
  <p><em>high bias</em> 알고리즘이라면 <code>m</code> 이 을 많이 수집한다 해도 <code>J_cv(0)</code> 의 감소율이 적기 때문에 별 도움이 되지 못한다. 다시 말해 <code>m</code> 을 많이 투입해도 얻어지는 <em>training error</em> 와 <em>CV error</em> 의 차이는 미미하다.</p>
</blockquote>

<p>반면 <em>high variance</em> 의 경우에는 <code>m</code> 이 크면 클수록 <em>training error</em> 의 증가율이 점점 줄어들고, <em>overfit</em> 이기 때문에 <em>CV error</em> 는 <em>training set</em> 과 차이가 많이 난다. 그래프는</p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552431_2697.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>결국</p>

<blockquote>
  <p><em>high variance</em> 일 경우 <code>m</code> 을 많이 투입하면 할수록 낮은 <em>CV error</em> 를 얻는데 도움이 된다.</p>
</blockquote>

<p>다시 말해 이 두가지 경우는 <em>training error</em> 와 <em>CV error</em> 의 차이가 꽤 클때는 <code>m</code> 을 높이면 낮은 <em>CV error</em> 를 적은 비용으로 얻을 수 있다는 뜻이다.</p>

<h3 id="applyingtoneuralnetwork">Applying to Neural Network</h3>

<p>이제 처음에 나왔던 6가지 경우를 고려해 보자.</p>

<p>(1) Get more training examples -> <em>fixing high variance</em> <br />
(2) Try smaller sets of features -> <em>fixing high variance</em> <br />
(3) Try getting additional features -> <em>fixing high bias</em> <br />
(4) Try adding polynomial features -> <em>fixing high bias</em> <br />
(5) Try decreasing <em>lambda</em> -> <em>fixing high bias</em> <br />
(5) Try increasing <em>lambda</em> -> <em>fixing high variance</em>  </p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552523_3279.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>bias vs variance</em> 문제를 <em>neural network</em> 에 적용시켜보자. </p>

<p>(1) 작은 사이즈의 신경망이라면 계산 비용은 저렴한 대신 <em>underfit</em> 할 수 있다. <br />
(2) 큰 사이즈의 신경망이라면 계산 비용은 비싸고 <em>overfit</em> 할 수 있다. 따라서 <em>regurarization</em> 을 이용해 <em>overfit</em> 되는 정도를 줄일 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552606_9371.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h3 id="machinelearningsystemdesign">Machine Learning System Design</h3>

<p>간단한 스팸 분류기를 작성한다고 하자. <em>supervised learning</em> 을 위해서</p>

<p>(1) <code>x</code> = features of email (<em>choose 100 words indicative of spam or not</em>) <br />
(2) <code>y</code> = spam <code>1</code> or not spam <code>0</code>  </p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360804751_1943.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>각 단어가 이메일 본문에 등장했는지 아닌지를 각 <em>feature</em> 의 값으로 사용한다. (<code>1</code> or <code>0</code>)</p>

<p>일반적으로는 100개를 수동으로 고르는게 아니라, 스팸에서 많이 사용된 단어를 <code>n</code> 개 골라 사용한다.</p>

<p>그럼 <em>low error</em> 를 얻기 위해서는 무엇을 해야할까?</p>

<p>(1) Collect lots of data : 항상 도움이 되진 않는다. <br />
(2) Develop sophisticated features based on email routing information <br />
(3) Develop sophisticated features for message body. e.g should "discount" and "discounts" be treated as the same word? <br />
(4) Develop sophisticated algorithm to detect misspelings e.g m0rtgage  </p>

<p>등등 의 다양한 방법을 고안할 수 있다. 이 중 무엇을 선택해야 할까? 좀 더 체계적인 방법은 없을까? 여기 몇 가지 가이드라인이 있다.</p>

<blockquote>
  <ol>
  <li>Start with a simple algorithm that can implement quickly. Implement it and test it on your corss-validation data.</li>
  <li>Plot learning curves to decide if more data, more features, etc. are likely to help.</li>
  <li>Error analysis: manually examine the examples (in corss validation set) that your algorithm made errors on. See if you spot any systematic trend in what type of examples it is making errors on.</li>
  </ol>
</blockquote>

<h3 id="erroranalysis">Error Analysis</h3>

<p><em>error analysis</em> 하는 방법은 <em>CV error</em> 를 발견했을 때, 각각의 에러를 수동으로 검사하면서 분류하는 것이다.</p>

<p>이메일의 타입이 무엇인지, 혹은 어떤 <em>feature</em> 가 알고리즘에서 이 이메일을 분류하는데 도움이 될만한지 생각해 본다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360804909_5716.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>error analysis</em> 가 에러가 나타난 이유에 대한 어떤 경향을 제공할 수 있기 때문에 간단히 먼저 구현해 보고 분석 해 보는것도 나쁘지 않다.</p>

<p><em>error analysis</em> 는 실제로 분석 결과를 새로운 알고리즘에 적용했을때 <em>performace</em> 가 더 좋을지 알려주지 않는다. 따라서 해보고 <em>numerical evaluation</em> 을 비교해 본다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360804976_1060.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h3 id="skewedclasses">Skewed Classes</h3>

<p>암을 진단한다고 하자. <em>logistic regression</em> 을 구현했고, 놀랍게도 <em>test error</em> 가 <code>1%</code> 라고 하자.</p>

<p>근데, 만약에 환자중에 <code>0.5%</code> 만 암환자라면, 차라리 모두 암이 아니라고 진단하는 다음의 함수가 더 에러가 낮다.</p>

<pre><code class="matlab">function y = predictCancer(x)  
  y = 0; 
return  
</code></pre>

<p>이렇게 확률이 희박한 <em>class</em> 를 <strong>skewed class</strong> 라 부른다. 또 한가지 사실을 알 수 있는데, <em>error</em> 가 낮다고 해서 항상 좋은 알고리즘이 아니라는 사실이다. <code>y = 0</code> 은 <code>99.5</code> 의 정확도를 보여주지만 알고리즘이 아니다. 에러값 말고 다른 평가방법이 필요하다!</p>

<h3 id="precisionrecall">Precision / Recall</h3>

<p>그림을 먼저 보자. 예측 여부와 실제 값에 따라서 <code>2 x 2</code> 매트릭스를 붙일 수 있다. </p>

<p><img src='http://my.csdn.net/uploads/201208/06/1344228190_4576.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>여기서 <em>precision</em> 과 <em>recall</em> 이란 개념을 끌어낼 수 있는데</p>

<blockquote>
  <p><em>*Precision: *</em> Of All patients where we predicted y = 1, what fraction actually has cancer?</p>
  
  <p><em>*Recall: *</em> Of all patients that actually have cancer, what fraction did we correctly detect as having cancer?</p>
</blockquote>

<p>다시 말해 <em>precision</em> 은 우리가 암이 있다고 진단한 환자중 실제 암이 있는 환자의 비율이고, <em>recall</em> 은 실제 암이 있는 환자 중 우리가 암이 있다고 진단한 환자의 비율이다.</p>

<p>위의 함수처럼 <code>y = 0</code> 으로 진단하는 경우 <em>true positive</em> = <code>0</code> 이므로 <em>recall</em> = <code>0</code> 이다.</p>

<p>단순히 <em>error</em> 만으로 판단하는 것은 위의 예처럼 잘못된 판단일 수 있다. 따라서 <em>skewed class</em> 가 있더라도 <em>precision</em> 과 <em>recall</em> 을 보면 알고리즘에 속임수가 있는지, 없는지를 파악할 수 있다.</p>

<h3 id="tradingoffprecisionandrecall">Trading off Precision and Recall</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360805261_5122.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>일반적으로 <code>h(x) &gt;= 0.5</code> 일경우에 <code>1</code> 을, <code>h(x) &lt; 0.5</code> 일 경우에 <code>0</code> 을 예측하는데, 이 수치를 좀 더 올려 <code>0.7</code> 이상 또는 미만으로 예측한다 해 보자.</p>

<p>이 경우 좀 더 확실한 환자만 암이라 진단하므로 <em>precision</em> 은 올라가는 반면 <em>recall</em> 은 내려간다. </p>

<p>거꾸로 수치를 <code>0.3</code> 으로 낮추면 덜 확실해도 그냥 암이라 우기므로 <em>recall</em> 은 높아지겠지만 예측한 것중 실제 환자를 의미하는 <em>precision</em> 값은 떨어진다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360805315_5777.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위 그림을 보면 <em>threshold</em> 에 따라서 <em>recall</em> 과 <em>precision</em> 값이 얼추 반비례하는 걸 볼 수 있다. 디테일에 따라서 구체적인 그래프의 모양은 다를 수 있다.</p>

<p>그럼 이제 문제는, <em>threshold</em> 를 고를 수 있느냐, 다시 말해 어느 <em>(precision, recall)</em> 쌍이 더 좋은가 하는 문제다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360805419_2578.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>단순히 평균을 쓰면 <code>y = 1</code> 로 예측하는 것과 같은 알고리즘들이 높은 값을 얻을 수 있다. 예를 들어 위 그림에서 <em>algorithm 3</em> 가 그렇듯이.</p>

<p>따라서 단순히 평균을 하기 보다는 <em>F1 score</em> 를 많이 쓴다.</p>

<p><img src='http://my.csdn.net/uploads/201208/06/1344234475_3823.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>따라서 <em>CV set</em> 에 대해 높은 <em>F1 score</em> 를 가지는 <em>threshold</em> 를 택함으로써 좋은 알고리즘을 고를 수 있다.</p>

<h3 id="dataformachinelearning">Data for Machine Learning</h3>

<p>지금까지는 <em>evaluation</em> 에 대한 논의었고, <em>data</em> 에 대한 이야기를 좀 더 해 보자. 앞에서는 단순히 데이터가 많다고 해서 좋다는 뉘앙스로 이야기를 했지만 실제 특정 상황에서, 특정 알고리즘은 다량의 데이터를 이용하면 좋은 성능을 내기도 한다. 실제 그런가 보자. 4개의 서로 다른 알고리즘을 트레이닝 셋 사이즈를 늘려가며 정확도를 비교한 결과다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360806606_8278.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<blockquote>
  <p><em>"It's not who has the best algorithm that wins, It's who has the most data."</em></p>
</blockquote>

<p>항상 그렇지는 않다. 집 값을 예측 할 때 <em>feature</em> 로 사이즈 하나만 준다면 정확하게 예측하기란 불가능하다. 양이 문제가 아니고 집 값을 예측하기에 충분한 정보가 필요하다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360807112_1041.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>많은 수의 <em>parameter</em> 가 있다. 하자. <em>low bias</em> 기 때문에 <code>J_train(0)</code> 는 작을 것이다. (<em>not underfit</em>)</p>

<p>그리고 여기에 <em>parameter</em> 보다 훨씬 많은 <em>training set</em> 을 사용한다면, <em>overfit</em> 하지 않는다 볼 수 있다. 따라서 <em>underfit</em> 도 아니고 <em>overfit</em> 도 아니므로</p>

<p><code>J_test(0)</code> 는 <code>J_train(0)</code> 에 근사한 값을 가진다 볼 수 있다. 결국 작은 <code>J_test(0)</code> 을 얻을 수 있다.</p>

<p>정리하자면, 충분한 양의 정보를 가지고 있고 (<em>large parameters</em>), 큰 사이즈의 데이터를 대상으로 알고리즘을 훈련 시킨다면 상당히 좋은 성능을 뽑아낼 수 있다는 훈훈한 이야기. (거꾸로 말하면, 반복하지만, 데이터만 많다고, 혹은 파라미터만 많다고 좋은 결과를 얻을 수 없다는 이야기)</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a> <br />
(4) <a href='http://www.4four.us/article/2010/11/bias-variance-tradeoff' >http://www.4four.us</a></p>]]></description><link>http://1ambda.github.io/machine-learning-week-6/</link><guid isPermaLink="false">58386046-1a88-4f88-b8dc-b5c6c76aa5cb</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine lerning]]></category><category><![CDATA[precision]]></category><category><![CDATA[bias]]></category><category><![CDATA[learning curves]]></category><category><![CDATA[recall]]></category><category><![CDATA[variance]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 14 Nov 2014 05:00:50 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 3]]></title><description><![CDATA[<p>하스켈에서 <em>repetition (반복)</em> 은 <em>recursion</em> 을 통해 표현됩니다. 간단한 재귀부터 시작해서 <em>mutual recursion</em> 까지 알아보고, <em>Higher order function</em> (특히 <code>fold</code>) 에 대해 배운 뒤 적용을 위해 <em>church numerals</em> 를 구현해보고, 마지막으로 간단한 문자열 전송기를 모델링 해 보겠습니다.</p>

<h3 id="tailcall">Tail call?</h3>

<p><em>recursion</em> 을 주로 사용한다면 <em>stack</em> 이 많이 쌓일 수 있습니다. 이런 문제를 해결해 주는 것이 <em>tail call elimination</em> 입니다.</p>

<p>간단한 재귀 함수를 만들어서 스택이 어떻게 변하나 한번 보죠.</p>

<pre><code class="haskell">factorial 0 = 1  
factorial n = n * factorial(n - 1)  
</code></pre>

<p>이 때 <code>factorial 3</code> 을 평가한다면</p>

<pre><code class="haskell">factorial 3  
3 * factorial 2  
3 * (2 * factorial 1)  
3 * (2 * (1 * factorial 0))  
3 * (2 * (1 * 1))  
3 * (2 * 1)  
3 * 2  
6  
</code></pre>

<p>이렇게 각 단계가 확장되면서 <code>n</code> 이 매우 클 경우 마지막 단계에서 연산의 길이가 엄청나게 길어집니다. 함수 한번 호출당 스택이 하나씩 생긴다고 보면 어마어마한 스택이 생기는 것이죠. </p>

<p>다행히도 하스켈은 <em>tail recursion optimization (꼬리 재귀 최적화)</em> 를 가지고 있습니다. 꼬리 재귀에 대한 이야기는 나중에 더 이야기 하도록 하지요.</p>

<h3 id="recursiononlists">Recursion on Lists</h3>

<p>리스트는 같은 타입을 여러개 저장할 수 있기 때문에 <em>recursion</em> 을 사용하기 적합하죠.</p>

<p>리스트 내의 모든 원소의 곱을 구하는 <code>product</code> 함수를 만들어 볼까요? 하스켈에 원래 있지만, 재미삼아 만들어 봅시다. 이름은 충돌이 안나게 <code>productC</code> 라 부릅시다.</p>

<pre><code class="haskell">productC :: [Int] -&gt; Int  
productC [] = 1  
productC (n : ns) = n * productC ns  
</code></pre>

<p><code>length</code> 와 <code>reverse</code> 도 만들어 봅시다.</p>

<pre><code class="haskell">lengthC :: [a] -&gt; Int  
lengthC [] = 0  
lengthC (x : xs) = 1 + length xs

reverseC :: [a] -&gt; [a]  
reverseC [] = []  
reverseC (x : xs) = reverse(xs) ++ [x]  
</code></pre>

<p>조금 더 복잡한 <code>zip</code>, <code>drop</code> 함수나 <code>++</code> 연산자도 어렵지 않습니다. </p>

<pre><code class="haskell">zipC :: [a] -&gt; [b] -&gt; [(a, b)]  
zipC [] _ = []  
zipC _ [] = []  
zipC (x:xs) (y:ys) = (x, y) : zip xs ys

dropC :: Int -&gt; [a] -&gt; [a]  
dropC 0 xs = xs  
dropC _ [] = []  
dropC n (x:xs) = drop (n-1) xs

(++) :: [a] -&gt; [a] -&gt; [a]
[] ++ ys = ys
(x:xs) ++ ys = x : (xs ++ ys)
</code></pre>

<h3 id="quicksort">Quick sort</h3>

<p>퀵소트 알고리즘은 간단합니다. 매 함수 호출에서, <em>pivot</em> 이라 불리는 리스트 내 원소를 고른 후 <em>pivot</em> 좌측에는 그 보다 작은 수를, 우측에는 <em>pivot</em> 보다 큰 수를 배치합니다. 그리고 <em>pivot</em> 을 제외한 좌측 과 우측에 대해 재귀 호출을 하지요.</p>

<p><img src='https://sadakurapati.files.wordpress.com/2013/10/qsort_2.png?w=902&amp;h=617'  alt="" /></p>

<p align="center">(<a href='https://sadakurapati.wordpress.com/' >https://sadakurapati.wordpress.com</a>)</p>

<p>지난 강의에서 배운 <em>list comprehension</em> 을 이용하면 매우 간단하게 <em>quick sort</em> 를 만들 수 있습니다.</p>

<pre><code class="haskell">qsort :: [Int] -&gt; [Int]  
qsort [] = []  
qsort (x:xs) = qsort smaller ++ [x] ++ qsort larger  
               where
                 smaller = [a | a &lt;- xs, a &lt;= x]
                 larger = [b | b &lt;- xs, b &gt; x]
</code></pre>

<p>위 코드에서는 매 재귀마다 인자로 받는 리스트의 첫번째 원소 <code>x</code> 를  <em>pivot</em> 으로 사용했습니다.</p>

<p><img src='http://media-cache-ec0.pinimg.com/736x/11/09/78/11097867a0e6c772c36285d97d94623b.jpg'  alt="" /></p>

<h3 id="recursion">Recursion</h3>

<p>위의 예에서 보았듯이 자기 자신을 호출하는 함수 패턴을 <em>recursion (재귀)</em> 라 부릅니다. 언제 유용할까요? 재귀를 이용하면 <em>induction (귀납법)</em> 을 이용해 함수의 성질을 증명할 수 있습니다. 제대로 동작하는지, 의도 했던대로 동작하는지 등을요.</p>

<blockquote>
  <p>Properties of functions defined using recursion can be proved using the simple but powerful mathematical technique of <strong>induction</strong></p>
</blockquote>

<h3 id="mutialrecursion">Mutial recursion</h3>

<p><em>mutual recursion</em> 은 서로 다른 두개의 함수가 상호간 재귀를 이용해 정의되는 방식입니다. </p>

<p><code>odd</code> 와 <code>even</code> 함수를 <em>mutual recursion</em> 을 이용해 정의할 수 있습니다. 일반적으로는 효율성을 위해  2로 나눈 나머지를 이용해 정의하지만, 양수에 대해서는 아래와 같이 <em>mutual recursion</em> 으로 만들 수 있죠.</p>

<pre><code class="haskell">even :: Int -&gt; Bool  
even 0 = True  
even n = oddC (n-1)

odd :: Int -&gt; Bool  
odd 0 = False  
odd n = evenC (n-1)  
</code></pre>

<p>비슷하게 리스트에서 짝수번째, 혹은 홀수번째 원소들만 돌려주는 <code>evens</code> 와 <code>odds</code> 함수도 <em>mutual recursion</em> 을 이용해 정의할 수 있습니다. <code>evens</code> 는 0번째 부터 돌려줍니다. <code>odds</code> 는 턴을 넘기는데 쓰고 실제 작업은 <code>evens</code> 에서 한다고 생각하면 금방 이해할 수 있습니다.</p>

<pre><code class="haskell">evens :: [a] -&gt; [a]  
evens [] = []  
evens (x:xs) = x : odds xs

odds :: [a] -&gt; [a]  
odds [] = []  
odds (_:xs) = evens xs  
</code></pre>

<h3 id="adviceonrecursion">Advice on recursion</h3>

<p>재귀는 자전거 타기와 비슷합니다. 처음엔 불가능해 보이는데 한번 시도해보면 정말 쉽게 탈 수 있죠. 여기 재귀를 만드는데 도움이 될만한 5가지 스텝이 있습니다. <code>init</code> 함수를 예로 들어 설명하겠습니다.</p>

<p>(1) define the type  </p>

<pre><code class="haskell">init :: [a] -&gt; [a]  
</code></pre>

<p>(2) enumerate the cases  </p>

<pre><code class="haskell">init (x:xs) =  
</code></pre>

<p>(3) define the simple case  </p>

<pre><code class="haskell">init (x:xs) | null xs = []  
            | otherwise = 
</code></pre>

<p>(4) define the other cases  </p>

<pre><code class="haskell">init (x:xs) | null xs = []  
            | otherwise = x : init xs
</code></pre>

<p>(5) generalise and simplify</p>

<pre><code class="haskell">init :: [a] -&gt; [a]  
init [_] = []  
init (x:xs) = x : init xs  
</code></pre>

<h3 id="examples">Examples</h3>

<p>예제 몇 가지를 좀 더 살펴봅시다. 먼저 곱셈 연산입니다.</p>

<pre><code class="haskell">(*) :: Int -&gt; Int -&gt; Int
m * 0 = 0  
m * n = m + (m * (n - 1))  
</code></pre>

<p>정렬된 리스트에 원소를 삽입하는 <code>insert</code> 함수입니다. 바로 다음에 만들 <code>isort</code> (<em>insertion sort</em>) 를 구현한 함수에서 사용합니다.</p>

<pre><code class="haskell">insert :: Ord a =&gt; a -&gt; [a] -&gt; [a]  
insert x [] = [x]  
insert x (y:ys) | x &lt;= y = x : y : ys  
                | otherwise = y : insert x ys

isort :: Ord a =&gt; [a] -&gt; [a]  
isort [] = []  
isort (x:xs) = insert x (isort xs)  
</code></pre>

<p>이번엔 <em>merge sort</em> 입니다.</p>

<pre><code class="haskell">merge :: Ord a =&gt; [a] -&gt; [a] -&gt; [a]  
merge [] ys = ys  
merge xs [] = xs  
merge (x:xs) (y:ys) =  
  if x &lt;= y then x : merge xs (y: ys) else y : merge (x:xs) ys

halve :: [a] -&gt; ([a], [a])  
halve xs = splitAt (length xs `div` 2) xs

msort :: Ord a =&gt; [a] -&gt; [a]  
msort [] = []  
msort [x] = [x]  
msort xs = merge (msort ys) (msort zs)  
           where (ys, zs) = halve xs
</code></pre>

<h3 id="higherorderfunction">Higher-order function</h3>

<p><em>higher-order function</em> 은 함수를 인자로 받아 다시 함수를 돌려주는 함수를 말합니다. <del>응?</del></p>

<blockquote>
  <p>A function is called <em>higher-order</em> if it takes a function as an argument or returns a function as a result</p>
</blockquote>

<pre><code class="haskell">twice :: (a -&gt; a) -&gt; a -&gt; a  
twice f x = f (f x)  
</code></pre>

<p><code>twice</code> 는 인자 <code>x</code> 에 <code>f</code> 를 두번 적용한 뒤 값을 돌려줍니다. 더 정확히는 <em>curried function</em> 이므로 <code>twice f</code> 는 앞으로 뭘 인자로 받을지 모르지만 <code>f</code> 를 두번 적용하는 함수를 돌려줍니다.</p>

<p>이런 <em>higher-order function (고차함수)</em> 가 언제 유용할까요?</p>

<blockquote>
  <ol>
  <li><p><strong>Common programming idioms</strong> can be encoded as functions within the language itself.</p></li>
  <li><p><strong>Domain specific languages</strong> can be defined as collections of higher-order functions.</p></li>
  <li><p><strong>Algebraic properties</strong> of higher-order functions can be used to reason about programs.</p></li>
  </ol>
</blockquote>

<h3 id="map">map</h3>

<p>먼저 <code>map</code> 함수를 살펴봅시다.</p>

<pre><code class="haskell">map :: (a -&gt; b) -&gt; [a] -&gt; [b]

map (+1) [1, 3, 5, 7]  
-- [2, 4, 6, 8]
</code></pre>

<p>이 <code>map</code> 함수는 우리가 이전에 배웠던 <em>list comprehension</em> 으로 똑같이 작성할 수 있습니다.</p>

<pre><code class="haskell">map f xs = [f x | x &lt;- xs]  
</code></pre>

<p>아니면 <em>recursive function</em> 으로 작성할 수도 있습니다.</p>

<pre><code class="haskell">map f [] = []  
map f (x:xs) = f x : map f xs  
</code></pre>

<h3 id="filter">filter</h3>

<p><code>filter</code> 도 고차함수입니다. <code>filter</code> 는 <em>predicate</em> 즉, <code>(a -&gt; Bool)</code> 을 받아 <code>True</code> 인 원소만 모아 돌려줍니다.</p>

<pre><code class="haskell">filter :: (a -&gt; Bool) -&gt; [a] -&gt; [a]

filter even [1..10]  
-- [2, 4, 6, 8, 10]
</code></pre>

<p><code>filter</code> 도 마찬가지로 <em>list comprehension</em> 과 <em>recursive function</em> 두 가지 버전으로 작성될 수 있습니다.</p>

<pre><code class="haskell">filter p xs = [x | x &lt;- xs, p x]

filter p [] = []  
filter p (x:xs)  
  | p x = x : filter p xs
  | otherwise = filter p xs
</code></pre>

<p>단순히 <em>list comprehension</em> 으로 작성하는 것 보다, <em>recursive function</em> 으로 작성하면 위에서 볼 수 있듯이 공통점을 파악할 수 있습니다. 그러면 한단계 더 추상화 할 수 있지요. <code>filter</code> 와 <code>map</code> 의 공통점이 보이시나요?</p>

<h3 id="foldr">foldr</h3>

<p>위의 두 가지 예에서 <code>filter</code>, <code>map</code> 모두 빈 리스트와 그렇지 않은 리스트를 구분했습니다. 그리고 각각의 원소에 대해서 연산을 수행했지요. </p>

<pre><code class="haskell">f [] = v  
f (x:xs) = x pred f xs  
</code></pre>

<p>빈 원소라면 특정 값 <code>v</code> 를 돌려주고 아니라면 원소 <code>x</code> 에 <code>pred</code>를 적용하고, 나머지 <em>tail</em> <code>xs</code> 에 <code>f</code> 를 적용합니다. 비슷한 예제를 살펴볼까요?</p>

<pre><code class="haskell">-- v = 0, pred = +
sum [] = 0  
sum (x:xs) = x + sum xs

-- v = 1, pred = *
product [] = 1  
product (x:xs) = x * product xs

-- v = True, pred = &amp;&amp;
and [] = True  
and (x:xs) = x &amp;&amp; and xs  
</code></pre>

<p>따라서 다음과 같이 <code>foldr</code> (<em>fold right</em>) 을 이용해 정의할 수 있습니다.</p>

<pre><code class="haskell">sum = foldr (+) 0

product = foldr (*) 1

or = foldr (||) False

and = foldr (&amp;&amp;) True  
</code></pre>

<p>위에서 대략적인 정의를 봤지만, 더 엄밀하게 <code>foldr</code> 은 이렇게 정의할 수 있습니다.</p>

<pre><code class="haskell">foldr :: (a -&gt; b-&gt; b) -&gt; b -&gt; [a] -&gt; b  
foldr f v [] = []  
foldr f v (x:xs) = f x (foldr f v xs)  
</code></pre>

<p>보면 알겠지만, 리스트의 <em>the right-most (가장 우측)</em> 부터 연산합니다. 그래서 <em>fold right</em> 라는 이름이 붙었지요. 그림으로 보자면</p>

<p><img src='http://www.pling.org.uk/cs/funimg/foldr.png'  alt="" /></p>

<p align="center">(<a href='http://www.pling.org.uk/cs/fun.html' >http://www.pling.org.uk/cs/fun.html</a>)</p>

<pre><code class="haskell">sum [1, 2, 3]  
foldr (+) 0 [1, 2, 3]  
foldr (+) 0 (1:(2:(3:[])))  
1 + (2 + (3 + 0))  
</code></pre>

<p>콘싱 <code>:</code> 하고 비슷합니다. 이 부분에 연산자를 집어넣고, <code>[]</code> 에 초기값 <code>v</code> 를 넣는다고 생각하면 이해하기 쉽습니다.</p>

<p><code>length</code> 도 비슷한 패턴을 가지고 있기 때문에 <code>foldr</code> 로 바꿀 수 있습니다.</p>

<pre><code class="haskell">length :: [a] -&gt; Int  
length [] = 0  
length (x:xs) = 1 + length xs

length = foldr (\_ n -&gt; 1 + n) 0  
</code></pre>

<p>이렇게 바꿀 수 있는 이유는</p>

<pre><code class="haskell">length [1, 2, 3]  
length (1: (2: (3:[])))  
1 + (1 + (1 + 0)))  
</code></pre>

<p>여기서 각 <code>:</code> 을 <code>\_ n -&gt; 1 + n</code> 으로 바꾸면 되기 때문입니다.</p>

<pre><code class="haskell">reverse [] = []  
reverse (x:xs) reverse xs ++ [x]  
</code></pre>

<p>이제 위 <code>reverse</code> 함수도 <code>foldr</code> 을 이용할 수 있습니다.</p>

<pre><code class="haskell">reverse = foldr (\x xs -&gt; xs ++ [x]) []  
</code></pre>

<p>처음의 <code>filter</code>, <code>map</code> 도 이렇게 정의할 수 있습니다.</p>

<pre><code class="haskell">foldr :: (a -&gt; b -&gt; b) -&gt; b -&gt; [a] -&gt; b  
foldr f v [] = v  
foldr f v (x:xs) = f x (foldr f v xs)

filter :: (a -&gt; Bool) -&gt; [a] -&gt; [a]  
filter p xs = foldr (\x acc -&gt; if p x then x : acc else acc) [] xs

map :: (a -&gt; b) -&gt; [a] -&gt; [b]  
map p xs = foldr (\x acc -&gt; p x : acc) [] xs  
</code></pre>

<p><code>foldr</code> 을 이용하면 몇 가지 장점이 있습니다.</p>

<blockquote>
  <ol>
  <li><p>Some recursive functions on lists, such as sum, are <strong>simpler</strong> to define using foldr.</p></li>
  <li><p>Properties of functions defined using foldr can ben proved using algebraic properties of foldr, such as <strong>fusion</strong> and the <strong>banana split</strong> rule.</p></li>
  <li><p>Advanced program <strong>optimizations</strong> can be simpler if foldr is used in place of explicit recursion.</p></li>
  </ol>
</blockquote>

<p>여기서 <em>fusion</em> 은, 하나의 <code>foldr</code> 은 리스트를 순회하면서 새로운 리스트를 리턴하고, 다른 <code>foldr</code> 을 그 결과에 사용할 때 <em>intermediate list</em> 를 생성하는 것 없이 계산을 해 낸다는 뜻입니다.</p>

<blockquote>
  <p>In particular <strong>fusion</strong> means that I have two functions. One that uses <code>foldr</code> to traverse one list and return another list. And if I do another <code>foldr</code> on the result of that I can fuse these two together, such that the <strong>intermediate list is never constructed</strong>. So program can be optimized.</p>
</blockquote>

<p>다른 고차함수들을 좀 살펴봅시다.</p>

<h3 id="composition">composition</h3>

<p><code>(.)</code> 은 함수를 <em>composition (합성)</em> 해 줍니다. </p>

<pre><code class="haskell">(.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; (a -&gt; c)
f . g = \x -&gt; f(g x)  
</code></pre>

<p>예를 들어</p>

<pre><code class="haskell">odd :: Int -&gt; Bool  
odd = not . even  
</code></pre>

<p><em>compoisition</em> 을 사용할때는 괄호와 나머지 인자를 제거하여 함수의 정의를 간단히 할 수 있습니다.</p>

<pre><code class="haskell">twice f x = f (f x)

-- same as
twice f = f f  
</code></pre>

<h3 id="allany">all, any</h3>

<p>모든 원소에 대해 <code>p</code> 를 적용한 결과가 참인지를 돌려주는 <code>all</code> 은 다음처럼 정의할 수 있습니다.</p>

<pre><code class="haskell">all :: (a -&gt; Bool) -&gt; [a] -&gt; Bool  
all p xs = and [p x | x &lt;- xs]  
</code></pre>

<p>이번엔 <em>list comprehension</em> 을 사용했습니다. <code>foldr</code> 과의 차이는, <code>foldr</code> 은 모든 순회 가능한 데이터 타입에 적용 가능한 반면 <em>list comprehension</em> 은 리스트에만 사용할 수 있습니다. 위 예제를 <code>foldr</code> 로 바꾸면</p>

<pre><code class="haskell">all :: (a -&gt; Bool) -&gt; [a] -&gt; Bool  
all p xs = foldr (\x acc -&gt; p x &amp;&amp; acc) True xs  
</code></pre>

<p><code>any</code> 도 만들 수 있습니다.</p>

<pre><code class="haskell">import Data.Char

any :: (a -&gt; Bool) -&gt; [a] -&gt; Bool  
any p xs = or [p x | x &lt;- xs]

-- same as
any p xs = or (map p xs)  
</code></pre>

<h3 id="takewhiledropwhile">takeWhile, dropWhile</h3>

<p><code>takeWhile</code> 은 <em>predicate</em> 가 참인 원소까지만 돌려줍니다. 예를 들어</p>

<pre><code class="haskell">takeWhile :: (a -&gt; Bool) -&gt; [a] -&gt; [a]  
takeWhile p [] = []  
takeWhile p (x:xs) | p x = x : takeWhile p xs  
                    | otherwise = [] 

takeWhile isAlpha "abc def"  
-- "abc"
</code></pre>

<p>반면 <code>dropWhile</code> 은 <em>predicate</em> 를 적용한 결과가 참인 원소를 모두 버리고 나머지만 돌려줍니다. 예를 들어</p>

<pre><code class="haskell">dropWhile :: (a -&gt; Bool) -&gt; [a] -&gt; [a]  
dropWhile p [] = []  
dropWhile p (x:xs) | p x = dropWhile p xs  
                    | otherwise = x:xs

dropWhile isAlpha "fp 101"  
-- " 101" 
</code></pre>

<h3 id="churchnumerals">Church Numerals</h3>

<blockquote>
  <p><strong>Church Numerals</strong> give us a way to <em>abstract</em> over the concrete representation of a number by means of <strong>functions</strong> and <strong>unction application</strong>.</p>
</blockquote>

<p>숫자 <code>n</code> 은 <em>zero</em> 에 <code>n</code> 번의 <code>s</code> <em>function application</em> 을 통해 정의합니다. </p>

<pre><code class="haskell">zero = \s z -&gt; z  
one = \s z -&gt; s z  
two = \s z -&gt; s (s z)

-- same as
two = \s z -&gt; (s . s) z

-- we can remove z
two = \s -&gt; s . s  
</code></pre>

<p>여기서 데이터 <code>z</code> 자체는 아무것도 정해진 것이 없습니다. 다시 말해 어떤 타입이든 가져다 쓸 수 있다는 뜻이지요.</p>

<p>우리가 숫자 3을 표현하기 위해 <code>1</code>을 세번 더해 <code>3</code> 을 표시하든, 아니면 <code>*</code> 를 세번 컨싱하든 상관 없다는 뜻 입니다.</p>

<pre><code class="haskell">zero = \s z -&gt; z  
one = \s z -&gt; s z  
two = \s -&gt; s . s

-- church to int
c2i x = x (+1) 0

c2i zero  
-- 0

c2i one  
-- 1

c2i two  
-- 2
</code></pre>

<p><em>* (에스터리스크)</em> 의 개수로 숫자를 정의해 봅시다.</p>

<pre><code class="haskell">-- church to int
c2s x = x ('*' :) ""

c2s zero  
-- ""

c2s one  
-- "*"

c2s two  
-- "**"
</code></pre>

<p>이제 연산자를 만들어 봅시다. 덧셈부터 시작해 보죠! <code>c2i</code> 에 <code>x</code> 를 넣어 만들어낸 <em>수 (Number)</em> 를 <code>x'</code> 라 하고 <code>y</code> 를 넣어 만든 수를 <code>y'</code> 라 합시다. </p>

<pre><code class="haskell">x' = c2i x  
y' = c2i y  
</code></pre>

<p>그러면 덧셈은 이렇게 정의할 수 있습니다.</p>

<pre><code class="haskell">x' + y' = c2i (add x y)  
</code></pre>

<p>증명해 봅시다.</p>

<pre><code class="haskell">x' + y'  
= c2i x + c2i y
= x (+1) 0 + c2i y -- 0 is substituted
= x (+1) (c2i y)
= x (+1) (y (+1) 0)
= (\s z -&gt; x s (y s z)) (+1) 0 -- by beta expension
</code></pre>

<p>보면 알겠지만 <code>c2i y</code> 나 <code>0 + c2i y</code> 나 같습니다. 따라서 <code>0</code>을 지우고 <code>x c2i</code> 의 베이스 값으로 <code>(c2i y)</code> 를 사용할 수 있죠.</p>

<p>그리고 마지막 치환은 <code>s</code> 와 <code>z</code> 를 <code>(+1)</code> 과 <code>0</code> 으로 취하는 <em>lambda</em> 를 구할 수 있습니다. <code>\s z -&gt; x s (y s z)</code> 를 <code>add</code> 라 부르면</p>

<pre><code class="haskell">x' + y' = (add x y) (+1) 0  
= c2i (add x y)
</code></pre>

<p>결국 <em>addtion</em> 은</p>

<pre><code class="haskell">add x y = \s z -&gt; x s (y s z)

c2i (add one two)  
-- 3
</code></pre>

<p><em>multiplication (곱셈)</em>은 어떻게 만들까요? 간단한 예제부터 시작해 <em>intuition</em> 을 얻어보도록 합시다.</p>

<pre><code class="haskell">two = \s -&gt; s . s  
three = \s -&gt; s . s . s  
</code></pre>

<p>결국 <code>n</code> 번째 수란건 <code>s</code> <em>successor function</em> 을 <code>n</code> 번 만큼 수행한거지요. 그럼 <code>a * b</code> 의 곱셈은 <code>b</code> 번 적용한 <em>successor</em> 를 <code>a</code> 번 적용하면 되므로</p>

<pre><code class="haskell">mul = \s z -&gt; x (y s) z

c2i (mul two five)  
-- 10
</code></pre>

<h3 id="examples">Examples</h3>

<pre><code class="haskell">id :: a -&gt; a  
id = \x -&gt; x

compose :: [a -&gt; a] -&gt; (a -&gt; a)  
compose = foldr (.) id  
</code></pre>

<p><code>id</code> 함수는 받은걸 그대로 돌려주기 때문에 <code>id . f</code>, <code>f . id</code> 는 <code>f</code> 입니다. 따라서 함수 리스트를 위한 <code>foldr</code> 의 초기값으로 <code>id</code> 를 사용할 수 있습니다.</p>

<h3 id="stringtransmitter">String Transmitter</h3>

<p>간단한 문자열 전송을 모델링한 코드를 작성해 봅시다.</p>

<pre><code class="haskell">import Data.Char

type Bit = Int

bin2int :: [Bit] -&gt; Int  
bin2int bits = sum [w * b | (w, b) &lt;- zip weights bits]  
  where weights = iterate (*2) 1

-- or
-- bin2int bitis = foldr (\x acc -&gt; x + acc * 2) 0

int2bin :: Int -&gt; [Bit]  
int2bin 0 = []  
int2bin n = n `mod` 2 : int2bin(n `div` 2)

make8 :: [Bit] -&gt; [Bit]  
make8 bits = take 8 (bits ++ repeat 0)

encode :: String -&gt; [Bit]  
encode = concat . map (make8 . int2bin . ord)

chop8 :: [Bit] -&gt; [[Bit]]  
chop8 [] = []  
chop8 bits = take 8 bits : chop8 (drop 8 bits)

decode :: [Bit] -&gt; String  
decode = map (chr . bin2int) . chop8

channel :: [Bit] -&gt; [Bit]  
channel = id

transmit :: String -&gt; String  
transmit = decode . channel . encode  
</code></pre>

<p>재밌는 부분은 마지막 <code>channel</code> 부분인데요, <code>id</code> 함수를 써서 인코딩된 문자열이 바로 디코딩을 위해 전송된다는 것을 표현했습니다.</p>

<p>위 코드 중에서 <code>int2bin</code> 과 <code>chop8</code> 은 헤드에 특정 연산을 수행하고, <code>tail</code> 에 나머지 연산을 수행 한 결과를 다시 재귀적으로 호출하는 패턴을 가지고 있는데요, <code>unfold</code> 함수로 추상화 할 수 있습니다. </p>

<p>쉽게 말해서 <code>fold</code> 가 리스트를 <em>접어 (folding)</em> 원소 하나로 만든다면, <code>unfold</code> 는 리스트를 더 한단계 펼친다고 볼 수 있습니다.</p>

<pre><code class="haskell">unfold p h t x  
  | p x = []
  | otherwise = h x : unfold p h t (t x)
</code></pre>

<p>그리하면 구현을</p>

<pre><code class="haskell">type Bit = Int  
int2bin :: Int -&gt; [Bit]  
int2bin = unfold (== 0) (`mod` 2) (`div` 2)

chop8 :: [Bit] -&gt; [[Bit]]  
chop8 = unfold null (take 8) (drop 8)  
</code></pre>

<p><code>map</code> 과 <code>iterate</code> 도 구현할 수 있습니다.</p>

<pre><code class="haskell">map2 f = unfold null (f . head) tail

iterate' f = unfold (const False) id f -- const False is pred. always return False  
</code></pre>

<p>여기서 <code>const False</code> 는 항상 <code>False</code> 만 돌려주는 <em>predicate</em> 라 보시면 됩니다.</p>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> in <em>edx</em> <br />
(2) <a href='https://sadakurapati.wordpress.com/' >https://sadakurapati.wordpress.com</a> <br />
(3) <em>Programming in Haskell, Chapter 6, 7</em> <br />
(4) <a href='http://www.pling.org.uk/cs/fun.html' >http://www.pling.org.uk/cs/fun.html</a>  </p>]]></description><link>http://1ambda.github.io/haskell-intro3/</link><guid isPermaLink="false">6ae03a58-8478-4f0d-a716-75f09c81a985</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[recursion]]></category><category><![CDATA[church numerals]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 12 Nov 2014 02:10:13 GMT</pubDate></item><item><title><![CDATA[Foundations of Data Analysis, Week1]]></title><description><![CDATA[<p><em>edx</em> 수업. R 을 이용해 실제 데이터에 학습한 통계 이론들을 적용하는 수업이다. <em>edx</em> 에서 제공하는 <em>discussion board</em> 대신에 <em>piazza board?</em> 이런것도 쓰고, <em>lab</em> 전에 비슷한 질문을 하는 <em>pre-lab</em> 도 있고.. 구성이 친절하다. 여러모로 신경을 많이 쓴듯 </p>

<h3 id="classifyingvariables">Classifying Variables</h3>

<p><em>population (모집단)</em> 의 각각을 <em>unit</em>, <em>subject</em> 라 부른다. <em>Galapagos Tortoises</em> 
예제에서 <em>unit</em> 은 각각의 거북이들이다.</p>

<p>연구자들이 갈라파고스 거북이들로부터 몇 가지 특징들을 뽑아내 도표로 만들었는데, 이런 특징들을 <em>varaible</em> 이라 부른다.</p>

<p><em>variable</em> 은 종류에 따라서 <em>categorical</em>, <em>numerical</em> 로 구분한다. 다른말로는 <em>qualitative (= categorical)</em>, <em>quantitative (= numerical)</em> 이라 부르기도 한다.</p>

<p>날씨나 등 껍질 종류 같은 경우는 <em>qualitative variable</em> 이고 <em>number of individuals repatriated</em> 는 <em>quantitative variable</em> 이다. 저 속성이 뭔 소린가 했는데, 갈라파고스 거북이들은 섬의 중앙에서 보호를 받고 자라다가 나중에 야생으로 돌아간다고.. 그 숫자를 의미하는것이 <em>number of indiviaudls repatriated</em> 다.</p>

<p><em>complete counting</em> 혹은 <em>census (인구조사)</em> 같은 경우는 대부분의 경우 힘들기 때문에 <em>population</em> 에서 일부를 떼어낸 <em>sample</em> 을 이용하게 된다.</p>

<blockquote>
  <p>It is common to use a smaller, representative group from the population, called a <em>sample</em></p>
</blockquote>

<h3 id="errors">Errors</h3>

<p><em>sample</em> 이 <em>population</em> 을 대표하지 못할 수도 있기 때문에, 완벽히 <em>parameter (모수)</em> 를 추정하는 것은 어렵다. 그래서 통계학자들은 <em>point estimate</em> 나 <em>interval estimiate</em> 를 사용한다. 예를 들면</p>

<blockquote>
  <p><em>"I am 95% confident that the true number of tortoises is actually between 561 and 1075."</em></p>
</blockquote>

<p><em>true paramter</em> 와 샘플로부터 얻어진 <em>statistic</em> 간 차이는 <em>sampling error</em> 라 부른다.</p>

<p>갈라파고스 거북이를 조사 할 때 밀집 지역에서만 거북이를 골라낸다고 하자. 그리고 그 샘플을 전체 지역에 대한 통계값을 얻을 때 사용하면 너무 높은 값이 나올 수 있다. 이런 종류의 오류를 <em>bias</em> 라 부른다. 다행히도 통계학자들이 <em>bias</em> 를 피할 수 있는 다양한 도구들을 준비 해 놓았으니 배우기만 하면 된다.</p>

<h3 id="levelsofmeasurement">Levels of Measurement</h3>

<p>아까는 <em>variable</em> 을 간단히 두 종류로 나누어 봤지만 더 자세하게 나눌 수 있다. </p>

<blockquote>
  <p>A <strong>nominal measurement</strong> is one in which the values of the variable are names. The names of the different species of Galapagos tortoises are an example of a nominal measurement</p>
  
  <p>An <strong>ordinal measurement</strong> involves collecting information of which the order is somehow significant. The name of this level is derived from the use of ordinal numbers for ranking. If we measured the different species of tortoise from the largest population to the smallest, this would be an example of ordinal measurement.</p>
  
  <p>With <strong>interval measurement</strong>, the distance between any two values has a specific meaning. An example commonly cited for interval measurement is temperature. A change of 1 degree is the same if the temperature goes from <code>0C</code> to <code>1C</code> as it is when the temperature goes from <code>40C</code> to <code>41C</code>. In addition, there is meaning to the values between the ordinal numbers. That is, a half of a degree has meaning.</p>
  
  <p>A <strong>Ratio measurement</strong> is the estimation of the ratio between a magnitude of a continuous quantity and a unit magnitude of the same kind. A variable measured at this level not only includes the concepts of order and interval, but also adds the idea of <code>nothingness</code>, or absolute zero. With the temperature scale of the previous example, <code>0C</code> is really an arbitrarily chosen number and does not represent the absence of tempertature. As a result, the ratio between temperature is relative, and <code>40C</code>, for example, is not twice as hot as <code>20C</code>.</p>
</blockquote>

<p>간단히 정리하자면 <em>nominal measurement</em> 는 이름으로 분류를 할 수 있는 경우다. </p>

<p><em>ordinal measurement</em> 는 각 <em>unit</em> 간 순위, 순서를 매긴 것이다. 이 경우 값 자체가 1, 2, 3 같은 순서기 때문에 <em>unit</em> 간 차이는 아무런 의미도 없다.</p>

<p><em>interval measurement</em> 는 두 값간 <em>distance (차이)</em> 가 의미를 가지는 경우다. 온도를 잘 보면 40도와 39도의 차이 1은, 1도와 0도의 차이 와 같다. 그리고 <em>interval measurement</em> 에서는 각 <em>unit</em> 사이의 값들도 의미가 있다. (ex. 0.5도)</p>

<p>마지막으로 <em>ratio measurement</em> 는 <em>nothingness</em> 혹은 <em>absolute zero</em> 가 존재하는 값이다. 켈빈 온도의 경우 20K 는 40K 의 1/2 이다. 반면 섭씨 온도의 경우 20C 가 40C 보다 1/2 덥다고 말할 수가 없다. </p>

<p>이렇게 <em>nominal, ordinal, interval, ratio</em> 로 구분하는 방법을 <em>Stevens' Theory</em> 라 부른다. 단순히 <em>numerical, categorical</em> 로 구분하는 것 보다 좀 더 자세히 분류할 수 있다.</p>

<p>몇 가지 예제를 좀 더 살펴보자면</p>

<p>(1) 학생들의 <em>gender, race, political opinions</em> 등은 모두 <em>nominal measurement</em> 다. <br />
(2) 학생들의 학년(7, 8, 9) 를 수집한다면 <em>ordinal measurement</em> 다. <br />
(3) SAT 수학 점수를 모은다면, 그건 <em>interval measurement</em> 다. (아마 상대평가인가 봄) <br />
(4) 나이, 키, 몸무게, 점수(0-100) 등을 수집한다면 <em>ratio measurement</em> 다.</p>

<p><em>nominal</em> 에서 <em>ratio</em> 로 갈수록 값들이 점점 복잡해진다. </p>

<p><img src='https://dr282zn36sxxg.cloudfront.net/datastreams/f-d%3A92ba1471fd7e4ab92e330423cc7653fc15f9e1808cbbd03f8cdad61a%2BIMAGE%2BIMAGE.1'  alt="" /></p>

<p align="center">(<a href='http://www.ck12.org/statistics' >http://www.ck12.org/statistics</a></p>

<p>이렇게 데이터를 구분하는 이유는, 각각 에 쓸 수 있는 <em>Tool</em> 이 다르기 때문이다. 어떤 툴은 <em>categorical variable</em> 에 유용할 수도 있고, 그렇지 않은 툴도 있기 마련이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>UT.7.01x Foundations of Data Analysis</em> <br />
(2) <a href='http://www.ck12.org/statistics/Levels-of-Measurement/lesson/Levels-of-Measurement/' >http://www.ck12.org/statistics</a></p>]]></description><link>http://1ambda.github.io/foundations-of-data-analysis-week1/</link><guid isPermaLink="false">7a56ea31-f2e1-4117-a5db-5140868a8668</guid><category><![CDATA[edx]]></category><category><![CDATA[statistics]]></category><category><![CDATA[R]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 12 Nov 2014 01:51:36 GMT</pubDate></item><item><title><![CDATA[Graphs, The Contraction Algorithm]]></title><description><![CDATA[<p>이번엔 지난시간에 배운 <em>randomized algorithm</em> 을 새로운 <em>domain</em> 인 그래프에 적용해 보고, <em>contraction algorithm</em> 이 무엇인지 알아본다.</p>

<h3 id="graphs">Graphs</h3>

<p>용어 정리부터 시작하자. <em>edge</em> <code>(E)</code> 는 <em>pair of vertices</em> 와 같은 말이다. <code>(E)</code> 는 <em>directed or undirected</em> 일 수 있으므로 <em>unordered pair</em> 또는 <em>ordered pair</em> 일 수 있다. <em>directed edges</em> 는 다른말로 <em>arcs</em> 라 부르기도 한다.</p>

<p><em>cut</em> 은 그래프를 비어있지 않은 두개의 그룹으로 분리하는 것을 말한다.</p>

<blockquote>
  <p>A cut of a graph <code>(V, E)</code> is a partition of <code>V</code> into two non-empty sets <code>A</code> and <code>B</code></p>
</blockquote>

<p>따라서 <em>vertice</em> 가 <code>n</code> 개라면 <code>2^n - 2</code> 개의 <em>cut</em> 을 만들 수 있다.</p>

<h3 id="minimumcutproblem">Minimum Cut Problem</h3>

<p><em>crossing edge</em> 를 최소로 하는 <em>cut</em> 을 찾는 문제다. 이걸 어디다 쓸 수 있을까?</p>

<p>(1) identify network bottlenecks / weaknesses <br />
(2) community detection in social network  </p>

<p>두 사람 혹은 집단간 강하게 결합되고 나머지와는 약하게 결합된 부분(<em>mimimum cut</em>) 을 찾으면 두 개체간 관련성이 있다고 볼 수 있다.    </p>

<p>(3) image segmentation  </p>

<p>이미지를 <em>2D grid</em> 라 <em>grid edge</em> 를 만들어 <em>same object</em> 에서 왔을 가능성을 나타내는 가중치를 부여해 <em>min cut</em> 을 하면 쓸모 없는 부분이 잘려나간다.</p>

<h3 id="graphrepresentation">Graph representation</h3>

<p>그래프가 <em>sparse graphs</em>, <em>dense graphs</em> 냐에 따라 알고리즘이 성능이 잘 나올수도 있고 아닐수도 있기 때문에 이 두 가지를 구분해 보자.</p>

<p><code>n</code> 을 <em>the number of vetices</em>, <code>m</code> 을 <em>the number of edges</em> 라 하자. 대부분의 경우에 <code>m</code> 은 <code>Omega(n)</code>, <code>O(n^2)</code> 이다.</p>

<p><em>sparse graph</em> 는 <code>m</code> 이 <code>O(n)</code> 에 가깝고 <em>dense graphs</em> 는 <code>m</code> 이 <code>O(n^2)</code> 에 가깝다.</p>

<h3 id="adjacencymatrix">Adjacency Matrix</h3>

<p>그래프를 자료구조로 표현하는 몇 가지 방법이 있는데 <em>Adjacency matrix (인접행렬)</em> 의 경우에는 노드 수, <code>n</code> 에 대해 <code>n x n</code> 의 행렬 <code>A</code> 를 만들어서 <code>A_ij</code> 를 <code>i</code> 노드와 <code>j</code> 노드가 연결되었다면 값을 <code>1</code> 채운다</p>

<p>몇 가지 변형이 있을 수 있는데 <em>parallel edges</em> 가 허용된다면 <code>A_ij</code> 는 연결된 엣지 수 일 수 있고, <code>A_ij</code> 에 가중치를 담는 경우도 있다. <em>directed graph</em> 면 <code>i -&gt; j</code> 냐 <code>j -&gt; i</code> 냐에 따라 <code>-1 or +1</code> 을 값으로 사용할 수 있다.</p>

<p>어떤 경우든 <em>adjacency matrix</em> 방식 자체는 <em>edge</em> 수와는 관계 없이 <em>vertice</em> 수의 제곱에 비례하는 공간이 필요하다. 따라서 <em>sparse graphs</em> 에서는 사용하지 않는 편이 낫다.</p>

<h3 id="adjacencylist">Adjacency List</h3>

<p><em>Adjacency list (인접 리스트)</em> 로 그래프를 표현할 경우엔 </p>

<p>(1) array (or list) of vertices (<code>theta(n)</code>) <br />
(2) array (or list) of edges (<code>theta(m)</code>) <br />
(3) each edge points to its endpoint (<code>theta(m)</code>) <br />
(4) each vertex points edges (<code>theta(m)</code>)</p>

<p>(4) 의 경우 <em>undirected graph</em> 라면 명확한데, <em>directed graph</em> 의 경우에는 <em>tail</em> 만 저장 한다던지 몇가지 방법을 쓸 수 있다. </p>

<p>그럼 <em>adjacency list</em> 는 얼마의 공간을 차지할까? (3) 의 경우는 위에 표시했듯이 (<code>theta(m)</code>) 인데, 각각의 <em>edge</em> 는 2 개의 <em>vertex</em> 를 저장하지만 <code>2</code> 는 상수 취급한다.</p>

<p>(4) 가 노드마다 간선 수가 달라 계산이 어려울 수 있는데, (3) 과 1:1 대응이라 보면 된다. 노드가 가리키는 간선이나, 간선이 가리키는 노드나 수는 같다. 따라서 (<code>theta(m)</code>) 이므로 전체 메모리 사용은 (<code>theta(m + n)</code>) 이다. </p>

<p>그러면 인접 행렬과 인접 행렬중 어떤게 더 나을까? 둘 다 장단이 있지만 <em>graph search</em> 는 단연 인접 행렬이 더 낫고, 요즘엔 <em>node</em> 는 정말 많은 반면 <em>edge</em> 는 좀 적기 때문에 인접 리스트가 더 낫다.</p>

<p>간단히 웹만 생각해봐도 노드 자체는 엄청나게 많은 반면 간선은 적다. 만약 인접 행렬로 그래프를 표현하면 노드 수의 제곱에 비례하는 메모리가 필요한데, 이건 리소스 문제를 겪을 수 있다.</p>

<h3 id="randomcontractionalgorithm">Random Contraction Algorithm</h3>

<p><em>min cut</em> 을 해결하기 위해 <em>quick sort</em>, <em>randomized selection</em> 에서 보았던 랜덤 샘플링을 이용할건데, 이 문제는 랜덤 샘플링이 그래프 문제에도 얼마나 효과적인지 보여준다. 알고리즘은 이렇다.</p>

<p>(1) while there are more than 2 vertices <br />
(2) pick a remaining edge <code>(u, v)</code> uniformly at random <br />
(3) merge (or "contract") <code>u</code> and <code>v</code> into a single vertex <br />
(4) remove self-loops <br />
(5) return cut represented by final 2 vertices  </p>

<p>해보면 알겠지만 이 알고리즘은 <em>min cut</em> 을 답으로 제공할 수도, 아닐 수도 있다. 따라서 문제는, <em>What is prob of success?</em> 를 계산하는 것으로 바뀐다.</p>

<h3 id="analysiscontractionalgorithm">Analysis: Contraction Algorithm</h3>

<p>분석 전에 몇 가지 용어를 정의하고 가자. <em>graph</em> <code>G = (V, E)</code> 에 대해 <code>n</code> 개의 <em>vertices</em>, <code>m</code> 개의 <em>edges</em> 가 있다. 그리고 <em>minimum cut</em> <code>(A, B)</code> 는 <code>G</code> 를 두개의 비어있지 않은 그룹 <code>A</code>, <code>B</code> 로 나눈다. 그리고 <code>k</code> 를 <code>(A, B)</code> 의 <em>crossing edges</em> 숫자라 하자. 그리고 이들 <em>crossing edges</em> 를 <code>F</code> 라 부르자.</p>

<p>만약에 <code>F</code> 중 하나의 <em>edge</em> 가 <em>contraction</em> 알고리즘 중에 선택 된다면 <code>(A, B)</code> 는 섞여버린다. </p>

<p>따라서 이터레이션 동안 <code>A</code> 내부에 있는 <em>vertex</em> 끼리만, 그리고 <code>B</code> 내부에 있는 <em>vertex</em> 끼리만 <em>contraction</em> 이 일어나야 한다. 그래야만 <em>minimum cut</em> 을 찾을 수 있다.</p>

<p>따라서 올바른 <code>(A, B)</code> 를 아웃풋으로 얻을 확률은 <code>F</code> 중 어느 <em>edge</em>도 선택되지 않을 확률과 같다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5Boutput%20%5C%20is%20%5C%20%28A%2C%20B%29%5D%20%3D%20P_r%5Bnever%5C%20contracts%5C%20an%5C%20edge%5C%20of%20F%5D'  alt="" /></p>

<p><del>Tex 에 맛들려서 이미지를 추가한건 아니요!</del></p>

<p><code>S_i</code> 를 <code>F</code> 에 있는 <em>edge</em> 가 이터레이션 <code>i</code> 에서 <em>contracted</em> 되는 <em>event (사건)</em> 이라 하자. 그럼 우리의 목표는 다음의 확률을 계산하는 것이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_1%20%5Ccap%20%5Cneg%20S_2%20%5Ccap%20%5Ccdots%20%5Ccap%20%5Cneg%20S_%7Bn-2%7D%5D'  alt="" /></p>

<p>증명에 사용할 재미난 그래프의 특징이 하나 있다. 모든 <em>vertex</em> 의 <em>incident edges, degree</em> 의 값은 <code>k</code> 보다 크거나 같다. 왜냐하면 모든 <em>vertex</em> 는 그 자신과 나머지를 분리하는 <em>cut</em> 을 가지는데, 이게 <code>k</code> 라면 <em>min cut</em> 이고 아니라면 <code>k</code> 보다 크기 때문이다.    </p>

<blockquote>
  <p>degree of each vertex is at least <code>k</code></p>
</blockquote>

<p>그리고 모든 <em>vertex</em> 의 <em>degree</em> 는 <code>2m</code>, 즉 모든 <em>edge</em> 수의 2배이기 때문에 아래 식은 참이고, </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum_%7Bv%7Ddegree%28v%29%20%3D%202m'  alt="" /></p>

<p>위 식과 각 <em>degree</em> 합은 <code>kn</code> 보다 크거나 같으므로 <code>2m</code> 도 <code>kn</code> 보다 크거나 같다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?2m%20%5Cgeq%20kn'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?m%20%5Cgeq%20%28kn/2%29'  alt="" /></p>

<p>여기서 처음 이터레이션에서 <code>F</code> 내에 있는 <em>edge</em> 가 선택될 확률인 <code>P(S_1) = k / m</code> 이기 때문에 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B2%20%5Cover%20n%7D%20%5Cgeq%20%7Bk%20%5Cover%20m%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5BS_1%5D%20%5Cleq%20%7B2%20%5Cover%20n%7D'  alt="" /></p>

<p>이제 <code>P(S_1)</code> 을 구했으니, 두번째 이터레이션에서 <code>F</code> 내에 있는 <em>edge</em> 가 선택되지 않을 확률을 구해보자. 조건부 확률 공식을 이용하면, </p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_1%20%5Ccap%20%5Cneg%20S_2%5D%20%3D%20P_r%5B%5Cneg%20S_2%20%7C%20%5Cneg%20S_1%5D%20' *%20P_r%5B%5Cneg%20S_1%5D" alt="" /></p>

<p>이때 <code>P(~S_1)</code> 이 <code>n/2</code> 보다 작거나 같으므로</p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_1%5D%20%5Cgeq%20%281%20-%20%7B2%20%5Cover%20n%7D%29'  alt="" /></p>

<p>나머지 <code>P(~S_2 | ~S_1)</code> 을 구하려다 보니 남아있는 <em>edge</em> 가 얼만지 알 수가 없다. </p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_2%20%7C%20%5Cneg%20S_1%5D%20%3D%201%20-%7Bk%20%5Cover%20number%20%5C%20of%5C%20remaining%20%5C%20edges%7D'  alt="" /></p>

<p>그런데, 본래의 그래프가 모든 <em>vertex</em> 에 대해 <em>at least</em> <code>k</code> 개의 <em>edge</em> 를 가졌으면 <em>contracted</em> 된 그래프도 모든 <em>vertex</em> 에 대해 <em>at least</em> <code>k</code> 개의 <em>edge</em> 를 가져야 한다. (우리는 <code>F</code> 내의 <em>edge</em> 를 선택하지 않았기 때문)</p>

<p>따라서 <em>remaining edge</em> 는 <code>1/2 * k * (n-1)</code> 보다 크다. (1/2 은 <code>n</code> 으로 <em>edge</em> 수를 세면 두번씩 카운팅하기 때문에 필요)</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7Bnumber%20%5C%20of%5C%20remaining%20%5C%20edges%7D%20%5Cgeq%201/2%20' *%20k%20*%20%28n-1%29" alt="" /></p>

<p><em>denominator</em> 의 <em>lower bound</em> 를 구했기 때문에 <em>fraction</em> 의 <em>upper bound</em> 를 구한셈이 된다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_2%20%7C%20%5Cneg%20S_1%5D%20%5Cgeq%201%20-%7B2%20%5Cover%20n%20-%201%7D'  alt="" /></p>

<p>이제 규칙성이 보인다. 우리가 구하려는 값은 </p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_1%20%5Ccap%20%5Cneg%20S_2%20%5Ccap%20%5Ccdots%20%5Ccap%20%5Cneg%20S_%7Bn-2%7D%5D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%3D%20P_r%5B%5Cneg%20S_1%5D%20' *%20P_r%5B%5Cneg%20S_2%20%7C%20S_1%5D%20*%20P_r%5B%5Cneg%20S_3%20%7C%20%5Cneg%20S_2%20%5Ccap%20%5Cneg%20S_1%5D%20*%20%5Ccdots%20*%20P_r%5B%5Cneg%20S_%7Bn-2%7D%20%7C%20%5Cneg%20S_1%20%5Ccap%20%5Ccdots%20%5Ccap%20%5Cneg%20S_%7Bn-3%7D%5D" alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cgeq%20%281%20-%20%7B2%20%5Cover%20n%7D%29' *%281%20-%20%7B2%20%5Cover%20%28n%20-%201%29%7D%29*%281%20-%20%7B2%20%5Cover%20%28n%20-%202%29%7D%29*%5Ccdots*%20%281%20-%20%7B2%20%5Cover%20%28n%20-%20%28n-4%29%29%7D%29%20*%20%281%20-%20%7B2%20%5Cover%20%28n%20-%20%28n-3%29%29%7D%29" alt="" /></p>

<p>정리하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%3D%20%7B2%20%5Cover%20n%20%5C%20%28n-1%29%7D%20%5Cgeq%20%7B1%20%5Cover%20n%5E2%7D'  alt="" /></p>

<p>따라서 <em>contraction</em> 알고리즘이 성공할 확률은 <code>n</code> 이 크면 굉장히 낮다. 근데 이게 <em>brute-force</em> 에 비하면 놀랍게도 굉장히 높은 성공률이다. </p>

<p>본래 <code>n</code> 개의 <em>vertex</em> 가 있으면 모든 <em>cut</em> 을 다 해 보려면 <code>2^n</code> 의 시도가 필요하다. 따라서 <em>contraction</em> 알고리즘은 꽤 높은 확률을 보장하는 알고리즘이다. </p>

<p><code>T_i</code> 를 <code>i</code> 번째 <em>trial</em> 에서 <em>min cut</em> 을 찾아낼 확률이라 하자. <code>N</code> 번의 <em>trial</em> 동안 <em>min cut</em> 을 찾지 못할 확률은, 매 <em>trial</em> 이 독립적이기 때문에 </p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20T_1%20%5Ccap%20%5Cneg%20T_2%20%5Ccap%20%5Ccdots%20%5Ccap%20%5Cneg%20T_N%20%5Ccap%20%5D%20%3D%20%5Cprod_%7Bi%20%3D%201%7D%5EN%20P_r%5B%5Cneg%20T_i%5D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cprod_%7Bi%20%3D%201%7D%5EN%20P_r%5B%5Cneg%20T_i%5D%20%5Cleq%20%281%20-%20%7B1%20%5Cover%20n%5E2%20%7D%29%5EN'  alt="" /></p>

<p>이 때 <code>1 + x &lt;= e^x</code> 란 사실을 이용하면 좀 더 간단한 <em>upper bound</em> 를 찾으 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%281%20-%20%7B1%20%5Cover%20n%5E2%20%7D%29%5EN%20%5Cleq%20%28e%5E%7B-1%20%5Cover%20n%5E2%7D%29%5EN'  alt="" /></p>

<p>이때 <code>N = n^2</code> 이라면 <code>N</code> 번째까지 실패할 확률은 <code>1/e</code> 보다 작거나 같다. 만약에 <code>N = n^2 lnn</code> 이면 <code>1/n</code> 까지 내려간다.</p>

<p>따라서 단순히 계산을 반복하는 것만으로도 성공 확률을 <code>1/n^2</code> 에서 <code>1 - 1/n</code> 까지 올릴 수 있다.</p>

<p><em>running time</em> 은 <code>Omega(n^2 * m)</code> 쯤 된다. <code>n^2</code> 정도의 <em>trial</em> 이 필요하고 매 <em>trial</em> 마다 <code>m</code> 의 <em>edge</em> 를 살펴봐야 한다.</p>

<p>여전히 느리다. 이후에는 단순히 <em>trial</em> 을 늘리는 것 뿐만 아니라 다양한 옵티마이제이션 기법을 활용하는법을 배워보자. 거의 <code>O(n^2)</code> 까지 줄일 수 있다.</p>

<h3 id="countingminimumcuts">Counting Minimum Cuts</h3>

<p>그래프를 그려보면 알겠지만 <em>min cut</em> 은 한개가 아니라 여러개 일 수 있다. 그러면 <code>n</code> 개의 <em>vertice</em> 를 가진 그래프에서 최대로 가질 수 있는 <em>min cut</em> 은 몇개 일까? </p>

<p>그래프에서 각 노드마다 <em>edge</em> 가 하나밖에 없을땐 <code>n-1</code> 이고, 아무리 <em>cut</em> 이 많아봐야 <code>2^n - 2</code> 보다 적으니까 이 사이에 있는건 분명하다.</p>

<p>답은 <em>n choose 2</em>, <code>(n * (n - 1)) / 2</code> 다.</p>

<p>먼저 <em>lower bound</em> 부터 보자. <em>n-cycle</em> 그래프를 보면 2개를 끊으면 되므로 <code>nC2</code> 다. </p>

<p>따라서 <code>n</code> 개의 <em>vectice</em> 를 가진 모든 그래프 중에서 가장 많은 <em>min-cut</em> 을 가진 그래프들은 적어도 이것보다는 많은 <em>min-cut</em> 을 가져야 한다.</p>

<p><em>upper bound</em> 를 보자. <code>(A1, B1), (A2, B2), ..., (At, Bt)</code> 만큼의 <em>min cut</em> 이 있다 하자. 이 때 특정 <em>min cut</em> 인 <code>(Ai, Bi)</code> 가 나올 확률은 위의 증명을 다시 보면 <code>1/n^2</code> 보다 큰 <code>2/(n(n-1))</code> 이다. 이건 <code>nC2</code> 를 뒤집은 수다.</p>

<p>다시 말해서 <em>min cut</em> 을 뽑아낼 확률이</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5Boutput%5C%20%3D%5C%20%28A_i%2C%20B_i%29%5D%20%5Cgeq%20%7B2%20%5Cover%20n%28n-1%29%7D%20%3D%20%7B1%20%5Cover%20%5Cbinom%7Bn%7D%7B2%7D%7D'  alt="" /></p>

<p>이 때 <code>S_i</code> 를 <code>(A_i, B_i)</code> 가 나오는 사건이라 하면 <code>S_i</code> 각각은 <em>disjoint</em> 다.</p>

<p>중요하니까 다시 한번 반복하면, <code>S_i</code> 는 <em>disjoin</em> 고 이로인해 모든 <code>S_i</code> 를 합하면 <code>1</code> 이다. 따라서 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%7Bt%20%5Cover%20%5Cbinom%7Bn%7D%7B2%7D%7D%20%5Cleq%201'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%7Bt%7D%20%5Cleq%20%5Cbinom%7Bn%7D%7B2%7D'  alt="" /></p>

<p>이건 <em>upper bound</em> 다. <em>lower bound</em> 와 같으므로 모든 <code>n</code> 개의 <em>vertice</em> 를 가진 그래프는 최대 <code>nC2</code> 의 <em>min cut</em> 을 가진다.</p>

<h3 id="conditionalprob">Conditional Prob</h3>

<p>중간에 잠깐 조건 부 확률과 독립성, 그리고 기대값에 대해 나오는데 반-직관적인 예제를 교수님이 소개해 주셔서 적어볼까 한다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?X_1%2C%20X_2%20%5Cin%20%5C%7B%200%2C%201%20%5C%7D%20%5C%20and%20%5C%20X_3%20%3D%20X_1%20%5Coplus%20X_3'  alt="" /></p>

<p>일때 <code>X_1</code> 과 <code>X_3</code> 는 독립이고, <code>X_1, X_3</code> 와 <code>X_2</code> 는 독립이 아니다. 기대값을 이용하면 쉽게 증명이 가능하다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?E%5BX_1%2C%20X_2%2C%20X_3%5D%20%5Cneq%20E%5BX_1%2C%20X_2%5D%20' *%20E%5BX_3%5D" alt="" /></p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong>  </p>]]></description><link>http://1ambda.github.io/graphs-the-contraction-algorithm/</link><guid isPermaLink="false">29f4c654-dc5f-4724-b30c-760a534e17c2</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[randomization]]></category><category><![CDATA[graph]]></category><category><![CDATA[contraction]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 08 Nov 2014 05:00:35 GMT</pubDate></item><item><title><![CDATA[Randomized Selection]]></title><description><![CDATA[<h3 id="intuition">Intuition</h3>

<p>중복이 없는 <code>n</code> 개의 원소를 가진 배열에서 <code>i</code> 번째로 큰 원소를 얻고 싶다고 하자. 간단한 방법은 먼저 정렬을 한 뒤 거기서 <code>i</code> 번째 원소를 고르면 된다. 이 방법을 <em>reduction</em> 이라 부르는데 <em>selection</em> 문제를 <em>sorting</em> 문제로 바꾸어 푼 것이다. 이 경우 정렬에 머지소트를 사용한다면 <code>O(n logn)</code> 만큼의 시간이 걸릴 것이다.</p>

<p><em>selection</em> 문제는 <code>O(n)</code> 시간 안에 <em>deterministic</em> 하게 해결할 수 있다. 지난시간에 잠깐 논의했던 <em>randomization</em> 을 이용하면 된다. 어떻게 그럴 수 있을까? 저기서 정렬을 더 개선할 수 없다는건 모두가 알고 있는 사실인데</p>

<p><em>quick sort</em> 를 수정해서 <em>pivot</em> 을 <em>median of medians</em> 로 고르면 된다. <del>아니 의사양반 이게 무슨 개소리요!</del></p>

<p>더 정확히 말해서 이 문제는 <strong>정렬 문제가 아니기 때문에</strong> 더 개선할 여지가 있다. <em>pivot</em> <code>P</code> 를 기준으로 좌측이나 우측 한쪽만 선택하면 되는 <em>selection</em> 문제다.</p>

<p><em>worst case</em> 는 당연히 매 재귀호출마다 문제 수가 1씩 줄어드는 경우이므로 <code>O(n^2)</code> 일테다. 만약에, <em>bast case</em> 로 문제가 절반씩 줄어든다면? <em>master method</em> 를 이용하면 <code>a = 1, b = 2, d = 1</code> 에서 <code>T(n) = O(n^1)</code> 이다.</p>

<p><img src='https://acrocontext.files.wordpress.com/2014/01/master-method.png?w=300&amp;h=160'  alt="" /></p>

<p>그럼 이제 문제는 어떻게 사이즈를 <code>1/2</code> 로, 더 정확히는 <em>median</em> 을 <em>pivot</em> 으로 삼느냐다.</p>

<h3 id="analysis">Analysis</h3>

<p><em>randomized selection</em> 문제를 풀기 위해 구현한 함수를 <code>rSelect</code> 라 하자. 매 재귀마다 문제 사이즈가 <code>n</code> 이라고 하면, 각 재귀에서의 <code>rSelect</code> 의 연산은 <code>c * n</code> 보다 작거나 같다. (<code>c</code> 는 상수)</p>

<p>이제 본격적인 분석전에  잠깐 <em>notation</em> 을 하나 만들고 가면 <code>phase j</code> 는 문제의 사이즈가 <code>(3/4)^j+1 * n</code> 과 <code>(3/4)^j * n</code> 사이에 있는 <code>rSelect</code> 다. 따라서 문제의 사이즈가 <code>n</code> 부터 <code>3/4</code> 가 되기 전까지의 모든 <code>rSelect</code> 는 <code>phase 0</code> 에 있다.</p>

<p>그리고 <code>Xj</code> 를 <code>phase j</code> 에 있는 <code>rSelect</code> 호출의 수라 정의하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20%5Csum_%7Bphase%20j%7D%20X_j%20' *%20c%20*%20%28%7B3%20%5Cover%204%7D%29%5Ej%20*%20n" alt="" /></p>

<p>이렇게 정의해 놓으면 재밌는 조건을 하나 쓸 수 있다. 바로 <em>pivot</em> 이 <code>25%-75%</code> 사이로 분할만 해주면, 다시 말해서 반으로 갈린 문제 중 작은 한쪽이 적어도 <code>25%</code> 가 넘으면 현재 <em>phase</em> 가 끝난다. 그럼 이제 전체 알고리즘의 기대값을 구하기 위해 <em>linearity of expectation</em> 을 이용해서 <code>E(Xj)</code> 를 구하면 된다. </p>

<p><code>25-75%</code> 로 피벗이 걸릴 확률 <code>P(25-75%) = 1/2</code> 이고 그럴때의 <code>Xj = 1</code> 이다. 반면 두번째에 피벗이 제대로 걸릴 확률은 <code>1/4</code> 이고, 세번째에 피벗이 제대로 걸릴 확률은 <code>1/2^3</code> 이다.</p>

<p>기대값은 이 모든 각각 확률변수값과 그 확률의 곱이므로 계산하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B1%20%5Cover%202%7D%20&plus;%20%7B1%20%5Cover%202%5E2%7D%20&plus;%20%7B1%20%5Cover%202%5E3%7D%20&plus;%20%5Ccdots%20%5Cleq%202'  alt="" /></p>

<p>이것 말고 더 재밌는 계산법도 있다. 자세한 건 강의 내용을 참조 </p>

<p><img src='http://latex.codecogs.com/gif.latex?E%28X_j%29%20%3D%201%20&plus;%20%7B1%20%5Cover%202%7D%20' *%20E%28X_j%29" alt="" /></p>

<p>이제 <em>average running</em> 타임을 구하기 위해 <code>T(n)</code> 의 평균을 구하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20E%5Bc%20' *%20n%20*%20%5Csum_%7Bphase%20j%7D%20%28%7B3%20%5Cover%204%7D%29%5Ej%20*%20X_j%5D" alt="" /></p>

<p>여기서 <em>linearity of expectation (기대값의 선형성)</em> 을 이용하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20c%20' *%20n%20*%20%5Csum_%7Bphase%20j%7D%20%28%7B3%20%5Cover%204%7D%29%5Ej%20*%20E%28X_j%29" alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20c%20' *%20n%20*%20%5Csum_%7Bphase%20j%7D%202%20*%20%28%7B3%20%5Cover%204%7D%29%5Ej" alt="" /></p>

<p>무한급수 공식을 적용하면,</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20c%20' *%20n%20*%204" alt="" /></p>

<p><del>얼마나 멋진가?</del></p>

<h3 id="deterministicselection">Deterministic Selection</h3>

<p>만약에 <em>randomization</em> 을 이용할 수 없다면? 그럼 이제 문제는 <em>good pivot</em>, 즉 <code>50/50</code> 에 최대한 가깝게 잘라내는 <em>pivot</em> 을 찾아야 한다. <em>median of medians</em> 를 이용하면 해낼 수 있다.</p>

<p><em>deterministic selection</em> 알고리즘을 구현한 함수를 <code>dSelect</code> 라 부르면</p>

<pre><code>dSelect(array A, length n, order statistic i)  
</code></pre>

<p>(1) Break <code>A</code> into groups of 5, sort each group <br />
(2) C = the <code>n/5</code> "middle elements" <br />
(3) p = <code>dSelect(C, n/5, n/10)</code>, recursivly computes median of C <br />
(4) Partition <code>A</code> around <code>p</code> <br />
(5) if <code>j = i</code> return <code>p</code> <br />
(6) if <code>j &lt; i</code> return <code>dSelect(1st part of A, j-1, i)</code> <br />
(7) if <code>j &gt; i</code> return <code>dSelect(2nd part of A, j-j, i-j)</code>  </p>

<p><code>4-7</code> 스텝은 <em>randomized selection</em> 과 똑같다. 더 복잡해진 부분은 앞의 <code>1-3</code> 스텝에서 피벗을 고르는 일이다.</p>

<p>퍼포먼스를 다시 이야기 해 보자 <em>randomized selection</em> 은 <em>pivot</em> 이 정말 나쁘게 선택되면 <code>O(n^2)</code> 이 될 수 있다. </p>

<p>반면 <em>deterministic selection</em> 은 모든 경우에 <code>O(n)</code> 을 보장한다. 그러나 실제로는 <em>randomized</em> 보다 성능이 나쁜데, 이유는 알고리즘에서 볼 수 있듯이 새로운 배열 <code>C</code> 가 필요하고 (<em>not in-place</em>), 표기법에는 상수가 생략되는데 <em>deterministic selection</em> 은 이 상수가 꽤나 커질 수 있다.</p>

<h3 id="analysis">Analysis</h3>

<p>이제 좀 더 자세히 살펴보자.</p>

<p>(1) Break <code>A</code> into groups of 5, sort each group  </p>

<p>이건 얼마의 시간이 걸릴까? 주어진 배열을 5개씩 짜르고, 각각의 그룹을 정렬하는데 걸리는 시간은? <code>O(n)</code> 이다.</p>

<p>먼저 <code>n = 120</code> 이라 하자. 정렬에 <em>merge sort</em> 를 사용하면 <em>merge sort</em> 연산 수 공식은</p>

<p><img src='http://latex.codecogs.com/gif.latex?6n%20' *%20log_2%28n&plus;1%29" alt="" /></p>

<p>따라서 잘려진 5개짜리를 정렬하는데 걸리는 시간은 <code>30 * log_2(6)</code> 에서, 이 값은 적어도 120 보다는 작음을 알 수 있다. 따라서 전체 그룹의개수 <code>n/5</code> 를 곱하면, <code>24n</code> 으로 <code>O(n)</code> 임을 알 수 있다. 비록 상수가 좀 크긴 하지만</p>

<p>(2) C = the <code>n/5</code> "middle elements" <br />
(3) p = <code>dSelect(C, n/5, n/10)</code>, recursivly computes median of C <br />
(4) Partition <code>A</code> around <code>p</code> <br />
(5) if <code>j = i</code> return <code>p</code> <br />
(6) if <code>j &lt; i</code> return <code>dSelect(1st part of A, j-1, i)</code> <br />
(7) if <code>j &gt; i</code> return <code>dSelect(2nd part of A, j-j, i-j)</code>  </p>

<p>(2), (4) 는 <code>O(n)</code> 임을 알 수 있고, (3) 은 <code>T(n/5)</code> 다. 문제는 (6), (7) 이다. 둘 중에 하나만 호출되긴 하지만 선택되는 <em>pivot</em> <code>p</code> 에 따라서 문제의 사이즈가 달라진다. 모르니까 <code>T(?)</code> 라 두자 그러면 <em>determinitic selection</em> 의 <em>running time</em> 은</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20T%28n/5%29%20&plus;%20T%28%3F%29'  alt="" /></p>

<p>간단한 가설을 세워보자. </p>

<blockquote>
  <p><strong>두번째 <code>dSelect</code> 호출의 input size 는 <code>7/10 * n</code> 보다 작거나 같다</strong></p>
</blockquote>

<p>그러면 수식을 이렇게 바꿀 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20T%28n/5%29%20&plus;%20T%287n/10%29'  alt="" /></p>

<p>(2) 에서 <em>medians</em> 를 찾고, 이걸 (3)에서 재귀에 한번 더 넘기면 <em>median of medians</em> 을 찾게된다. 이게 어떤 효과가 있냐면, 모든 원소를 5개씩 짤라 아래에서 위로 정렬, <em>medians</em> 는 좌에서 우로 정렬하면 다음과 같은 행렬이 나오는데</p>

<p><img src='http://i.imgur.com/gaOxb1A.jpg?1'  alt="" title="" /><p align="center">(<a href='http://functionspace.org/articles/19' >http://functionspace.org/articles/19</a>)</p></p>

<p>모든 원소 중 좌측 하단에 있는 <code>30%</code> 는 <em>median of medians</em> 보다 분명히 작다. 그리고 우측 상단 <code>30%</code> 는 <em>medians of medians</em> 보다 분명히 크다. 따라서 나머지 40% 값이 어쨌던건 간에 적어도 <code>30-70%</code> 분할은 해주므로 문제의 사이즈가 (6) 스텝에서 <code>7n/10</code> 보다 작거나 같다는 것을 분명히 보장해준다. 따라서 아래 식은 참이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20T%28n/5%29%20&plus;%20T%287n/10%29'  alt="" /></p>

<p>쉽게 <em>master method</em> 를 이용하고 싶은데 문제가 서로 다른 사이즈로 분할되니까 사용할 수 없다. <em>induction</em> 을 이용하자. 아래가 참임을 보이면 된다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20an'  alt="" /></p>

<p>우선 <em>base case</em> 는 <code>T(1) = 1</code> 이므로 <code>T(1) &lt;= a (where a &gt;= 1)</code> 에서 참이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20T%28n/5%29%20&plus;%20T%287n/10%29'  alt="" /></p>

<p>이제 위 식에서 <em>induction hypothesis</em> 를 이용하고, 정리하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20a%28n/5%29%20&plus;%20a%287n/10%29'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20n%20' *%20%289a/10%29" alt="" /></p>

<p>이 때 <code>c</code> 는 상수이므로 <code>c = a / 10</code> 이라 하면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20an'  alt="" /></p>

<p>따라서 <em>deterministic selection</em> 의 성능은 <code>O(n)</code> 이다.</p>

<h3 id="lowerboundforsorting">lower bound for sorting</h3>

<p><em>comparison-based sorting</em> 의 <em>lower bound</em> 는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%0A%5COmega%20' (n*log%20n)" alt="" /></p>

<p>여기 해당되는 정렬들은 <em>merge sort, quick sort, heap sort</em> 등이 있다. 이런 정렬들은 데이터가 어떠할 것이라는 가정 없이 정렬을 해낸다. </p>

<p>반면 데이터의 분포를 안다면 <em>bucket sort</em> 같은 경우 <em>linear time</em> 으로 해결할 수 있다. <em>counting sort</em> 나 <em>radix sort</em> 같은 정렬도 데이터에 대한 정보(정수)라는 것을 이미 알고 있는 경우이므로 <code>O(n)</code> 으로 정렬 가능하다.</p>

<p>데이터에 대한 정보를 모른다고 해 보자. <code>1, 2, ..., n</code> 까지의 데이터를 가지고 있다면 이 데이터들이 배열 안에 담겨있을 수 있는 경우의 수는 <code>n!</code> 이다.</p>

<p><code>n!</code> 개의 모든 종류의 인풋에 대해서 <code>k</code> 번만큼, 혹은 그보다 더 적게 비교가 일어난다고 하자. 그럼 모든 <code>n!</code> 종류의 인풋에 대해서 <code>2^k</code> 개의 서로 다른 <em>execution</em> 이 생긴다.</p>

<blockquote>
  <p>Suppose algorithm always makes &lt;= k comparisons to correctly sort these <code>n!</code> inputs. Across all <code>n!</code> possile inputs algorithms exhibits &lt;= <code>2^k</code> distinct executions</p>
</blockquote>

<p>쉽게 생각해서 <code>k-bit</code> 문자열이 있을때 이걸로 얻을 수 있는 문자열은 <code>2^k</code> 개수다. 즉 어떤 문자는 없을수도 있다.</p>

<p>비둘기 집 원리를 생각해 보자. 우리는 <code>n!</code> 비둘기가 있고, <code>2^k</code> 개의 비둘기 집이 있다. 만약에 <code>k</code> 가 작아 <code>2^k &lt; n!</code> 이면 서로 다른 두개의 인풋에 대해서 같은 종류의 <em>execution</em> 을 공유 한다는 뜻이다. 따라서 둘 중 하나는 제대로 정렬되고, 나머지 하나는 제대로 정렬되지 않는다. </p>

<p>따라서 <code>2^k &gt;= n!</code> 이다. 이때 </p>

<p><img src='http://latex.codecogs.com/gif.latex?n%21%20%5Cgeq%20n%20' *%20%28n-1%29%20*%20%28n-2%29%20%5Ccdots%20%28n/2%29%20%5Cgeq%20%28n/2%29%5E%7B%28n/2%29%7D" alt="" /></p>

<p>이므로 </p>

<p><img src='http://latex.codecogs.com/gif.latex?2%5Ek%20%5Cgeq%20%28n/2%29%5E%7Bn/2%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?k%20%5Cgeq%20%28n/2%29' *%20log_2%28n/2%29" alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?k%20%5Cgeq%20%5COmega%28n' *logn%29" alt="" /></p>

<p><code>k</code> 가 연산 수 이므로 <em>comparison-based sorting</em> 의 <em>lower bound</em> 는 <code>Omega(n logn)</code> 이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong> <br />
(2) <a href='http://functionspace.org/articles/19' >http://functionspace.org/articles/19</a></p>]]></description><link>http://1ambda.github.io/randomized-selection/</link><guid isPermaLink="false">fa03e2ba-fcfe-46a0-987a-4a8137bba43f</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[quick sort]]></category><category><![CDATA[selection]]></category><category><![CDATA[randomization]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 07 Nov 2014 08:17:47 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 5]]></title><description><![CDATA[<p>지난시간엔 왜 <em>neural network</em> 를 사용하는지 알아보았다. 데이터의 차수가 매우 클 때 <em>logistic regression</em> 으로는 성능이 떨어지거나 <em>overfitting</em> 의 문제가 발생할 수 있다는 사실을 알게 되었고, 마지막엔 <em>multi class</em> 문제를 어떻게 해결할지도 잠깐 논의 해봤다.</p>

<p>이번에는 <em>back propagation</em>, <em>gradient checking</em> 에 대해서 배워보자.</p>

<h3 id="costfunction">Cost Function</h3>

<p>시작하기 전에 몇 가지 표기법을 정의하자.</p>

<p><code>L</code> 을 레이어의 수, <code>s_l</code> 을 해당 레이어의 유닛 수라 하자. 그러면 <em>bianry classification</em> 에서 <code>S_L = 1</code> 이다. 아웃풋 레이어의 유닛 수를 더 간단히 <code>K</code> 라 하자. </p>

<p>이제 <em>neural network</em> 에 대한 <em>cost function</em> 을 볼건데 먼저 <em>binary classification</em> 의 <em>regularized cost function</em> 식을 다시 보자.</p>

<p><img src='http://3.bp.blogspot.com/-qNym-oCdMIg/Trd03YeslWI/AAAAAAAAApQ/GUfXiJ3vpUE/s400/Screen+shot+2011-11-07+at+3.03.55+AM.png'  alt="http://aimotion.blogspot.kr/" /></p>

<p>지난 시간에 언급했듯이 신경망에서 각 단계는 <em>logistic regression</em> 과 같이 때문에 <code>L</code> 의 신경망은 <code>L-1</code> 의 <em>logistic regression</em> 의 식으로 변환할 수 있다.</p>

<p><img src='http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20' [3].png" align="center" /></p>

<p><del>이 식의 가장 큰 문제점은 이 식을 보면 당황스럽다는 것이다.</del></p>

<p>뒷 부분 <em>regularization term</em> 은 이해하기 어렵지 않다. 신경망에선 <code>weight</code> (<em>theta</em>) 의 행렬이 이전 레이어와 다음 레이어의 유닛 수로 구성되므로 <code>(theta_ji^l)^2</code> 으로 모든 <code>theta^2</code> 를 구할 수 있다.</p>

<p>여기서 <code>i = 1</code> 부터 시작하는 이유는 <em>logistic regression</em> 의 <em>regularization term</em> 에서 <code>theta_0</code> 을 포함하지 않는것과 같다.</p>

<p>문제는 시그마 <code>K</code> 부분인데, <code>K</code> 가 이 신경망에서 클래스의 개수 라는 점을 고려하면 <code>y_k</code> 는 <code>[0; 0; 1; 0; ...]</code> 에서 <code>k</code> 번째 값, <code>(h0)_k</code> 또한 <code>k</code> 번째 <em>output unit</em> 의 값 이라 보면 된다.</p>

<p>원래 <em>cost function</em> 정의 자체가 우리가 가진 <em>hypothesis</em> 로 구한 값과 본래의 값 <code>y</code> 와의 차이를 알려주는 것이므로 <code>K</code> 개의 클래스가 있을때는 각 클래스 위치의 값과 본래의 <em>k-dimensional vector</em> <code>y</code> 값의 해당 포지션의 차이를 모두 합한 값을 구하는 것이라 <em>neural network</em> 의 <em>cost function</em>  정의할 수 있다.</p>

<h3 id="backpropagationalgorithm">Backpropagation: Algorithm</h3>

<p><em>gradient computation</em> 을 위해서는 <em>cost function</em> 과 각 <code>l</code> 의 <code>i</code>, <code>j</code> 위치의 <code>theta</code> 에 대해서 <em>cost function</em> 의 <em>partial derivative</em> 를 구해야 한다. <del>네?</del></p>

<p><img src='http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20' [7].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/' >http://www.holehouse.org/</a>)</p>

<p><img src='http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20' [8].png" alt="http://www.holehouse.org/mlclass/09<em>Neural</em>Networks<em>Learning</em>files/Image%20[8].png" title="" /></p>

<p>다음과 같은 신경망이 있다고 하자, 그리고 <em>training set</em> 이 <code>(x, y)</code> 만 있다고 한다면 <em>cost function</em> 을 얻기 위해 다음의 <em>forward propagation</em> 을 진행하면 된다.</p>

<p><img src='http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20' [9].png" alt="http://www.holehouse.org/mlclass/09<em>Neural</em>Networks<em>Learning</em>files/Image%20[9].png" title="" /></p>

<p align="center">(<a href='http://www.holehouse.org/' >http://www.holehouse.org/</a>)</p>

<p>그럼 <code>i, j, l</code> 에 대한 <em>cost function</em> 의 <em>partial derivative</em> 는 어떻게 구할까?</p>

<p><strong>back propagation</strong> 을 이용하면 된다. 개요는 이렇다. 마지막 단계에서 신경망을 이용해 얻은 값 <code>a4</code> 와 실제 값인 <code>y</code> 의 차이를 <code>d4</code>(<em>delta</em>) 라 하자. 보면 알겠지만 이건 <em>error</em> 다. 이 에러값을 이용해 <code>d3</code> 즉 레이어 3 에서의 에러값을 구하고, 반복하면서 <code>d2</code> 까지 구한다. (<code>d1</code> 은 없다. <code>a1</code> 이 <em>input</em> 이기때문) </p>

<p><em>forward propagation</em> 과 다르게 뒤에서 앞쪽으로 <em>error</em> 가 전파되기 때문에 <em>back propagation, BP</em> 라 부른다. BP 로 찾은 <code>d</code> 값을 이용하면 <em>partial derivative</em> 를 쉽게 구할 수 있다. <code>d3, d2</code> 를 구하는 방법은 아래와 같다. </p>

<p><img src='http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20' [10].png" alt="http://www.holehouse.org/mlclass/09<em>Neural</em>Networks<em>Learning</em>files/Image%20[10].png" title="" /></p>

<p align="center">(<a href='http://www.holehouse.org/' >http://www.holehouse.org/</a>)</p>

<p>식에 대한 <em>intuition</em> 은 이전 레이어의 유닛의 <code>d</code> 를 얻기 위해서 다음 레이어의 모든 <code>d</code> 와 <code>theta</code> 의 곱을 이용한다는 사실이다. 이건 <em>FP</em> 에서 다음 단계의 유닛 <code>a</code> 를 얻기 위해 이전 단계의 모든 유닛과 <code>theta</code> 를 이용한다는 사실을 거꾸로 생각해보면 이해할 수 있다.</p>

<p>이때 <em>sigmoid function</em> <code>g</code> 의 미분은 <code>g' = g(1-g)</code> 이고, <code>g'(z3)</code> 는 <code>a3 * (1 - a3)</code> 으로 고쳐쓸 수 있다.</p>

<p>만약에 <em>regularization term</em> 을 무시한다면 다시 말해 <code>lambda = 0</code> 이면, <em>partial derivative</em> 는 <code>d</code> 를 이용해 쉽게 작성할 수 있다.  </p>

<p>알고리즘을 좀 자세히 살펴보면 </p>

<p><img src='http://my.csdn.net/uploads/201207/18/1342599882_9006.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>지금까지의 설명과 같이 먼저 <em>FP</em> 를 진행해서 각 레이어의 유닛 <code>a</code> 을 구하고, <em>BP</em> 를 진행한다.</p>

<p>이 때 마지막 단계에서 삼각형(<em>large delta</em>, <code>Delta</code>) 에 이전 단계의 <code>DELTA</code> 와 <code>aj^(l)di(l+1)</code> 를 더하는데, 사실 <code>aj^(l)di(l+1)</code> 가 바로 <em>reulgarization term</em> 을 무시했을 때의 <em>partial derivative</em> 다.</p>

<p>이렇게 모든 <code>DELTA</code> 를 구하고 나서 이제 <code>D</code> 에 <em>regularization term</em> 을 추가한다.</p>

<p><img src='http://my.csdn.net/uploads/201207/19/1342669084_1797.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>이제 <em>regularization term</em> 까지 더한 <code>D</code> 가 바로 <em>partial derivative</em> 다. <del>너무 난해하다</del></p>

<h3 id="backpropagationintuition">Back propagation: Intuition</h3>

<p>조금 더 <em>Back propagation, BP</em> 를 살펴보자. <code>dj^(l-1)</code> 를 얻기 위해 <code>d^(l)</code> 과 <code>theta</code> 를 이용한다는 사실은 알겠다. 근데 <code>g'</code> 이라던지 이런건 도대체 어디서 나온걸까?</p>

<p>처음으로 다시 돌아가면 <em>cost function</em> 에서 <em>training set</em> 이 1개라면 다시 말해 <code>m=1</code> 이고, <code>lambda=0</code> 이라면 <em>cost function</em> 은 <code>h(x), y</code> 에 의해 좌우된다. 결국 <em>squared error</em> 와 다를바 없다는 소리다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/08/1360304035_3064.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>결국 <code>dj^(l)</code> 은 <code>aj^(l)</code> 의 <em>error of cost</em> 다. 더 엄밀히 수학적으로 말하자면 <code>dj^(l)</code> 은 <code>cost(i)</code> 에 대한 <code>zj^(l)</code> 의 <em>partial derivative</em> 다. <code>zj^(l)</code> 이 변할때 <code>i</code> 에 대한 <em>cost</em> 가 얼마나 변하는지가 바로 <code>d</code> 란 이야기다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/08/1360304589_4715.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><code>d</code> 에 대한 더 엄밀한 수학적 증명은 </p>

<p><img src='http://latex.codecogs.com/gif.latex?' \delta_k%20=%20\frac{\partial%20J(\Theta)}{\partial%20z_k}%20=%20\frac{\partial%20J(\Theta)}{\partial%20a_k}\frac{\partial%20a_k}{\partial%20z_k}%20=%20\Theta_{k}\delta_{k+1}\cdot%20g%27(z_k)%20\\%20\Delta%20w_{ij}%20=%20\Delta%20w_{ij}%20+%20\frac{\partial%20J(\Theta)}{\partial%20w_{ij}}%20=%20\Delta%20w_{ij}%20+%20a_j^l%20\cdot%20\delta_k^(l+1)\\%20\frac{\partial%20J(\Theta)}{\partial%20w_{ij}}%20=%20\frac{\partial%20J(\Theta)}{\partial%20z_k}%20\cdot%20\frac{\partial%20z_k}{\partial%20w_{ij}}" alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<h3 id="unrollingparameters">Unrolling Parameters</h3>

<p><em>octave</em> 에서 <code>reshape</code> 함수를 이용해서 벡터를 매트릭스로 변환하는 방법을 알려준다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/08/1360306972_1270.png'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/08/1360307271_1026.png'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p></p>

<h3 id="gradientchecking">Gradient Checking</h3>

<p><em>BP</em> 를 이용해서 <em>neural network</em> 의 <em>cost function</em> 을 위한 <em>partial derivative</em> 를 구하는 방법을 배웠는데, 안타깝게도 이게 쉽게 구현할 수 있는것이 아니라서 버그가 생길 수 있다.</p>

<p><em>gradient checking</em> 이란 방법을 이용하면 <em>FP, BP</em> 의 구현이 완벽함을 보일 수 있다. 배워보자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/08/1360308451_8919.png'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p></p>

<p>말 그대로 기울기에 대한 근사치를 구해서 비교하여 검증하는 방법이다. <code>e</code>(엡실론) 이 매우 작다 하고, <code>0-e</code> 와 <code>0+e</code> 두 점 사이의 기울기를 구해 <em>gradient</em> 와 근사한 값을 구한다.</p>

<p>우리는 <code>0</code> 가 하나가 아니기 때문에, 각각의 <code>0</code>(<code>theta</code>) 에 대해 모두 <em>gradient</em> 의 근사치를 구해야 한다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/08/1360308632_9597.png'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/08/1360308843_4503.png'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p></p>

<p>마지막에서 <em>gradient checking</em> 을 이용해 구한 <code>gradApprox</code> 와 실제 <em>BP 를 이용해 구한 *graident</em> 인 <code>Dvec</code> 과 비슷한지 검사한다.</p>

<p>그러나, 한가지 알아야할 사실이 있다. <em>gradient checking</em> 은 굉장히 비싸기 때문에 <code>Dvec</code> 과 비슷한 값을 구했는지 검사한 후에는 <em>gradient checking</em> 를 꺼야한다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/08/1360310625_8308.png'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p></p>

<h3 id="randominitialization">Random Initialization</h3>

<p><em>gradient desecnt</em> 를 위한 함수를 사용할때 <code>initialTheta</code> 를 줘야한다. 그냥 <code>zeros</code> 로 만들까? <em>neural network</em> 에서 모든 <code>theta</code> 가 <code>0</code> 으로 시작하면 모든 유닛의 값이 같아진다. 오류(<code>d</code>) 도 같고, <em>partial derivative</em> 의 값도 같으므로  다음 이터레이션에서도 같은 유닛은 같은 값을 가지고 이게 반복된다. </p>

<p>결국 내가 가진 모든 히든 유닛이 같은 계산을 해 내고 있으므로, 하나의 <em>feature</em> 에 대한 극도로 중복된 연산을 볼 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/08/1360312970_4725.png'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p></p>

<p><code>theta</code> 가 대칭이기 때문에 발생하는 문제인데 <em>symmetry breaking</em> 을 위해 <code>[-e, e]</code> 사이의 <code>theta</code> 를 랜덤으로 골라보자. 물론 이 <code>e</code> 는 <em>gradient checking</em> 에서의 <code>e</code> 와 관련이 없다.</p>

<p><img src='http://my.csdn.net/uploads/201207/20/1342765672_2379.jpg'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p></p>

<h3 id="puttingittoghther">Putting It Toghther</h3>

<p>(1) <em>neural network</em> 를 훈련시킬 때 먼저 해야 할 일은 아키텍쳐를 고르는 일이다. </p>

<p><em>output unit</em> 과 <em>input unit</em> 은 <em>class</em> 와 <em>feature</em> 수로 결정된다. 문제는 <em>hidden unit</em> 과 <em>hidden layer</em> 의 수다.</p>

<p>기본적으로는 1개의 히든 레이어를 사용하거나, 1개 이상을 사용한다면 같은 수의 히든 유닛을 모든 히든 레이어에서 사용하는것이 대부분 계산 비용 면에서 낫다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360373142_6515.png'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p></p>

<p>(2) <em>weights</em> 를 랜덤하게 초기화 한다. <br />
(3) <em>forward propagation</em> <br />
(4) <em>cost function</em> 을 구한다. <br />
(5)  <em>partial derivatives</em> 구하기 위해 <em>back propagation</em>  </p>

<p><em>BP</em> 를 할때는 <em>traning set</em> 의 수 <code>m</code> 번 만큼 루프를 돌면서 각 <code>(xi, yi)</code> 를 이용해 <em>FP</em>, <em>BP</em> 를 한다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360373729_4414.png'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p></p>

<p>(6) <em>gradient checking</em> 을 이용해 얻은 근사치와 <em>partial derivatives</em> 를 비교한다. 값이 적당히 비슷하면 <em>gradient checking</em> 코드를 제거한다. <br />
(7) <em>cost function</em> 을 최소화 하기 위해 <em>gradient descent</em> 나 <em>advanced optimization method</em> 를 사용한다.</p>

<p>한 가지 알아야 할 사실은 <em>neural network</em> 의 <em>cost function</em> 은 <em>non-convex</em> 이기 때문에 <em>local optimum</em> 에서 멈출 수 있다. </p>

<p>그런덷 문제가 굉장히 크다면 <em>gradient descent</em> 로 찾은 <em>local optimum</em> 도 충분히 좋은 값이라고 한다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360374039_7863.png'  alt="" title="" /><p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p></p>

<p>처음에 1장에서 봤던 언덕 그림이다.</p>

<p><img src='http://cfile28.uf.tistory.com/image/2401353E52D618322EDFB5'  alt="" title="" /><p align="center">(<a href='http://mapository.tistory.com/59' >http://mapository.tistory.com/59</a>)</p></p>

<p>여기서 <em>gradient descent</em> 가 하는 일은 언덕을 내려가는거고, <em>back propagation</em> 이 하는 일은 방향을 잡아주는 일이다.(<code>z</code> 가 변했을 때 <em>cost function</em> 값이 변하는 양인 오차 <code>d</code> 의 값이 적어지도록 방향을 잡아줌)</p>

<p>그래서 신경망에서 <em>gradient descent</em> 를 사용한다 하더라도 적당히 좋은 로컬 옵티멈을 찾아준다는 훈훈한 이야기</p>

<h3 id="autonomousdriving">Autonomous Driving</h3>

<p>무인 운전을 신경망으로 어떻게 해결하는지를 보여준다. 미리 사람이 한번 운전한 경로(<code>y</code>) 를 바탕으로 학습하는데, 생각도 못해본 분야들에 이미  이런 기술들이 적용되어 있구나 싶다. <del>무려 1992년에 했던 실험이다</del></p>

<h3 id="references">References</h3>

<p>(1) <a href='http://aimotion.blogspot.kr/' >http://aimotion.blogspot.kr/</a> <br />
(2) <a href='http://www.holehouse.org/mlclass/09_Neural_Networks_Learning.html' >http://www.holehouse.org/mlclass/</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer/article/details/7758797' >http://blog.csdn.net/abcjennifer/</a> <br />
(4) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>  </p>]]></description><link>http://1ambda.github.io/machine-learning-week-5/</link><guid isPermaLink="false">b96b67f2-7881-4413-ac1c-b11177f200d2</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine lerning]]></category><category><![CDATA[neural network]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 06 Nov 2014 10:10:59 GMT</pubDate></item><item><title><![CDATA[Functional Programming in Scala, Chapter 7]]></title><description><![CDATA[<p>7주차에 걸친 대장정의 마지막이다. 이번시간에는 <em>stream</em>, <em>lazy evaluation</em> 에 대해 배우고 이걸 이용해 길이가 무한인 컬렉션을 만들어 보기도 하고 계산을 늦추는 것을 다양한 예제에 적용해 본다.</p>

<h3 id="structuralinductionontrees">Structural Induction on Trees</h3>

<p>지난번엔 함수가 올바르게 동작함을 증명하기 위해 <em>induction</em> 을 사용했었는데 이번시간엔 <em>tree</em> 에 대해 <em>induction</em> 을 사용한다.</p>

<p>모든 트리 <code>t</code> 에 대해서 속성 <code>P(t)</code> 가 참임을 증명하려면 </p>

<p>(1) 먼저 트리의 모든 <em>leave</em> 에 대해 <code>P(1)</code> 임을 보인다. <br />
(2) 서브트리 <code>s1, ..., s</code> 을 가진 <em>internal node</em> 에 대해 <code>P(s1) ^ ... ^ P(sn)</code> 임을 보인다.</p>

<p>이제 몇 주 전에 만들었던 <code>IntSet</code> 을 증명해 보자.</p>

<pre><code class="scala">  abstract class IntSet {
    def incl(x: Int): IntSet
    def contains(x: Int): Boolean
  }

  object Empty extends IntSet {
    def contains(x: Int): Boolean = false
    def incl(x: Int): IntSet = NonEmpty(x, Empty, Empty)
  }

  case class NonEmpty(elem: Int, left: IntSet, right: IntSet) extends IntSet {
    def contains(x: Int): Boolean =
      if (x &lt; elem) left contains x
      else if (x &gt; elem) right contains x
      else true

    def incl(x: Int): IntSet =
      if (x &lt; elem) NonEmpty(elem, left incl x, right)
      else if (x &gt; elem) NonEmpty(elem, left, right incl x)
      else this
  }
</code></pre>

<p>구현에 대한 증명을 한다는건 구현이 포함하는 <em>law</em> 를 증명한다는 것을 의미한다. 예를들면</p>

<pre><code class="scala">Empty contains x == false  
(s incl x) contains x == true
(s incl x) contains y == s contains y (if x != y)
</code></pre>

<p><code>(s incl x) contains x == true</code> 부터 증명하자. <del>쉬우니까</del></p>

<p>(1) <em>base case (<code>P(1)</code>)</em> 은 <code>Empty</code> 를 <code>s</code> 에 집어넣으면 된다.   </p>

<p><code>NonEmpty(x, Empty, Empty) contains x</code> 이므로 <code>true</code> 다.</p>

<p>(2) <em>induction step: <code>s</code> 가 <code>NonEmpty(z, l, r)</code></em> 에 대해서 증명하자.</p>

<p><code>NonEmpty(z, l, r) incl x contains x</code> 인데, <code>z == x</code>, <code>z &lt; x</code>, <code>z &gt; x</code> 인 3 가지 경우로 나눠서 참임을 보이면 된다. 뒤의 두개는 같은 증명이며 각각의 마지막 단계에서 <em>induction hypothesis</em> 를 사용하면 된다.</p>

<pre><code class="scala">(NonEmpty(z, l, r) incl x) contians x // z &lt; x
(NonEmpty(z, l, r incl x) contains x
(r incl x) contians x // by def of NonEmpty.contains
true // by induction hypothesis  
</code></pre>

<p><code>(xs incl y) contains x == xs contians x</code>, <code>(if x != y)</code> 를 증명해 보자.</p>

<p>마찬가지로 <em>base case</em> 는 <code>Empty</code> 를 이용하면 된다. <code>y &lt; x</code>, <code>y &gt; x</code> 인 두 가지 경우로 나누어 참임을 보이자.</p>

<p>다음으로 <em>inductive step</em> 인데, <code>xs</code> 가 <code>NonEmpty(z, l, r)</code> 일때다. 아래의 5가지 경우를 고려해야 한다. </p>

<pre><code class="scala">z = x  
z = y  
z &lt; y &lt; x  
y &lt; z &lt; x  
y &lt; x &lt; z  
</code></pre>

<p>마찬가지로 <code>z = x, z = y</code> 도 <code>y &lt; x, y &gt; x</code> 로 나누어 풀자. 나머지 증명은</p>

<pre><code class="scala">// z &lt; y &lt; x, to show NonEmpty(z, l, r) contains x
NonEmpty(z, l, r incl y) contains x  
(r incl y) contains x
r contains x  // by induction hypothesis  
NonEmpty(z, l, r) contains x // by def of NonEmpty.contains

// y &lt; z &lt; x
NonEmpty(z, l incl y, r) contains x  
r contains x  
NonEmpty(z, l, r) contains x // by def of NonEmpty.contains

// y &lt; x &lt; z
(NonEmpty(z, l, r) incl y) contains x
NonEmpty(z, l incl y, r) contains x  
(l incl y) contains x
l contains x // by induction hypothesis  
NonEmpty(z, l, r) contains x  
</code></pre>

<p>조금 더 어려운 증명으로 <code>union</code> 이 참임을 보일 수 있다.</p>

<pre><code class="scala">(xs union ys) contains x = xs contains x || ys contains x
</code></pre>

<p>마찬가지로 <code>xs</code> 에 대해 <em>structural induction</em> 을 이용하면 된다.</p>

<h3 id="streams">Streams</h3>

<p>1000 부터 10000 사이에 있는 소수 중 두번 째 것을 찾는다 하자.</p>

<pre><code class="scala">((1000 to 10000) filter isPrime)(1)
</code></pre>

<p>짧고 엘레강스 하지만 문제가 하나 있다. 1000 부터 10000 까지의 소수를 모두 찾은 뒤 2번째 원소에 접근하므로 성능 문제가 생긴다. 필요없는 나머지 소수도 같이 찾아버리는 것이다.</p>

<p>그래서 스칼라에서는 <em>stream</em> 을 지원한다.</p>

<blockquote>
  <p>Avoid computing the tail of a sequence until it is needed for the evaluation result which might be never</p>
</blockquote>

<p>다시 말해서 <em>sequence</em> 에서 각 부분이 <em>evaluation (평가)</em> 되기 전까지 계산을 미루는 클래스를 스칼라에서는 <em>stream</em> 이란 이름으로 만들어 놨다.</p>

<p>스트림은 리스트와 유사하지만 <em>tail</em> 부분이 <em>on-demand</em> 로 <em>evaluation</em> 된다.</p>

<pre><code class="scala">&gt; Stream(1, 2, 3)
scala.collection.immutable.Stream[Int] = Stream(1, ?)

&gt; Stream.empty
res1: scala.collection.immutable.Stream[Nothing] = Stream()

&gt; (1 to 1000).toStream
scala.collection.immutable.Stream[Int] = Stream(1, ?)

&gt; val xs = Stream(1, Stream.cons(2,  Stream.empty))
xs: scala.collection.immutable.Stream[Any] = Stream(1, ?)  
</code></pre>

<p>보면 알겠지만 진짜로 <em>tail</em> 부분이 <code>?</code> 로 되어있다.</p>

<pre><code class="scala">  def streamRange(l: Int, h: Int): Stream[Int] = {
    if (l &gt;= h) Stream.empty 
    else Stream.cons(l, streamRange(l + 1, h))
  }

  def listRange(l:Int, h: Int): List[Int] = {
    if (l &gt;= h) Nil
    else l :: listRange(l + 1, h)
  }
</code></pre>

<p>스트림을 만드는 <code>streamRange</code> 와 리스트를 만드는 <code>listRange</code> 를 보면 하는 생긴건 비슷하지만 실제로는 완전히 다른 일을 한다.</p>

<p><code>listRange</code> 는 마지막 원소가 <code>Nil</code> 인 리스트를 만들지만 <code>streamRange</code> 는 두번 째 원소가 <code>?</code> 인 스트림을 만든다. </p>

<p>다시 처음의 예제로 돌아와서 </p>

<pre><code class="scala">((1000 to 10000).toStream filter isPrime)(1)
</code></pre>

<p><em>stream</em> 은 리스트와 관련된 메소드를 모두 사용할 수 있다. 하나만 빼고, 바로 <code>cons ::</code> 다.<code>Stream.cons</code> 는 <code>#::</code> 다.</p>

<p>마찬가지로 <code>#::</code> 도 패턴으로 사용할 수 있다.</p>

<p>스트림의 구현은 대부분 리스트와 비슷한데, <code>empty</code> 가 좀 다르다.  <code>Stream.empty</code> 처럼 스트림 내부에 정의되어있다.</p>

<p>그리고 가장 중요한 차이점은 <code>Stream.cons</code> 의 파라미터다.</p>

<pre><code class="scala">object Stream {  
  def cons[T](hd: T, tl: =&gt; Stream[T]) = new Stream[T] {
    def isEmpty = false
    def head = hd
    def tail = tl
  }
}
</code></pre>

<p><code>tl: =&gt; Stream[T]</code> 를 보면 알 수 있듯이 <code>tl</code> 은 <em>call-by-name</em> 이다. 따라서 바로 평가되지 않으며 사용하는 시점에 평가된다.</p>

<p>이제 <code>filter</code> 의 구현을 좀 보자.</p>

<pre><code class="scala">def filter(p: T =&gt; Boolean): Stream[T] =  
  if (isEmpty) this
  else if (p(head)) cons(head, tail.filter(p))
  else tail.filter(p)
}
</code></pre>

<p>여기서 중요한 부분이 <code>cons(head, tail.filter(p))</code> 다. 스트림의 <code>cons</code> 의 두번째 인자로 <code>tail.filter(p)</code> 를 넘겨주기 때문에 이 식의 평가는 나중에 호출될 때 이루어진다. 다시 말해 지금 당장은 <code>head</code> 만 <em>predicate <code>p</code></em> 가 적용된다는 뜻이다.</p>

<p>따라서 <code>streamRange</code> 를 이렇게 수정하면 어떤 값이 출력될까?</p>

<pre><code class="scala">  def streamRange(l: Int, h: Int): Stream[Int] = {
    println("l: " + l)
    if (l &gt;= h) Stream.empty 
    else Stream.cons(l, streamRange(l + 1, h))
  }

streamRange(1, 10).take(3).toList  
</code></pre>

<p>답은 <code>1 2 3</code> 이다. <code>take(3)</code> 가 아니라 <code>toList</code> 때문에 그렇다. <code>take(3)</code> 는 여전히 <em>stream</em> 이다. 따라서 첫 번째 원소인 <code>1</code> 만 평가된 상태이며 리스트로 바꾸는 순간 <code>1, 2, 3</code> 이 모두 평가되어야 하므로 그때 출력된다.</p>

<h3 id="lazyevaluation">Lazy Evaluation</h3>

<p>이제 까지 본 <em>stream</em> 구현은 필요 없는 <code>tail</code> 부분을 계산하지 않게 해 주었지만 심각한 결함이 있다. <code>tail</code> 이 여러번 호출된다면 어떻게 될까? 매번 다시 계산되야 한다.</p>

<p>그래서 첫 번째 <code>tail</code> 을 계산할 때 결과를 저장해 놓고, 그 다음부터는 재활용 하는 방법으로 이 문제를 해결해 보자. </p>

<p>사실 이건 함수형 프로그래밍에서 함수는 매번 같은 결과를 반환한다는 원칙에도 부합한다.</p>

<p>이걸 <em>lazy evaluation</em> 이라 부른다. 우리가 이제 까지 보아왔던 것은 <em>by-name evaluation</em> 이다. 필요할 때 평가하긴 하지만 매번 다시 계산해야하기 때문에 성능이 떨어진다. 그리고 <em>strict evaluation</em> 은 바로 평가되는 일반 <code>val</code> 변수라 보면 된다.</p>

<p>하스켈은 <em>lazy evaluation</em> 이 디폴트지만 스칼라는 <em>strict evaluation</em> 이 기본이다.</p>

<pre><code class="scala">lazy val x = expr  
def x expr  
</code></pre>

<p>다음 두 식의 차이는 무엇일까? 둘 다 <em>on-demand</em> 로 평가되지만 <code>def</code> 는 매번 다시 계산되고 <code>lazy val</code> 은 처음의 계산을 재활용한다.</p>

<p>그런 이유로 다음의 코드를 실행시키면</p>

<pre><code class="scala">  def expr = {
    val x = { println("x"); 1 }
    lazy val y = { println("y"); 2 }
    def z = { println("z"); 3 }
    z + y + x + z + y + x
  }

  expr
  // x
  // z
  // y
  // z
</code></pre>

<p><code>xzyz</code> 가 출력된다.</p>

<p>이제 <em>lazy evaluation</em> 을 <em>stream</em> 구현에 적용하자</p>

<pre><code class="scala">object Stream {  
  def cons[T](hd: T, tl: =&gt; Stream[T]) = new Stream[T] {
    def isEmpty = false
    def head = hd
    lazy val tail = tl
  }
}
</code></pre>

<p>근데 이렇게 작성한 코드가 실제로 <em>on-demand</em> 로 평가되는지 어떻게 알까? <em>substitution model</em> 에 적용해보자.</p>

<pre><code class="scala">(streamRange(1000, 10000) filter isPrime) apply 1

// will be expanded 

cons(1000, streamRange(1000 + 1, 10000)).filter(isPrime).apply(1)  
</code></pre>

<p>이제 <code>cons(1000, streamRange(1000 + 1, 10000))</code> 를 <code>C1</code> 이라 하자. </p>

<pre><code class="scala">C1.filter(isPrime).apply(1)

// same as
(if (isPrirme(C1.head)) 
  cons(C1.head, C1.tail.filter(isPrime))
else C1.tail.filter(isPrime))  
apply(1)  
</code></pre>

<p>이 때 <code>C1.head == 1000</code> 이므로 소수가 아니다. 따라서 이 식은</p>

<pre><code class="scala">C1.tail.filter(isPrime).apply(1)

// same as
streamRange(1001, 10000).filter(isPrime).apply(1)  
</code></pre>

<p>이렇게 첫 번째 소수를 찾을 때 까지 반복된다. <code>cons(1009, streamRange(1009 + 1, 10000)</code> 을 <code>C2</code> 라 부르면 </p>

<pre><code class="scala">C2.filter(isPrime).apply(1)

// same as
cons(1009, C2.tail.filter(isPrime)).apply(1)  
</code></pre>

<p>이 된다 스트림의 <code>apply</code> 가 다음과 같이 구현되어 있다고 하자.</p>

<pre><code class="scala">def apply(n: Int): T =  
  if (n == 0) head
  else tail.apply(n - 1)
</code></pre>

<p>그럼 위 식은 이렇게 확장된다.</p>

<pre><code class="scala">cons(1009, C2.tail.filter(isPrime)).tail.apply(0)


// same as
C2.tail.filter(isPrime).apply(0)

// same as
streamRange(1010, 10000)).filter(isPrime).apply(0)  
</code></pre>

<p>마찬가지로 다음 번 소수 <code>1013</code> 을 찾을 때 까지 <code>streamRange.tail</code> 와 <code>filter</code> 가 반복되며 식이 확장된다.</p>

<pre><code class="scala">cons(1013, streamRange(1013 + 1, 10000)).filter(isPrime).apply(0)  
</code></pre>

<p>여기서 <code>cons(1013, streamRange(1013 + 1, 10000))</code> 를 <code>C3</code> 라 하자.</p>

<pre><code class="scala">C3.filter(isPrime).apply(0)

// same as
cons(1013, C3.tail.filter(isPrime)).apply(0)  
</code></pre>

<p>따라서 <code>1013</code> 이 나온다. 결국 모든 과정에서 <em>stream</em> 의 <code>cons</code> 내부의 <code>tail</code> 은 <code>apply</code> 나 <code>filter</code> 이후에 호출됨을 알 수 있다.</p>

<h3 id="computingwithinfinitesequences">Computing with Infinite Sequences</h3>

<p>스트림에서 <em>tail</em> 이 필요할 때만 평가되기 때문에 <em>infinite stream</em> 을 만드는 것도 가능하다!</p>

<pre><code class="scala">def from(n: Int): Stream[Int] = n #:: from(n + 1)


val nats = from(0) // natural number  
val m4s = nats map (_ * 4)

(m4s take 3).toList // List(0, 4, 8)
</code></pre>

<p>이제 무한한 길이의 스트림을 만드는 방법을 배웠으니 이걸 이용해 우주에 존재하는 모든 소수를 포함하는 스트림을 만들어보자.</p>

<p>고대의 소수 계산 방법인 <em>The Sieve of Eratosthenes</em> 를 이용한다. 2 부터 시작해서 하나씩 숫자를 증가 시키며 해당 숫자의 배수를 모두 제거하는 방식으로 소수를 찾는다. <del>무려 몇천년 뒤의 컴퓨터 기술을 고려하고  알고리즘을 구현한 갓 고대인들</del></p>

<pre><code class="scala">def sieve(s: Stream[Int]): Stream[Int] =  
  s.head #:: sieve(s.tail filter (_ % s.head != 0))

val primes = sieve(from(2))  
primes.take(4).toList  
// List(2, 3, 5, 7)
</code></pre>

<p>다른 곳에도 좀 활용 해보자. 오래전에 <a href='http://1ambda.github.io/functional-programming-in-scala-chapter-1/' >1강</a> 에서 <em>뉴튼-랩슨</em> 법으로 제곱근을 구하는 함수를 작성한 적이 있었다. 그 때 제곱근의 값이 한 재귀 호출마다 특정 값 미만으로 변하는지 검사하는 <code>isGoodEnough</code> 함수를 작성했었고 이를 이용해서 제곱근 구하는 함수가 무한 재귀에 빠지지 않도록 했었다.</p>

<p><em>lazy evaluation</em> 을 이용하면 계산을 미룰 수 있기 때문에 무한 재귀에 빠지는걸 막을 수 있다.</p>

<pre><code class="scala">  def sqrtStream(x: Double): Stream[Double] = {
    def improve(guess: Double) = (guess + x / guess) / 2
    lazy val guesses: Stream[Double] = 1 #:: (guesses map improve)
    guesses
  }

  sqrt(4).take(10).toList  
</code></pre>

<p>참고로 원리가 알고싶다면 <a href='https://www.google.co.kr/search?q=y+%3D+1%2Fx&amp;oq=y+%3D+1%2Fx&amp;aqs=chrome..69i57j69i65l2j69i64l2.3051j0j1&amp;sourceid=chrome&amp;es_sm=122&amp;ie=UTF-8' #newwindow=1&amp;q=y+%3D+(4%2Fx+%2B+x)+%2F+2">여기</a> 그래프를 한번 보라.</p>

<p>물론 <code>sqrtStream</code> 은 <em>stream</em> 을 리턴하므로 좀 더 세밀한 값을 얻기 위해 <code>isGoodEnough</code> 를 활용할 수도 있다.</p>

<pre><code class="scala">def isGoodEnough(x: Double, guess: Double) =  
  math.abs((guess * guess - x ) / x) &lt; 0.0001

sqrtStream(4).filter(isGoodEnough(_, 4)).take(10).toList  
</code></pre>

<p>그럼 이제 무한한 길이를 가진 컬렉션을 <code>map</code> 과 <code>filter</code> 두 가지 방법으로 구현할 수 있다는 사실을 알게 되었을 텐데, 어느게 더 빠를까?</p>

<pre><code class="scala">val xs = from(1) map (_ * N)  
val ys = from(1) filter (_ % N == 0)  
</code></pre>

<p>당연히 <code>map</code> 이 더 빠르다. 필터는 원소를 돌면서 필터링 하는거고, 맵은 바로 곱해서 값을 구한다. </p>

<h3 id="thewaterpouringproblem">The Water Pouring Problem</h3>

<p>기본적인 아이디어는 물컵에 대한 액션(<code>Move</code>)을 <code>Empty, Fill, Pour</code> 로, 액션을 수행할 상태를 <code>type State = Vector[Int]</code> 모델링한다.</p>

<p>최초 상태 <code>initialState</code> 에 대해 가능한 모든 종류의 <code>Move</code> 를 미리 <code>moves</code> 에 만들어 놓고 (쉽게 만들 수 있다) 한번 씩 수행해 가면서 답이 있는지 검사한다. </p>

<p>이 과정에서 만들어지는 <code>List[Move]</code> 를 <code>Path</code> 라 볼 수 있다. 쉽게 연산하기 위해(리스트의 컨싱을 이용) <code>Path</code> 의 <code>head</code> 가 제일 마지막 <code>Move</code> 라 하자. </p>

<p>이러면 하나의 <code>Path</code> 는 우리가 가진 <code>initialState</code> 에 대해 <code>List[Move]</code> 를 적용해 마지막 상태를 알 수 있다. 이 것을 <code>endState</code> 함수로 구현한다. 이 때 마지막 <code>Move</code> 가 먼저 적용되야 하므로 <code>foldRight</code> 를 이용하면 <em>one-liner</em> 로 구현할 수 있다.</p>

<p><code>Path</code> 가 가진 <code>List[Move]</code> 에 새로운 <code>Move</code> 를 컨싱으로 연결하는 <code>extend</code> 메소드를 만들고, 우리가 풀어야 할 문제의 답은 하나의 <code>Path</code> 이므로 출력을 위해 <code>toString</code> 도 오버라이드 하자.  </p>

<p>하나의 <code>Path</code> 에서 <code>moves</code> 를 적용하면 다수의 <code>Path</code> 가 나온다. 이걸 <code>Paths: Set[Path]</code> 라 부르면 한 단계 한 단계 액션을 적용할 때마다 <code>Set[Path]</code> 가 생기는것이다. </p>

<p>그런데, 재귀를 이용해 구현한다 해도 무한정 계산할 수 없으므로 스트림을 이용해 다음단계의 계산은 필요할때로 미룰 수 있다. <code>Set[Path]</code> 를 받아 <code>Stream[Set[Path]]</code> 를 돌려주는 <code>from</code> 함수를 만들자.</p>

<pre><code class="scala">class Pouring(capacity: Vector[Int]) {

  // State
  type State = Vector[Int]
  val initialState = capacity map { _ =&gt; 0 }

  // Move
  trait Move {
    def change(s: State): State
  }
  case class Empty(glass: Int) extends Move {
    def change(s: State) = s updated(glass, 0)
  }
  case class Fill(glass: Int) extends Move {
    def change(s: State) = s updated(glass, capacity(glass))
  }
  case class Pour(from: Int, to: Int) extends Move {
    def change(s: State) = {
      val amount = s(from) min (capacity(to) - s(to))
      s updated (from, s(from) - amount) updated (to, s(to) + amount)
    }
  }

  val glasses = 0 until capacity.length

  val moves =
    (for (glass &lt;- glasses) yield Empty(glass)) ++
    (for (glass &lt;- glasses) yield Fill(glass)) ++
    (for (from &lt;- glasses; to &lt;- glasses if from != to) yield Pour(from, to))

  // Path

  class Path(history: List[Move]) {
    def endState: State = (history foldRight initialState)(_ change _)
    def extend(move: Move): Path = new Path(move :: history)
    override def toString = "\n" + (history.reverse mkString " ") + "--&gt;" + endState
  }

  val initialPath = new Path(Nil)

  def from(paths: Set[Path]): Stream[Set[Path]] = {
    if (paths.isEmpty) Stream.empty
    else {
      val more = for {
        path &lt;- paths
        next &lt;- moves map path.extend
      } yield next

      paths #:: from(more)
    }
  }

  val pathSets = from(Set(initialPath))

  def solutions(target: Int): Stream[Path] = {
    for {
      pathSet &lt;- pathSets
      path &lt;- pathSet
      if path.endState contains target
    } yield path
  }
}
</code></pre>

<p>그런데, 실제로 코드를 돌려보면 상당히 느리다.</p>

<pre><code class="scala">val problem = new Pouring(Vector(4, 7, 8))  
println(problem.solutions(6))  
</code></pre>

<p>이는 <code>from</code> 함수에서 <code>path</code> 를 <code>extend</code> 할 때 기존에 있던 <code>path</code>  도 포함하기 때문이다. 따라서 각 <code>path</code> 에서 <code>endState</code> 를 담은 <code>explored</code> 를 인자에 넘겨주고, 다시 넘겨 받으면</p>

<pre><code class="scala">  def from(paths: Set[Path], explored: Set[State]): Stream[Set[Path]] = {
    if (paths.isEmpty) Stream.empty
    else {
      val more = for {
        path &lt;- paths
        next &lt;- moves map path.extend
      } yield next

      paths #:: from(more, explored ++ (more map (_.endState)))
    }
  }

  val pathSets = from(Set(initialPath), Set(initialState))
</code></pre>

<p>그리고 <code>endState</code> 도 재귀함수로서 자주 호출되는데 매번 다시 계산되야 하므로 변수로 저장하면</p>

<pre><code class="scala">  class Path(history: List[Move], val endState: State) {
    def extend(move: Move): Path = new Path(move :: history, move change endState)
    override def toString = "\n" + (history.reverse mkString " ") + "--&gt;" + endState
  }

  val initialPath = new Path(Nil, initialState)
</code></pre>

<p><del>내 경우는 옵티마이징 한 결과가 더 느렸다;;</del></p>

<p>여기서 중요한 아이디어 두개를 짚어보면</p>

<p>(1) <code>List[Move]</code> 에서 앞쪽 <code>Move</code> 가 더 나중에 적용되는 것을 통해 매 <code>extend</code> 마다 전체 리스트를 순회할 필요가 없도록 하고 계산은 <code>foldRight</code> 를 이용해 쉽게 구현 <br />
(2) 무한한 재귀를 <em>stream</em> 을 이용해 계산을 미룬 <code>solution</code> 이나 <code>from</code> 함수. </p>

<p>특히 <code>solution</code> 은 <code>Stream[Path]</code> 를 리턴하도록 하여 첫번째 답까지 찾는 계산만 수행하는데, 이는 스트림에 <code>for-loop</code> 을 돌려도 스트림을 돌려준다는 사실을 알려준다. (<em>filter</em> 와 같다고 생각하면 편하다.*)</p>

<pre><code class="scala">def ex =  
  for(i &lt;- (1 to 10).toStream if i % 2 == 0)

ex.take(3).toList // List(2, 4, 6)  
</code></pre>

<h3 id="coursesummary">Course Summary</h3>

<p>이제 까지 우리가 다뤄 온 것들은</p>

<ul>
<li>higher-order functions</li>
<li>case classes and pattern matching</li>
<li>immutable collections</li>
<li>absence of mutable state</li>
<li>flexible evaluation strategies: <em>strict / lazy / by-name</em></li>
</ul>

<p>앞으로 다룰 것들은 (아마 <em>reactive programming</em> 에서)</p>

<ul>
<li><p><strong>functional programming and state</strong> <br />
<em>what does it mean to have mutable state?</em> <br />
<em>what changes if we add it?</em>  </p></li>
<li><p><strong>parallelism</strong> <br />
<em>how to exploit immutablility for parallel execution</em>  </p></li>
<li><p><strong>DSL</strong> <br />
<em>high-level libraries as embedded DSLs</em> <br />
<em>interpretation techniques for external DSLs</em></p></li>
</ul>

<h3 id="references">References</h3>

<p>2014-11-04, <strong>Functional Programming in Scala</strong>, Coursera</p>]]></description><link>http://1ambda.github.io/functional-programming-in-scala-chapter-7/</link><guid isPermaLink="false">2074b056-743c-46be-b701-5cda683aa29e</guid><category><![CDATA[scala]]></category><category><![CDATA[coursera]]></category><category><![CDATA[functional programming]]></category><category><![CDATA[lazy evaluation]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 05 Nov 2014 11:52:10 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 2]]></title><description><![CDATA[<p>이번시간엔 <em>list comprehension</em> 을 배웁니다. 수학에서는 집합의 원소를 이용해 새로운 집합을 만들 때 사용하는데요,</p>

<blockquote>
  <p>In mathematics, the <em>comprehension</em> notion can be used to construct new sets from old sets.</p>
</blockquote>

<p>비슷하게 하스켈에선 컬렉션에다 사용 할 수 있죠.</p>

<blockquote>
  <p>In Haskell, a similar comprehension notion can be used to construct new lists from old lists</p>
</blockquote>

<pre><code class="haskell">[x^2 | x &lt;- [1..3]] -- [1, 4, 9]
</code></pre>

<p>여기서 <code>x &lt;- [1..5]</code> 같은 <em>expression</em> 을 <strong>generator</strong> 라 부릅니다. <em>comprehension</em> 은 한 개 이상의 <em>generator</em> 를 가질 수 있습니다.</p>

<pre><code class="haskell">[(x, y) | x &lt;- [1..3], y &lt;- [4..5]]
-- [(1,4),(1,5),(2,4),(2,5),(3,4),(3,5)]
</code></pre>

<p><em>generator</em> 의 순서를 바꿈으로써 생성되는 원소들의 순서도 바꿀 수 있습니다.</p>

<pre><code class="haskell">[(x, y) | y &lt;- [4..5], x &lt;- [1..3]]
-- [(1,4),(2,4),(3,4),(1,5),(2,5),(3,5)]
</code></pre>

<p>보면 알겠지만 <em>multiple generators</em> 는 <em>nested loop</em> 와 비슷합니다. 뒤에 오는 <em>generator</em> 가 <em>inner-loop</em> 처럼 동작하죠.</p>

<p>그럼 <code>j = i + 1</code> 과 같은 변수도 <em>generator</em> 로 표현 가능할까요? 그럼요!</p>

<pre><code class="haskell">[(x, y) | x &lt;- [1..3], y &lt;- [x + 1]]
-- [(1,2),(2,3),(3,4)]
</code></pre>

<p>앞에 오는 <em>generator</em> 의 변수를 뒤에 오는 <em>generator</em> 에서 사용 할 수 있습니다. <em>dependant generator</em> 라 부릅니다.</p>

<p>이제 <em>dependant generator</em> 를 이용해서 <code>concat</code> 함수를 만들어 봅시다.</p>

<pre><code class="haskell">concat :: [[a]] -&gt; [a]  
concat xss = [x | xs &lt;- xss, x &lt;- xs]

concat [[1, 2, 3], [4, 5], [6]]  
-- [1,2,3,4,5,6]
</code></pre>

<h3 id="guards">Guards</h3>

<p><em>generator</em> 에서 변수를 걸러내기 위해 <em>guards</em> 를 사용할 수 있습니다.</p>

<pre><code class="haskell">[x | x &lt;- [1..10], even x]
-- [2, 4, 6, 8, 10]
</code></pre>

<p>약수를 골라내는 <code>factors</code> 함수도 만들어 볼 수 있겠죠? 그리고 소수를 판별하는 <code>prime</code> 도 같이 작성합시다.</p>

<pre><code class="haskell">factors :: Int -&gt; [Int]  
factors n = [x | x &lt;- [1..n], n `mod` x == 0]

factors 17 -- [1,17]  
factors 15 -- [1,3,5,15]

prime :: Int -&gt; Bool  
prime n = factors n == [1, n]  
</code></pre>

<p>소수를 찾아주는 <code>primes</code> 도 만들어볼까요?</p>

<pre><code class="haskell">primes :: Int -&gt; [Int]  
primes n = [x | x &lt;- [2..n], prime x]

primes 40  
-- [2,3,5,7,11,13,17,19,23,29,31,37]
</code></pre>

<h3 id="zip">zip</h3>

<p><code>zip</code> 함수는 두 개의 리스트를 받아 하나의 리스트를 만듭니다. </p>

<pre><code class="haskell">-- zip :: [a] -&gt; [b] -&gt; [(a, b)]

zip [1, 2, 3]  ['a', 'b', 'c', 'd']  
[(1,'a'),(2,'b'),(3,'c')]
</code></pre>

<p><code>pairs</code> 와 같은 함수도 만들어 볼 수 있겠죠?</p>

<pre><code class="haskell">pairs :: [a] -&gt; [(a, a)]  
pairs xs = zip xs (tail xs)

pairs [1, 2, 3, 4]  
-- [(1,2),(2,3),(3,4)]
</code></pre>

<p><code>pairs</code> 함수를 이용하면 하나의 리스트에 있는 한 원소와 그 다음 원소의 <em>pair</em> 를 구할 수 있으므로 리스트가 정렬되었는지를 검사하는 <code>sorted</code> 함수에 사용할 수 있습니다.</p>

<pre><code class="haskell">sorted :: Ord a =&gt; [a] -&gt; Bool  
sorted =  
  and [x &lt;= y | (x, y) &lt;- paris xs]

sorted [1, 2, 3, 4] --True  
sorted [1, 2, 5, 3, 4] --False  
</code></pre>

<p>하스켈 리스트은 배열과는 달라서 인덱스가 없습니다. 리스트에서 주어진 값과 같은 값을 가지는 원소들의 리스트를 구하는 <code>positions</code> 함수를 <code>zip</code> 을 이용해 만들어봅시다.</p>

<pre><code class="haskell">positions :: Eq a =&gt; a -&gt; [a] =&gt; [Int]  
positions x xs =  
  [i | (x', i) &lt;- zip xs [0..n], x == x']
  where n = (length xs) - 1

positions 0 [0, 1, 0, 1, 1, 1, 1, 0]  
-- [0,2,7]  
</code></pre>

<h3 id="stringcomprehensions">String comprehensions</h3>

<p>하스켈에선 <em>스트링 (문자열)</em> 이 <em>캐릭터</em> 의 리스트라는 걸 지난시간에 이야기 했습니다. 따라서 리스트를 인자로 받는 <em>polymorphic</em> 함수에 스트링을 적용할 수 있습니다.</p>

<pre><code class="haskell">zip "abc" [1, 2, 3] -- [('a',1),('b',2),('c',3)]  
*Main&gt; take 3 "asdasd" -- "asd"
length "adasd" -- 5  
</code></pre>

<p>그런 이유에서 <em>list comprehension</em> 을 이용해 스트링을 조작할 수 있습니다.</p>

<pre><code class="haskell">import Data.Char

lowers :: String -&gt; Int  
lowers xs = length [x | x &lt;- xs, isLower x]  
</code></pre>

<h3 id="thecaesarcipher">The Caesar cipher</h3>

<p><em>Caesar cipher (시저 암호)</em> 는 간단한 치환 암호입니다. 알파벳을 특정 자리수 만큼 밀어 인코딩된 새로운 문자열을 만들어 내지요.</p>

<p>간단하게 구현하기 위해 모든 문자가 소문자라 가정하겠습니다. 알파벳은 26개이니 <code>a</code> 를 <code>0</code> 에 매핑하지요.</p>

<pre><code class="haskell">import Data.Char

let2int :: Char -&gt; Int  
let2int c = ord c - ord 'a'

int2let :: Int -&gt; Char  
int2let n = chr(n + ord 'a')  
</code></pre>

<p><code>ord</code> 함수는 캐릭터를 받아 아스키 숫자로 변환하고 <code>chr</code> 함수는 그 반대의 역할을 합니다. 위 코드에서 <code>let2int</code> 는 캐릭터를 받아 <code>0</code> 부터 <code>25</code> 사이의 숫자로 변환합니다. 물론 <code>c</code> 가 소문자임을 가정합니다. <code>int2let</code> 은 반대의 역할을 하고요.</p>

<p>이제 주어진 소문자 알파벳을 <code>n</code> 번 만큼 이동시키는 <code>shift</code> 함수를 만들어 봅시다.</p>

<pre><code class="haskell">shift :: Int -&gt; Char -&gt; Char  
shift n c | isLower c = int2let((let2int c + n) `mod` 26)  
          | otherwise = c

shift (-1) 'a' -- 'z'  
shift (3) 'a' -- 'd'  
</code></pre>

<p>이제 <em>list comprehension</em> 을 이용해 <code>encode</code> 함수를 만들어 봅시다.</p>

<pre><code class="haskell">encode :: Int -&gt; String -&gt; String  
encode n cs = [shift n c | c &lt;- cs]

encode 1 "abc"  
-- "bcd"
encode 3 "haskell is fun"  
-- "kdvnhoo lv ixq"
encode (-3) "kdvnhoo lv ixq"  
-- "haskell is fun"
</code></pre>

<h3 id="crackingtheciper">Cracking the Ciper</h3>

<p>시저 암호를 깨는 방법은 다음과 같습니다.</p>

<p>(1) 대량의 텍스트를 분석해 각 알파벳이 문장속에서 나올 확률을 가지고 있는 <em>frequency table</em> 을 준비합니다. <br />
(2) 인코딩된 암호를 0 부터 25 까지 시프팅 해 가면서 우리가 준비한 <em>frequency table</em> 과 같은 비율을 가지고 있는지 검사합니다.</p>

<p>물론 이 방법은 텍스트가 너무 짧거나, 아니면 우리가 가지고 있는 <em>frequency table</em> 과 다른 분포를 가지고 있는 텍스트를 복호화 하지 못합니다. </p>

<p>일단 한번 해 봅시다.</p>

<pre><code class="haskell">table :: [Float]  
table = [8.2, 1.5, 2.8, 4.3, 12.7, 2.2, 2.0, 6.1, 7.0, 0.2, 0.8, 4.0, 2.4,  
        6.7, 7.5, 1.9, 0.1, 6.0, 6.3, 9.1, 2.8, 1.0, 2.4, 0.2, 2.0, 0.1]

count :: Eq a =&gt; a -&gt; [a] -&gt; Int  
count x xs = length [x' | x' &lt;- xs, x == x']

lowers :: String -&gt; Int  
lowers cs = length [c | c &lt;- cs, isLower c]

percent :: Int -&gt; Int -&gt; Float  
percent n m = (fromIntegral n / fromIntegral m) * 100

freqs :: String -&gt; [Float]  
freqs xs = [percent (count x xs) n | x &lt;- ['a'..'z']]  
           where n = lowers xs
</code></pre>

<p><code>freqs</code> 함수는 주어진 문자열에 대해 <em>frequency table</em> 을 돌려줍니다. <code>count</code> 와 <code>percent</code>, <code>lowers</code> 함수를 이용해서 만들었습니다. </p>

<p>이제 우리가 가지고 있는 <code>table</code> (<code>es</code>, <em>expected</em>) 과 인코딩된 텍스트를 시프팅 해서 얻은 <code>os</code> (<em>observed</em>) 테이블과의 차를 구하는 <code>chisqr</code> 함수를 만들겠습니다. 이 차이가 가장 작으면 <code>os</code> 가 우리가 가진 테이블에 가장 근접한 <em>frequency table</em> 을 가지는 테이블이라는 뜻이죠. </p>

<p>카이 제곱 분포를 이용할 건데, 공식은 다음과 같습니다.</p>

<p><img src='http://www.maritzresearch.com/maritzstats/HelpFiles/images/ChiSquareFormula-ChiSquareValue.bmp'  alt="http://www.maritzresearch.com/maritzstats/HelpFiles/Formula_ChiSquareTest.htm" /></p>

<pre><code class="haskell">chisqr :: [Float] -&gt; [Float] -&gt; Float  
chisqr os es = sum [(o- e)^2 / e | (o, e) &lt;- zip os es]  
</code></pre>

<p>하스켈 참 쉽죠? 이제 본래 인코딩 된 텍스트를 왼쪽으로 시프팅 하는 함수를 만들겁니다. <code>rotate</code> 라고 부릅시다. <code>take</code>, <code>drop</code> 을 이용하면</p>

<pre><code class="haskell">rotate :: Int -&gt; [a] -&gt; [a]  
rotate n xs = drop n xs ++ take n xs  
</code></pre>

<p>이제 인코딩된 텍스트에 대해 <code>[0..25]</code> 번 <code>rotate</code> 해 가며 <code>chisqr</code> 을 호출한 결과 중 가장 작은 값을 가지는 <code>factor</code> 를 찾아 <code>encode</code> 에  <code>-factor</code> 로 입력하면 암호가 깨집니다. 이런 일을 하는 함수를 <code>crack</code> 이라 부르고 작성해 봅시다.</p>

<pre><code class="haskell">positions :: Eq a =&gt; a -&gt; [a] -&gt; [Int]  
positions x xs = [i | (x', i) &lt;- zip xs [0..n], x' == x]  
  where n = (length xs) - 1

crack :: String -&gt; String  
crack xs = encode (-factor) xs  
  where
    factor = head (positions (minimum chiTab) chiTab)
    chiTab = [chisqr (rotate n table') table | n &lt;- [0..25]]
    table' = freqs xs
</code></pre>

<p>이제 이 함수를 사용해 봅시다.</p>

<pre><code class="haskell">crack "kdvnhoo lv ixq"  
-- "haskell is fun"
crack "vscd mywzboroxcsyxs kbo esopev"  
-- "list comprehensioni are uieful"
crack "vscd mywzboroxcsyxs kbo ecopev"  
-- "list comprehensioni are useful"

crack (encode 3 "haskell")  
-- "piasmtt"
crack (encode 3 "boxing wizards jump quickly")  
-- "wjsdib rduvmyn ephk lpdxfgt"
</code></pre>

<p>아래 두개의 예제는 복호화의 실패한 경우를 보여줍니다. 인코딩된 텍스트의 테이블이 우리가 가진 테이블과 많이 다르기 때문이지요.</p>

<h3 id="exercise">Exercise</h3>

<p>두개의 <em>generator</em> 를 가진 하나의 <em>comprehension</em> 은 하나의 <em>generator</em> 를 가진 두개 이상의 <em>comprehension</em> 으로 작성할 수 있습니다. 다음의 두 라인은 동일합니다.</p>

<pre><code class="haskell">[(x, y) | x &lt;- [1, 2, 3], y &lt;- [4, 5, 6]]

concat [[(x, y) | y &lt;- [4, 5, 6]] | x &lt;- [1, 2, 3]]  
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> in <em>edx</em> <br />
(2) Chapter 5, Programming in haskell <br />
(3) <a href='http://ko.wikipedia.org/wiki/%EC%B9%B4%EC%9D%B4%EC%82%AC%EB%A5%B4_%EC%95%94%ED%98%B8' ><em>Caesar cipher</em></a> <br />
(4) <a href='http://www.maritzresearch.com/maritzstats/HelpFiles/Formula_ChiSquareTest.htm' >http://www.maritzresearch.com</a></p>]]></description><link>http://1ambda.github.io/haskell-intro2/</link><guid isPermaLink="false">6893f28c-dffc-4c58-8195-730189d88711</guid><category><![CDATA[programming language]]></category><category><![CDATA[functional programming]]></category><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 04 Nov 2014 16:26:11 GMT</pubDate></item><item><title><![CDATA[Intro to Computational Thinking and Data Science 1]]></title><description><![CDATA[<h3 id="simulationmodels">Simulation Models</h3>

<p>Simulation attempts to build an <strong>experimental device</strong> called <em>model</em></p>

<p>Simulation model is <em>descriptive, not prescriptive</em></p>

<p>직역하자면 시뮬레이션은 실험가능한 도구인 모델을 만들어낸다. 모든 모델이 정확하진 않지만, 다시 말해 현상을 완벽하게 설명하진 못하지만, 어떤 모델들은 대략 비슷하게 사실을 예측해 낸다. 그런점에서 모델은 유용하다.</p>

<p>(1) <strong>Deterministic simulations</strong> are completely defined by the model <em>rerunning the simulation will not change the result</em> <br />
(2) <strong>Stochastic simulations</strong> include randomness. <em>Difference runs can generate different results</em>  </p>

<h3 id="nondeterminism">Nondeterminism</h3>

<p>*Casual nondeterminism: * Not every event is caused by previous events</p>

<p>*Predictive nondeterminism: * Lack of knowledge about the world makes it impossible make accurate predictions about future states</p>

<p>*Stachastic Processes: * An ongoing process where the next state might depend on both the previous states and <strong>some random element</strong></p>

<pre><code class="python">def rollDie():  
   """returns an int between 1 and 6"""

def rollDie():  
   """returns a random int between 1 and 6 """
</code></pre>

<p>위쪽 <code>rollDie</code> 는 <em>underdetermined</em> 인 반면 아래쪽은 <em>non-deterministric</em></p>

<h3 id="hashtable">Hash Table</h3>

<p><em>Many to One</em> 이기 때문에 <em>Collision</em> 이 생긴다. <strong>bucket</strong> 을 이용해서 같은 키값을 가진 것들을 같은 버켓에 저장하도록 하면 충돌을 어느정도는 예방할 수 있다. </p>

<p>물론, 테이블이 커지면 충돌이 적어지고 탐색시간이 빨라지지만 메모리가 많이 들고, 테이블이 작아지면 충돌이 많아지고 탐색시간이 <em>linear search</em> 에 가깝게 느려지지만 메모리는 적게든다. <em>Time / Space trade off</em></p>

<p>그리고 좋은 해쉬 함수는 <em>uniform distribution</em> 을 생성한다. 다시 말해서 모든 버킷은 같은 수의 데이터를 담고 있어야 한다.</p>

<p>해시 테이블은 <em>time / space trade off</em> 를 극명하게 보여주는데, <em>collision</em> 이 하나도 없을 때 개당 <em>1 byte</em> 인 10^9 개의 원소를 담고자 한다면, 1GB 가 필요하다.</p>

<p>그래서 해시 테이블을 만들 때는 가능한한 메모리가 허락하는 한도 내에서 최적화 할 필요가 있다. 다시 말하면 <em>table size</em> 와 <em>lookup time</em> 을 동시에 고려해야 한다는 뜻이다.</p>

<p>버킷 내부에 <code>a</code> 개를 저장하면 원소를 검색하는데 <code>O(a)</code> 시간이 걸리지만 메모리는 <code>1/a</code> 배 만큼 줄어든다.</p>

<p>이제 해쉬 함수의 성능을 <em>적어도 한번 충돌이 일어날 수 있는 확률</em> 로 표현해 보자. 한번도 충돌이 나지 않을 경우를 1 에서 빼면 된다.</p>

<p>입력 원소 <code>K</code> 개에 대해, 해쉬함수가 <code>range(n)</code> 의 <em>uniform distribution</em> 을 만들때 <code>hash(k) = 1/n</code> 이다. 이 때 충돌이 한번도 일어나지 않을 확률은 <code>1 * (n-1)/n * (n-2)/n  * .. (n-(k-1))/n</code> 이다. 이 값을 1에서 빼면 <em>적어도 한번 충돌이 일어날 수 있는 확률</em>을 구할수 있다.</p>

<h3 id="birthdayattack">Birthday Attack</h3>

<p>일년이 365일 이라 하면, 얼핏 생각하기에 365명 정도는 모여야 생일이 같은 사람 있을 것 같은데 사실 그렇지 않다. 실제로는 23명만 모여도 생일이 같은 두사람이 있을 확률이 50%를 넘고, 57명이 모이면 99%를 넘는다.</p>

<p>생일이 같은 두 사람을 찾는 것과 비슷하게, 암호학적 해시 결과가 같은 두 입력값을 자는 것 역시 모든 입력값을 계산하지 않앋 충분히 높은 확률로 해시 충돌을 찾을 수 있다. 이러한 암호 공격을 <em>birthday attack</em> 이라 부른다.</p>

<p>바꿔 말하면 <em>birth day problem</em> 은 해시 버켓이 365개인 해시 테이블이라 봐도 무방하다.</p>

<p><code>atLeastTwoSameBirthday</code> 함수는 <code>n + 1</code> 명이 있는 방 안에서 적어도 두명은 생일이 같을 확률을, <code>minNumOfPeopleProb</code> 는 인자로 받은 <code>p</code> 보다 큰, 생일이 같을 확률을 얻기 위한 최소한의 인원을 돌려준다.</p>

<pre><code class="python">import operator


def atLeastTwoSameBirthday(n):  
    xs = range(365 - n, 365)
    ys = map((lambda x: float(x) / 365), xs)
    return 1 - reduce(operator.mul, ys)


def minNumOfPeopleProb(p):  
    for n in range(1, 365):
        if atLeastTwoSameBirthday(n) &gt;= p:
            return n

    return n


print atLeastTwoSameBirthday(29)  
print atLeastTwoSameBirthday(249)  
print minNumOfPeopleProb(0.99)  
</code></pre>

<h3 id="lowoflargenumbers">Low of Large Numbers</h3>

<blockquote>
  <p>In repeated <strong>independent tests</strong> with the same actual probabilty <em>p</em> of a particular outcome in each test, the chance of that the <em>fraction of times</em> that outcome occurs differs from p converges to zero as the number of trials goes to infinity</p>
</blockquote>

<p><em>low of large numbers</em> 는 <strong><code>|head - tail|</code> 이 0에 수렴한다</strong> 를 의미하지 않는다. 오히려 <code>|head - tail|</code> 는 특정 비율이다(<em>ratio</em>)</p>

<p>이제 실제로 그러한지 시뮬레이션을 하기 위해 코드를 작성하면</p>

<pre><code class="python">import pylab  
import random


def flipPlot(minExp, maxExp):  
    ratios = []
    diffs = []
    xAxis = []

    for exp in range(minExp, maxExp + 1):
        xAxis.append(2 ** exp)

    for flips in xAxis:
        heads = 0
        for n in range(flips):
            if random.random() &lt; 0.5:
                heads += 1

        tails = flips - heads
        ratios.append(heads / float(tails))
        diffs.append(abs(heads - tails))

    pylab.title('Diff between Heads and Tails')
    pylab.xlabel("# of Flips")
    pylab.ylabel("Abs(#Heads - #Tails)")
    pylab.plot(xAxis, diffs)
    pylab.figure()
    pylab.title("Heads / Tails Ratios")
    pylab.xlabel("# of Flips")
    pylab.ylabel("Heads / Tails")
    pylab.plot(xAxis, ratios)

random.seed(0)  
flipPlot(4, 20)  
pylab.show()  
</code></pre>

<p>돌려서 나온 <code>|head - tail|</code> 의 그래프에서 선형 관계가 있다고 느낄 수 있는데 사실이 아니다. 우리는 x 축 값을 지수로 증가시켰기 때문에 우측에는 데이터가 별로 없는 반면 왼쪽에는 압축되어있다.</p>

<p>선 대신에 점 형태로 그래프를 그리고 축에 로그를 씌우는 코드로 바꾸자.</p>

<pre><code class="python">    #...

    pylab.title('Diff between Heads and Tails')
    pylab.xlabel("# of Flips")
    pylab.ylabel('Abs(#Heads - #Tails)')
    pylab.plot(xAxis, diffs, 'bo')
    pylab.semilogx()
    pylab.semilogy()
    pylab.figure()
    pylab.title('Heads / Tails Ratios')
    pylab.xlabel('# of Flips')
    pylab.ylabel('Heads / Tails')
    pylab.semilogx()
    pylab.plot(xAxis, ratios, 'ro')

    #...
</code></pre>

<p><code>heads / tails</code> 는 1에 수렴하는걸 알 수 있다. 반면 <code>|heads - tails|</code> 는 완벽하진 않지만 선형의 그래프를 그리는걸 알 수 있다.</p>

<p>여기서 한 가지 사실을 알 수 있다.</p>

<blockquote>
  <p>Never possible to be assured of perfec accuracy through samplings, unless you sample the entire population</p>
</blockquote>

<p>그렇다면 <em>sample</em> 에 대한 경향이 참일때, <em>population</em> 에 대한 경향이 참임을 증명하기 위해서 얼마나 많은 <em>sample</em> 을 살펴봐야 할까?</p>

<blockquote>
  <p>Depends upon the variance in the underlying distribution</p>
</blockquote>

<p>물론 우리는 <em>distribution</em> 을 볼 수 없다. 샘플만 가지고 있기 때문에. 그럼 샘플로 <em>variance</em> 를 얻어보자.</p>

<blockquote>
  <p>We measure the amount of variance in the outcomes of multiple trials</p>
</blockquote>

<p><em>standard deviation</em> 을 이용하자. 표준편차는 우리가 가진 샘플이 평균에 모여있는지, 아닌지를 알려주는 지표다. </p>

<p>다시 말해서 <em>standard deviation</em> 이 작으면, 그래서 샘플의 평균에 샘플들이 대부분 모여있다는걸 알 수 있다면 작은 샘플에 대해서 얻은 어떤 경향이 <em>population</em> 에도 적용된다는 걸 알 수 있다.</p>

<pre><code class="python">def flipPlot(minExp, maxExp, trials):  
    meanRatios = []
    meanDiffs = []
    sdRatios = []
    sdDiffs = []
    xAxis = []

    for exp in range(minExp, maxExp + 1):
        xAxis.append(2 ** exp)

    for flips in xAxis:
        ratios = []
        diffs = []

        for t in range(trials):
            heads, tails = runTrial(flips)
            ratios.append(heads / float(tails))
            diffs.append(abs(heads - tails))
        meanRatios.append(sum(ratios) / trials)
        meanDiffs.append(sum(diffs) / trials)
        sdRatios.append(stdDev(ratios))
        sdDiffs.append(stdDev(diffs))

    pylab.title('Mean of Diff bet Heads and Tails ('+str(trials)+' Trials)')
    pylab.xlabel("# of Flips")
    pylab.ylabel('mean Abs(#Heads - #Tails)')
    pylab.plot(xAxis, meanDiffs, 'bo')
    pylab.semilogx()
    pylab.semilogy()

    pylab.figure()
    pylab.title('SD of Diff bet Heads and Tails ('+str(trials)+' Trials)')
    pylab.xlabel('# of Flips')
    pylab.ylabel('SD Abs(#Heads - #Tails)')
    pylab.plot(xAxis, sdDiffs, 'bo')
    pylab.semilogx()
    pylab.semilogy()

    pylab.figure()
    pylab.title('Mean Heads / Tails Ratios')
    pylab.xlabel('# of Flips')
    pylab.ylabel('mean Heads / Tails')
    pylab.semilogx()
    pylab.plot(xAxis, meanRatios, 'ro')

    pylab.figure()
    pylab.title('SD Heads / Tails Ratios')
    pylab.xlabel('# of Flips')
    pylab.ylabel('SD Heads / Tails')
    pylab.semilogx()
    pylab.semilogy()
    pylab.plot(xAxis, sdRatios, 'ro')

random.seed(0)  
flipPlot(4, 20, 20)  
pylab.show()  
</code></pre>

<p>이제 코드를 돌려보면, <code>heads / tails</code> 의 평균은 1로 수렴하는 것을, 표준편차는 <code>n</code> 이 커질수록 급격히 <code>0</code> 에 가까워지는걸 알 수 있다.</p>

<p>반면 <code>|heads - tails|</code> 의 평균은 <code>n</code> 이 증가할수록 여전히 커지고, 표준편차도 증가한다. </p>

<p>그럼, <code>n</code> 이 클수록 <code>|heads - tails|</code> 의 표준편차가 증가하므로 우리가 얻은 어떤 경향성이 <code>n</code> 이 클수록 더 믿지 못한다는 뜻일까?. </p>

<p>당연히 그렇지 않다! <strong>표준편차는 그 자체로만 보아서는 안되고 평균과 연관지어 생각해야 한다.</strong> 평균이 100억일때, 표준편차가 100이라면 그건 데이터가 모여있음을 의미한다.</p>

<p>결국 <em>평균</em> 이 매우 달라지는 테스트를 할 경우엔 <em>표준편차</em> 를 사용하는건 적절하지 못하다는 사실을 알 수 있다.</p>

<h3 id="coefficientofvariation">coefficient of variation</h3>

<p>그럼 평균이 달라지는경우 표준편차가 의미가 없다면, 어떤 값을 사용해야 <em>population</em> 의 <em>variance</em> 를 알 수 있을까? 표준편차를 평균으로 나눈 <em>coefficient of variance</em> 를 이용하면 된다. 일반적으로 이 값이 1 보다 작은지 아닌지를 기준으로 삼는다.</p>

<p><img src='https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/files_finger_exercises_pythonland.png'  alt="" />
<img src='https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/files_finger_exercises_montyland.png'  alt="" /></p>

<p align="center">(<a href='http://courses.edx.org/courses/MITx/600.2_2x' >http://courses.edx.org/courses/MITx/600.2_2x</a>)</p>

<p>위 두 도시의 스카이라인중 어떤 도시의 <em>coefficient of variance</em> 가 더 클까?</p>

<p>한가지 더 생각해볼 문제가 있다. 다음의 두 변수는 CoV 를 계산하는 것이 의미가 있을까?</p>

<p>(1) <em>Daily Temperature in Celsius for the city of Boston</em> <br />
(2) <em>The X coordinate of a drunk in the random walk</em>  </p>

<p>의미가 없다. <em>CoV</em> 가 의미있으려면, <em>true zero</em> 가 있어야 한다. 바꿔 말하면 <em>ratio scale</em> 에 대해서만 <em>CoV</em> 가 의미가 있다. 위 두 수치들은 양수 또는 음수값이 있기 때문에 <em>ratio scale</em> 이 아니다.</p>

<h3 id="histogram">Histogram</h3>

<p><em>pylab</em> 에서는 히스토그램을 어떻게 그릴까?</p>

<pre><code class="python">import pylab  
import random


def exampleHist(n):  
    xs = []
    for x in range(n):
        xs.append(random.random())

    pylab.hist(xs, bins=11)
    pylab.show()

exampleHist(10000)  
</code></pre>

<h3 id="references">References</h3>

<p>(1) <a href='http://ko.wikipedia.org/wiki/%EC%83%9D%EC%9D%BC_%EB%AC%B8%EC%A0%9C' >http://ko.wikipedia.org</a> <br />
(2) <em>MIT 6.00.2 2x</em> in <strong>edx</strong></p>]]></description><link>http://1ambda.github.io/edx-600-2x-1/</link><guid isPermaLink="false">ea5cceae-c2b4-4745-9127-5cc8d042a92a</guid><category><![CDATA[edx]]></category><category><![CDATA[python]]></category><category><![CDATA[histograms]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 04 Nov 2014 09:19:14 GMT</pubDate></item><item><title><![CDATA[Divide and Conquer]]></title><description><![CDATA[<p><em>Divide and Conquer (분할 정복)</em> 을 배운다. <em>merge, quick sort</em> 를 배우고 이 과정에서 왜 <em>combine</em> 단계가 <code>O(n)</code> 이 되어야 하는지 알아본다. 뒷부분에서는 <em>Big O</em> 뿐만 아니라 <em>master method</em>, <em>decomposition approach</em> 를 이용해 성능을 분석한다.</p>

<h3 id="divideandconquer">Divide and Conquer</h3>

<p>각 level 의 문제 갯수는 <code>2^j (j = 0, 1, 2, ... , log2n)</code> 이고 문제의 사이즈는 <code>n / 2^j</code> 이므로 연산수를 <code>k</code> 라 하면, 각 레벨에서 연산 수는 <code>k * n</code>, 레벨의 <em>depth</em> 가 <code>log2n + 1</code> 이므로, </p>

<p><em>merge sort</em> 같은 경우는 연산수 <code>k = 6</code> 에서 <code>6n (log2n + 1)</code></p>

<p>Big O 는 <code>O(f(n))</code> 이라 했을때 <em>at most</em>, <code>f(n)</code> 에 proportional 하므로 upper 바운드. <br />
반면 Omega 는 <code>omega(f(n))</code> 이라 했을 때 <em>at least</em> <code>f(n)</code> 에 proportional 하므로 lower 바운드.</p>

<p>분할 정복의 핵심은 각 sub-problem 에서 연산 수를 o(n) 으로 맞출 수 있느냐 없느냐, 맞춘다면 nlogn 알고리즘이 되는 것이다. </p>

<p>알고리즘은 3단계로 구성된다.</p>

<p>(1) Divide <br />
(2) Conquer sub problems <br />
(3) combine (merge)  </p>

<p>여기서 중요한건, combine 단계인데 이게 O(n) 이기만 하면 전체 알고리즘의 성능을 O(nlogn) 으로 보장할 수 있음.</p>

<h3 id="mastermethodmotivation">Master Method: Motivation</h3>

<p>T(n) 을 O(n) 으로 upper bound 를 구하긴 했지만 O(n) 연산 수 구하는게 좀 힘들다. 재귀 호출의 갯수나, 문제의 분할 사이즈로 O(n) 을 쉽게 구해보자.</p>

<p>가우스 곱셈? 의 경우에 T(n) &lt;= 4 * T(n/2) + O(n)</p>

<p>그러나 더 작아질 수 있음. (a+b)(c+d) 에서 ad+bc = (a+b)(c+d) - ad - bd 로 구할 수 있음</p>

<p>즉 3개의 부분식만 구해도 됌.</p>

<p>T(n) &lt;= 3 * T(n/2) + O(n)</p>

<p>머지소트는 2 * T(n/2) + O(n) 쯤 되니까 가우스보다 더 낫긴 함. 그럼 가우스의 그것은 얼마일까?</p>

<h4 id="mastermethod">Master Method</h4>

<p><em>Master method</em> 는 재귀 문제의 러닝타임을 구하는데 <em>black box</em> 같은 역할을 한다. 대강의 코드만으로도 러닝타임을 추측할 수 있다.</p>

<p>그러나 <em>master method</em> 는 가정을 하나 하는데, 바로 모든 문제가 같은 사이즈로 분할 된다는 것.</p>

<blockquote>
  <p>All sub priblems have equal size</p>
</blockquote>

<p><code>n</code> 이 충분히 작다면, <code>T(n)</code> 은 상수라 볼 수 있고 만약 <code>n</code> 이 충분히 크다면 <em>master method</em> 는 다음의 포맷을 가진다.</p>

<p><img src='https://acrocontext.files.wordpress.com/2014/01/master-method.png?w=300&amp;h=160'  align="center" />  </p>

<p align="center">(<a href='https://acrocontext.wordpress.com/' >https://acrocontext.wordpress.com</a>)</p>

<p>여기서 <code>a</code> 는 재귀 함수 호출의 수고, <code>b</code> 는 분할된 문제의 사이즈다. <code>d</code> 는 <em>combine</em> 스텝에서 사용하는 함수의 러닝타임의 지수다. (<em>merge-sort</em> 에서 머징하는 함수라 보면 된다.)</p>

<ul>
<li><code>a</code>: number of recursive calls (<code>&gt;= 1</code>)  </li>
<li><code>b</code>: input size shrinkage factor (<code>&gt; 1</code>)  </li>
<li><code>d</code>: exponent in running time of <em>combine step</em> (<code>&gt;= 0</code>)</li>
</ul>

<p>이제 몇 가지 예제를 좀 살펴보자.</p>

<p><em>merge sort</em> 의 경우는 <code>a = 2, b = 2, d = 1</code> 이므로 <code>2 = 2^1</code> 이어서 <code>O(n^1 * logn)</code> 즉 <code>O(nlogn)</code> 의 러닝타임을 가진다.</p>

<p><em>binary search</em> 는 문제 수가 절반으로 줄긴 하나 반쪽만 사용하고, 매 재귀호출 마다 한번의 비교만 하므로 <code>a = 1, b = 2, d = 0</code> 이므로 <code>a = b^d</code> 는 <code>1 = 1^1</code> 이 되어 <code>O(nlogn)</code> 이 된다. </p>

<p>가우스 곱셈은 <code>a = 3, b = 2, d = 1</code> 이므로 <code>O(n^log2_3)</code> 이 된다. 더 정확히는 <code>O(n^1.59)</code> <em>merge-sort</em> 보다 빠르진 않지만 <em>quadratic</em> 보단 빠르다.</p>

<p><em>strassen</em> 행렬 곱셈은 어떨까? <code>a = 7, b = 2, d = 2</code> 에서 마찬가지로 <em>case 3</em> 이므로 <code>O(n^log2_7)</code> 이다. <code>O(n^2.81)</code> 쯤 되므로 <code>O(n^3)</code> 보다는 훨씬 낫다.</p>

<p><em>merge-sort</em> 에서 <code>d = 2</code> 라면 <code>O(n^2)</code> 이 나온다. 사실 일반적으로 생각하기에는 <code>O(n^2 * logn)</code> 이 나올거 같은데, 사실 이건 <em>upper bound</em> 이므로 <code>O(n^2)</code> 이 좀 더 나은 <em>upper bound</em> 임을 알 수 있다. 이 사실은  <em>master method</em> 를 이용하면 수학적으로 더 근사한 값을 찾아낼 수 있다는걸 알려준다.</p>

<h4 id="proofmastermethod">Proof: Master Method</h4>

<p>재귀의 각 단계를 <code>j = 0, 1, 2, ... , logb_n (base b)</code> 라 하면 각 단계에서는 <code>a^j</code> 사이즈의 <em>sub-problem</em> 수와 <code>n / b^j</code> 사이즈의 문제가 있다. </p>

<p>단계 <code>j</code> 에서의 연산은 <code>a^j * c * (n / b^j)^d</code> 즉 <em>문제의 수 x 각 문제의 사이즈와 일어나는 거기서 일어나는 연산 수</em> 로 정의할 수 있다. 수식을 <code>j</code> 로 다시 정리하면</p>

<p>각 단계의 <em>sub problem</em> 에서 일어나는 연산은 <code>c * n ^d * (a / b^d)^j</code> 다. 따라서 전체 단계를 구하려면 여기에 시그마를 씌우면 된다.</p>

<p>식을 좀 더 자세히 보면</p>

<ul>
<li><em><code>a</code>:</em> rate of sub problem proliferation <em>(RSP)</em> </li>
<li><em><code>b^d</code>:</em> rate of work shirinkage <em>(RWS)</em></li>
</ul>

<p><code>d</code> 가 <code>n^d</code> 에도 섞여있어 좀 복잡하긴 한데 느낌만 알아보자면 <code>b = 2, d = 1</code> 일때는 <em>sub-problem</em> 당 문제가 1/2 씩 줄어든다. 하지만 <code>b = 2, d  = 2</code> 라면 문제의 수가 2배가 될때 문제 사이즈는 4배가 되고, <code>b^d = 4</code> 가 되어 1/4 만큼의 연산만 줄어든다. 따라서 <code>d</code> 가 커지는 건 생각보다 영향이 큰 걸 알 수 있다.</p>

<p>위 식으로부터 다음의 관계를 이끌어 낼 수 있다.</p>

<p>(1) if <em>RSP &lt; RWS</em>, then the amount of work is decreasing with the recursion level <code>j</code> <br />
(2) if <em>RSP > RWS</em>, then the amount of work is increasing with the recursion level <code>j</code> <br />
(3) if <em>RSP = RWS</em>, then the amount of work is same at every recursion level <code>j</code>  </p>

<p>따라서 <code>(3)</code> 의 경우 각 단계에서의 연산이 <code>c* n^d * 1^j</code> 이므로 깊이 <code>logb_n (base b)</code> 을 곱하면 <code>O(n^d * logn)</code> 이다. <em>(<code>a</code>, <code>b</code> 는 문제의 사이즈와 관계가 없다 그리고 더 정확히는 시그마를 더하면 <code>O(n^d * (1 + logb_n)</code> 이다)</em> </p>

<p><code>(2)</code> 의 경우 깊이가 깊어질 수록 각 단계에서의 연산이 급격하게 줄어들고, 루트에서의 (<code>j = 0</code>) 연산이 가장 크므로 루트에서의 연산을 <em>upper bound</em> 로 보면 <code>O(n^d)</code> 라 볼 수 있다. </p>

<p>마지막으로 <code>(1)</code> 의 경우 깊이가 깊어질수록 연산이 늘어나고, 대충 생각하면 마지막 노드의 개수에 비례하는 <em>Big O</em> 를 가지리라는 생각을 해볼 수 있다. </p>

<p>좀 더 수식에 대한 이해를 얻기 위해 수학적으로 접근해 보자.</p>

<p><code>1 + r + r^2 + ... + r^k</code> 를 귀납법으로 풀면 <code>r^(k+1) - 1 / r - 1</code> 이란 값이 나온다. <code>(r != 1)</code> 이 때 </p>

<p><code>r &lt; 1</code> 이고 <code>k</code> 가 충분히 크다면 이 식은 <code>1 / (1 - r)</code> 이라 보아도 된다. 다시 말해서 <code>k</code> 와는 관련 없는 상수라 보아도 된다는 뜻이다. 그리고 첫번 째 항이 다른 것들의 합보다 크다고 볼 수 있다.</p>

<p><code>r &gt; 1</code> 이라 했을때, 우측 식 <code>r^(k+1) - 1 / r - 1</code> 은 <code>r^k * (1 + 1 / r - 1)</code> 보다 항상 작거나 같다는 사실을 알 수 있다 <em>(upper bound)</em> 다시 말해서 마지막 항 <code>r^k</code> 의 2배보다 작거나 같다는 사실을 알 수 있다. 이것도 <code>r = 2</code> 일때나 맥시멈 두배다. </p>

<p>1 부터 256까지 더해봐도 512 보다 작거나 같다는 사실을 알 수 있다. 다시 말해서 마지막 항이 그 전 모든 항을 합한 것 보다 크다.</p>

<p>이제 다시 <em>master method</em> 로 다시 돌아오자.</p>

<p><code>c* n^d * sigma(j) (a / b^d)^j</code> (<code>j = 0 to logb_n</code>) 에서 <code>a / b^d</code> 를 <code>r</code> 이라 두자.</p>

<p><em>RSP &lt; RWS (case 2)</em> 이면 <code>r &lt; 1</code> 이므로 시그마를 합해봐야 특정 상수다. <code>O(n^d)</code></p>

<p>반대로 <em>RSP > RSW (case 3)</em> 이면 <code>r &gt; 1</code> 이므로 시그마를 합해봐야 <code>r^k * 상수</code> 보다 작거나 같으므로 가장 큰 항 <code>r^k</code> 는 <code>(a / b^d)^logb_n</code> 이다. 여기서 <code>b^(-dlogb_n)</code> 이 <code>n^-d</code> 라는 사실을 이용하면 <code>O(a^logb_n)</code>만 남는다.</p>

<p>그런데, 재미있는 사실은 <code>logb_n</code> 이 마지막 단계이고, <code>a</code> 는 각 단계에서 분할되는 노드의 갯수이므로 <code>a^(logb_n)</code> 은 <em>recursion tree</em> 에서 <em>leave</em> 의 갯수다. </p>

<p>다시 말해서 마지막 단계에서의 노드의 갯수에 연산이 비례한다. 근데 처음에 우리가 봤던건 <code>n^(logb_n)</code> 아니었던가? 사실 로그를 배우면 위 두 식은 같다는걸 알 수 있다.</p>

<h3 id="quicksort">Quick Sort</h3>

<p>퀵소트는 평균적으로 <code>O(n logn)</code> 성능을 보여주며 <em>in-place</em> 로 작동하는 인기있는 정렬 알고리즘이다.</p>

<p><em>key idea</em> 는 <em>pivot</em> 을 중심으로 문제를 좌우로 분할하는 것이다.   <em>less than pivot</em> 들은 왼쪽에, <em>greater than pivot</em> 들은 우측에 놓음으로써 최소한 한번의 분할당 하나의 원소 <em>(pivot)</em> 은 자리를 잡는 다는 것을 보장한다.</p>

<p>퀵소트의 매 호출당 일어나는 <em>partition (분할)</em> 은 다음의 두 특징을 가진다.</p>

<p>(1) linear time, <code>O(n)</code> <br />
(2) no extra memory</p>

<p>대강의 로직은 이렇다. <code>Quicksort(array A, length n)</code> 에 대해서</p>

<p>(1) if <code>n = 1</code> return <code>A</code> <br />
(2) <code>p</code> = choose <code>Pivot(A, n)</code> <br />
(3) partition <code>A</code> round <code>p</code> => <code>L, R</code> <br />
(4) recursively solve <code>L</code>, <code>R</code></p>

<p>보면 알겠지만 <em>combine</em> 혹은 <em>merge</em> 스텝이 전혀 없다. </p>

<h4 id="partitioninplace">Partition: In-place</h4>

<p><code>O(n)</code> 의 추가 메모리를 사용하면 연산시간 <code>O(n)</code> 을 구현하기 쉽다. 추가 메모리 없이 어떻게 <code>O(n)</code> 으로 <em>partitioning</em> 을 구현할 수 있을까?</p>

<p>(1) 첫 번째 원소를 <em>pivot</em> 이라 놓고 <br />
(2) <em>pivot</em> 다음의 원소를 <code>i</code>, <code>j</code> 가 가리키게 한다. <br />
(3) <code>j</code> 보다 작은 원소들은 <em>partitioned</em> , 큰 원소는 <em>unpartitioned</em> 라 보고 <br />
(4) <code>i</code> 보다 작은 원소들은 <em>pivot</em> 보다 작은 값, 큰 원소들은 <em>pivot</em> 보다 큰 값이다. <br />
(5) <code>i &lt;= j</code> 이며, <code>i == j</code> 일때는 <code>j</code> 값을 증가시켜 원소를 비교 한뒤 <code>j</code> 에 있는 원소가 <code>i</code> 가 가리키는 원소보다 크면 <em>swap</em> 하고 <code>i += 1, j +=1</code> 아니면 <code>j += 1</code> 한다.</p>

<p>이해가 쉽게 그림을 첨부하면</p>

<p><img src='http://sadakurapati.files.wordpress.com/2013/10/qsort_1.png'  align="center" /> <br />
<img src='http://sadakurapati.files.wordpress.com/2013/10/qsort_2.png'  align="center" />  </p>

<p align="center">(<a href='http://sadakurapati.wordpress.com/' >http://sadakurapati.wordpress.com</a>)</p>

<p>이런 로직으로 <code>n</code> 개의 원소를 순회하면, <code>n-1</code> 번 만큼 <code>j</code> 순회를 하고 최악의 경우 <code>n-1</code> 번의 <em>swap</em> 과 <em>i += 1</em> 연산이 일어난다.  다시 말해 각 원소마다 <code>O(1)</code> 연산이므로, <em>partition</em> 연산은 <code>O(n)</code> 이라 보장할 수 있다.</p>

<p><em>quick-sort</em> 는 귀납법으로 증명하기도 쉬운데, <code>P(n)</code> 이 1부터 <code>n</code> 까지의 정렬된 원소를 가지고 있는 배열이라고 하면, </p>

<p><code>P(1)</code> 임은 자명하고, 문제의 수 <code>k</code> 에 대해 퀵소트가 <code>P(k)</code> 일때  <code>P(k+1)</code> 임을 보이면 <code>P(n)</code> 에 대해서도 참임을 알 수 있다.</p>

<p>그런데, <code>P(k+1)</code> 에서 <em>pivot</em> 을 제외한 좌측과 우측의 사이즈를 <code>k1</code>, <code>k2</code> 라 하면 <code>k1, k2 &lt; k</code> 이다. 좌측 또는 우측이 없을 때라야 <code>k1 or k2 = k</code> 다. 이때 <code>P(k)</code> 가 참이므로 이보다 작거나 같은 <code>k1, k2</code> 의 문제 사이즈에 대해서도 참이다. 따라서 <code>P(k+1)</code> 도 참이다.</p>

<h4 id="choosingagoodpivot">Choosing a good pivot</h4>

<p>그럼 <em>pivot</em> 은 무엇을 기준으로 잡는게 좋을까? 어차피 비교에서 <code>i != p and j != p</code> 라면 구현에는 어느 위치에 잡던 문제가 없을것 같은데..</p>

<p>만약에 <em>pivot</em> 이 첫 번째 원소이고, 입력이 이미 정렬이 된 배열이라면 성능이 어떻게 될까? 바로 <code>O(n^2)</code> 이다. 왜냐하면 이미 정렬이 되어있으므로 문제가 1/2 로 분할되지 않기 때문이다. 배열 사이즈만 1씩 줄어들면서 재귀호출이 반복된다.</p>

<p>그럼 만약에, <em>pivot</em> 을 원소들의 <em>median (중앙값)</em> 으로 고른다면? 매 재귀마다 문제가 좌우로 분할되므로 <code>O(nlogn)</code> 이라 볼 수 있다.</p>

<p>근데 생각해 볼 거리가 있다. <em>pivot</em> 을 구하는 함수의 비용은 어떻게 되는걸까? 이것 또한 <code>O(n)</code> 이므로 전체 <em>partition</em> 의 비용은 <code>O(n)</code> 이라 보아도 된다.</p>

<h4 id="randomizedpivots">Randomized pivots</h4>

<p>그럼 만약에 <em>pivot</em> 을 무작위로 고르면 어떻게 될까 생각해 보자. <em>pivot</em> 을 무작위로 선택했을 때 한쪽이 <code>25-75%</code> 로 분할될 확률은 1/2 이다. </p>

<p>그리고 무작위로 <em>pivot</em> 을 선택했을때 첫번째 다음 재귀 호출에 넘겨질 배열의 길이의 기대값을 구하면, 다시 말해 <code>X</code> 를 <em>subproblem size</em> 라 했을때 <code>E(X)</code> 를 구하면</p>

<p><code>1/n * (0 + 1 + ... + (n - 1)) = (n - 1) / 2</code> 다.</p>

<p>여기서 잠깐 중요한 속성인 <em>linearity of expection</em> 을 설명하면 </p>

<blockquote>
  <p>모든 <em>random variable</em> <code>X</code> 의 합의 기대값은, 각 <code>X</code>의 기대값의 합과 같다.</p>
</blockquote>

<p><img src='http://www.opendatastructures.org/ods-java/img333.png'  align="center" />  </p>

<p align="center">(<a href='http://www.opendatastructures.org/' >http://www.opendatastructures.org</a>)</p>

<p><code>Xj(i)P(i)</code> 를 컬럼의 개수가 <code>j</code>, 행의 개수가 <code>i</code> 인 행렬의 원소로 보면 이 <em>linearity of expectation</em> 은 쉽게 이해할 수 있다. 이 속성은 꽤나 유용하다.</p>

<p>예를 들어 두개의 주사위를 독립적으로 굴린다고 할 때 나오는 값인 <em>random variable</em> <code>X1, X2</code> 에 대한 기대값을 직접 구하려면 36개의 <em>sample space</em> 를 살펴봐야 하는데, 그러지 말고 하나를 굴렸을때의 값을 구해 이걸 2배 하면 된다. 하나를 굴렸을때는 6개의 <em>sample space</em> 만 살피면 되니 금방 구한다.</p>

<p>로드 밸런싱문제에 <em>linearity of expectation</em> 을 적용해보자. <code>n</code>개의 서버가 있고 여기에 <code>n</code> 개의 프로세스를 랜덤하게 할당할때 한개의 서버에 할당될 프로세스의 기대값은 얼마일까? 다시 말해 평균적으로 몇개의 프로세스가 서버에 할당될까?</p>

<p><em>sample space</em> 는 <code>n</code> 개의 항끼리의 곱에서 항의 개수를 구하는 문제와 같으므로 <code>n^n</code> 이다.</p>

<p>이때 <code>Y</code> 를 첫 번째 서버에 할당된 프로세스 수의 합이라 하면 이때 <code>Y</code> 는 <code>sigma Xj (j = 1 to n, Xj = 1 or 0)</code>이다.</p>

<p><code>E[Y]</code> 를 구하는 것이 본래의 문제인데 가능한 <code>Y</code> 값을 모두 구한 뒤에 각각의 확률을 곱해서 더하느니, <code>Y</code> 를 분해해 각각의 기대값을 구한 후 더하는게 훨씬 빠르다. (주사위 굴리기 문제처럼)</p>

<p>다시 말해서, <code>Y</code> 가 여러개의 항으로 구성될때는 각각의 기대값을 구하는게 더 계산이 빠르다는것이 <em>lineariry of expectation</em> 의 본질이다.</p>

<p>따라서 기대값을 시그마 뒤쪽으로 빼서 계산하면 <code>1</code> 이 나온다. 다시 말해 서버 하나당 평균적으로 1개의 프로세스를 가진다는 이야기.</p>

<p>다시 이 확률 테크닉을 <em>randomized pivot</em> 을 선택하는 <em>merge sort</em> 에 적용하러 가 보자.</p>

<h3 id="decompositionprinciple">Decomposition Principle</h3>

<p>일단 랜덤 피벗을 가지는 퀵소트를 <em>master method</em> 로는 <em>Big O</em> 를 찾을 수가 없다는 사실을 알아 두자. 이는 입력한 배열이 일정하게 분할되지 않고 피벗때문에 랜덤하게 분할되지 때문이다.</p>

<p>이제, 퀵 소트의 각 재귀에서 일어나는 연산 중 <em>comparison (비교)</em> 가 다른 연산보다 <em>dominant</em> 하다고 하면, 다시 말해서 비교하는 숫자에 의해 연산 수가 결정된다고 하자. 이건 생각해보면 사실인데, <em>partition</em> 과정에서 일어나는 비교가 각 <em>sub-problem</em> 에서의 연산 수를 결정한다.</p>

<p>이렇게 하면 연산수의 기대값, 다시 말해서 <em>비교가 일어나는 회수의 평균으로</em>, 퀵소트의 평균 성능을 찾아낼 수 있다.</p>

<p>그런데 입력 배열에 대한 전체 비교 수를 <code>C</code> 라 두면 <code>E(C)</code> 는 사실 구하기가 굉장히 어렵다. 그런데, <code>E(C)</code> 를 시그마 두번으로 분해할 수 있고, 심지어 가장 내부의 항은 <code>1</code> 또는 <code>0</code> 을 가지는 원소이다. 따라서 <em>linearity of expectation</em> 을 이용할 수 있다 <del>할렐루야</del> </p>

<p>참고로 가장 내부의 항에 대해서 설명하자면, 전체 입력에서 두개의 원소를 골랐을 때 이 두개의 원소가 비교 되는 수다. 이 두개의 원소는 <code>i</code>, <code>j</code> 를 기준으로 구할 수 있으므로 <code>X_ij</code> 라 두면 <code>i, j</code> 에 각각에 대해 시그마를 씌울 수 있다. 이것이 <code>C</code> 이므로 <code>E(C)</code> 를 구하기는 상당히 복잡함을 알 수 있다. 그런데 <code>X_ij</code> 자체는 <code>0</code> 또는 <code>1</code> 만 가지는 값이니 이것에 대해 <code>E(X_ij)</code> 를 구하면 심플해진다. (수식을 적기 힘드니 자세한 내용은 강의 <em>Analysis I: A Decomposition Principle</em> 을 참조)</p>

<p>따라서 <code>E(C)</code> 는 <code>sigma i &lt;- 1 to n-1, sigma j &lt;- i+1 to n P(X_ij = 1)</code> 이다. </p>

<p>여기서 잠깐 이제 까지 나온 <em>decompositio principle</em> 을 설명하자면</p>

<p>(1) 구하고자 하는 랜덤 변수 <code>Y</code> 를 정의하고 <br />
(2) <code>Y</code> 를 더 간단한 랜덤 변수 <code>X</code> 의 합으로 정의하자. <code>X</code> 가 0 또는 1만 가지는 값이면 더 좋다. 
(3) <em>linearity of expectation</em> 을 적용  </p>

<p>다시 말해 알고리즘의 성능을 결정하는 <em>dominant operation</em> 을 확률변수로 표현할 수 있고, 더 간단한 확률 변수의 합으로 표현할 수 있다면 해해 여기에 <em>기대값의 선형성</em> 을 이용해 알고리즘의 평균적인 성능을 구할 수 있다는 뜻이다.</p>

<p><code>sigma i &lt;- 1 to n-1, sigma j &lt;- i+1 to n P(X_ij = 1)</code> 다시 이 식으로 돌아오자. 여기에 적용할 수 있는 퀵소트의 특징이 있다. 여기서 <code>z_i</code> 를 정렬된 배열의 <code>i</code> 번쨰 원소라 했을때 <em>pivot</em> 이 될 수 있는 것은 <code>z_i, z_i+1, ... z_j-1, z_j</code> 다. 이때</p>

<p>(1) <code>z_i</code> 또는 <code>z_j</code> 가 <em>pivot</em> 이 되면, 즉 가장 작은 수나 가장 큰 수가 <em>pivot</em> 이 되면 <code>z_i</code> 와 <code>z_j</code> 는 한번만 비교된다. (이후에는 다른 재귀로 넘어가 둘 중 하나의 수만 남음) <br />
(2) <code>z_i+1</code>, ..., <code>z_j-1</code> 이 <em>pivot</em> 이 되면 <code>z_i</code> 와 <code>z_j</code> 는 절대로 비교되지 않는다. <em>pivot</em> 기준으로 큰 수와 작은수는 서로 비교되지 않으며 둘 다 피벗과만 비교된다. 이후에도 다른 파티션으로 나누어져 비교되지 않는다.</p>

<p>따라서 각 <em>sub-problem</em> 에서 일어나는 비교가 일어날 확률은 <code>2 / (j - i + 1)</code> 이다. 다시 말해서 전체 원소 중에서 <code>z_i</code> 와 <code>z_j</code> 를 피벗으로 삼는 경우에만 비교가 일어난다.</p>

<p>따라서 평균 연산 수 <code>E(C)</code> 는 <code>sigma i &lt;- 1 to n-1, sigma j &lt;- i+1 to n [2 / (j -i + 1)]</code> 이다.</p>

<p>이때 <code>j = i +1</code> 부터 시작하므로 내부 시그마는 <code>1/2 + 1/3 + ... 1/n</code> 이다. 그리고 내부 시그마에서 <code>i</code> 가 사라졌으므로 외부 시그마 <code>i &lt;- 1 to n-1</code> 을 <code>n-1</code> 대신 대략 <code>n</code> 이라고 놓으면,</p>

<p><code>E(C) &lt;= 2 * n * [sigma k &lt;- 2 to n (1/k)]</code> 다. </p>

<p>이때 <code>sigma k &lt;- 2 to n (1/k)</code> &lt;= <code>ln n</code> 인데, 본래 식의 <code>k</code> 1 부터의 시그마보다 작으므로 이걸 적분으로 넓이를 구하면 <code>ln n - ln 1 =  ln n</code> 이다. </p>

<p>따라서 <code>E(C) &lt;= 2 * n * ln n</code></p>

<h3 id="notes">Notes</h3>

<p>이하는 필기 노트입니다. </p>

<h4 id="matrixmultiplication">matrix multiplication</h4>

<p>단순히 brute force 로 3 for-loop 로 구현하면 당연히 o(n^3) -_-;</p>

<p>스트라센 매트릭스 곱셈으로 구현하면 놀랍게도 n^2 </p>

<h4 id="multiplication">Multiplication</h4>

<ol>
<li>define Input, output  </li>
<li>assess performance</li>
</ol>

<p>can we do better strait forard?</p>

<p>일반적인 곱셈(초등3학년)은 2n * n</p>

<h4 id="karatsubamultiplication">Karatsuba Multiplication</h4>

<p>a * c <br />
b * d = 2652 <br />
(a + b)(c + d) = 6164
(a+b)(c+d) - a*c - b * d = 2840</p>

<p>ad bc </p>

<p>6164 + * 10000 <br />
+ 2652
+ 2840 * 100</p>

<p>x = 10^n/2 a + b <br />
y = 10^n/2 c + d</p>

<p>x * y => 10^n ac + 10 n/2 (ad+bc) + bd <br />
따라서 <em>Karatsuba multiplication</em> 은 <em>product</em> 문제를 ac, ad, bc, bd 의 곱으로 쪼갬.</p>

<p>여기서도, ac, ad, bc, bd 를 모두 구하는 대신에</p>

<p>(a+b)(c+d) - ac bd 를 빼면,  ac bd (a+b)(c+d) 3개만 구하면 된다.</p>

<p>따라서 3개의 recursive multiplication 만 필요</p>

<h4 id="closestpairs">Closest Pairs</h4>

<p>brute force 는 n^2 인데, </p>

<p>1D 의 closest pair 에서 sorting 하면 n^2 가 아니라 nlogn 이다.</p>

<p>로직은 다음과 같다.</p>

<p>문제를 반으로 잘라가면서 왼쪽에서 거리가 가장 짧은것 좌표 쌍, 오른쪽에서 가장 짧은것을 찾고, 각 영역에 좌표가 하나씩 있는 쌍도 검사 한다.</p>

<p>(1) 주어진 배열을 P 라 하고 반으로 각각 좌우 Q, R 자른다. O(n) Q를 x 정렬한것을 Qx, y 축 기준으로 Qy, R도 Rx, Ry. 이건 전체 인풋 n 에 대해서 n logn <br />
(2) ClosestPair(Qx, Qy), Closest(Rx, Ry) 해서 각각 좌 우에서 가장 짧은 거리를 가진 pair 쌍을 찾는다.  이걸 (p1, q1), (p2, q2)  라 하면 <br />
(3) (p1, q1), (p2, q2) 의 거리를 구해 최소값인 d 를 찾는다 <br />
(4) Closest(Px, Py, d) 해서 (p3 , q3) 가 있으면 찾아낸다. 여기서 찾은건 하나는 Q 하나는 R 에 있는 d 보다 작은 거리를 가진 점의 쌍 <br />
(5) p1, p2, p3 쌍중 가장 작은 d 를 가진 것을 리턴 </p>

<p>ClosestSplitPair</p>

<p>(1) Px 의 가운데 점을 xBar 라 하면 이것 기준으로 -d, +d 의 x 값을 가진 점들을 Py 에서 찾아낸다. 정의에 의해서 x1 - x2 &lt;= d 이기 때문에 아무리 커봐야 xBar 기준으로 좌우 d 까지밖에 존재하지 못함. 이걸 Sy 라 부르자. 이건 Py 가 이미 정렬되어 있기 때문에 O(n) 시간. <br />
(2) Sy 는 y 축 기준으로 이미 정렬되어 있는데, 여기서 Sy 의 원소를 루프로 돌면서 이것 기준으로 +7개 원소를 검사하면서 거리가 d 보다 작은것이 있는지 검사. 이것 또한 마찬가지로 d 의 정의와 두 점이 Q, R 에 있다는 점을 이용해서 증명이 가능함. </p>

<p>y1 - y2 도 d 보다 작거나 같이 때문에 y 기준으로 정렬된 점을 기준으로 잡았을때, </p>

<p>p 와 같은 왼편에 있는 것들은 p와의 거리가 d 보다 작을 수 없다. 왜냐하면 d 자체가 같은 사이드에 있는 것들의 최소 거리이기 때문. <br />
이런점들을 아무리 많이 왼쪽에 구겨 넣어도 3개. p 포함하면 4개다. 마찬가지로 q 와 같은 편에 있는것들도 3개.</p>

<p>따라서 운이 나쁠 경우 Sy 에서 p, q + 6개를 더 검사해야. </p>

<p>직사각형을 그려보면 이해가 쉬움.</p>

<p>Input 은 (x1, y1) ... (xn, yn) 의 pair n개 편의상 p1, p2, ... pn</p>

<p>d(p<em>i, p</em>j) 는 두 point 사이 거리</p>

<p>(1) 모든 점들을 x 기준으로 정렬했을때 가운데에 있는 점을 xBar 라 하면 S<em>y 는 xBard - d, xBar + d 사이에 있는 모든 점이다. 만약에 왼쪽에 있는 p, 오른쪽에 있는 q 가 존재한다면 이 둘은 S</em>y 사이에 있고 아래 증명에 에해서 x1, x2 사이 거리는 d 보다 작다.</p>

<p>왜냐하면, p(x1, y1), q(x2, y2) 사이의 거리가 d 보다 작기 때문에 x1 - x2 &lt;= d 이다. </p>

<p>(2) S_y 에서 p, q 가 존재한다면 그건 y 기준으로 7 원소 이내에 인접해 있다. </p>

<h3 id="references">References</h3>

<p>(1) <a href='https://acrocontext.wordpress.com/' >https://acrocontext.wordpress.com</a> <br />
(2) <a href='http://sadakurapati.wordpress.com/2013/10/25/quicksort-a-practical-and-efficient-sorting-algorithm/' >http://sadakurapati.wordpress.com</a> <br />
(3) <a href='http://www.opendatastructures.org/ods-java/1_3_Mathematical_Background.html' >http://www.opendatastructures.org</a></p>]]></description><link>http://1ambda.github.io/divide-and-conquer/</link><guid isPermaLink="false">30db0108-971b-46ea-8793-427ecb229117</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[divide and conquer]]></category><category><![CDATA[master method]]></category><category><![CDATA[merge sort]]></category><category><![CDATA[quick sort]]></category><category><![CDATA[decomposition principle]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 29 Oct 2014 13:02:22 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 1]]></title><description><![CDATA[<p>먼저 이 글은 <strong>edx</strong> 의 <em>FP101.x (Introduction to Functional Programming)</em> 수업을 기반으로 작성되었음을 알려드립니다.</p>

<p>시작에 앞서서, 하스켈을 설치하려면 <a href='http://www.haskell.org/platform/linux.html' >Haskell Platform</a> 을 설치하신 후 터미널에서 <code>ghci</code> 를 입력하면 됩니다. 하스켈 플랫폼은 하스켈 구현체로 <a href='http://www.haskell.org/ghc/' >Glasgow Haskell Compiler, <em>GHC</em></a> 를 포함하고 있습니다. <code>ghci</code> 를 입력하면 하스켈 인터프리터를 사용할 수 있습니다.</p>

<p>깔기 귀찮으시다면 <a href='https://www.fpcomplete.com/' >https://www.fpcomplete.com/</a> 여기서 웹으로 코드를 작성하고 컴파일 할 수 있습니다.</p>

<h3 id="basics">Basics</h3>

<p>먼저 <code>sum [1..10]</code> 을 인터프리터에 입력하면 1부터 10 까지의 합, <code>55</code> 을 돌려줍니다. <code>sum</code> 은 리스트의 원소를 모두 합한 값을 구하는 함수고 <code>[1..10]</code> 은 1-10 을 포함하는 리스트를 생성합니다.</p>

<p>이제 인터프리터를 잠깐 끈 후에 <em>quick-sort</em> 함수를 파일에 작성한 뒤 로드해 봅시다. 아참, <code>ghci</code> 를 종료하려면 <code>ctrl + d</code> 를 입력합니다.</p>

<pre><code class="haskell">-- quicksort.hs

f [] = []  
f (x:xs) = f ys ++ [x] ++ zs  
           where
             ys = [a | a &lt;- xs, a &lt;= x]
             zs = [b | b &lt;- xs, b &gt; x]
</code></pre>

<p>수학 표기법 같은데, 놀랍게도 잘 동작합니다. 다시 <code>ghci</code> 실행하고 <code>:load quicksort.hs</code> 를 입력합니다. 그러면 우리가 작성한 <code>f</code> 함수가 인터프리터에 로드 됩니다. <em>퀵-소트</em> 를 사용할 수 있다는 뜻이죠.</p>

<pre><code>ghci &gt; f [3, 2, 9, 5, 4]  
[2, 3, 4, 5, 9]
</code></pre>

<p>제대로 정렬 되는걸 확인할 수 있습니다. 매번 인터프리터를 종료했다가 다시 실행시키긴 귀찮으니 파일을 다시 수정했을때 <code>:reload</code> 명령어를 사용해서 다시 로드합니다. 이외에도 다른 명령어를 보고싶다면 <code>ghci</code> 에 <code>:help</code> 를 입력해보세요.</p>

<p>이제 대충 어떻게 돌아가는지 알았으니 기본적인 함수를 좀 알아볼까요? 다른 함수형 언어처럼 하스켈도 <code>List</code> 에 대한 기본적인 연산들이 있습니다.</p>

<pre><code class="haskell">head [2, 3, 4] -- 2  
tail [2, 3, 4] -- [3, 4]

head [2] -- []  
tail [2] -- []

init [2, 3, 4] -- [2, 3]  
last [2, 3, 4] -- 4

take 2 [2, 3, 4] -- [2, 3]  
drop 2 [2, 3, 4] -- [4]  
</code></pre>

<p>리스트 원소에 접근하려면 <code>!!</code> 를 이용합니다. 다른 언어와 마찬가지로 <code>0</code> 부터 인덱스가 시작합니다. </p>

<pre><code class="haskell">[1, 2, 3, 4] !! 1 -- 2
[1, 2, 3, 4] !! 2 -- 3
[1, 2, 3, 4, 5] !! 2 -- 3
[1, 2, 3, 4, 5] !! 0 -- 1
</code></pre>

<p>하스켈의 리스트는 자료구조의 그것처럼, <code>n</code> 번째 원소에 접근하려면 <code>O(n)</code> 의 비용이 듭니다. 그런 이유에서 리스트의 원소를 구하는 <code>length</code> 도 <code>O(n)</code> 의 비용이 듭니다. 자바의 배열과는 좀 다르죠? </p>

<p>이제 리스트에 대한 몇 가지 연산을 더 알아봅시다.</p>

<pre><code class="haskell">product [1, 2, 3, 4, 5] -- 120  
[1, 2, 3] ++ [4, 5] -- [1, 2, 3, 4, 5]
reverse [1, 2, 3, 4] -- [4, 3, 2, 1]  
</code></pre>

<p><code>++</code> 는 <em>append</em> 연산입니다. 앞에 온 리스트에, 뒤에 온 리스트를 붙여줍니다. </p>

<h3 id="functionapplication">Function Application</h3>

<p>이제 함수를 사용하는 법을 좀 알아볼까요? 일반적으로 <code>f</code> 라는 함수에 파라미터 <code>a</code> 를 적용하려면 <code>f(a)</code> 이렇게 쓸 텐데요. 하스켈에선 <code>f a</code> 라고 작성해도 됩니다. 왜냐하면 함수의 우선순위가 다른 연산자들보다 높거든요</p>

<blockquote>
  <p>Function application is assumed to have higer priority than all other operators</p>
</blockquote>

<p>이런 이유에서 <code>f a + b</code> 는 <code>f(a) + b</code> 입니다. <code>f(a + b)</code> 를 의도했다면 <code>f(a + b)</code> 라고 쓰셔야 합니다.</p>

<pre><code class="haskell">f x -- f(x)  
f x y -- f(x, y)  
f (g x) -- f(g(x))  
f x (g y) -- f(x g(y))  
f x * g y -- f(x) * g(y)  
</code></pre>

<p>이제 좀 스크립트에 다른 함수를 작성해 볼까요?</p>

<pre><code class="haskell">-- test.hs

double x = x + x  
quadruple x = double (double x)  
</code></pre>

<p><code>double</code> 은 <em>function</em> 이고 왼쪽에 오는 <code>x</code> 는 <em>argument</em> 입니다. <code>=</code> 뒤에 오는건 함수의 <em>body</em> 로 함수가 무슨일을 하는지 기록한 것이죠.</p>

<p>이제 <code>:load test.hs</code> 후 <code>take (double 2) [1, 2, 3, 4, 5, 6]</code>을 입력하면 <code>[1, 2, 3, 4]]</code> 를 돌려줄겁니다. 다른 함수를 좀 더 만들어 봅시다.</p>

<pre><code class="haskell">-- test.hs

factorial n = product [1..n]  
avg ns = sum ns `div` length ns  
</code></pre>

<p><code>factorial</code> 은 별로 놀랍지 않죠? 그런데 평균을 구하는 <code>avg</code> 는 문법이 좀 신기합니다. <code>ns</code> 는 리스트입니다. <code>sum</code> 을 적용해야 하니까요. 그리고 끝에 <code>s</code> 를 붙이는건 관례인데, 일반적으로 변수 끝에 <code>s</code> 를 붙이면 리스트란 뜻입니다. <code>ns</code> 란 이름은 <em>정수 리스트</em> 라고 알려주는 것이지요. </p>

<p><code>sum ns</code> 는 <code>ns</code> 의 합을 구하고, <code>length ns</code> 는 <code>ns</code> 의 길이를 구합니다. <code>div</code> 함수를 <em>back-quote</em> 감싼 것은 함수가 두개의 파라미터를 가질때 가운데 위치할 수 있도록 해 줍니다. </p>

<p>그래서 <em>back quote</em> 로 감싼  함수를 만나면 하스켈 컴파일러는 <strong>"왼쪽과 오른쪽에 있는 것들을 파라미터로 가지는 함수"</strong> 임을 깨닫죠. 이런 문법은 <code>3 / 5</code> 처럼 함수를 <em>operator (연산자)</em> 쓰듯이 사용할 수 있게 해줍니다. 따라서 위에 나온 코드의 본래 모양은 이렇습니다.</p>

<pre><code class="haskell">avg ns = div (sum ns) (length ns)  
</code></pre>

<blockquote>
  <p><em>x <code>f</code> y</em> is just <strong>syntatic sugar</strong> for <em><code>f</code> x y</em></p>
</blockquote>

<p>아참 그리고 함수의 이름은 소문자로 시작해야 합니다. <code>Avg</code> 는 함수 이름으로 쓸 수 없어요. 그리고 <code>nss</code> 처럼 변수 이름이 <code>s</code> 두개로 끝나면, 그건 리스트의 리스트라는 것을 뜻합니다. 물론 관례죠. 필수는 아닙니다. 그러나 우리가 작성하는건 남들이 볼 수도 있으니 따라주는 편이 좋습니다.</p>

<p>그리고 변수의 정의에 대해 <em>layout</em> 을 지키면 <code>{}</code> 블럭을 안 사용해도 됩니다. 예를 들어 다음의 두 코드는 똑같은 코드입니다.</p>

<pre><code class="haskell">a = b + c  
    where
      b = 1
      c = 2
d = a * 2

a = b + c  
    where
      { b = 1
      c = 2 }
d = a * 2  
</code></pre>

<h3 id="booleantuple">Boolean, Tuple</h3>

<p>하스켈은 대 소문자를 구분하기 때문에 <em>Boolean false</em> 를 얻을려면 <code>False</code> 를 입력해야 합니다.</p>

<pre><code class="haskell">False || True -- True  
</code></pre>

<p>괄호로 감싼 두개의 값들을 <em>tuple</em> 이라 부릅니다. <em>list</em> 는 같은 종류만 담을 수 있지만 <em>tuple</em> 은 달라도 상관 없지요. <code>fst</code>, <code>snd</code> 는 <em>tuple</em> 에서 첫 번째 와 두 번째 값을 돌려주는 함수입니다.</p>

<pre><code class="haskell">fst (1, "Hello") -- 1  
snd (1, "Hello") -- "Hello"  
fst (snd (1, (2, 3))) -- 2  
</code></pre>

<p>아참, <code>ghci</code> 에서 <code>:t</code> 을 입력하면 <em>expression</em> 의 타입을 알 수 있습니다. <code>:t False</code>, <code>:t length</code>, <code>:t head</code>, <code>:t (1, "Hello")</code> 등을 입력해보세요.</p>

<h3 id="types">Types</h3>

<p>다른 언어처럼 하스켈도 타입이 있습니다. <code>False</code> 와 <code>True</code> 은 <code>Bool</code> 타입이죠. <code>ghci</code> 에서 <code>:t False</code> 를 입력하면 <code>False :: Bool</code> 이란 결과를 돌려줍니다. <code>e :: t</code> 는 <code>e</code> 가 <code>t</code> 타입을 가지고 있다는 뜻입니다.</p>

<p>모든 <em>expression (식)</em> 은 타입을 가지고 있습니다. 하스켈 컴파일러는 컴파일 타임에 <em>type inference (타입 추론)</em> 을 통해서 타입을 찾아냅니다. 만약 함수의 타입과 불일치하는 인자가 파라미터로 넘겨진다면 타입 에러가 발생하는 것이지요.</p>

<p>하스켈에서 문자열을 나타내는 타입인 <code>String</code> 은 사실 문자 하나를 의미하는 <code>Char</code> 의 리스트입니다. </p>

<p>그리고 <em>fixed-precision integer</em> 를 의미하는 <code>Int</code> 이외에도  파이썬 처럼 <em>arbitrary-precision integer</em> 를 위한 <code>Integer</code> 타입이 있습니다. 실수는 <code>Float</code> 타입을 이용해 나타냅니다.</p>

<p>앞서 언급했듯이 <em>Tuple</em> 과 달리 <em>List</em> 는 같은 타입만 가질 수 있습니다. 그래서  <code>[False, False, True]</code> 의 경우  <code>[Bool]</code> 타입입니다. 문자열은 문자의 리스트이므로 <code>String</code> 타입은 <code>[Char]</code> 입니다. 스트링의 리스트는 <code>[String]</code> 이고 더 정확히는 <code>[[Char]]</code> 입니다.</p>

<p>그리고 아까는 <em>Tuple</em> 을 두개의 원소만 가질 수 있다고 했지만 사실은 두개 이상의 원소를 가질 수 있습니다 <code>n</code> 개의 원소를 가진 <em>tuple</em> 을 <em>n-tuple</em> 이라 부릅니다. 예를 들어 이런 <em>tuple</em> 도 있을 수 있습니다.</p>

<pre><code class="haskell">(False, 'a', True) :: (Bool, Char, Bool)
(True, ['a', 'b']) :: (Bool, [Char])
</code></pre>

<h3 id="functiontype">Function Type</h3>

<p>함수는 한 타입의 값을 다른 타입의 값으로 매핑합니다.</p>

<blockquote>
  <p>A <em>function</em> is a mapping from values of one type to values of another types</p>
</blockquote>

<p>예를 들어 <code>:t not</code> 을 <code>ghci</code> 에서 입력하면 아래처럼 출력됩니다. 
<code>not</code> 함수는 <code>Bool</code> 타입을 받아 <code>Bool</code> 타입을 돌려준다는 뜻입니다.</p>

<pre><code class="haskell">not :: Bool -&gt; Bool  
</code></pre>

<p>이제 파일에 타입까지 같이 명시해서 함수를 작성해 봅시다.</p>

<pre><code class="haskell">add :: (Int, Int) -&gt; Int  
add (x, y) = x + y

zeroto :: Int -&gt; [Int]  
zeroto n :: [0..n]  
</code></pre>

<p>함수가 만약 <em>tuple</em> 을 인자로 받으면 괄호가 필요합니다.</p>

<h3 id="curriedfunction">Curried Function</h3>

<p>여기서 잠깐 <em>Currying</em> 을 설명할 텐데요, 하스켈에서 빠질 수 없는 부분이니 이해가 어렵다면 다른 글을 찾아서라도 이해를 하시는 편이 좋습니다.</p>

<p><em>Currying</em> 의 기본 개념은 이렇습니다. 함수가 <code>(Int, Int) -&gt; Int</code> 타입이라면 <strong>계산을 끝내기 위해 두개의 정수를 받아</strong> 하나의 <code>Int</code> 를 돌려줄겁니다. </p>

<p>다시 한번 반복하자면, 계산을 끝내기 위해서는 두개의 정수가 필요합니다. 그렇다면 하나의 정수만 받고, 나머지는 계산이 필요한 시점에 받으면 안될까요?</p>

<pre><code class="haskell">Int -&gt; (Int -&gt; Int)  
</code></pre>

<p>바꿔 말해서, 인자 하나를 받아서 계산을 일정부분 해 내고, 나머지는 <strong>인자를 하나 더 받아 계산을 마무리 해 돌려주는 함수</strong> 를 리턴해도 괜찮지 않을까요? 나머지 계산은 그 함수에서 할거니까, 결국 인자 2개로 계산을 해 내는 건 똑같으니까요.</p>

<p>이게 <em>Currying</em> 의 기본 개념입니다. 다시 말해서 다음의 두 타입은 같은 일을 한다는 거죠.</p>

<pre><code class="haskell">(Int, Int) -&gt; (Int)

-- same as
Int -&gt; (Int -&gt; Int)  
</code></pre>

<p>이게 언제 유용할까요? 인자를 부분적으로 채운 함수가 필요할 때를 생각 해 봅시다. </p>

<pre><code class="haskell">add :: Int -&gt; (Int -&gt; Int)  
add x y = (x + y)

add3 = add 3  
add3 4 -- 7  
</code></pre>

<p>3을 미리 더 해놓은 <code>add3</code> 이란걸 만들어서 써먹었습니다. 이렇게 <em>Currying</em> 을 활용할 수 있죠. <code>:t</code> 를 입력하면 <code>Int -&gt; Int</code> 를 확인할 수 있습니다. <code>:take 5</code> 도 <em>curried function</em> 이죠.</p>

<p><strong>결국 <em>Currying</em> 은 <code>n</code> 개의 인자를 가진 함수를 <code>n-1</code> 개의 부분적으로 계산된 함수로 바꿀 때</strong> 쓸 수 있습니다. 단지 <code>n</code> 개의 파라미터만 가진 <strong>하나의 함수</strong> 보다 <strong>여러 개의 부분적인 함수</strong>를 만들어 놓으면 재활용 할 수 있으므로 훨씬 좋죠. 인자에 함수를 넘길 수 있는 함수형 언어에서는 함수를 재활용 할 수 있다는 건 정말 좋은 일입니다..</p>

<p>하스켈에서는 <em>Currying</em> 을 아주 중요하게 여깁니다. 얼마나 중요하게 생각하는지, 함수 타입에 괄호가 없으면 자동으로 <em>curried function</em> 이 되게끔 해 놓았지요. 아래의 두 함수는 같습니다.</p>

<pre><code class="haskell">add :: Int -&gt; (Int -&gt; Int)

-- same as

add :: Int -&gt; Int -&gt; Int  
</code></pre>

<p>다시 말해 함수의 타입은 <em>right-associative (우측 결합)</em> 입니다. 반대로 함수의 호출은 <em>left-associative (좌측 결합)</em> 이죠.</p>

<pre><code class="haskell">add 3 4

-- same as

(add 3) 4
</code></pre>

<p>그래서 그냥 함수 타입에 괄호를 안쓰시고 인자의 갯수가 <code>n</code> 개라면 이 함수를 호출 할 때 <code>n-1</code> 개의 <em>curried function</em> 을 호출하신다고 생각하면 됩니다.</p>

<h3 id="generics">Generics</h3>

<p><em>polymorphic</em> 은 <em>of many form (다양한 형태의)</em> 라는 뜻입니다. 프로그래밍에선 주로 다양한 타입을 이야기 할때 사용한 용어인데요, <code>length</code> 같은 경우 타입을 보면 이렇습니다.</p>

<pre><code class="haskell">length :: [a] -&gt; Int  
</code></pre>

<p><code>a</code> 라는 타입은 없으므로 여기선 <strong>아무 타입이나</strong> 와도 된다는 뜻입니다. 다시 말해 <code>length</code> 는 <em>polymorphic function</em> 입니다. 다양한 타입을 취할 수 있는 함수죠. <code>length</code> 는 사실 무슨 타입이 오든 관심이 없습니다. 갯수를 세는데만 정신이 팔려있는 함수지요.</p>

<p>여기서 <code>a</code>는 <em>type variable</em> 이라 부릅니다. <code>a</code> 가 아니라 <code>b</code>, <code>c</code> 등 소문자이기만 하면 됩니다.</p>

<p>참고로 프로그래밍에서 <em>polymorphism</em> 은 <em>generics</em> 와 <em>sub-typing</em> 의 두 가지 개념을 모두 포함하는 용어입니다. <em>generics</em> 는 <em>type parameterization</em> 을, <em>sub-typing</em> 은 <em>type-hierarchy</em> 를 의미하지요.</p>

<p>이제 몇 가지 <em>polymorphic function</em> 을 살펴봅시다.</p>

<pre><code class="haskell">*Main&gt; :t fst
fst :: (a, b) -&gt; a  
*Main&gt; :t head
head :: [a] -&gt; a  
*Main&gt; :t take
take :: Int -&gt; [a] -&gt; [a]  
*Main&gt; :t zip
zip :: [a] -&gt; [b] -&gt; [(a, b)]

*Main&gt; [1, 2, 3] `zip` ['a', 'b', 'c']
[(1,'a'),(2,'b'),(3,'c')]
</code></pre>

<p><em>polymorphic function</em> 이 특정 타입에 대해 제한 되었는 것을 하스켈에서는 <em>overloaded</em> 되었다고 부릅니다. 다시 말해 특정타입에만 해당 함수를 사용할 수 있다는 거죠. 이게 <em>C++</em> 에서의 <em>오버로딩</em> 과는 좀 의미가 다릅니다. </p>

<blockquote>
  <p>It really means that you're restricting the types of the parameters.</p>
</blockquote>

<p>숫자에 대해서만 사용할 수 있는 <code>sum</code> 을 좀 살펴볼까요?</p>

<pre><code class="haskell">sum :: Num =&gt; [a] -&gt; a  
</code></pre>

<p><code>sum</code> 은 정수나 실수에 대해 모두 사용할 수 있지만 문자열에 대해서는 불가능합니다. 이게 바로 <em>overloaded</em> 된 것이죠. 그 부분이 바로 <code>Num =&gt;</code> 이 의미하는 바입니다.</p>

<p>하스켈은 <em>overloading</em> 에 사용할 수 있는 다양한 타입 클래스가 있습니다. <code>Num</code>, <code>Eq</code>, <code>Ord</code> 등이 그것이죠. <code>ghci</code> 에서 <code>==</code> 를 타입 검사 해볼까요? 아참, <code>==</code> 은 <code>:t (==)</code> 로 검사해야합니다.</p>

<pre><code class="haskell">*Main&gt; :t (&lt;) -- Ordered types
(&lt;) :: Ord a =&gt; a -&gt; a -&gt; Bool
*Main&gt; :t (==) -- Equality types
(==) :: Eq a =&gt; a -&gt; a -&gt; Bool
*Main&gt; :t (+) -- Numeric types
(+) :: Num a =&gt; a -&gt; a -&gt; a
</code></pre>

<p>예를 들어 다음의 <code>palindrome</code> 함수 타입을 잘 보세요.</p>

<pre><code class="haskell">palindrome xs = reverse xs == xs

:t palindrome -- Eq [a] =&gt; [a] -&gt; Bool
</code></pre>

<p>다시 말해서 <code>[a]</code> 가 비교가 가능한 <code>Eq</code> 타입이어야 한다는 뜻입니다.</p>

<h3 id="basicclasses">Basic Classes</h3>

<p><code>Eq</code> 는 해당 클래스가 비교할 수 있음을, <code>Ord</code> 는 순서가 있음을 나타냅니다. 기본 타입인 <code>Bool</code>, <code>Char</code>, <code>String</code>, <code>Int</code>, <code>Integer</code>, <code>Float</code> 와 <code>Tuple</code>, <code>List</code> 는 모두 <code>Ord</code> 와 <code>Eq</code> 클래스의 인스턴스입니다. 참고로 하스켈에서 <em>Not equal</em> 은 <code>/=</code> 입니다.</p>

<p><code>(&gt;)</code>, <code>(&gt;=)</code>, <code>(&lt;)</code>, <code>(&lt;=)</code>, <code>max</code>, <code>min</code> 등이 <code>Ord</code> 클래스에 대해 적용할 수 있는 함수입니다. 그리고 <code>String</code>, <code>Tuple</code>, <code>List</code> 는 <em>사전 편찬 순서 (lexicographically)</em> 를 기준으로 비교됩니다. </p>

<h3 id="showabletype">Showable Type</h3>

<p>다른 언어의 <code>toString</code> 이 그렇듯이, <code>Show</code> 클래스의 인스턴스들은 <code>show</code> 함수를 이용하면 <code>String</code> 형태로 출력됩니다.</p>

<pre><code class="haskell">:t show -- Show a =&gt; a -&gt; String
show False -- "False"  
show [1, 2, 3] -- "[1, 2, 3]"  
</code></pre>

<h3 id="readabletype">Readable Type</h3>

<p><code>Read</code> 타입 인스턴스들은 <code>read</code> 함수를 이용해 <code>String</code> 으로부터 얻어질 수 있습니다. </p>

<pre><code class="haskell">:t read -- Read a =&gt; String -&gt; a

read "False" :: Bool  
read "[1, 2, 3]" :: [Int] -- [1, 2, 3]  
</code></pre>

<h3 id="integralfractionalrational">Integral, Fractional, Rational</h3>

<p>단순히 숫자 클래스로 <code>Num</code> 만 있는건 아니고 정수나, 분수, 유리수 등을 나타내는 다양한 클래스가 있고 여기에 적용할 수 있는 함수가 있고, 불가능한 함수가 있습니다. 예를 들어 <code>mod</code> 나 <code>div</code> 는 <code>Integral</code> 에만 적용 가능합니다. <code>(/)</code> 는 <code>Fractional</code> 에만 적용 가능합니다.</p>

<h3 id="guardedequations">Guarded Equations</h3>

<p><code>if</code> 대신에 더 좀 편하게 사용할 수 있는 <em>guarded equation</em> 이 있습니다. <strong>다른 계산 없이</strong> <code>if</code> 만 바로 사용한다면 다음과 같이 바꿔 쓸 수 있죠.</p>

<pre><code class="haskell">abs n = if n &gt;= 0 then n else -n  
signum n = if n &gt; 0 then 1 else  
             if n &lt; 0 then -1 else 0

-- same as

abs n | n &gt;= 0 = n  
      | otherwise = -n 

signum n | n &gt; 0 = 1  
         | n &lt; 0 = -1
         | otherwise = 0 
</code></pre>

<h3 id="patternmatching">Pattern Matching</h3>

<p><em>Scala</em> 나 <em>C#</em> 과는 다르게 하스켈은 패턴매칭을 바로 이용합니다. <code>case</code> 나 <code>switch</code> 없이요! 예를 들어</p>

<pre><code class="haskell">not :: Bool -&gt; Bool  
not False = True  
not True = False  
</code></pre>

<p>패턴 매칭은 위에서 부터 순서대로 적용됩니다. 예를 들어 <code>not False = False</code> 가 코드에 제일 위에 있다면 항상 <code>False</code> 만 돌려줄거에요. 우울한 일이 될겁니다.</p>

<p>이제 2개의 피 연산자를 갖는 연산자 <code>&amp;&amp;</code> 를 패턴매칭을 이용해 만들어 볼까요? 좌 우에 피 연산자를 가지는 함수를 만들기 위해서는 <code>(*)</code> 처럼 괄호로 감싸면 됩니다. </p>

<pre><code class="haskell">(&amp;&amp;) :: Bool -&gt; Bool -&gt; Bool

True &amp;&amp; True = True  
False &amp;&amp; False = False  
False &amp;&amp; True = False  
True &amp;&amp; False = False  
</code></pre>

<p>더 간단히는 <code>_</code> 를 이용할 수 있죠. <em>wild card pattern</em> 이라고 부릅니다. <code>_</code> 는 <em>아무거나 (Anything)</em> 이라고 생각하시면 됩니다. 스칼라를 배우셨다면 익숙하신 기호죠! $</p>

<pre><code class="haskell">(&amp;&amp;) :: Bool -&gt; Bool -&gt; Bool
True &amp;&amp; True = True  
_ &amp;&amp; _ = False  
</code></pre>

<p>그러나 위 정의보다 더 효율적인 <code>(&amp;&amp;)</code> 를 만드는 방법이 있습니다. 위 패턴매칭에서 둘 다 <code>True</code> 일 경우 우측 <code>True</code> 는 사실 평가할 필요가 없습니다. 매칭 시켜봤자 어차피 <code>True</code> 니까요.</p>

<pre><code class="haskell">True &amp;&amp; b = b  
False &amp;&amp; _ = False  
</code></pre>

<p>이 경우 패턴매칭에서 <code>b</code> 는 변수입니다. 왼쪽 피연산자가 <code>False</code> 일 경우도 우측 피 연산자 <code>_</code> 를 <em>evaluation (평가)</em> 하지 않고 바로 <code>False</code> 를 줍니다. 다시 말해 더 효율적이란 뜻이지요.</p>

<p>아참 그리고 패턴매칭에서 동일한 변수를 두번 사용할수 없습니다. <code>b &amp;&amp; b = b</code> 는 에러를 내뿜습니다. 주의하세요</p>

<h3 id="listpatterns">List Patterns</h3>

<p>함수형 언어에서는 리스트가 주된 자료구조 이기 때문에 패턴매칭에 리스트를 사용할 수 있다면 프로그래머의 삶을 편하게 만들 수 있습니다. </p>

<p><code>:</code> 는 <em>Cons</em> 라 부르는 연산자인데요, <code>[1, 2, 3, 4]</code> 는 <code>1 : 2 : 3 : 4 : []</code> 더 정확히는 <code>1 : (2 : ( 3: (4 : []))))</code> 입니다. 즉 원소와 뒤에오는 리스트를 연결해주는 것이죠. 요로코롬 패턴매칭에 활용할 수 있습니다.</p>

<pre><code class="haskell">head (x : _) = x  
tail (_ : xs) = xs  
</code></pre>

<p><code>head</code> 나 <code>tail</code> 모두 패턴이 <em>비어있지 않은 리스트</em> 이므로 빈 리스트가 인자로 올때는 에러가 납니다. 그리고, 함수 적용의 우선순위가 다른 연산자들 보다 높기 때문에 <code>head x:_</code> 는 <code>(head x) : _</code> 가 되어 에러가 납니다. 괄호를 잊지마세요.</p>

<h3 id="lambdaexpression">Lambda Expression</h3>

<p><em>lambda (람다)</em> 는 이제 유명합니다. <em>Java 8</em> 에도 추가되었으니 인기있는 대부분의 언어는 람다를 가지고 있죠. 익명함수라고 불리기도 하는데, 하스켈에선 <code>\</code> 를 이용해 람다를 표시합니다. 이를테면, <code>\x -&gt; x + 1</code> 처럼요. 람다가 왜 유용하나면</p>

<p>(1) <em>currying</em> 을 이용해 정의된 함수를 좀더 의미있게 표현할 수 있습니다.</p>

<blockquote>
  <p>Lambda expressions can be used to give a formal meaning to functions defined using <em>currying</em></p>
</blockquote>

<p>이를테면 다음의 두 함수는 동일합니다. 아래 람다를 이용해 정의한 식이 함수를 리턴하는 함수라는 의미가 더 강하죠.</p>

<pre><code class="haskell">add x y = x + y

-- same as

add = \x -&gt; (\y -&gt; x + y)

const :: a -&gt; b -&gt; a  
const x _ = x

-- same as

const :: a -&gt; (b -&gt; a)  
const x  
</code></pre>

<p>(2) 람다를 이용하면 컴퓨터 과학의 가장 큰 난제중 하나인 <em>naming (명명)</em> 을 피할 수 있습니다!</p>

<pre><code class="haskell">odds n = map f [0..n]  
          where
        f x = x `mod` 2 /= 0

odds1 n = map (\x -&gt; x `mod` 2 /= 0) [0..n]  
</code></pre>

<h3 id="sections">Sections</h3>

<p><em>in-fix operator</em> 는 괄호를 더해 맨 앞으로 끌어올 수 있습니다.</p>

<blockquote>
  <p>An operator written between its two arguments can be converted int a curried function written before its two arguments by using parentheses.</p>
</blockquote>

<pre><code class="haskell">1 + 2 -- 3

-- same as

(+) 1 2 -- 3
</code></pre>

<p>이렇게 연산자를 앞으로 옮길 수 있게 되면 피 연산자 하나와 괄호를 엮을 수 있습니다. <code>(x+)</code> 또는 <code>(+x)</code> 처럼요. 이렇게 피연산와 연산자가 괄호로 묶인 것을 <em>section</em> 이라 부릅니다. <code>x + y</code> 를 이용하면 두개의 섹션을 만들 수 있습니다. <code>(x+)</code> 와 <code>(+y)</code> 입니다.</p>

<p><em>section (섹션)</em> 은 언제 유용할까요? 우리는 섹션을 이용하면 람다를 만들어 주는 대신에 좀 더 의미있는 <em>partiall applied function (부분 함수)</em> 를 만들 수 있습니다.</p>

<p>이를테면 <code>double (k (/2))</code> 처럼요</p>

<p>이외에도 섹션은 연산자의 타입을 기술하거나 <code>(&amp;&amp;) ::</code>, 연산자가 다른 함수의 인자로 들어갈때 필요합니다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Programming Haskell</em></p>]]></description><link>http://1ambda.github.io/haskell-intro1/</link><guid isPermaLink="false">f011324c-e0cc-44ef-97ae-7aa23d60adc6</guid><category><![CDATA[programming language]]></category><category><![CDATA[functional programming]]></category><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Mon, 27 Oct 2014 09:18:37 GMT</pubDate></item><item><title><![CDATA[Functional Programming in Scala, Chapter 6]]></title><description><![CDATA[<p>지난 시간에는 <em>referential transparency (참조투명성)</em> 과 함수형 언어에서의 귀납법인 <em>structural induction</em> 에 대해서 배우고, 몇 개의 예제를 증명했었다. </p>

<p>이번 시간에는 스칼라의 컬렉션인 <code>Seq</code>, <code>Set</code>, <code>Map</code> 을 알아보고 마지막 챕터에서는 여기에 <em>higher-order function</em> 을 더해 미친듯한 표현력을 가진 코드를 작성해 본다. <del>one-liner 의 절정을 보여주시는 교수님</del></p>

<p>(번역이 서툴러 어중간한 의역을 하느니 단어를 그대로 사용하고 필요할 경우 원문을 첨부한다)</p>

<h3 id="othercollections">Other Collections</h3>

<h4 id="vector">Vector</h4>

<p><code>List</code> 는 처음 원소는 <code>O(1)</code> 로 빠르게 접근하지만, 중간이나 마지막 원소에 대해서는 조금 느린편이다. 만약에 중간이나 마지막 원소에 대한 탐색을 빠르게 하고싶다면 다른 <em>sequence implementation</em> 인 <code>Vector</code> 를 사용하면 된다. <code>Vector</code> 는 다른 원소들에 대한 접근이 <em>evenly balanced</em> 하다. </p>

<blockquote>
  <p>This one has more evenly balanced access pattern then <code>List</code>.</p>
</blockquote>

<p><code>Vector</code> 는 <code>2^5 = 32</code> 개의 원소를 가진 리스트의 트리로 구현된다. 따라서 처음 단계에서는 <code>2^5</code> 개를 저장할 수 있고, 그 다음 단계에서는 <code>2^5 * 2^5 = 2^10</code>, 그 다음 단계에서는 <code>2^15</code> 를 저장할 수 있다. <code>2^5</code> 의 배수만큼 증가하는 것이다. <em>binary tree</em> 에서 자식의 갯수가 <code>2</code> 개가 아니라 <code>32</code> 개라고 생각하면 된다.</p>

<p>이런 이유로, 원소를 탐색하는데 걸리는 시간은 <code>log_32 (N)</code> (<em>32 based-log</em>) 라 보면 된다. <em>random access</em> 에 대해서는 <code>List</code> 보다 훨씬 낫다.</p>

<p><code>Vector</code> 의 또 다른 장점은 <code>map</code>, <code>for</code> 같은 <em>bulk operator</em> 에 대해서 빠른 연산이 가능하다는 것이다. 이것은 원소들이 32개씩 뭉쳐있기 때문에 <em>single cache line</em> 에 있을 확률이 높아진다. 리스트의 경우에는 콘셀이 같은 <em>cache line</em> 에 있으리라는 보장이 없기 때문에 <code>Vector</code> 보다 <em>locality</em> 가 떨어진다.</p>

<p>그럼 <code>List</code> 가 필요없을까? 그렇지 않다. <code>head</code>, <code>tail</code> 과 같은 연산을 할때 빠르다. 깊이가 깊은 <code>Vector</code> 구조에서, <code>head</code> 나 <code>tail</code> 의 경우 몇 번의 연산이 필요한지 생각해보면 쉽게 이해할 수 있다.</p>

<p>(1) <code>map</code>, <code>for</code> 과 같은 <em>bulk operation</em> 은 <code>Vector</code> 가 <br />
(2) <code>tail</code>, <code>head</code> 는 <code>List</code> 가 더 빠르다.  </p>

<p><code>Vector</code> 는 대부분의 <code>List</code> 연산을 사용할 수 있는데 예외가 하나 있다. 바로 <code>::</code> 콘싱은 <code>List</code> 를 위한 연산이기 때문이다.</p>

<p>따라서 <code>Vector</code> 에서는 원소 추가나, 패턴 매칭을 위해 <code>x +: xs</code>, <code>x :+ x</code> 를 사용하면 된다.</p>

<p><code>Vector</code> 는 <code>List</code> 처럼 <em>immutable</em> 이기 때문에 원소를 추가하면 기존의 데이터는 변경되지 않는다. 따라서 가장 깊은 깊이에 새로운 <code>Vector</code> 를 추가하고 그 벡터를 가리키는 상위 벡터, ..., 루트 벡터까지 만드는 비용은 <code>log32(N)</code> 이 된다. 물론 이건 <em>object creation</em> 비용이다.</p>

<h4 id="sequence">Sequence</h4>

<p><code>Vector</code>, <code>List</code>, <code>Range</code> 는 <code>Seq</code> 의 <em>sub-type</em> 다. <code>Seq</code> 이외에도 <code>Set</code>, <code>Map</code> 등이 있으며 <code>Seq, Set, Map</code> 은 <code>Iterable</code> 의 <em>sub-type</em> 이다. <em>hierarchy</em> 를 살펴보면,</p>

<p><a href='http://docs.scala-lang.org/resources/images/collections.png' > <br />
<img src='http://docs.scala-lang.org/resources/images/collections.png'  align="center" /></a>  </p>

<p align="center">(<a href='http://docs.scala-lang.org/' >http://docs.scala-lang.org</a>)</p>

<p><a href='http://docs.scala-lang.org/resources/images/collections.immutable.png' > <br />
<img src='http://docs.scala-lang.org/resources/images/collections.immutable.png'   align="center" /> <br />
</a>  </p>

<p align="center">(<a href='http://docs.scala-lang.org/' >http://docs.scala-lang.org</a>)</p>

<p><code>Array</code> 와 <code>String</code> 은 점선으로 연결된 걸 볼 수 있는데 이건 두 클래스가 <code>Java</code> 에서 왔기 때문이다. 스칼라 클래스는 아니지만 스칼라의 <code>Seq</code> 로 볼 수 있다. (<em>View</em>) 따라서 다음과 같은 코드는 정상 동작한다.</p>

<pre><code class="scala">"Hello World" filter { c =&gt; c.isUpper }  
</code></pre>

<h4 id="range">Range</h4>

<p>다른 <code>Seq</code> 구현체로는 <code>Range</code> 가 있다. <code>Range</code> 는 <em>evenly spaced intergers</em> 를 나타낸다. </p>

<pre><code class="scala">val r: Range = 1 until 5 // Range(1, 2, 3, 4)  
val s: Range = 1 to 5 // Range(1, 2, 3, 4)  
1 to 10 by 3  
6 to 1 by -2  
</code></pre>

<p>그렇기에 <code>Range</code> 는 <em>upper bound, lower bound, step value</em> 를 클래스의 멤버로 가지고 있다.</p>

<h4 id="sequenceoperations">Sequence Operations</h4>

<p><code>Seq</code> 에 대해서 <code>exists</code>, <code>forall</code>, <code>zip</code>, <code>unzip</code>, <code>flatMap</code>, <code>sum</code>, <code>product</code>, <code>max</code> 등을 사용할 수 있다.</p>

<p><code>zip</code> 은 두개의 <code>Seq</code> 의 각 원소를 <code>pair</code> 로 묶는거고, <code>unzip</code> 은 각 <code>pair</code> 를 푼다.</p>

<pre><code class="scala">scala&gt; a  
res13: scala.collection.immutable.Range.Inclusive = Range(1, 2, 3, 4, 5)

scala&gt; b  
res14: List[Char] = List(h, e, l, l, o)

scala&gt; a zip b  
res15: scala.collection.immutable.IndexedSeq[(Int, Char)] = Vector((1,h), (2,e), (3,l), (4,l), (5,o))

scala&gt; a zip b unzip  
res16: (scala.collection.immutable.IndexedSeq[Int], scala.collection.immutable.IndexedSeq[Char]) = (Vector(1, 2, 3, 4, 5),Vector(h, e, l, l, o))  
</code></pre>

<p><br/></p>

<p><code>flatMap</code> 은 각 원소에 <code>map</code> 을 적용한 뒤, 풀어 헤친다. 예를 들어</p>

<pre><code class="scala">scala&gt; "HelloWorld" flatMap { c =&gt; List('.', c) }  
res17: String = .H.e.l.l.o.W.o.r.l.d  
</code></pre>

<p><code>flatMap</code> 은 맵을 두번하면 할 때 자주 쓰인다. 예를 들어  <code>n</code>, <code>m</code> 에 대해 <em>combinator (조합)</em> 을 찾을때 <code>flatMap</code> 을 사용하면 <code>Vector</code> 의 <code>Vector</code> 가 아니라 <code>Vector</code> 만 얻는다.</p>

<pre><code class="scala">1 to m flatMap { x =&gt; 1 to n map { y =&gt; (x, y) } }  
</code></pre>

<p>벡터에 대해 스칼라 곱을 하고 싶다면, <code>zip</code> 을 이용할 수 있다. <code>zip</code> 을 이용하면 두 <code>Seq</code> 의 <code>pair</code> 가 나오므로, 곱한 후 <code>sum</code> 하자.</p>

<pre><code class="scala">(xs zip ys).map(xy =&gt; xy._1 * xy._2).sum
</code></pre>

<p>그런데, <code>zip</code> 해서 나오는 <code>pair</code> 에 패턴매칭을 적용할 수 있으므로</p>

<pre><code class="scala">(xs zip ys).map { case(x, y) =&gt; x * y }.sum
</code></pre>

<p>참고로, <code>x =&gt; match { case ... }</code> 은 <code>{ case ... }</code> 으로 바로 줄여쓸 수 있다. </p>

<h3 id="combinatorialsearchandforexpression">Combinatorial Search and For-Expression</h3>

<h4 id="handlingnestedsequences">Handling Nested Sequences</h4>

<p>보다 작은 두 수 <code>i, j (1 &lt;= j &lt; i &lt; n)</code> 에 대해서 <code>i + j</code> 가 소수인 <code>i, j</code> 를 찾는다고 하자. </p>

<blockquote>
  <p>Given a positive integer <code>n</code>, find all pairs of positive integers <code>i</code> and <code>j</code> with <code>1 &lt;= j &lt; i &lt; n</code> such that <code>i + j</code> is prime</p>
</blockquote>

<p>이렇게 코드를 작성해 볼 수 있다.</p>

<pre><code class="scala">1 until 5 flatMap { i =&gt; 1 until i map { j =&gt; (i, j) }}

res36: scala.collection.immutable.IndexedSeq[(Int, Int)] = Vector((2,1), (3,1), (3,2), (4,1), (4,2), (4,3))  
</code></pre>

<p>재밌는 사실은 <code>Range</code> 를 사용했음에도 <code>Vector</code> 가 나온다는 점이다. 더 정확히는 <code>IndexedSeq</code> 다. 무슨 일이 일어난 걸까? <code>Range</code> 는 <code>Pair</code> 를 원소로 가질 수 없기 때문에 상위 타입인 <code>IndexedSeq</code> 를 가지게 되고, 이것의 구체적 타입인 <code>Vector</code> 가 된다.</p>

<p><a href='http://docs.scala-lang.org/resources/images/collections.immutable.png' > <br />
<img src='http://docs.scala-lang.org/resources/images/collections.immutable.png'   align="center" /> <br />
</a>  </p>

<p align="center">(<a href='http://docs.scala-lang.org/' >http://docs.scala-lang.org</a>)</p>

<p><code>flatMap</code> 을 안쓰면 <code>Vector</code> 의 <code>Vector</code> 가 나오는데, 여기에 <code>foldRight Seq[Int]() (_ ++ _)</code> 을 사용하거나 아니면 <code>flatten</code> 을 사용할 수도 있다.</p>

<pre><code class="scala">(1 until 5 { i =&gt; 1 until i map { j =&gt; (i, j) }}).flatten
</code></pre>

<p>결국 <code>flatMap</code> 은 <code>map</code> 후 <code>flatten</code> 을 적용한 결과를 돌려줌을 알 수 있다. 이제 여기에 <code>filter</code> 를 적용하면 처음에 주어졌던 문제를 해결할 수 있다.</p>

<pre><code class="scala">    1 until n flatMap { i =&gt; 1 until i map {j =&gt; (i, j)} } filter { case (i, j) =&gt; isPrime(i + j)}
</code></pre>

<h4 id="forexpression">For-Expression</h4>

<p><code>map</code> 과 같은 <em>higher-order function</em> 은 <em>expressive</em> 한데 읽기가 좀 힘들때가 있다. 스칼라에서는 이를 위해 <code>for</code> 을 제공한다. 다음의 두 문자을 보자. 완전히 동일하다.</p>

<pre><code class="scala">case class Person(name: String, age: Int)

for (p &lt;- persons if p.age &gt; 20) yield p.name  
persons filter (p =&gt; p.age &gt; 20) map (p =&gt; p.name)  
</code></pre>

<p><code>for</code> 는 <em>imperative language</em> 의 그것과 비슷하긴 한데, 스칼라의 <code>for</code> 은 무언갈 변경하지 않고 새로운 <code>List</code> 를 <code>yield</code> 를 통해 생성한다.</p>

<p><code>for (s) yield e</code> 문법을 좀 자세히 살펴보자.</p>

<blockquote>
  <p>where <code>s</code> is a sequence of <em>generators</em> and <em>filters</em>, and <code>e</code> is an expression whose value is returned by an iteration</p>
</blockquote>

<p><em>generator</em> 는 <code>p &lt;- e</code> 형태의 <em>form</em> 인데 <code>p</code> 는 <em>pattern</em> 이고 <code>e</code> 는 <em>value</em> 로 <em>collection</em> 을 가진 <em>expression</em> 이다.</p>

<p><em>filter</em> 는 <code>Boolean</code> <em>expression</em> 을 가지는 <em>form</em> 이다.</p>

<p><code>for</code> 루프 여러개 중첩하는 것처럼 <em>generator</em> 가 여러개 일 수 있는데, 이 경우 마지막에 오는 <em>generator</em> 가 여러번 돈다. </p>

<blockquote>
  <p>If there are several generators in the sequence, the last generators vary faster than the first.</p>
</blockquote>

<p>그리고 <code>( s )</code> 대신에 <code>{ s }</code> 를 사용할 수도 있는데, 이러면 세미콜론 없이 <em>filter</em> 와 <em>generator</em> 를 여러줄에 걸쳐서 작성할 수 있다.</p>

<p>이제 처음에 나왔던 문제를 <code>for</code> 로 작성해 보자.</p>

<pre><code class="scala">for {  
  i &lt;- 1 until n
  j &lt;- 1 until i
  if isPrime(i + j)
} yield (i, j)
</code></pre>

<p>읽기도 쉬워졌다. <del>flatMap 따위</del> </p>

<p>이제 아까 나왔던 벡터간 스칼라 곱을 하는 함수를 다시 작성해 보면</p>

<pre><code class="scala">def scalaProduct(xs: List[Double], ys: List[Double] =  
    (for ((x, y) &lt;- xs zip ys) yield (x * y)).sum
</code></pre>

<p>해보면 알겠지만 <code>for { x &lt;- xs; y &lt;- ys } yield x * y sum</code> 은 안된다. 루프가 중첩되기 때문이다.</p>

<h3 id="combinatorialsearchexample">Combinatorial Search Example</h3>

<p>자 이제 <code>Seq</code> 말고 <code>Set</code> 에 대해서 알아보자. <code>Seq</code> 의 대부분의 연산도 사용할 수 있고, 비슷비슷허다. <code>Seq</code> 와 <code>Set</code> 은 <code>Iterable</code> 의 <em>sub-type</em> 이므로 <code>Iterable</code> 스칼라독을 보면 어떤 연산을 사용할 수 있는지 확인 할 수 있다.</p>

<p><code>Seq</code> 와의 차이점은 다음과 같다.</p>

<p>(1) <code>Set</code> 은 순서가 없다. <br />
(2) <code>Set</code> 은 중복된 원소를 가질 수 없다. <br />
(3) <code>contain</code> 이 <em>fundamental operation</em> 이다.  </p>

<pre><code class="scala">val a = 1 to 4 toSet

scala&gt; a  
res53: scala.collection.immutable.Set[Int] = Set(1, 2, 3, 4)

scala&gt; a map (_ / 2)  
res54: scala.collection.immutable.Set[Int] = Set(0, 1, 2)  
</code></pre>

<h4 id="nqueensproblem">N-Queens Problem</h4>

<p>이제 <code>Set</code> 을 이용해 좀 문제를 풀어보자.</p>

<blockquote>
  <p>The n-queens problem is to place <code>n</code> queens on a chess board so that no queen is threatened by another <br/></p>
  
  <p>In other words, there can't be two queens in the same row, column, or diagonal</p>
</blockquote>

<p>모든 조합을 뽑아내고, 열을 <code>List</code> 로 표현하고, 그 순서를 행이라 한 뒤 모든 조합을 뽑아내 <code>Set</code> 에 넣으면 자동으로 중복된 결과가 제거된다. 로직은 다음과 같다.</p>

<p>(1) 내게 <code>placeQueens</code> 라는 1 개의 퀸을 위치시킬 수 있는 함수가 있다. <br />
(2) <code>n = 1, 2, ... , n</code> 으로 <code>placeQueens</code> 를 재귀적으로 호출해 가며 이전 단계에서 얻은 퀸들을 이용하여 하나의 퀸을 새롭게 배치한다. <br />
(3) 각 단계에서는 새 퀸을 배치할 수 있는지 없는지 검사할 <code>isSafe</code> 함수가 필요하다.  </p>

<p>이게 <em>Recursion</em> 에서 문제를 풀 때 기본적으로 필요한 생각인 것 같다. <strong>문제를 작게 잘라 매번 <code>1/n</code> 씩 해결할 수 있다면</strong> 이라 가정 한 뒤 <code>1/n</code> 문제를 풀기 위한 함수와 <code>1/n</code> 문제의 종료조건을 정의하는 것. 우리의 경우엔 그 함수가 <code>isSafe</code> 였다.</p>

<pre><code class="scala">  def nQueens(n: Int): Set[List[Int]] = {

    def isSafe(col: Int, queens: List[Int]): Boolean = {
      val row = queens.length // where new queen will be placed
      val queensWithRow = (row - 1 to 0 by -1) zip queens
      queensWithRow forall {
        case (r, c) =&gt; col != c &amp;&amp; math.abs(col - c) != row - r
      }
    }

    def placeQueens(k: Int): Set[List[Int]] =
      if (k == 0) Set(List())
      else
        for {
          queens &lt;- placeQueens(k - 1)
          col &lt;- 0 until n
          if isSafe(col, queens)
        } yield col :: queens

    placeQueens(n)
  }
</code></pre>

<p><em>diagonal</em> 을 어떻게 검사할까가 고민이 될 수 있겠는데, 사실 생각해보면 쉽다. 컬럼의 차이와 행의 차이가 같으면 <em>diagonal</em> 인 것.</p>

<p>여기에 출력하기 위한 함수를 요로코롬 만들고 출력하면</p>

<pre><code class="scala">  def showQueens(queens: List[Int]) = {
    val lines =
      for {
        col &lt;- queens.reverse
      } yield Vector.fill(queens.length)("[ ]").updated(col, "[*]").mkString

    "\n\n" + (lines.mkString("\n"))
  }


[ ][ ][*][ ]
[*][ ][ ][ ]
[ ][ ][ ][*]
[ ][*][ ][ ],

[ ][*][ ][ ]
[ ][ ][ ][*]
[*][ ][ ][ ]
[ ][ ][*][ ]
</code></pre>

<p><code>nQueens(8) take 3 map show</code> 처럼 응용도 가능하다.</p>

<h3 id="querieswithfor">Queries with For</h3>

<p>지난 시간에 배운 <code>for</code> 는 <code>SQL</code> 과 비슷한데 좀 더 자세히 살펴보자. 다음과 같은 <em>case class</em> 가 있다고 하자.</p>

<pre><code class="scala">case class Book(title: String, authors: List[String])  
</code></pre>

<p>이제 다음과 같은 코드를 이용해 쿼리처럼 질의할 수 있다.</p>

<pre><code class="scala">for {  
  b &lt;- books
  a &lt;- b.authros
  if a startWith "Bird")
} yield b.title

for {  
  b &lt;- books
  if b.title indexOf "Programming" &gt;= 0
} yield b.title

for {  
  b1 &lt;- books
  b2 &lt;- books
  if b1 != b2
  a1 &lt;- b1.authors
  a2 &lt;- b2.authors
  if a1 == a2
} yield a1
</code></pre>

<p>세번째 <code>for</code> 문은 약간 문제가 있는데 내용이 똑같고 순서만 다른 <code>List</code> 를 만들 수 있다 따라서 중복을 피하기 위해 <code>&lt;</code> 를 비교로 사용하자.</p>

<pre><code class="scala">for {  
  b1 &lt;- books
  b2 &lt;- books
  if b1.title &lt; b2.title
  a1 &lt;- b1.authors
  a2 &lt;- b2.authors
  if a1 == a2
} yield a1
</code></pre>

<p>근데 만약에 같은 작가가 3개의 책을 출판했다면? <code>title</code> 이 <code>a &lt; b &lt; c</code> 와 같은 순서를 가지므로 <code>(a, b), (a, c), (b, c)</code> 처럼 비교되어 3번 출력된다. </p>

<p>중복을 제거하기 위해 <code>distint</code> 를 사용할 수 있다. 더 좋은 방법은 <code>Set</code> 을 사용하면 된다.</p>

<h3 id="translationoffor">Translation of For</h3>

<p><code>for</code> 을 이용하면 <code>map, flatMap, filter</code> 를 쉽게 구현할 수 있는데</p>

<pre><code class="scala">def mapFun[T, U](xs: List[T], f: T =&gt; U): List[U] =  
  for (x &lt;- xs) yield f(x)

def flatMap[T, U](xs: List[T], f: T =&gt; Iterable[U]): List[U] =  
  for (x &lt;- xs; y &lt;- f(x)) yield y

def filter[T](xs: List[T], p: T =&gt; Boolean): List[T] =  
  for (x &lt;- xs; if (p(x)) yield x  
</code></pre>

<p>사실 스칼라 컴파일러는 <code>for</code> 을 <code>map</code>, <code>flatMap</code>, <em>lazy variant of <code>filter</code></em> 로 바꿔치기한다.</p>

<blockquote>
  <p>Scala compiler expresses <code>for</code> expressions in terms of <code>map</code>, <code>flatMap</code> and a <em>lazy variant of <code>filter</code></em></p>
</blockquote>

<p>예를 들어 <code>for (x &lt;- e1) yield e2</code> 는 <code>e1.map(x =&gt; e2)</code> 로 바꾼다</p>

<pre><code class="scala">for (x &lt;- e1 if f; s) yield e2  
</code></pre>

<p><code>f</code> 가 <em>filter</em> 고 <code>s</code> 가 <em>sequence of generators and filters</em> 라면 다음과 같이 번역된다.</p>

<pre><code class="scala">for (x &lt;- e1.withFilter(x =&gt; f); s) yield e2  
</code></pre>

<p>여기서 <code>withFilter</code> 는 바로 적용되는 것이 아니라, 뒤 따라오는 <code>map</code> 또는 <code>flatMap</code> 등에 적용된다고 보면 된다. 원문을 첨부하면</p>

<blockquote>
  <p>You can think of <code>withFilter</code> as a variant of <code>filter</code> that does not produce an intermediate list, but instead filters the following <code>map</code> or <code>flatMap</code> function application</p>
</blockquote>

<pre><code class="scala">for (x &lt;- e1; y &lt;- e2; s) yield e3  
</code></pre>

<p>이건 다음처럼 번역된다.</p>

<pre><code class="scala">e1.flatMap(x =&gt; for (y &lt;- e2; s) yield e3)  
</code></pre>

<p>그리고 내부의 <code>for</code> 가 다시 한번 더 번역된다.</p>

<pre><code class="scala">for {  
  i &lt;- 1 until n
  j &lt;- 1 until i
  if isPrime(i + j)
} yield (i, j)
</code></pre>

<p>이것은</p>

<pre><code class="scala">(1 until n) flatMap(i =&gt;
  (1 until i).withFilter(j =&gt; isPrime(i + j))
  .map(j =&gt; (i, j)))
</code></pre>

<p>이제 아까 <em>lazy variant of <code>filter</code></em> 어쩌구 하던 내용을 이해할 수 있는데, 중간에 <code>withFilter</code> 는 <code>1 until i</code> 에 적용 되는것이 아니라 <code>map</code> 이 만들어낸 <em>pair</em> <code>(i, j)</code> 에 대해 적용된다.</p>

<p>다시 말해 <code>for</code> 문에서 <code>if</code> <em>guard</em> 는 나중에 적용되는 <code>withFilter</code> 다.</p>

<pre><code class="scala">for (b &lt;- books; a &lt;- b.authros if a startsWith "Bird") yield b.title  
</code></pre>

<p>요건 이렇게 번역된다.</p>

<pre><code class="scala">b.flatMap(b =&gt; b.authors.withFilter(a =&gt; a.startsWith "Bird").map(x =&gt; x.title)  
</code></pre>

<p><code>for</code> 는 다양한 컬렉션에도 적용할 수 있는데 이는 <code>for</code> 가 <code>map</code>, <code>flatMap</code>, <code>withFilter</code> 이 3개의 함수를 기반으로 만들어졌기 때문이다. 따라서 커스텀 타입에도 이 3개의 함수를 만들면 <code>for</code> 를 사용할 수 있다.</p>

<p>이런 이유로 데이터베이스 클라이언트가 <code>map</code>, <code>flatMap</code>, <code>withFilter</code> 같은 메소드를 정의하면 <code>for</code> 을 이용해 쿼리할 수 있다.</p>

<p>이것이 바로 <em>ScalaQuery</em> 나 <em>Slick</em> 같은 스칼라 데이터베이스 프레임워크가 사용하는 방법이다. <em>LINQ</em> 도 비슷한 개념이다.</p>

<h3 id="maps">Maps</h3>

<p>자 이제 <code>Seq</code>, <code>Set</code> 을 살펴보았으니 <code>Map</code> 을 알아보자. </p>

<p><code>Map</code> 은 <code>Iterable</code> 일뿐만 아니라 <code>Function</code> 이다. 그래서 함수 호출하듯이 <em>Key</em> 를 인자로 주어 호출하면 <em>Value</em> 를 얻을 수 있다. 그러나 없는 <em>Key</em> 에 대해서 호출하면 <code>NoSuchElementException</code> 이 발생한다.</p>

<p>예외 대신에 있는지 없는지 알려면 <code>get</code> 을 이용하면 된다. 없으면 <code>None</code> 있으면 <code>Option[Value]</code> 를 돌려준다.</p>

<h4 id="optiontype">Option Type</h4>

<p><code>Option</code> 은 <em>Trait</em> 인데</p>

<pre><code class="scala">trait Option[+A]  
case class Some[+A](value: A) extend Option[A]  
object None extend Option[Nothing]  
</code></pre>

<p><em>covaraint</em> 기 때문에 <code>Option[Type]</code> 에 <code>None</code> 을 넣을 수 있다. <code>None</code> 은 <code>Option[Nothing]</code> 이므로 모든 <code>Option</code> 의 하위타입이다.  참고로 <code>get</code> 의 결과에 패턴매칭을 이용할 수 있다.</p>

<h4 id="sortedandgroupby">Sorted and GroupBy</h4>

<p><em>SQL Query</em> 처럼 <code>sorted</code> 와 <code>groupBy</code> 를 이용할 수 있다.</p>

<pre><code class="scala">scala&gt; fruit  
res70: List[String] = List(apple, pear, orange, pineapple)

scala&gt; fruit.sorted  
res71: List[String] = List(apple, orange, pear, pineapple)

scala&gt; fruit.sortWith(_.length &lt; _.length)  
res72: List[String] = List(pear, apple, orange, pineapple)

scala&gt; fruit.groupBy(_.head)  
res73: scala.collection.immutable.Map[Char,List[String]] = Map(p -&gt; List(pear, pineapple), a -&gt; List(apple), o -&gt; List(orange))  
</code></pre>

<p><code>groupBy</code> 는 컬렉션을 <em>discriminator</em> 를 이용해 <code>Map</code> 으로 파티셔닝한다.</p>

<p><em>Ploynomials (다항식)</em> 을 <code>Map</code> 을 이용해 표현해 보자. 다항식은 각 차수가 한개씩 있고, 상수도 하나씩 붙어 있으므로 <code>Map</code> 으로 표현하기에 적합하다.</p>

<pre><code class="scala">  class Poly(val terms: Map[Int, Double]) {
    def + (other: Poly): Poly = new Poly(terms ++ other.terms)
    override def toString = {
      (for((exp, coeff) &lt;- terms.toList.sorted.reverse) yield  coeff + "x^" + exp) mkString " + "
    }
  }
</code></pre>

<p>이렇게 만들면 제대로 된 계산이 안된다. 왜냐하면 <code>Map</code> 의 <code>++</code> 오른쪽에 오는 <code>Map</code> 에 똑같은 <em>key</em> 를 가지고 있는 원소가 있으면 덮어 쓰기 때문이다. 다항식에서 차수가 같으면 <em>coefficient (계수)</em> 를 덧셈해야 하는데 덮어씌우면 올바른 계산이 아니다. 따라서 <code>other.terms</code> 에 같은 <em>Key</em> 를 가진 원소가 있나 없나 계산해서 있으면 현재 <code>terms</code> 와 계수를 더한 새로운 <code>pair</code> 를 돌려줘야 한다. (<code>Map</code> 의 원소는 <code>pair</code> 다) </p>

<pre><code class="scala">  class Poly(val terms: Map[Int, Double]) {
    def + (other: Poly): Poly = 
    new Poly(terms ++ (other.terms map adjust))

    def adjust(term: (Int, Double)): (Int, Double) = {

      val (exp, coeff) = term

      terms.get(exp) match {
        case None =&gt; term
        case Some(coeff1) =&gt; (exp, coeff + coeff1)
      }
    }

    override def toString = {
      (for{
        (exp, coeff) &lt;- terms.toList.sorted.reverse
      } yield  coeff + "x^" + exp) mkString " + "
    }
  }
</code></pre>

<h4 id="defaultvalues">Default Values</h4>

<p><code>Map</code> 은 <em>partial function</em> 이기 때문에 없는 <em>Key</em> 에 대해 <code>Map</code> 을 호출하면 예외가 발생한다.</p>

<p><code>Map</code> 에 <code>withDefaultValue</code> 를 적용하면 <em>total function</em> 으로 바꿀 수 있다. <code>Poly</code> 에 적용해 보자.</p>

<pre><code class="scala">  class Poly(val terms0: Map[Int, Double]) {
    val terms = terms0 withDefaultValue 0.0
    def + (other: Poly): Poly = new Poly(terms ++ (other.terms map adjust))
    def adjust(term: (Int, Double)): (Int, Double) = {

      val (exp, coeff) = term
      (exp, coeff + terms(exp))
    }
    override def toString = {
      (for{
        (exp, coeff) &lt;- terms.toList.sorted.reverse)}
      yield coeff + "x^" + exp) mkString " + "
    }
  }
</code></pre>

<p>음. 다 좋은데 생성할 때 <code>Map</code> 을 주는 대신 여러개의 <code>Pair</code> 를 주고 <code>Map</code> 으로 바꾸면 좀 더 나을것 같다. 다음의 생성자를 추가하자.
    def + (other:Poly): Poly = 
    new Poly((other.terms foldLeft terms)(addTerm))
    def addTerm(ts: Map[Int, Double], t: (Int, Double)): Map[Int, Double] = {
      val (exp, coeff) = t
      ts + (exp -> (coeff + terms(exp)))
    }</p>

<pre><code class="scala">def this(arg: (Int, Double)*) = this(arg.toMap)  
</code></pre>

<p>그리고 <code>++</code> 대신 <code>fold</code> 를 이용하면 <code>Map</code> 을 생성하지 않고 바로 기존의 <code>terms</code> 에 원소를 추가하기 때문에 더 효율적이다.</p>

<pre><code class="scala">    def + (other:Poly): Poly = 
    new Poly((other.terms foldLeft terms)(addTerm))
    def addTerm(ts: Map[Int, Double], t: (Int, Double)): Map[Int, Double] = {
      val (exp, coeff) = t
      ts + (exp -&gt; (coeff + terms(exp)))
    }
</code></pre>

<p>아래는 테스트 케이스</p>

<pre><code class="scala">  "(x^2 + 3x) + (-2x + 7)" should "be x^2 + x + 7" in {
    val p1 = new Poly(2-&gt;1, 1-&gt;3)
    val p2 = new Poly(1-&gt;(-2), 0-&gt;7)
    val p3 = new Poly(2-&gt;1, 1-&gt;1, 0-&gt;7)

    assert((p1 + p2).terms == p3.terms)
  }
</code></pre>

<h3 id="puttingthepiecestogether">Putting the Pieces Together</h3>

<p>이번엔 전화번호를 알파벳으로 바꾸는 예제를 통해서 스칼라의 컬렉션과 고차함수가 얼마나 <em>expressive</em> 한지 알아본다.</p>

<p>여기 나온 예제는 7 가지 언어로 이미 실험이 되었는데 스크립트 언어는 대략 100 라인, C 나 C++ 같은 언어는 대략 200-300 라인정도가 나왔다고 한다. (2000년)</p>

<pre><code class="scala">  val mnem = Map(
    '2' -&gt; "ABC",
    '3' -&gt; "DEF",
    '4' -&gt; "GHI",
    '5' -&gt; "JKL",
    '6' -&gt; "MNO",
    '7' -&gt; "PQRS",
    '8' -&gt; "TUV",
    '9' -&gt; "WXYZ")
</code></pre>

<p>이런 맵이 있다고 하자. <code>7225247386</code> 을 인코딩 하면 여러가지 경우가 나오겠지만, 그 중 하나는 <code>SCALA IS FUN</code> 이어야 한다. <del>교수님 센스보소</del></p>

<pre><code class="scala">  val path = "/home/anster/github/coursera-scala/src/main/scala/coursera/chapter6/linux.words"
  val in = Source.fromFile(path)
  // java's iterator doesn't have groupBy
  val words = in.getLines.toList filter { _ forall { _.isLetter }}

  val mnem = Map(
    '2' -&gt; "ABC",
    '3' -&gt; "DEF",
    '4' -&gt; "GHI",
    '5' -&gt; "JKL",
    '6' -&gt; "MNO",
    '7' -&gt; "PQRS",
    '8' -&gt; "TUV",
    '9' -&gt; "WXYZ")

  // A to Z -&gt; 2 to 9
  val charCode = mnem flatMap { case(k, v) =&gt; v map { c =&gt; (c, k) } }
  // or for ((digit, str) &lt;- mnem; ltr &lt;- str) yield ltr -&gt; digit

  // "Java" -&gt; "5282"
  def wordCode(word: String): String = word.toUpperCase map charCode

  // "5282" -&gt; List("Java", "Kava", ...), "1111" -&gt; List()
  val wordsForNum: Map[String, Seq[String]] =
    words groupBy wordCode withDefaultValue Seq()

  // return all ways to encode a number as a list of words
  def encode(number: String): Set[List[String]] =
    if (number.isEmpty) Set(List())
    else {
      (for {
        split &lt;- 1 to number.length
        word &lt;- wordsForNum(number take split)
        rest &lt;- encode(number drop split)
      } yield word :: rest).toSet
    }

  def printEncoded(number: String) = {
    encode(number) map { _ mkString " "} map println
  }

  def translate(number: String): Set[String] = {
    encode(number) map { _ mkString " " }
  }

  translate("7225247386") foreach { println _ }
</code></pre>

<p>군더더기 없이 깔끔하다. <del>스칼라는 넉넉하게 50라인에서 끝납니다요</del></p>

<p><code>encode</code> 가 좀 난해하긴 한데, 경우의 수를 모두 찾아내야 하므로 길이를 모두 짤라 <code>wordForNum</code> 에 넣고 각 길이마다 인코딩을 할 수 있는지 검사한 후 나머지도 <code>encode</code> 함수에 넣어 모든 경우의 수를 찾는다. 주의할 부분은 <code>wordsForNum(number take split)</code> 에서 없는 경우가 나올 수 있으니 <code>withDefaultValue Seq()</code> 로 처리하면 된다. 그리고 <code>1 to number.length</code> 가 <code>Range</code> 이기 때문에 리턴 타입이 <code>IndexedSeq</code> 다. 타입 에러를 해결하기 위해 <code>toSet</code> 을 사용한다. </p>

<h3 id="summary">Summary</h3>

<p>마지막 <em>6.7 Putting the Pieces Toghther</em> 챕터를 보면서 스칼라는 정말 <em>expressive</em> 하다는걸 느낀다. 교수님 말로는 <em>immutable collection</em> 은</p>

<p>(1) <em>easy to use:</em> <strong>few steps to do the job</strong> <br />
(2) <em>concise:</em> <strong>one word replaces a whole loop</strong> <br />
(3) <em>safe:</em> <strong>type checker is really good at catching erros</strong> <br />
(4) <em>fast:</em> <strong>collection ops are tuned, can be parallelized</strong> <br />
(5) <em>universal:</em> <strong>one vocabulary to work on all kinds of collections</strong></p>

<p><del>내 컴퓨터에서 돌아가는 <em>SBT</em> 를 보면 스칼라가 빠른지는 의문이지만</del></p>

<p>그리고 항상 느끼는 점이지만, <em>Problem</em> = <em>Algorithm</em> + <em>Data Structure</em> 다. 자료구조를 잘 선택하면 알고리즘이 간단해진다. <del>그래서 둘 다 배워야 하는거고 크흑</del>  </p>

<h3 id="references">References</h3>

<p>(1) <a href='http://docs.scala-lang.org/overviews/collections/overview.html' >http://docs.scala-lang.org</a></p>

<p>2014-10-25, <strong>Functional Programming in Scala</strong>, Coursera</p>]]></description><link>http://1ambda.github.io/functional-programming-in-scala-chapter-6/</link><guid isPermaLink="false">d4f41772-52eb-4a9c-a778-d73f962245b5</guid><category><![CDATA[scala]]></category><category><![CDATA[coursera]]></category><category><![CDATA[functional programming]]></category><category><![CDATA[collection]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 24 Oct 2014 14:07:21 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 4]]></title><description><![CDATA[<p>지난 시간에는 실리콘 밸리의 머신러닝 개발자들이 귀한대접을 받는다는 훈훈한 덕담으로 강의가 끝났다. 이번시간에는 뜬금없이 <em>Neural Network (신경망)</em> 을 건들다가 놀랍게도 그것이 <em>logistic regression</em> 과 연관이 있으며 <code>n</code> 이 매우 클 경우의 <em>classification</em> 문제를 해결할 수 있다는 것을 배운다.</p>

<h3 id="nonlinearhypotheses">Non-Linear Hypotheses</h3>

<p>다음과 같은 트레이닝 셋이 있을때, 두 집단을 <em>classification</em> 하는 <em>hypothesis</em> 를 찾는다고 하자. </p>

<p><img src='http://www.holehouse.org/mlclass/08_Neural_Networks_Representation_files/Image.png'  align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/' >http://www.holehouse.org</a>)</p>

<p><code>x1</code> 과 <code>x2</code> 만으로는 찾을 수 없으니, 더 많은 <em>feature</em>  <code>x1^2, x1x2, x2^2</code> 를 도입한다 하자. 트레이닝 셋에 적합한 가설을 찾을수는 있겠지만, 항상 좋은건 아니다.</p>

<p>(1) 우선 지난 시간에 언급했듯이 <em>Overfitting</em> 이 발생할 수 있고 <br />
(2) <em>feature</em> 수가 <code>n</code> 이라 할때, 모든 <em>quadratic feature</em> 를 도입하면 <em>feature</em> 수가 <code>O(n^2)</code> (<code>n^2/2</code>)만큼 늘어난다. (아래 그림 참조) 다시 말해서 계산 비용이 엄청나게 비싸진다.</p>

<p><img src='http://img.blog.csdn.net/20140507021224421'  align="center" />  </p>

<p align="center">(<a href='http://blog.csdn.net/feliciafay' >http://blog.csdn.net/feliciafay</a>)</p>

<p>그리고 <em>feature</em> 수를 줄이기 위해 <code>x1^2, x2^2, x3^2 ...</code> 등 <em>quadratic feature</em> 만을 도입하고 나머지 <em>parameter</em> 를 버리면, <em>hypothesis</em> 가 <em>underfit</em> 할 수 있다.</p>

<p>만약 <em>feature</em> 를 <em>cubic</em> 까지 도입하면 <em>feature</em> 수가 <code>O(n^3)</code> 으로 늘어나 계산시간은 어마어마하게 걸린다. 따라서 차수를 늘려 문제를 해결하려는 방법은 <code>n</code> 이 클때 좋은 방법이 아니다. 게다가 일반적으로 대부분의 문제들은 <code>n</code> 이 큰편이다.</p>

<p>자동차 이미지 인식 문제를 고려해 보자. 이미지는 픽셀이므로, 50 * 50 픽셀로 구성된 경우 <code>n = 2500</code> 이다.</p>

<p><img src='http://img.blog.csdn.net/20140507021231812'  align="center" />  </p>

<p align="center">(<a href='http://blog.csdn.net/feliciafay' >http://blog.csdn.net/feliciafay</a>)</p>

<p>이건 그레이스케일의 경우고 만약 RGB 라면 여기에 3을 곱해서 <code>n = 7500</code> 이 된다. <em>quadratic</em> 이면 <code>7500^2 / 2</code>, 대략 3 millions 개의 <em>feature</em> 를 가지게 된다. 이쯤되면 답이 없다. <code>n</code> 이 큰 <em>classification</em> 에 대해 사용할 수 있는 다른 방법은 없을까?</p>

<h3 id="modelrepresentation">Model Representation</h3>

<p>잠깐 눈을 돌려 <em>Neural Networks</em> 에 대해 이야기 해 보자. 다양한 알고리즘을 개발하는 대신  스스로 학습하는 뇌를 모방한 알고리즘을 개발할 수 있다면 진짜 AI 를 구현할 수 있지 않을까? 라는 질문에서 <em>Neural networks</em> 는 출발한다.</p>

<p>뇌를 모방한 알고리즘을 만들려면, 인간의 뇌가 어떻게 작동하는지 알아야한다. 뇌는 <em>Neuron</em> 이라는 단위의 집합으로 구성되었는데, 요로코롬 생겼다.</p>

<p><img src='http://home.agh.edu.pl/' ~vlsi/AI/intro/neuron.png" align="center" />  </p>

<p align="center">(<a href='http://home.agh.edu.pl/' ~vlsi/AI/intro/'>http://home.agh.edu.pl/~vlsi/AI/intro/</a>)</p>  

<p><br/></p>

<p>여기서 <em>Dendrite</em> 라는 부분이 <strong>input</strong> 이고, <em>Axon</em> 이 <strong>output</strong> 이다. 이걸 모델링하면,</p>

<p><img src='http://img.blog.csdn.net/20140507021238515'  align="center" />  </p>

<p align="center">(<a href='http://blog.csdn.net/feliciafay' >http://blog.csdn.net/feliciafay</a>)</p>

<p>위 그림에서 좌측에 있는 <code>x1, x2, x3</code> 가 <em>input</em> 이라 보면 되고, <code>h0(x)</code> 는 이전처럼 <code>0^T * x</code> 에 <em>sigmoid function</em> 을 적용한 것이다. 그리고 <em>neural network</em> 에서 <em>parameter</em> 대신 <code>0(theta)</code> 를 <strong>weights</strong> 라 부르기도 한다. <code>x0</code> 은 값이 <code>1</code> 이고, <em>bias unit</em> 이라 부르는데 편의상 그리기도 하고 안그리기도 한다. <del>교수님 뜻대로 하소서</del>
<br/><br/></p>

<p>여기까지는 단일 <em>neuron</em> 을 모델링 한것이고, <em>neural network</em> 는 여러개의 <em>neuron</em> 들이 합쳐진 것이다. 간단히 그려보면, </p>

<p><img src='http://img.blog.csdn.net/20140507021247656'  align="center" />  </p>

<p align="center">(<a href='http://blog.csdn.net/feliciafay' >http://blog.csdn.net/feliciafay</a>)</p>

<p>여기서 <em>layer 1</em> 은 <em>input layer</em>, 마지막인 <em>layer 3</em>은 <em>output layer</em> 다. 그리고 가운데 있는 레이어들, 여기서는 <em>layer2</em>, <strong>hidden layer</strong> 라 부른다. 디버깅이 아니라면 <em>hidden layer</em> 에서 산출되는 값들을 관측하려고 할 필요는 없다. <em>hidden layer</em> 는 하나 이상일 수 있다. 실제 계산 과정을 보면</p>

<p><img src='http://img.blog.csdn.net/20140507021254640'  align="center" />  </p>

<p align="center">(<a href='http://blog.csdn.net/feliciafay' >http://blog.csdn.net/feliciafay</a>)</p>

<p><code>ai^j</code> 는, <code>j</code> 번째 <em>hidden layer</em> 에서 <code>i</code> 번째 <em>unit</em> 이다. <code>0(theta)^j</code> 는 <em>layer j</em> 와 <em>layer j+1</em> 사이에서 사용되는 <em>weights</em> 다. 이때 <em>hidden layer</em> 의 각 <em>unit</em> 마다 <em>input</em> 을 위한 <em>weight</em> 를 가지고 있다고 하면 위의 그림에서 <code>0</code> 의 <em>dimension</em> 은 <code>3 * 4</code> 다. (<em>bias unit</em> <code>x0</code> 포함)</p>

<blockquote>
  <p>If network has <code>s_j</code> units in layer <code>j</code>, <code>s_j+1</code> units in layer <code>j+1</code>, then <code>0^j</code> will be dimension <code>s_j+1 * (s_j + 1)</code></p>
</blockquote>

<p>이제 <em>output layer</em> 를 잘 보면 이 레이어의 <em>input</em> 은 <code>a^(2)</code> 고, <em>weight</em> 로 <code>0^2</code> 를 가지고 있다. 따라서 <code>h0(x)</code> 는 위의 식처럼 된다.</p>

<h3 id="forwardpropagation">Forward Propagation</h3>

<p>위 그림처럼 <code>x</code> 를 받아, <code>h0(x)</code> 를 계산하는 방법을 <em>forward propagation</em> 이라 부르는데 <em>vectorization</em> 을 이용해서 간단히 해 보자.</p>

<p><img src='http://www.try2go.com/wp-content/uploads/2014/08/forward-propogation.jpg'  align="center" />  </p>

<p align="center">(<a href='http://www.try2go.com/201408/neural-networks-1/' >http://www.try2go.com/201408/neural-networks-1/</a>)</p>

<p><em>sigmoid fucntion</em> <code>g</code> 내부의 수식을 <code>z</code> 라 부르고 <code>a^(1) = x</code> 라 두면, 우측처럼 수식이 심플해진다. <code>z^(2) = 0^(1) * a^(1)</code> 이고, 여기에 <em>sigmoid function</em> 을 적용하면 <code>a^(2)</code> 가 나온다. 여기에 <em>bias unit</em> <code>a_0^(2) = 1</code> 을 더해 <code>a^(2)</code> 를 4차원 벡터로 만들면 다시 <code>z^(3)</code> 를 계산할 수 있다. 
<br/><br/></p>

<p>자, 이제 왜 <em>neural network</em> 를 뜬금없이 공부하다가 <em>forward propagation</em> 의 <em>vectorization</em> 까지 고려했는지를 밝힐 시간이다! 위 그림에서 <code>a^(1)</code> 즉, <em>layer 1</em> 을 가려버리면 아래와 같은데</p>

<p><img src='http://www.try2go.com/wp-content/uploads/2014/08/learn-features.jpg'  align="center" />  </p>

<p align="center">(<a href='http://www.try2go.com/201408/neural-networks-1/' >http://www.try2go.com/201408/neural-networks-1/</a>)</p>

<p>이때 <code>h0(x)</code> 를 계산하는 식을 구해보면, <em>logistic regression</em> 과 똑같다. <del>오오 머신러닝 오오</del> </p>

<p><strong>결국, <em>neural network</em> 가 하는 일은 <em>logistic regression</em> 이다.</strong> 단지  <em>hidden layer</em> 에서 <code>x1, x2, x3</code> 를 적당한 <em>weight</em> 로 훈련시켜 새로운 <em>feature</em> <code>a1^(2),  a2^(2), a3^(2)</code> 를 만들어 내고, 그걸로 <em>logistic regression</em> 을 할 뿐이다. </p>

<p>다시 한번 정리하자면 <em>neural network</em> 는 <em>feature</em> 를 훈련시켜 다른 값을 가진  <em>feature</em> 로 바꾸는 과정을 통해 <em>hypothesis</em> 를 매우 고차의 다항식으로 만들지 않고도 <code>n</code> 이 매우 큰 경우의 <em>classification</em> 을 풀 수 있도록 한다. 항상 같은 개수의 <em>feature</em> 만 나오는건 아니고, 더 줄이거나 좀 더 늘릴 수도 있다. 아래의 그림을 보자.</p>

<p><img src='http://alphaism.files.wordpress.com/2012/11/selection_001.png?w=630'  align="center" />  </p>

<p align="center">(<a href='http://alphaism.wordpress.com/' >http://alphaism.wordpress.com/</a>)</p>

<h3 id="examples">Examples</h3>

<p>먼저 간단히 <em>AND</em> 연산을 <em>neural network</em> 로 구현한다 하자. </p>

<p><img src='http://www.try2go.com/wp-content/uploads/2014/08/and.jpg'  align="center" />  </p>

<p align="center">(<a href='http://www.try2go.com/201408/neural-networks-1/' >http://www.try2go.com/201408/neural-networks-1/</a>)</p>

<p>위 그림처럼 <code>z^(2) = -30 + 20x1 + 20x2</code> 라면, 우측 표 처럼 각각 <code>h0(x)</code> 값이 나오고, <em>sigmoid function</em> 은 <code>4.6</code> 정도일때 <code>y ~= 0.99</code> 이므로 <code>g(+10)</code> 은 거의 <code>1</code>, <code>g(-10)</code> 은 거의 <code>0</code> 이라 볼 수 있다.</p>

<p><em>XNOR</em> 은 <em>AND</em> <em>~ AND ~</em> 그리고 <em>OR</em> 을 조합하면 만들 수 있다. 아래 그림을 보자.</p>

<p><img src='http://www.holehouse.org/mlclass/08_Neural_Networks_Representation_files/Image%20' [17].png" align="center" />  </p>

<p align="center">(<a href='http://www.holehouse.org/' >http://www.holehouse.org</a>)</p>

<p>결국 <em>neural network</em> 는 각 <em>hidden layer</em> 에서 함수를 이용해 이전 단계의 결과에 어떤 처리를 가해 복잡한 일들을 해낼 수 있는 것이다.</p>

<h3 id="multiclassclassification">Multiclass Classification</h3>

<p>이제 <em>multi-class</em> 를 고려해 보자.</p>

<p><img src='http://www.try2go.com/wp-content/uploads/2014/08/one-vs-all.jpg'  align="center" />  </p>

<p align="center">(<a href='http://www.try2go.com/201408/neural-networks-1/' >http://www.try2go.com/201408/neural-networks-1/</a>)</p>

<p>위 그림처럼 4개의 클래스가 있을 때, <em>output</em> 인 <code>h(x)</code> 를 <code>4 * 1</code> vector 로 만들도록 하고, 각 클래스에 대해서 <code>[1; 0; 0; 0], [0; 1; 0; 0], [0; 0; 1; 0], [0; 0; 0; 1]</code> 이 되도록 훈련시키면 된다. 기본적인 아이디어는 <em>one vs all method</em> 와 같다.</p>

<h3 id="references">References</h3>

<p>(1) <a href='http://blog.csdn.net/feliciafay/article/details/25171147' >http://blog.csdn.net/feliciafay</a> <br />
(2) <a href='http://www.holehouse.org/mlclass/08_Neural_Networks_Representation.html' >http://www.holehouse.org</a> <br />
(3) <a href='http://home.agh.edu.pl/' ~vlsi/AI/intro/">http://home.agh.edu.pl/~vlsi/AI/intro/</a> <br />
(4) <a href='http://www.try2go.com/201408/neural-networks-1/' >http://www.try2go.com/201408/neural-networks-1/</a> <br />
(5) <a href='http://alphaism.wordpress.com/2012/11/13/neural-network-algorithm/' >http://alphaism.wordpress.com/</a></p>]]></description><link>http://1ambda.github.io/machine-learning-week-4/</link><guid isPermaLink="false">02903e2d-5c8c-4abf-9635-da5747fd9c01</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine lerning]]></category><category><![CDATA[classification]]></category><category><![CDATA[neural network]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 23 Oct 2014 07:11:31 GMT</pubDate></item></channel></rss>