<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Old Lisper]]></title><description><![CDATA[Lisp, Emacs, Scala]]></description><link>http://1ambda.github.io/</link><generator>Ghost 0.5</generator><lastBuildDate>Thu, 18 Dec 2014 07:28:04 GMT</lastBuildDate><atom:link href="http://1ambda.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Substring Search Algorithm]]></title><description><![CDATA[<h3 id="introtosubstringsearch">Intro to Substring Search</h3>

<p><code>N</code> 길이의 텍스트에서 <code>M</code> 길이의 패턴을 찾는 문제다. 일반적으로 <code>N &gt;&gt; M</code> 이다. <code>N</code> 이 좀 많이 (무한히) 길기 때문에 지난시간까지 배운 알고리즘을 적용하기가 좀 힘들다.</p>

<p>(1) <em>suffix sort</em> 를 쓰려고 보니 <em>suffixes</em> 를 만드는 것 자체가 어렵다. 따라서 <em>manber-myers MSD</em> 도 패스.</p>

<p>(2) <em>R-way</em> 든 <em>Ternary</em> 든 <em>tries</em> 자체를 만들기 어렵다. 탐색해야 할 문서는 어마어마하기 때문에 메모리의 양이 모자랄 수 밖에 없다. </p>

<p>뭔가 문서를 <em>streaming</em> 취급하면서 처리할 수 있는 알고리즘이 필요하다.</p>

<p>주된 <em>application</em> 은</p>

<ul>
<li><strong>computer forensics:</strong> search memory, disk for signatures</li>
<li><code>CTRL + F</code></li>
<li><strong>spam filtering:</strong> 특정 패턴이 발견되면 스팸이라 볼 수 있다.</li>
<li><strong>internet traffic monitoring:</strong> 보안</li>
<li><strong>screen scraping:</strong> 관련있는 패턴을 추출할 수 있다.</li>
</ul>

<p>자바에서는 <code>indexOf</code> 메소드가 문자열에서 해당 패턴을 발견해 시작 인덱스를 돌려준다.</p>

<h3 id="bruteforce">Brute Force</h3>

<p><del>언젠가 양자 컴퓨터가 나오면 쓸모 있을까</del></p>

<pre><code class="java">public static int bruteForce(String pattern, String docs) {  
    int M = pattern.length();
    int N = docs.length();

    for (int i = 0; i &lt; N - M; i ++) {
        int j;

        for (j = 0; j &lt; M; j++) 
            if (pattern.charAt(j) != docs.charAt(i + j)) break;

        if (j == M) return i;
    }

    return N;
}
</code></pre>

<p>성능은 <em>worst case</em> 에서 <code>~M N</code> 번의 <em>char compares</em> 가 필요하다. 예를 들어 문서가 <code>AAAAAAAAAAAB</code> 고 패턴이 <code>AAAAAB</code> 면 최악이다.</p>

<h4 id="backup">Backup</h4>

<p>대부분의 <em>application</em> 에서 <em>backup</em> 하길 원치 않는다. 서론에 언급했듯이 스트림처럼 취급하고싶은데, <em>brute force</em> 에서는 <em>backup</em> 이 필요하기 때문에 <em>last <code>M</code> characters</em> 의 버퍼를 유지한다거나의 방법을 쓸 수 있다.</p>

<p>아래의 구현은 똑같은 비교 회수를 가지는데, <em>backup</em> 한다는걸 확실히 보여준다.</p>

<ul>
<li><code>i</code> points to end of sequence of already-matched chars in docs</li>
<li><code>j</code> stores # of already-matched chars (end of sequence in pattern)</li>
</ul>

<pre><code class="java">public static int bruteForceBackup(String pattern, String docs) {  
    int i, N = docs.length();
    int j, M = pattern.length();

    for (i = 0, j = 0; i &lt; N &amp;&amp; j &lt; M; i++) 
        if (docs.charAt(i + j) == pattern.charAt(j)) j++;
        else { i -= j; j = 0; }

    if (j == M) return i - M;
    else return N;
}
</code></pre>

<p>이게 <code>M</code> 이 작으면 문제가 안되는데, <code>M</code> 이 크면 문제가 될 수 있다.</p>

<p>우리가 풀어야 할 문제는</p>

<p>(1) <em>linear-tme guarantee</em> 가 필요 <br />
(2) <em>backup</em> 하지 않기</p>

<h3 id="knuthmorrispratt">Knuth-Morris-Pratt</h3>

<p>아이디어는 간단하다. 매칭에 실패했을 경우, 현재까지 처리한 문자들에 대한 <em>정보</em> 를 가지고 있기 때문에, 이걸 이용해서 필요 없는 부분을 건너 뛴다.</p>

<pre><code>// pattern: BAAAAAAAAA

A B A A A A B A A A A A A A A A  
  B A A A A ^ // fail
            B // ignore previous chars
</code></pre>

<h4 id="dfa">DFA</h4>

<p><em>Knuth-Morris-Pratt</em> 알고리즘은 <em>deterministic finite state automation, DFA</em> 란 것에 이론적으로 기반한다.</p>

<p><em>DFA</em> 는 <em>abstract string-searching machine</em> 이다.</p>

<ul>
<li>Finite number of states (including start and halt)</li>
<li><strong>Exactly one transition</strong> for each char in alphabet</li>
<li>Accept if sequence of transitions leads to half state</li>
</ul>

<p><img src='http://www-igm.univ-mlv.fr/' ~lecroq/string/images/rwadfa2.png" alt="" /></p>

<p align="center">(<a href='http://www-igm.univ-mlv.fr/' >http://www-igm.univ-mlv.fr</a>)</p>

<p>더 크게 보면 <em>DFA</em> 는 <em>Finite State Machine, FSM</em> 의 한 종류다. <em>DFA</em> 말고도 <em>Nondeterministic Finite Automata, NFA</em> 가 있는데,  차이점은 이렇다.</p>

<blockquote>
  <p>비결정적 유한 오토마타는 결정적 유한 오토마타와는 다르게 입력 기호에 대해서 <code>\epsilon</code>-transition 에 의해 0개 이상의 이동이 가능하다. 만약 가능한 다음 상태의 경우가 없다면, 기계는 입력을 거부한다.</p>
</blockquote>

<p>결정적 유한 오토마타는 입력값에 대해 출력 값이 1개라는 소리 같은데, 좀 모호해서 더 찾아봤다. <a href='http://math.stackexchange.com/questions/563829/difference-between-nfa-and-dfa' >여기</a> 에 의하면</p>

<blockquote>
  <p>Each input to a <strong>DFA</strong> or <strong>NFA</strong> affects the state of the automaton: if it was in state q immediately before the input, either it will be in some state q′ after the input, or the input will cause it to choke. (Note that q′ may be the same as q.) Suppose that we have an automaton in a state q. The difference in behavior between a DFA and an NFA is this:</p>
  
  <ul>
  <li><p>If it’s a <strong>DFA</strong>, each possible input determines the resulting state q′ uniquely. Every input causes a state change, and the new state is completely determined by the input. Moreover, the automaton can change state only after reading an input.</p></li>
  <li><p>If it’s an <strong>NFA</strong>, some inputs may allow a choice of resulting states, and some may cause the automaton to choke, because there is no new state corresponding to that input. Moreover, the automaton may be constructed so that it can change state to some new state q′ without reading any input at all.</p></li>
  </ul>
  
  <p>As a consequence of this difference in behavior, DFA’s and NFA’s differ in another very important respect.</p>
  
  <ul>
  <li><p>If you start a <strong>DFA</strong> in its initial state and input some word w, the state q in which the DFA ends up is completely determined by w: inputting w to the DFA will always cause it to end up in state q. This is what is meant by calling it deterministic.</p></li>
  <li><p>If you start an <strong>NFA</strong> in its initial state and input some word w, there may be several possible states in which it can end up, since some of the inputs along the way may have allowed a choice of state changes. Consequently, you can’t predict from w alone in exactly which state the automaton will finish; this is what is meant by calling it nondeterministic. (And it’s actually a little worse than I’ve indicated, since an NFA is also allowed to have more than one initial state.)</p></li>
  </ul>
  
  <p>Finally, these differences affect how we determine what words are accepted (or recognized) by an automaton.</p>
  
  <ul>
  <li><p>If it’s a <strong>DFA</strong>, we know that each word completely determines the final state of the automaton, and we say that the word is accepted if that state is an acceptor state.</p></li>
  <li><p>If it’s an <strong>NFA</strong>, there might be several possible final states that could result from reading a given word; as long as at least one of them is an acceptor state, we say that the automaton accepts the word.</p></li>
  </ul>
</blockquote>

<p><del>갓 아메리카</del></p>

<p>똑같은 입력에 대해 <em>NFA</em> 는 다양한 최종상태를 만들 수 있다고 한다. 그래서 그 중 하나라도 <em>accept</em> 되면, 처리 된 것으로 받아들인다고 함. 어디서 주워들은 <em>NP hardness</em> 와 비스무리한 개념인것 같다. 그림을 다시 보면</p>

<p><img src='http://www-igm.univ-mlv.fr/' ~lecroq/string/images/rwadfa2.png" alt="" /></p>

<p align="center">(<a href='http://www-igm.univ-mlv.fr/' >http://www-igm.univ-mlv.fr</a>)</p>

<p>검색하려는 패턴, 즉 <em>desired state</em> 나열하고 <em>transition</em> 를 그려가며 <em>DFA</em> 를 만든다. 이를 이용해 텍스트를 파싱하면서 <em>final state</em> 에 도달하는지 보면 된다.    </p>

<p>구현은 </p>

<pre><code class="java">public int kmpStringSearch(String docs, String pattern) {  
  int i, j;
  int N = docs.length(), M = pattern.length();
  Int[][] dfa = createDFA(pattern);

  for (i = 0, j = 0; i &lt; N &amp;&amp; j &lt; M; i++) {
    j = dfa[txt.charAt(i)][j];
  }

  if (j == M) return i - M 
  else N
}
</code></pre>

<p>재밌는 사실은 <em>backup</em> 이 더이상 필요 없기 때문에 입력을 <em>stream</em> 으로 받을 수도 있다.</p>

<pre><code>public int kmpStringSearch(In in, String pattern) {  
  int i, j;
  int M = pattern.length();
  Int[][] dfa = createDFA(pattern);

  for (i = 0, j = 0; !in.isEmpty() &amp;&amp; j &lt; M; i++) {
    j = dfa[in.readChar()][j];
  }

  if (j == M) return i - M 
  else N
}
</code></pre>

<p>따라서 <em>running time</em> 은 <em>DFA</em> 만 있다면 확실히 <code>N</code> 번의 <em>char access</em> 다. 그럼 이제 문제는, <em>DFA</em> 를 만드는데 얼마나 시간이 걸릴것 인가? </p>

<p><em>DFA</em> 를 만들면서 알아보자. <code>ABABAC</code> 의 패턴이 있을때</p>

<p>(1) <em>match transition</em></p>

<p>현재 상태가 <code>j</code> 이고 다음 문자인 <code>c</code> 가 <code>c == pattern.charAt(j)</code> 이면 <em>match transition</em> 이므로 <code>j++</code> 이다.</p>

<p>따라서 패턴 <code>ABABAC</code> 의 <em>DFA</em> 는</p>

<pre><code>               j     0 1 2 3 4 5 
pattern.charAt(j)    A B A B A C

dfa[][j]          A  1   3   5  
                  B    2   4  
                  C            6                  
</code></pre>

<p>(2) <em>mismatch transition</em></p>

<p>상태 <code>j</code> 에서 <code>c != pattern.chatAt(j)</code> 이면, <em>mismatch</em> 다. 그러면  방금 전까지 만든 <code>j-1</code> 까지의 <em>DFA</em> 를 이용해서 <code>pattern[1 .. j-1]</code> 까지를 인풋으로 넣어 돌리면 된다. 무슨말인고 하니</p>

<p><code>ABABAC</code> 에서 현재 <em>state</em> 가 <code>5</code> 면, 다음 인풋으로 <code>C</code> 를 받아야한다. <code>ABABA^C</code> 이렇게 표기하자. 그러면, <code>ABABA</code> 까지의 <em>DFA</em> 를 만들었으므로, 첫 문자 <code>A</code> 를 버리고 다음 문자 <code>C</code> 를 포함해서 <code>BABAC</code> 를 인풋으로 해서 <em>DFA</em> 를 돌리면 된다.</p>

<p>예를 들어 <code>j = 5</code>, <code>c = A, B</code> 에 대해 <code>j = 4</code> 까지의 <em>DFA</em> 를 짓고</p>

<pre><code>               j     0 1 2 3 4 5 
pattern.charAt(j)    A B A B A C

dfa[][j]          A  1 1 3 1 5  
                  B  0 2 0 4 0
                  C  0 0 0 0 0 6                  
</code></pre>

<p>에 대해서 <code>BABA</code> 를 반복하면, <code>j = 3</code> 이다. 따라서</p>

<ul>
<li><code>dfa['A'][5] = dfa['A'][3] = 1</code></li>
<li><code>dfa['B'][5] = dfa['B'][3] = 4</code></li>
</ul>

<p>이게 잘 보면 매번 <code>j - 1</code> 의 스텝을 반복해야하는 걸로 보일 수 있는데, 그러지 말고 <code>pattern[1 .. j-1]</code> 을 <em>state</em> <code>X</code> 라 부르고, 이걸 유지하면 <em>transition</em> 을 <em>constant time</em> 으로 지을 수 있다. 즉 <code>j</code> 가 하나 증가할 때 마다 </p>

<p><code>X = dfa[pattern.charAt(j)][X]</code></p>

<p>이렇게 <code>X</code> 를 업데이트하면, <code>j - 1</code> 까지의 상태가 <code>X</code> 다. 따라서 <em>DFA</em> 를 <em>linear time</em> 으로 만들 수 있다.</p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVTT3lJR08zSUdOalZUTm1WV0x6UVRPaDFDTmhkek10RXpZeFFXTGpWR1p3a1RZekkyTDRnek0wOHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<h4 id="performance">Performance</h4>

<p><em>DFA</em> 를 만드는 속도는 <code>M</code> <em>char access</em> 이므로 전체 문서를 검색하는데 걸리는 시간은 <code>M + N</code> <em>char access</em> 다. (<code>M</code> 은 패턴의 길이, <code>N</code> 은 문서의 길이)</p>

<p>그러나 <em>DFA</em> 를 만드는데 필요한 메모리가 <code>R * M</code> 이다.</p>

<p><em>NFA</em> 를 이용하면 <em>KMP</em> 알고리즘을 더 개선할 수 있다. <code>M</code> 에 비례하는 시간, 공간만으로도 패턴을 문서에서 탐색할 수 있다고 한다. <a href='http://algs4.cs.princeton.edu/53substring/KMPplus.java.html' >KMPplus.java</a></p>

<h4 id="kmpimplementation">KMP Implementation</h4>

<p>구현하면</p>

<pre><code class="java">public class DFA {

    int[][] dfa;

    public DFA(String pattern, int R) {
        int M = pattern.length();

        // initialize
        dfa = new int[R][];
        for (int r = 0; r &lt; R; r++)
            dfa[r] = new int[M];

        dfa[pattern.charAt(0)][0] = 1;

        // build DFA
        for (int X = 0, j = 1; j &lt; M; j++) {
            // mismatch
            for (int c = 0; c &lt; R; c++)
                dfa[c][j] = dfa[c][X];

            // match
            dfa[pattern.charAt(j)][j] = j + 1;

            // update X
            X = dfa[pattern.charAt(j)][X];
        }
    }

    public int search(String docs) {

        int i, j, M = pattern.length(), N = docs.length();

        for (i = 0, j = 0; i &lt; N &amp;&amp; j &lt; M; i++) {
            j = dfa[docs.charAt(i)][j];
        }

        if (j == M) return i - M;
        else return N;
    }
}
</code></pre>

<h3 id="boyermoore">Boyer-Moore</h3>

<p><em>KMP</em> 알고리즘은 <em>linear time</em> 인데, 이보다 더 빠르게 할 수 있을까?</p>

<p><br/></p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVDTmtkVE5qaHpZaWRUWWhSVEx5STJNaDFDWmlCek10SUdaeFlUTGlGVE0yRVdPakp6TDRJRE4wOHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(<a href='http://www.programering.com/' >http://www.programering.com</a>)</p>

<p>패턴의 우측부터 매칭해 가면, 꽤나 많은 <code>M</code> 사이즈의 텍스트를 빠르게 제낄 수 있다. 문제는 패턴이 어디까지 매칭되었는지에 따라 스킵할 수 있는 문자가 다르다는 것이다. 경우를 좀 나눠서 살펴보자 <code>i</code> 는 현재 문서의 탐색할 인덱스를, <code>^</code> 는 <em>mismatch</em> 를 나타낸다.</p>

<pre><code class="java">// case 1

          i     ^
. . . . . . . . T L E . . . . 
          N E E D L E

                  i
. . . . . . . . T L E . . . . 
                  N E E D L E
</code></pre>

<p><em>case 1</em> 은 운이 좋아서, 미스매치 <code>T</code> 가 패턴에 없기 때문에 <code>T</code> 다음으로 <code>i</code> 를 옮길 수 있다.</p>

<pre><code class="java">// case 2a

          i     ^
. . . . . . . . N L E . . . . 
          N E E D L E

                i 
. . . . . . . . N L E . . . . 
                N E E D L E
</code></pre>

<p>여기선 <em>mismatch</em> 문자 <code>N</code> 이 패턴에 있기 때문에 <em>rightmost</em> <code>N</code> 을 찾아 다시 비교를 시작한다. (우측부터 비교하기 때문)</p>

<pre><code class="java">// case 2b

          i     ^
. . . . . . . . E L E . . . . 
          N E E D L E

// rightmost 'E'          

      i          
. . . . . . . . E L E . . . . 
      N E E D L E


// just increament `i` by 1

                i         
. . . . . . . . E L E . . . . 
            N E E D L E
</code></pre>

<p>이 경우엔 <em>rightmost</em> <code>E</code> 가 별로 도움이 안되므로, 그냥 <code>i</code> 를 증가시킨다.</p>

<p>다시 한번 정리하면, </p>

<p>(1) 우측부터 시작해서 비교하다 <em>mismatch</em> 문자가 있을 때 필요 없는 문자를 몇개나 제낄 수 있느냐 하는 문제는, 패턴 안에서 해당 <em>mismatch</em> 문자가 있느냐 없느냐에 따라 다르다.</p>

<p>(2) 없다면 모두 제껴버리면 되는거고, </p>

<p>(3) 있다면 그 문자가 얼마나 우측에 오느냐에 따라 스킵할 수 있는 문자의 수가 달라진다. 우측에 오면 올 수록 거기서 부터 다시 비교해야 하기 때문에, <em>heuristic</em> 이 별로 도움이 안될 수도 있다. <em>case 2b</em> 가 바로 그 예다. 그럴때는 그냥 1 만큼 증가시키는것이 더 나을 수도 있다. </p>

<p><em>skip table</em> 을 만들면</p>

<pre><code class="java">int M = pattern.length();  
int[] right = new int[R];

for (i = 0; i &lt; R; i++) right[i] = -1;  
for (j = 0; j &lt; M; j++) right[pattern.charAt(j)] = j;  
</code></pre>

<p>이 테이블을 이용해 탐색을 하면</p>

<pre><code class="java">int N = docs.length();  
int M = pattern.length();

for (int i = 0; i &lt;= N - M; i++) {  
  int skip = 0;

  for (int j = M - 1; j &gt;=0; j--) {
    if (docs.charAt(i + j) != pattern.charAt(j)) {
      skip = Math.max(1, j - right[docs.charAt(i + j)]);
      break;
    }
  }

  if (skip == 0) return i;
}

return N;  
</code></pre>

<p>이 알고리즘에서 <code>skip</code> 을 계산하는 부분을 잘 보면</p>

<pre><code class="java">skip = Math.max(1, j - right[docs.charAt(i + j)]);  
</code></pre>

<p>현재 비교가 진행된 <code>j</code> 에서 <em>mismatch</em> 문자의 인덱스를 뺄셈해서 1 보다 큰지를 비교한다. 만약 1 보다 작다면, 다시 말해 <code>0</code> 이나 음수라면 <code>skip</code> 이 마이너스로, 즉 왼쪽으로 되기 때문에 스킵할 필요가 없다. 그냥 우측으로 <code>+1</code> 해서 다시 비교하면 된다.</p>

<p>전체 코드는</p>

<pre><code class="java">public class BoyerMoore {

    int[] right;
    String pattern;

    public BoyerMoore(String pattern, int R) {

        this.pattern = pattern;
        int M = pattern.length();

        // initialize skip table
        right = new int[R];
        for (int i = 0; i &lt; R; i++) right[i] = -1;
        for (int j = 0; j &lt; M; j++) right[pattern.charAt(j)] = j;
    }

    public int search(String docs) {

        int M = pattern.length();
        int N = docs.length();

        for (int i = 0; i &lt;= N - M; i++) {
            int skip = 0;

            for (int j = M - 1; j &gt;=0; j--) {
                if (pattern.charAt(j) != docs.charAt(i + j)) {
                    // calculate skip value
                    skip = Math.max(1, j - right[docs.charAt(i + j)]);
                    break;
                }
            }

            if (skip == 0) return i;
        }

        return N;
    }
}
</code></pre>

<p>이건 <em>bad character</em> 라는 특성을 이용한 방법이고, <em>good suffix</em> 등을 과 비교하여 얼마나 더 스킵할지를 결정할 수 있다. </p>

<p>보이어 무어 알고리즘에 대한 설명은 <a href='http://xenostudy.tistory.com/72' >여기</a>가 제일 잘 되어있다. </p>

<h4 id="performance">Performance</h4>

<p>일반적으로는(휴리스틱) <code>~N/M</code> 의 <em>char compare</em> 비교를 한다고 알려져있다. <em>sublinear</em> 한건데, </p>

<p><em>worst case</em> 에서는 <code>~ MN</code> 이다. 예를 들어 패턴이 <code>ABBBB</code> 고 문서가 <code>BBBBBBBBBBBBBBBBB..</code> 일때 최악이다.</p>

<p><em>worst case</em> 를 <code>~3N</code> 까지 개선할 수 있다. <em>KMP-like rule</em> 을 더해 반복적인 패턴을 비하면 된다.</p>

<p>실제로 보이어 무어 알고리즘은 검색할 문자열이 길때 효과가 있다. 그래야 스킵할것이 많기 때문이다. 그러나 대부분의 경우 검색어가 그다지 길지 않다는 것.</p>

<h3 id="rabinkarp">Rabin-Karp</h3>

<p><img src='http://terpconnect.umd.edu/' ~sthomas2/images/rabinkarp.jpg" alt="" /></p>

<p align="center">(<a href='http://terpconnect.umd.edu/' >http://terpconnect.umd.edu</a>)</p>

<p>기본 아이디어는 <em>modular hashing</em> 이다. 인덱스를 하나씩 증가시켜가면서 문자열의 해싱 값을 비교한다.</p>

<p>먼저 해야할 일은 <em>hash function</em> 을 만드는 건데, <code>t_i</code> 를 문서(<code>txt</code>) 의 <code>i</code> 번째 캐릭터라 하면</p>

<p><img src='http://chart.apis.google.com/chart?cht=tx&amp;chl=x_t%20%3D%20t_i%20R%5E%7BM-1%7D%5C%20%20%2B%5C%20%20t_%7Bi%2B1%7D%20R%5E%7BM-2%7D%5C%20%20%2B%5C%20%20%5Ccdots%20%5C%20%5C%20%20%2B%5C%20%20%20t_%7Bi%2BM-1%7D%20R%5E%7B0%7D%5C%20%5C%20%20' (mod)%5C%20%5C%20%20Q" alt="" /></p>

<p>여기서 <code>M</code>-<em>digit</em>, <code>R</code>-<em>base</em>, <code>Q</code> modulo 다. <code>M</code>-<em>degree</em> 다항식인데, <em>Horner's method</em> 를 쓰면 중복된 계산 없이 <em>linear time</em> 으로 <em>evaluation</em> 가능하다. </p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVTWjBnak1rUkRPeUVqWWpSVEwwRW1NaDFpWjVVek10WVROME1UTDNjVFl4SUdaemt6TDNjRE4wOHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(<a href='http://www.programering.com/' >http://www.programering.com/</a>)</p>

<p>난 첨에 뭔소린가 했는데 다항식의 값을 구할 때 중복된 계산을 피하기 위해 이렇게 구현하는걸 말한다.</p>

<p><img src='http://web-ext.u-aizu.ac.jp/course/alg1/ex/uk/ex04/horner2.png'  alt="" /></p>

<p><code>R</code> 에 대한 다항식이기 때문에, 해싱함수의 구현은</p>

<pre><code class="java">private long hash(String key, int M, int Q) {  
  long h = 0;

  for(int j = 0; j &lt; M; j++)
    h = (R * h + key.charAt(j)) % Q;

  return h;
}
</code></pre>

<p><code>x_i</code> 의 해싱값을 계산하고, 매칭이 안되면 다음으로 넘어가 <code>x_(i+1)</code> 을 계산해야 한다. 그런데, 좀 더 효율적으로 할 수 있는 방법이 없을까? 당연히 가능하다. 두 해싱값 서로 다른 1개의 항 빼고는 모두 같은 항을 가지고 있기 때문이다. </p>

<p><img src='http://chart.apis.google.com/chart?cht=tx&amp;chl=x_i%5C%20%20%3D%5C%20t_iR%5E%7BM-1%7D%5C%20%2B%5C%20t_%7Bi%2B1%7DR%5E%7BM-2%7D%5C%20%2B%5C%20%5Ccdots%5C%20%2B%5C%20t_%7Bi%20%2B%20M%20-%201%7DR%5E0%5C%5C%0A%5C%20%5C%5C%20%0A%5C%20%5C%5C%0A%5C%20%5C%5C%0A%5C%20%5C%5C%0A%5C%20%5C%5C%0Ax_i%5C%20%20%3D%5C%20t_%7Bi%20%2B%201%7DR%5E%7BM-1%7D%5C%20%2B%5C%20t_%7Bi%2B1%7DR%5E%7BM-2%7D%5C%20%2B%5C%20%5Ccdots%5C%20%2B%5C%20t_%7Bi%20%2B%20M%7DR%5E0'  alt="" /></p>

<p>따라서 <code>x_(i+1)</code> 은</p>

<p><img src='http://chart.apis.google.com/chart?cht=tx&amp;chl=x_%7Bi%2B1%7D%5C%20%20%3D%5C%20%20' (x_i%5C%20%20%5C%20-%20t_iR%5E%7BM-1%7D)%5C%20%20*%5C%20%20R%5C%20%2B%5C%20%20t_%7Bi%2BM%7D%20" alt="" /></p>

<p>이므로, 상수 시간 내에 다음 문자열의 해시값을 구할 수 있다. 따라서 매 <code>i</code> 마다 상수 시간이므로 <code>~N</code> 으로 패턴을 찾을 수 있다.</p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVpTmhKR00yWVROaEpHT2psVEwzTW1ONTBpWndjek10Z1RNbGxUTHpNR054WVdPM1l6TDVjRE4wOHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(<a href='http://www.programering.com/' >http://www.programering.com/</a>)</p>

<h4 id="implementation">Implementation</h4>

<p>전체 코드는 <a href='http://algs4.cs.princeton.edu/53substring/RabinKarp.java.html' >RabinKarp.java</a> 로</p>

<pre><code class="java">public class RabinKarp {

    String pattern;
    long patternHash;
    int M;
    long Q;
    int R;
    long RM; // R^(M-1) % Q

    public RabinKarp(String pattern) {
        this.pattern = pattern;

        R = 25;
        M = pattern.length();
        Q = longRandomPrime();

        // pre-compute R^(M-1) % Q for use in removing leading digit
        RM = 1;
        for (int i = 1; i &lt;= M-1; i++)
            RM = (RM * R) % Q;

        patternHash = hash(pattern, M);
    }

    private long hash(String key, int M) {
        long h = 0;

        for (int j = 0; j &lt; M; j++)
            h = (R * h + key.charAt(j)) % Q; 
        return h;
    }

    private static long longRandomPrime() {
        BigInteger prime = BigInteger.probablePrime(31, new Random());
        return prime.longValue();
    }

    public int search(String docs) {
        int N = docs.length();
        long docsHash = hash(docs, M);

        if (docsHash == patternHash) return 0;

        for (int i = M; i &lt; N; i++) {
            // remove leading digit
            docsHash = (docsHash + Q - RM * docs.charAt(i-M) % Q) % Q;
            // add trailing digit
            docsHash = (docsHash * R + docs.charAt(i)) % Q;

            // match
            if (patternHash == docsHash) return i - M + 1;
        }

        return N;
    }
}
</code></pre>

<p>참고로, 해시값을 비교하는 것에는 두 가지 버전이 있다.</p>

<p>(1) <strong>Monte Carlo version:</strong> return match if hash match <br />
(2) <strong>Las Vegas version:</strong> check for substring match if hash match and continue search if false collision.</p>

<p>몬테 카를로는 확률적으로 여러번 구해서 맞는 값을 찾는거다. 근데 만약에 <code>Q</code> 가 <code>MN^2</code> 정도로 상당히 크다면, 충돌이 일어날 확률은 <code>1/N</code> 이다.</p>

<p>실제 돌려보면 <code>Q</code> 를 충분히 크게 고르되, 오버플로우가 안 일어나면 <code>1/Q</code> 의 적은 확률로 충돌이 일어난다.</p>

<p>따라서</p>

<p>(1) <strong>Monte Carlo version</strong></p>

<ul>
<li>Always runs in linear time</li>
<li>Extremely likely to return correct answer (but not always)</li>
</ul>

<p>(2) <strong>Las Vegas version</strong></p>

<ul>
<li>Always returns correct answer</li>
<li>Extremely likely to run in linear time (but worst case is <code>M N</code>)</li>
</ul>

<p>라스베가스 버전에서 <em>worst case</em> 는, 충돌이 매번 나고 매번 검사하는건데. 그럴 일은 거의 없다.</p>

<h4 id="prosandcons">Pros and cons</h4>

<p><em>rabin-karp</em> 알고리즘은 앞서 보았던 <em>KMP</em> 나 <em>boyed moore</em> 에 비해 장점이 있는데</p>

<ul>
<li>Extends to 2d patterns</li>
<li>Extends to finding multiple patterns</li>
</ul>

<p>예를 들어서 다양한 패턴을 찾고싶다 하면, 그 패턴들의 심볼 테이블을 만들어 놓고 검색하면 된다.</p>

<p>단점으로는</p>

<ul>
<li>Arithmetic ops slower than char compares</li>
<li>라스베가스 버전은 백업을 필요로 함</li>
<li>poor worst case guarantee</li>
</ul>

<h3 id="summary">Summary</h3>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVpWTVNMlkxWVdOMUVXTXdJV0w0TWpZaDF5TjJrek10WTJZM0lXTDRjek5pSldabFIyTDBrRE4wOHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Part 2</em> by <strong>Ro$bert Sedgewick</strong> <br />
(2) <a href='http://introcs.cs.princeton.edu/java/73dfa/' >http://introcs.cs.princeton.edu</a> <br />
(3) <a href='http://math.stackexchange.com/questions/563829/difference-between-nfa-and-dfa' >Difference between NFA and DFA</a> <br />
(4) <a href='http://www-igm.univ-mlv.fr/' ~lecroq/string/node4.html">Automaton</a> <br />
(5) <a href='http://somemoreacademic.blogspot.kr/2012/09/boyer-moore-string-matching-algorithm.html' >Boyer Moore string matching algorithm</a> <br />
(6) <a href='http://xenostudy.tistory.com/72' >보이어 무어 알고리즘에 대한 고찰</a> <br />
(7) <a href='http://terpconnect.umd.edu/' ~sthomas2/rabin-karp.html">Rabin-Karp Algorithm</a></p>]]></description><link>http://1ambda.github.io/substring-search/</link><guid isPermaLink="false">2c08e92e-2241-4624-988e-32d552ed67e1</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[substring search]]></category><category><![CDATA[boyer-moore]]></category><category><![CDATA[rabin-karp]]></category><category><![CDATA[knuth-morris-pratt]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 17 Dec 2014 15:16:42 GMT</pubDate></item><item><title><![CDATA[Reactive Programming 1, Monads]]></title><description><![CDATA[<h3 id="whatisreactiveprogramming">What is Reactive Programming?</h3>

<p><em>reactive</em> 란 뜻은</p>

<ul>
<li><em>React to events</em> <strong>(event-driven)</strong></li>
<li><em>React to load</em> <strong>(scalable)</strong></li>
<li><em>React to failures</em> <strong>(resilient)</strong></li>
<li><em>React to users</em> <strong>(responsive)</strong></li>
</ul>

<h4 id="eventdriven">Event-driven</h4>

<p><em>event-driven</em> 을 통해 <em>scalable, resilient</em> 해질 수 있고, 이 3가지를 통해 <em>responsive</em> 한 서비스를 만들 수 있다.</p>

<p>옛날에는 시스템이 <em>multi-threaded</em> 로 구성되어 <em>shared, synchronized state</em> 를 통해 커뮤니케이션 했었다. 그래서</p>

<blockquote>
  <p>Strong coupling, hard to compose</p>
</blockquote>

<p>근데 요즘 시스템은 <em>loosely coupled even handlers</em> 로 구성되기 때문에</p>

<blockquote>
  <p>Events can be handled asynchoronously, without blokcing</p>
</blockquote>

<h4 id="scalable">Scalable</h4>

<blockquote>
  <p>An application is <strong>scalable</strong> if it is able to be expanded according ot its usage</p>
</blockquote>

<ul>
<li><strong>scale up:</strong> make use of parallelism in multi-core systems</li>
<li><strong>scale out:</strong> make use of multiple server nodes</li>
</ul>

<blockquote>
  <p><strong>Important for scalability:</strong> minimize shared mutable state</p>
  
  <p><strong>Important for scale out:</strong> location transparency, resilience</p>
</blockquote>

<h4 id="resilient">Resilient</h4>

<blockquote>
  <p>An application is <strong>resilient</strong> if it can recover quickly from failures</p>
</blockquote>

<p>일반적으로 <em>resilience</em> 는 나중에 (<em>afterthought</em>) 추가하기 어렵다. 시작부터 디자인의 일부로 고려해야한다. 이를 위해</p>

<ul>
<li>loose coupling</li>
<li>strong ecapsulation of state</li>
<li>pervasive supervisor hierarchies</li>
</ul>

<h4 id="responsive">Responsive</h4>

<blockquote>
  <p>An application is <strong>responsive</strong> if it provides rich, real-time interaction with its users even under load and in the presence of failures.</p>
  
  <p>Responsive applications can be built on an event-driven, scalable, and resilient architecture</p>
  
  <p>Still need careful attention to algorithms, system design, back-pressure, and many other details.</p>
</blockquote>

<h4 id="callback">Callback</h4>

<p>보통 이벤트를 다루기 위해 <em>callback</em> 이 사용되는데 자바를 예로 들면</p>

<pre><code class="scala">class Counter extends ActionListener {  
  private var count = 0
  button.addActinoListener(this)

  def actionPerformed(e: ActionEvent): Unit = {
    count += 1
  }
}
</code></pre>

<p>여기서 볼 수 있는 문제는 </p>

<p>(1) <em>shared mutable state</em> 가 필요하다 <br />
(2) <em>composing</em> 하기 힘들다 <br />
(3) 시스템이 커지면 <em>callback hell</em> 이 될 수 있다</p>

<h4 id="composableeventabstraction">Composable Event Abstraction</h4>

<p>일반적으로 함수형 프로그래밍에서 이를 해결하기 위한 방법은 <em>composable event abstraction</em> 이다.</p>

<ul>
<li>Events are first class</li>
<li>Events are often represented as messages</li>
<li>Handlers of events are also first-class</li>
<li>Complex handlers can be composed from primitive ones</li>
</ul>

<p>이 수업에서 다룰 내용은 <em>monad</em>, <em>future</em>, <em>observables</em>, <em>actor</em>, <em>supervisor</em>, <em>distributed actor</em> 등이다.</p>

<h4 id="functionpatternmaching">Function, Pattern Maching</h4>

<p>잠깐 복습하고 가면 <em>JSON</em> 을 모델링 하기 위해서</p>

<pre><code class="scala">abstract class JSON  
case class JSeq (elems: List[JSON])           extends JSON  
case class JObj (bindings: Map[String, JSON]) extends JSON  
case class JNum (num: Double)                 extends JSON  
case class JStr (str: String)                 extends JSON  
case class JBool (b: Boolean)                 extends JSON  
case class JNull                              extends JSON  
</code></pre>

<p>그러면 요로코롬 데이터를 표현할 수 있다.</p>

<pre><code class="scala">  val data = JObj(Map(
    "firstName"   -&gt; JStr("Jason"),
    "lastName"    -&gt; JStr("Bone"),
    "phoneNumber" -&gt; JSeq(List(
      JObj(Map(
        "type" -&gt; JStr("home"), "number" -&gt; JStr("212 555 3347"),
        "type" -&gt; JStr("fax"),  "number" -&gt; JStr("33312 555 3347")
      ))
    ))
  ))
</code></pre>

<p>자바스크립트에서 이거랑 똑같다. 좀 스칼라 버전이 복잡해 보이는데, 오더스키 말로는 더 문법적으로 간편하도록 작성할 수 있다고 한다. 아마 어디 라이브러리에 구현되어있을듯</p>

<pre><code class="javascript">data = {  
  "firstName": "Json",
  "lastName": "Bone",
  "phoneNumber": [
    { "type: "home", "number", "212 555 3347" },
    { "type: "fax",  "number", "33312 555 3347" }
  ]
}
</code></pre>

<p>이제 <code>JSON</code> 을 출력하는 <code>show</code> 함수를 만들어 보면</p>

<pre><code class="scala">  def show(json: JSON): String = json match {
    case JSeq(elems) =&gt; "[" + (elems map show mkString ", ") + "]"
    case JObj(bindings) =&gt;
      val assocs = bindings map {
        case (key, value) =&gt; "\"" + key + "\":" + show(value)
      }
      "{" + (assocs mkString ", ") + "}"

    case JNum(num) =&gt; num.toString
    case JStr(str) =&gt; "\"" + str + "\""
    case JBool(b) =&gt; b.toString
    case JNull() =&gt; "null"
  }
</code></pre>

<p><em>case class</em> 가 나와서 잠깐 보면 다음 타입은 무엇일까?</p>

<pre><code class="scala">{ case (key, value) =&gt; ...  }
</code></pre>

<p>이것 자체로는 아무 타입이 아닌데, 타입을 지정해 주면 <em>function</em> 이 될 수 있다. 무슨말인고 하니</p>

<pre><code class="scala">type JBinding = (String, JSON)  
val f = { case (key, value) =&gt; ...  } // error  
val f: JBinding =&gt; String = { case (key, value) =&gt; ...  }  
</code></pre>

<p>두 번째 <code>val</code> 만 성공적으로 컴파일된다. 그리고 스칼라에서 모든 구체적인 타입은 <em>class</em> 나 <em>trait</em> 의 구현체인데 <em>function</em> 도 마찬가지다.</p>

<p><code>JBinding =&gt; String</code> 은 <code>scala.Function1[JBinding, String]</code> 이다. 다시 말해서 모든 함수는 <code>Function</code> <em>trait</em> 의 구현이다.</p>

<pre><code class="scala">trait Function[-A, +R] {  
  def apply(x: A): R
}
</code></pre>

<p>여기서 <code>-A</code>, <code>+R</code> 등은 <em>variance</em> 와 관련된 것인데, 이 <em>variance</em> 란 것이 어떤 두 타입사이에 관계가 있다면, 컨테이너에 넣었을때의 관계는 어떠한가를 기술하는 것이다. </p>

<ul>
<li><code>S &lt;: T</code> means <strong>S is a subtype of T</strong></li>
<li><code>S :&gt; T</code> means <strong>S is a supertype of T</strong></li>
</ul>

<p>이걸 <em>bound</em> 라 부른다. 따라서 <em>mixed bound</em> 도 있다. <code>S &gt;: NonEmpty &lt;: IntSet]</code> 이라던지.</p>

<p><code>A &lt;: B</code>, 즉 <em>lower bound</em> 가 있고, 컨테이너 <code>C</code> 가 있을때</p>

<ul>
<li><code>C[A] &lt;: C[B]</code> means <strong>C is covariant</strong>, <code>C[+A]</code></li>
<li><code>C[A] &gt;: C[B]</code> means <strong>C is contravariant</strong>, <code>C[-A]</code></li>
<li>상관 없으면 <strong>C is non-variant</strong>, <code>C[A]</code></li>
</ul>

<p>위에서 봤듯이 함수의 파라미터는 <em>contravariant</em>, 리턴타입은 <em>covariant</em> 인데 이는 파라미터를 나중에 함수 호출할 수 있기 때문이다.</p>

<p>더 자세한 내용은 <a href='http://1ambda.github.io/functional-programming-in-scala-chapter-4/' >Functional Programming in Scala Chapter4</a> 를 참조하자.</p>

<p>함수는 <em>trait</em> 의 구현이고, <code>Map</code> 은 <code>Function1</code> 의 서브클래스다. 따라서 맵을 사용할때 <code>exampleMap(key)</code> 처럼 사용할 수 있다.</p>

<p><code>Seq</code> 도 마찬가지로 서브클래스다. 그래서 <code>Vector(3)</code> 처럼 사용할 수 있다.</p>

<h4 id="collection">Collection</h4>

<p>컬렉션도 잠깐 복습해 보자.</p>

<p><img src='http://librairie.immateriel.fr/baw/9780596155957/httpatomoreillycomsourceoreillyimages322250.png'  alt="" /></p>

<p align="center">(<a href='http://librairie.immateriel.fr/' >http://librairie.immateriel.fr</a>)</p>

<p><img src='http://i.stack.imgur.com/2fjoA.png'  alt="" /></p>

<p align="center">(<a href='http://stackoverflow.com/' >http://stackoverflow.com</a>)</p>

<p><em>filter, map</em> 과 같은 메소드들은 다양한 컬렉션을 지원하지만, <em>list</em> 에서는 <em>tail recursive</em> 하게 정의되어 있다고 한다.</p>

<h3 id="forexpression">For Expression</h3>

<p>스칼라에서 <code>for</code> 구문은 <code>map, flatMap</code> 그리고 <em>lazy variant</em> <code>filter</code> 로 번역된다.</p>

<p>(1) <code>for (x &lt;- e1) yield e2</code> 는</p>

<p><code>e1.map(x =&gt; e2)</code> 다.</p>

<p>(2) <code>for (x &lt;- e1 if f; s) yield e2</code> 는</p>

<p>여기서 <code>f</code> 는 <em>filter</em> 고 <code>s</code> 는 <em>sequence of generators and filters</em> 다. 따라서</p>

<p><code>for (x &lt;- e1.withFilter(x =&gt; f); s) yield e2</code> 로 번역된다. 외울 필요는 없고 <code>for</code> 루프를 쓸 때 <code>withFilter</code> 때문에 메모리 낭비가 적다는 사실 정도만 알고 있으면 된다.</p>

<blockquote>
  <p>You can think of <code>withFilter</code> as a variant of <code>filter</code> that doesn't produce an intermediate list, but instead filters the following <code>map</code> or <code>flatMap</code> function application</p>
</blockquote>

<p>(3) <code>for (x &lt;- e1; y &lt;- e2; s) yield e3</code> 는</p>

<p><code>e1.flatMap(x =&gt; for (y &lt;- e2; s) yield e3)</code> 로 번역된다.</p>

<p>(4) <code>for</code> 구문에서 <em>generator</em> 의 <em>left-hand side</em> 가 패턴일 수 있다. 무슨말인고 하니</p>

<pre><code class="scala">val data: List[JSON] = ...

for {  
  JObj(bindings) &lt;- data
  JSeq(phones) &lt;- bindings("phoneNumber")
  JObj(phone) &lt;- phones
  JStr(digits) = phone("number")
  if digits startWith "212"
} yield (bindings("firstName"), bindings("lastName"))
</code></pre>

<p><code>pattern &lt;- expr</code> 은 이렇게 번역된다.</p>

<pre><code class="scala">x &lt;- expr withFilter {  
        case pattern =&gt; true
        case _ =&gt; false
     } map {
       case pattern =&gt; x
     }
</code></pre>

<h3 id="functionalrandomgenerators">Functional Random Generators</h3>

<p><code>for</code> 구문은 <em>collection</em> 에만 쓸 수 있지 않다. <code>map, flatMap, withFilter</code> 만 구현 된다면 다른 곳으로의 응용도 가능하다. (LINQ 도 그 예라고 본것 같음)</p>

<p><em>random value generator</em> 가 하나의 예제인데, 뭔지 살펴보자.</p>

<pre><code class="scala">  trait Generator[+T] {
    def generate: T
  }

  val integers = new Generator[Int] {
    val rand = new java.util.Random
    def generate = rand.nextInt()
  }

  val booleans = new Generator[Boolean] {
    def generate = integers.generate &gt; 0
  }

  val pairs = new Generator[(Int, Int)] {
    def generate = (integers.generate, integers.generate)
  }
</code></pre>

<p>말 그대로 랜덤한 값들을 타입별로 생성해주는거다. 근데, 매번 해야하는 <em>boilerplate</em> 땜에 귀찮타. 더 좋은 방법은 없을까? 예를 들어 이렇게 쓸 수 있다면,</p>

<pre><code class="scala">val booleans = for (x &lt;- integers) yield x &gt; 0

def pairs[T, U](t: Generator[T], u: Generator[U]) = for {  
  x &lt;- t
  y &lt;- u
} yield (x, y)
</code></pre>

<p><del>존나</del> 쿨하다! 근데 이게 스칼라에서 이렇게 번역되기 때문에</p>

<pre><code class="scala">val booleans = integers map (x =&gt; x &gt; 0)

def pairs[T, U](t: Generator[T], u: Generator[U]) =  
  t flatMap(x =&gt; u map (y =&gt; (x, y)))
</code></pre>

<p><em>generator</em> 을 위한 <code>map</code>, <code>flatMap</code> 을 만들어야 한다. 이 함수들이  새로운 타입을 위한 <code>Generator</code> 를 돌려주면 된다. <del>모나드 느낌이 솔솔 난다</del></p>

<pre><code class="scala">trait Generator[+T] {  
  self =&gt; // an alias for "this"
  def generate: T

  def map[S](f: T =&gt; S): Generator[S] = new Generator[S] {
    def generate = f(self.generate)
  }

  def flatMap[S](f: T =&gt; Generator[S]): Generator[S] = 
    new Generator[S] {
      def generate = f(self.generate).generate
    }
}
</code></pre>

<p>여기서 <code>self</code> 가 필요한 이유는 <code>map</code> 함수 내부에서 <code>this</code> 컨텍스트를 사용할 수 없기 때문이다. <code>map</code> 의 <code>this</code> 로 해석되어 무한루프에 빠진다.</p>

<p>이렇게 <code>Generator</code> 를 위한 <code>map, flatMap</code> 을 만들면 <code>booleans</code> 가 이렇게 번역된다.</p>

<pre><code class="scala">val booleans = for (x &lt;- integers) yield x &gt; 0

val booleans = integers map { x =&gt; x &gt; 0 }

val booleans = new Generator[Booelan] {  
  def generate = (x =&gt; x &gt; 0)(integers.generate)
}

val booleans = new Generator[Booelan] {  
  def generate = integers.generate &gt; 0
}
</code></pre>

<pre><code class="scala">def pairs[T, U](t: Generator[T], u: Generator[U]) = t flatMap {  
  x =&gt; u map { y =&gt; (x, y) }
}

...
...
...

def pairs[T, U](t: Generator[T], u: Generator[U]) =  
  new Generator[(T, U)] {
    def generate = (t.generate, u.generate)
  }
</code></pre>

<p>여기 몇개 더 유용한 <em>generator</em> 를 좀 살펴보면</p>

<pre><code class="scala">  def single[T](x: T): Generator[T] = new Generator[T] {
    def generator = x
  }

  def choose(l: Int, h: Int): Generator[Int] =
    for (x &lt;- integers) yield l + x % (h - l)

  def oneOf[T](xs: T*): Generator[T] =
    for (i &lt;- choose(0, xs.length)) yield xs(i)
</code></pre>

<p>재밌는 사실은 <em>Generator</em> 가 <em>building block</em> 이 된다는 사실이다. <em>Generator</em> 를 조합해 <em>Generator</em> 를 만들고.</p>

<p>처음에 <em>reactive programming</em> 에 관해서 잠깐 이야기 하면서 <em>compose</em> 란 단어가 나왔는데, 이게 바로 <em>composing</em> 의 강력함이다.</p>

<h4 id="listgenerator">List Generator</h4>

<pre><code class="scala">  def lists: Generator[List[Int]] = for {
    isEmpty &lt;- booleans
    list &lt;- if (isEmpty) emptyLists else nonEmptyLists
  } yield list

  def emptyLists = single(Nil)

  def nonEmptyLists = for {
    head &lt;- integers
    tail &lt;- lists
  } yield head :: tail
</code></pre>

<h4 id="treegenerator">Tree Generator</h4>

<pre><code class="scala">  // tree generator
  trait Tree
  case class Leaf(x: Int)                   extends Tree
  case class Inner(left: Tree, right: Tree) extends Tree

  def leafs: Generator[Leaf] = for {
    x &lt;- integers
  } yield Leaf(x)

  def inners: Generator[Inner] = for {
    l &lt;- trees
    r &lt;- trees
  } yield Inner(l, r)

  def trees: Generator[Tree] = for {
    isLeaf &lt;- booleans
    tree &lt;- if (isLeaf) leafs else inners
  } yield tree
</code></pre>

<p>코드를 보면, 좀 뭔가 감이 올테다. 바로 <code>map</code>, <code>flatMap</code> 을 <code>Geneartor</code> 에 대해서 정의했기 때문에 <code>for</code> 내부에서 <code>Generator</code> 에서 <code>T</code> 타입을 빼올 수 있다. 그리고 <code>yield</code> 를 이용해 만드는 것 또한 <code>Generator</code> 가 된다. </p>

<p><del>오더스키 교수는 진짜 천재같다. 모나드를 이렇게 설명하다니. 예전 강의 들을때도 정말 쉽게 설명한다는 느낌을 많이 받았는데</del></p>

<h4 id="applicationrandomtesting">Application: Random Testing</h4>

<p>유닛테스팅을 할때 <em>input</em> 에 대해서 <em>expected output</em> 과 비교해 테스팅을 진행하는데, <em>input</em> 을 직접 만들지 않고 테스팅이 가능할까?</p>

<blockquote>
  <p>Yes, By generating random test inputs</p>
</blockquote>

<pre><code class="scala">def randomTest[T](g: Generator[T], times: Int = 100)(f: T =&gt; Boolean): Unit = {  
  for (i &lt;- 0 until times) {
    val value = g.generate
    assert(f(value), "test failed for" + value)
  }
  println("passed " + times + "tests")
}
</code></pre>

<p>이런 테스팅을 한다면, </p>

<pre><code class="scala">randomTest(pairs(lists, lits)) {  
  case (xs, ys) =&gt; (xs ++ ys).length &gt; xs.length
}
</code></pre>

<p>실패할 것이다. 둘다 <code>Nil</code> 이면 실패한다.</p>

<p>우리는 <em>test</em> 를 작성할 필요가 없고, 항상 참이어야 하는 <em>properties</em> 만 작성하면 된다. 그게 <a href='http://www.scalacheck.org/' ><em>ScalaCheck</em></a> 도구의 기본 아이디어다.</p>

<p><em>ScalaCheck</em> 튜토리얼을 보면 </p>

<pre><code class="scala">import org.scalacheck.Properties  
import org.scalacheck.Prop.forAll

object StringSpecification extends Properties("String") {

  property("startsWith") = forAll { (a: String, b: String) =&gt;
    (a+b).startsWith(a)
  }

  property("concatenate") = forAll { (a: String, b: String) =&gt;
    (a+b).length &gt; a.length &amp;&amp; (a+b).length &gt; b.length
  }

  property("substring") = forAll { (a: String, b: String, c: String) =&gt;
    (a+b+c).substring(a.length, a.length+b.length) == b
  }
}
</code></pre>

<p>하스켈의 <a href='https://www.haskell.org/haskellwiki/Introduction_to_QuickCheck1' ><em>QuickCheck</em></a> 가 먼저 구현되었다고 한다.</p>

<pre><code class="haskell">*A&gt; quickCheck ((\s -&gt; (reverse.reverse) s == s) :: [Char] -&gt; Bool)
</code></pre>

<h3 id="monads">Monads</h3>

<p><del>올것이 왔다</del></p>

<blockquote>
  <p>Data structures with <code>map</code> and <code>flatMap</code> seem to be quite common.</p>
  
  <p>In fact there's a name that describe this class of a data structure together with some algebraic laws that they hould have</p>
  
  <p>They are called <strong>monads</strong></p>
</blockquote>

<p>모나드는 <code>M[T]</code> 타입으로 표시하는데, 다음의 함수들을 구현해야 한다. 하스켈에서 <code>&gt;&gt;=, return</code> 과 동일하다.</p>

<pre><code class="scala">trait M[T] {  
  // `&gt;&gt;=` called bind
  def flatMap[U](f: T =&gt; M[U]): M[U]
}

// return
def unit[T](x: T): M[T]  
</code></pre>

<p>이미 우리가 모르는 사이에 썼던 모나드를 보면</p>

<ul>
<li><code>List</code> is a monad with <code>unit(x) = List(x)</code></li>
<li><code>Set</code> is a monad with <code>unit(x) = Set(x)</code></li>
<li><code>Option</code> is a monad with <code>unit(x) = Some(x)</code></li>
<li><code>Generator</code> is a monad with <code>unit(x) = single(x)</code></li>
</ul>

<p><code>flatMap</code> 은 이들 타입에 두루 쓰일 수 있는 반면 스칼라에서 <code>unit</code> 은 각 모나드 마다 다르다. </p>

<p>그리고 <code>map</code> 은 모나드에서 <code>flatMap</code> 과 <code>unit</code> 을 조합해 만들 수 있다.</p>

<pre><code class="scala">m map f

== m flatMap (x =&gt; unit(f(x)))
== m flatMap (f andThen unit) // composing functions
</code></pre>

<p>즉 <code>f</code> 를 받아 적용하고, <code>unit</code> 으로 모나드로 감싼뒤 <code>flatMap</code> 을 이용해 <em>flattening</em> 하면 <code>map</code> 의 결과가 나온다.</p>

<h4 id="monadlaws">Monad Laws</h4>

<ul>
<li><em>associativity</em></li>
</ul>

<pre><code class="scala">m flatMap f flatMap g == m flatMap (x =&gt; f(x) flatMap g)  
</code></pre>

<ul>
<li><em>left unit</em></li>
</ul>

<pre><code class="scala">unit(x) flatMap f == f(x)  
</code></pre>

<ul>
<li><em>right unit</em></li>
</ul>

<pre><code class="scala">m flatMap unit = m  
</code></pre>

<p><a href='http://en.wikibooks.org/wiki/Haskell/Understanding_monads' #Monad_Laws">하스켈 문법</a>으로 보면</p>

<pre><code class="haskell">(m &gt;&gt;= f) &gt;&gt;= g  =  m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g)  -- associativity

return x &gt;&gt;= f   =  f x                      -- left unit

m &gt;&gt;= return     =  m                        -- right unit  
</code></pre>

<p><em>associativity</em> 와 관련해서, <em>monoid</em> 란 것도 있는데 이건 <em>bind</em> 가 없는 모나드라 생각하면 쉽다. 예를 들어 <em>integer</em> 는 모노이드다</p>

<pre><code>(x + y) + z = x + (y + z)
</code></pre>

<p><em>monad laws</em> 를 확인하기 위해 <code>Option</code> 을 좀 보자.</p>

<pre><code class="scala">abstract class Option[+T] {  
  def flatMap[U](f: T =&gt; Option[U]): Option[U] = this match {
    case Some(x) =&gt; f(x)
    case None =&gt; None
  }
}
</code></pre>

<p><em>left unit</em> 을 보이려면 <code>return x &gt;&gt;&gt; f   =   f x</code>, 즉</p>

<pre><code class="scala">Some(x) flatMap f == f(x)

// ==
Some(x) match {  
  case Some(x) =&gt; f(x)
  case None =&gt; None
}

// == 
f(x)  
</code></pre>

<p><em>right unit</em> 을 보이려면 <code>m &gt;&gt; return     =    m</code> 임을 보이면 된다.</p>

<pre><code class="scala">opt flatMap Some // == opt

// == 
opt match {  
  case Some(x) =&gt; Some(x)
  case None =&gt; None
}
</code></pre>

<p><em>associative law</em> 를 보이려면 </p>

<pre><code class="haskell">(m &gt;&gt;= f) &gt;&gt;= g     =     m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g)
</code></pre>

<p>따라서 스칼라에선</p>

<pre><code class="scala">opt flatMap f flatMap g  
// == opt flatMap (x =&gt; f(x) flatMap g)

opt flatMap f flatMap g

// ==
opt match { case Some(x) =&gt; f(x) case None =&gt; None }  
    match { case Some(y) =&gt; g(y) case None =&gt; None }

// ==
opt match {  
  case Some(x) =&gt;
    f(x) match { case Some(y) =&gt; g(y) case None =&gt; None }
  case None =&gt;
    None match { case Some(y) =&gt; g(y) case None =&gt; None }
}

// ==
opt match {  
  case Some(x) =&gt; f(x) match {
    case Some(y) =&gt; g(y) case None =&gt; None
  }
  case None =&gt; None
}

// ==
opt match{  
  case Some(x) =&gt; f(x) flatMap g
  case None =&gt; None
}

// ==
opt flatMap (x =&gt; f(x) flatMap g)  
</code></pre>

<p>결국 <code>Option</code> 은 모나드다. 근데 이런 <em>monad laws</em> 를 지키면 얻는게 뭘까? </p>

<p><em>associativity</em> 가 지켜지면, 중첩된 <em>for-loop</em> 를 <em>inline</em> 할 수 있다.</p>

<pre><code class="scala">for (y &lt;- for (x &lt;- m; y &lt;- f(x)) yield y  
     z &lt;- g(y)) yield z

// ==
for (x &lt;- m;  
     y &lt;- f(x)
     z &lt;- g(y)) yield z
</code></pre>

<p><em>right unit</em> 은 </p>

<pre><code class="scala">for (x &lt;- m) yield x

== m
</code></pre>

<p>애석하게도 <em>left unit</em> 은 마땅한 <em>for-loop</em> 가 없다.</p>

<blockquote>
  <p>Left unit does not have an analogue for <em>for-expression</em></p>
</blockquote>

<h3 id="anothertypetry">Another type: Try</h3>

<p>강의 후반부에서 <code>Try</code> 라는 타입을 다룰건데, 이 타입은 <code>Option</code> 과 비슷하다. 서브타입이 <code>Success, Failure</code> 로 <em>exception</em> 이 발생할 경우와 아닐 경우를 처리하는데 쓸 수 있다.</p>

<pre><code class="scala">abstract class Try[+T]  
case class Success[T](x: T)         extends Try[T]  
case class Failure[T](e: Exception) extends Try[Nothing]  
</code></pre>

<p>이 <code>Try</code> 를 예외가 발생할 수 있는 <em>computation (연산)</em> 을 <em>thread, computer</em> 간 넘겨주는데 사용할 수 있다. 참고로 스칼라에서 <code>Nothing</code> 은 <em>bottom type</em> 이다.</p>

<p>이 <code>Try</code> 를 이용해 <em>computation</em> 을 감쌀 수 있다. <code>Try(expr)</code> 처럼</p>

<pre><code class="scala">object Try {  
  def apply[T](expr: =&gt; T): Try[T] =
    try Success(expr)
    catch {
      case NonFatal(e) =&gt; Failure(e)
    }
}
</code></pre>

<p>여기서 <code>=&gt; T</code> 로 <code>expr</code> 를 <em>by name</em> 으로 받는 이유는 연산을 나중에 하기 위해서다.</p>

<p><code>Try</code> 를 <em>for-loop</em> 에 활용하면</p>

<pre><code class="scala">for {  
  x &lt;- computeX
  y &lt;- computeY
} yield f(x, y)
</code></pre>

<p>이 구문이 하는 일은, <code>computeX</code>, <code>computeY</code> 가 모두 성공할 경우에만 <code>Success(f(x, y))</code> 를 돌려준다. 둘 중 하나라도 실패하면 <code>Failure(e)</code> 를 반환할 것이다.</p>

<p><code>Try</code> 를 위한 <code>map</code>, <code>flatMap</code> 은</p>

<pre><code class="scala">abstract class Try[T] {  
  def flatMap[U](f: T =&gt; Try[U]): Try[U] = this match {
    case Success(x) = try f(x) 
                      catch { case NonFatal(e) =&gt; Failure(ex)
    case fail: Failure =&gt; fail
  }

  def flatMap[U](f: T =&gt; U): Try[U] = this match {
    case Success(x) =&gt; Try(f(x))
    case fail: Failure =&gt; fail
  }
}


// t map f
// == t flatMap (f andThen Try)
</code></pre>

<p><code>Try</code> 를 모나드라 생각해 보자. <em>monad law</em> 중 실패하는 것이 있을까? 다시 한번 보면</p>

<pre><code class="haskell">return x &gt;&gt;= f     =    f x    -- left unit  
m &gt;&gt;= return       =    m      -- right unit  
-- associativity
(m &gt;&gt;= f) &gt;&gt;= g    =    m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g) 
</code></pre>

<p>아까 <em>for-expression</em> 에 사용했으니 <em>right unit, associativity</em> 는 맞을 거고 <em>left unit</em> 을 살펴보자.</p>

<pre><code class="scala">// return x &gt;&gt;= f     =    f x
Try(x) flatmap f

// ==
this match {  
  Success(x) =&gt; try f(x) 
                catch { case NonFatal(e) =&gt; Failure(ex)
  case fail: Failure =&gt; fail
}
</code></pre>

<p>보면 알겠지만, 예외가 발생하지 않을 경우에만 <em>left unit</em> 이 성립한다.</p>

<pre><code class="scala">Try(expr) flatMap f != f(expr)  
</code></pre>

<p>좌변은 예외를 그냥 던지지않고, 감싸서 준다. 반면 우측은 예외를 던질 수 있다. 즉 예외를 던지지 않는 <em>law</em> 를 얻기 위해 <em>left unit</em> 을 희생했다고 보면 된다.</p>

<blockquote>
  <p>An expression composed from <code>Try</code>, <code>map</code>, <code>flatMap</code> will never throw a non-fatal exception</p>
</blockquote>

<p>이거 <em>bullet-proof principle</em> 이라 부른다.</p>

<h3 id="summary">Summary</h3>

<p>이제까지 <em>collection</em> 뿐만 아니라 다양한 타입에 대해 <em>for-expression</em> 을 쓸 수 있음을 배웠다. <code>map</code>, <code>flatMap</code>, <code>withFilter</code> 등을 구현하면 된다.</p>

<p><code>flatMap</code> 을 구현한 많은 타입이 <em>monad</em> 다. 만약에 <code>withFilter</code> 를 구현하면 <em>monad with zero</em> 라 부른다.</p>

<p>모나드 법칙은 <em>API</em> 를 구현할때 가이드라인이 되지만, <code>Try</code> 의 예에서 봤듯이 모나드 법칙을 버려서 다른 이득을 얻을 수도 있다. <del>만만한 left unit</del></p>

<h3 id="references">References</h3>

<p>(1) <a href='http://stackoverflow.com/questions/1722137/scala-2-8-collections-design-tutoria$l' >Scala 2.8 Collection</a> <br />
(2) <a href='http://en.wikibooks.org/wiki/Haskell/Understanding_monads' #Monad_Laws">Haskell Wiki: Monad</a>  </p>]]></description><link>http://1ambda.github.io/reactive-programming-1/</link><guid isPermaLink="false">c49814fa-24c5-4f5f-83c4-d1a196a8b687</guid><category><![CDATA[scala]]></category><category><![CDATA[coursera]]></category><category><![CDATA[variance]]></category><category><![CDATA[monad]]></category><category><![CDATA[reactive programming]]></category><category><![CDATA[generator]]></category><category><![CDATA[scala check]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 17 Dec 2014 07:30:37 GMT</pubDate></item><item><title><![CDATA[Process Mining, Week4]]></title><description><![CDATA[<h3 id="twophaseprocessdiscoverylimitations">Two-Phase Process Discovery, Limitations</h3>

<p>지난시간에 두 단계를 거치는 프로세스 마이닝 알고리즘을 봤었다.</p>

<p>하나는 <em>heuristic mining</em> 으로 <em>dependency graph</em> 를 만들고, 이것을 <em>C-nets</em> 으로 변환했었다.</p>

<p>다른 하나는 <em>transition system</em> 을 학습하는 것으로 먼저 <em>state abstraction</em> 을 이용해 <em>transition system</em> 을 만들고 여기에 숨어있는 <em>state-based region</em> 을 이용해 <em>Petri-nets</em> 을 만들었다.</p>

<p>그런데, <em>state-based region</em> 접근 방법에는 문제점이 있다.</p>

<p>(1) Inability to discover particular <strong>process construct</strong>s <br />
(2) Inability to balance the four forces (<em>fitness</em>, <em>precision</em>, <em>generalization</em>, simplicity)</p>

<p>예를 하나 보자. <code>&lt;a, a&gt;^55</code> 란 로그가 있을때 만들어지는 트랜지션 시스템으로 <code>s1 -&gt; s2 -&gt; s3</code> 가 있다. 여기엔 몇개의 <em>non-trivial region</em> 이 있을까?</p>

<p>없다. <em>empty set</em>, <code>{s1, s2, s3}</code> 가 있는데, <em>trivial region</em> 이므로</p>

<p>따라서 이걸 이용해 <em>petri-net</em> 을 만들면 <em>place</em> 가 없는 <em>petri-net</em> 이 만들어 지고, <code>&lt;a, a, a&gt;</code> 등의 로그를 허용하므로 에러가 있다.</p>

<p><code>&lt;a, c&gt;, &lt;a, b, c&gt;, &lt;a, b, b, c&gt; ...</code> 의 로그를 훈련시켜 만든 트랜지션 시스템은 대략 이런 모양이다</p>

<p><code>s1 -&gt; s2 &gt; s3</code> (<code>s2</code> 는 자기 자신으로의 액션 <code>b</code> 가 있음) </p>

<p>이 때 여기에는 <em>non-trivial region</em> 이 3개가 생기는데, 이걸 이용해 <em>petri-net</em> 을 만들면 <code>b</code> 만 붕 떠 있어, <code>b</code> 가 가운데 실행되지 않고 먼저나, 나중에 실행되는 <em>petri-net</em> 이 만들어 진다. <em>underfit</em> 이다.</p>

<blockquote>
  <p>Petri net can simulate the behavior of the transition system, but not the other way around (no bisimulation)</p>
</blockquote>

<p>첫 번째 문제같은 경우는 <em>forward closure</em> 속성을 검사해서, 문제가 발견되면 <em>label</em> 을 <em>spliting</em> 하는걸로 해결할 수 있다. (이미지를 첨부하고 싶은데 찾을 수가 없다.) 두 번째 문제도 같은 방법으로 해결할 수 있다. <em>ProM</em> 에는 <em>bisimulation</em> 을 위한 플러그인이 있다.</p>

<p>이제 특정 프로세스 패턴을 발견하지 못하는 문제를 해결했다. 이제 문제 (2) 를 해결해 보자.</p>

<blockquote>
  <p>(2) Inability to balance the four forces (<em>fitness</em>, <em>precision</em>, <em>generalization</em>, simplicity)</p>
</blockquote>

<p>먼저 <em>step 1</em> 에서 트랜지션 시스템을 학습할때는 <em>fitness, generalization</em>, <em>precision</em>, <em>simplicity</em> 의 <em>trade-off</em> 를 봐가면서 해야한다.</p>

<p><em>step 2</em> 에서는 <em>region</em> 을 이용해서 <em>concurrency</em> 를 발견하는데 사실 잘 생각해 보면 <em>Petri-nets</em> 은 트랜지션시스템에서의 변환이므로 이 단계에서는 <em>simplicity</em> 나 <em>generalization</em> 의 개선 여지가 없다. 트랜지션 시스템이 이미 복잡한데 어떻게 페트리넷을 간단하게 할까? 마찬가지로 트랜지션 시스템이 이미 <em>overfit</em> 되어있는데, 어떻게 이 문제를 풀까? 이 두 가지 문제를 해결하려면 (1) 로 돌아가야 한다.</p>

<p>정리하자면 <em>Region-based techniques</em> 은 </p>

<ul>
<li><strong>Overfitting</strong> may be a problem</li>
<li>Inability to leave out <strong>infrequent</strong> behavior (but can be done in the transtion system)</li>
<li><strong>Noise</strong> and <strong>incompleteness</strong> connot be handled well</li>
</ul>

<h3 id="alternativeprocessdiscoverytechniques">Alternative Process Discovery Techniques</h3>

<p>이전까지는 모델의 퍼포먼스를 기준으로 삼았지만 사실 </p>

<ul>
<li>speed</li>
<li>memory usage</li>
<li>representational bias</li>
<li>flexibility(related problems),</li>
<li>implementation vs apporach</li>
</ul>

<p>등을 고려해야 한다. </p>

<p><em>petri net</em> 에서 무엇을 해야 <em>behavior</em> 를 추가할 수 있을까? <em>place</em> 는 일종의 <em>constraint</em> 라 보면 된다. 그리고 <em>place</em> 에 토큰이 많아지면 다 더 다양한 로그가 생길 수 있다.</p>

<ul>
<li>Add a transition</li>
<li>Remove a place</li>
<li>Add an arc from a transition to a place</li>
<li>Remove an arc from a place to a transtion</li>
</ul>

<p>반대로 <em>behavior</em> 를 제거하려면</p>

<ul>
<li>Remove a transition</li>
<li>Add a place</li>
<li>Add an arc from a place to transition</li>
<li>Remove an arc from a transition to a place</li>
</ul>

<p><em>process discovery</em> 가 <em>finding place</em> 라는 점을 고려하면 <em>alpha algorithm</em> 에서는 <em>constraint</em> 인 <em>place</em> 를 발견하는 과정이었다. <em>state-based region</em> 에서는 먼저 <em>transition</em> 을 만들고, 이걸 <em>place</em> 로 변환했었다.</p>

<p>이번엔 <em>language-based region</em> 이란 기법을 배워보자.</p>

<h3 id="languagebasedregion">Language-based Region</h3>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-36-728.jpg?cb=1305062477'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-37-728.jpg?cb=1305062477'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-38-728.jpg?cb=1305062477'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-40-728.jpg?cb=1305062477'  alt="" /></p>

<p><br/></p>

<p><code>c * 1 + A' * x - A * y &gt;= 0</code> 등의 식으로 표현되는데, 이 말은 <em>place</em> 가 음수가 될 수 없다는 뜻이라 보면 된다. <del>이제 나도 뭔소린지 모르겠다 너무멀리 와버렸음 ㅠㅠ</del></p>

<p><img src='http://latex.codecogs.com/gif.latex?c%20' *%201%20&plus;%20A%27%20x%20-%20Ay%20%5Cgeq%200" alt="" /></p>

<p>여기서 <code>A', A</code> 는 <em>log</em>, <code>x, y</code> 는 <em>petri-nets</em>, <code>c</code> 는 초기에 <em>place</em> 내에 있는 토큰의 수다. 이 때 위 방정식을 만족하는 <code>x, y, c</code> 가 <em>region</em> 이다. </p>

<ul>
<li><code>c</code> is the initial number of tokens in the place</li>
</ul>

<p>예를 들어</p>

<p><code>&lt;a&gt;, &lt;b&gt;, &lt;a, b&gt;, &lt;b, a&gt;</code> 인 로그가 있다고 하자. 그러면 진리표처럼 로그 내에 <code>a, b</code> 쌍을 <code>0, 1</code> 로 표현할 수 있다. 이걸 <code>A</code> 라 하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?A%20%3D%20%5Cbegin%7Bpmatrix%7D%201%20%26%200%5C%5C%200%20%26%201%5C%5C%201%20%26%201%5C%5C%201%20%26%201%20%5Cend%7Bpmatrix%7D'  alt="" /></p>

<p>그리고 <code>A'</code> 를 만들기 위해 마지막 <em>trace</em> 는 무시하도록 하자. 그러면 다음 식을 만들 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?c%20' *%20%5Cbegin%7Bpmatrix%7D%201%5C%5C%201%5C%5C%201%5C%5C%201%20%5Cend%7Bpmatrix%7D%20&plus;%20%5Cbegin%7Bpmatrix%7D%200%20%26%200%5C%5C%200%20%26%200%5C%5C%201%20%26%200%5C%5C%200%20%26%201%20%5Cend%7Bpmatrix%7D%20*%20%5Cbegin%7Bpmatrix%7D%20x_a%5C%5C%20x_b%20%5Cend%7Bpmatrix%7D%20-%20%5Cbegin%7Bpmatrix%7D%201%20%26%200%5C%5C%200%20%26%201%5C%5C%201%20%26%201%5C%5C%201%20%26%201%20%5Cend%7Bpmatrix%7D%20*%20%5Cbegin%7Bpmatrix%7D%20y_a%5C%5C%20b_b%20%5Cend%7Bpmatrix%7D%20%5Cgeq%20%5Cbegin%7Bpmatrix%7D%200%5C%5C%200%5C%5C%200%5C%5C%200%20%5Cend%7Bpmatrix%7D" alt="" /></p>

<ul>
<li><code>x_a</code> is the number of arcs from transition <code>a</code> to the place</li>
<li><code>x_b</code> is the number of arcs from transition <code>b</code> to the place</li>
<li><code>y_a</code> is the number of arcs from the place to transtion <code>a</code></li>
<li><code>y_b</code> is the number of arcs from the place to transtion <code>b</code></li>
</ul>

<p>식을 풀면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5C%20%5C%5C%20c%20-%20y_a%20%5Cgeq%200%20%5C%5C%20c%20-%20y_b%20%5Cgeq%200%20%5C%5C%20c%20&plus;%20x_a%20-%20y_a%20-%20y_b%20%5Cgeq%200%20%5C%5C%20c%20&plus;%20x_b%20-%20y_a%20-%20y_b%20%5Cgeq%200%20%5C%5C'  alt="" /></p>

<p>하나의 답으로 </p>

<ul>
<li><code>c=1, x_a=0, x_b=0, y_a=1, y_b=0</code></li>
<li><code>c=1, x_a=0, x_b=0, y_a=0, y_b=1</code></li>
</ul>

<p><em>language-based region</em> 에서는</p>

<ul>
<li>any solution is a feasible place</li>
<li>additional constraints can be added easily</li>
<li><strong>goal function</strong> can be used to select most interesting places</li>
<li>optimiazation problem (e.g ILP)</li>
</ul>

<h3 id="geneticprocessmining">Genetic Process Mining</h3>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-22-728.jpg?cb=1305062477'  alt="" /></p>

<p>이번엔 <em>genetic process mining</em> 기법을 살펴보자.</p>

<p><em>event log</em> 로 부터 <em>initial population</em> 을 만들고, 이것에 대해 <em>conformance checking</em> 등을 이용해 얼마나 좋은 모델인가 본다. 이것을 다시 매 턴마다 랜덤하게 변이시키면서 계속 반복하는 것이다.</p>

<p>많은 <em>generation</em>, <em>mutation</em> 이 있을 수 있기 때문에 굉장히 느리지만 <em>very flexible</em> 할 수 있다. 왜냐하면 <em>qualty measure</em> 을 이용해서 4 품질(fitness 등) 을 조절할 수 있기 때문이다.</p>

<h3 id="inductiveprocessmining">Inductive Process Mining</h3>

<p>로그를 <em>trace</em> 를 기준으로 쪼개는 방법인데</p>

<pre><code>abdef  
acdef  
abdeg  
adceg  
</code></pre>

<p>가 있을때, <code>abcd</code>, <code>efg</code> 기준으로 쪼개면</p>

<pre><code>abd  
acd  
abd  
adc

ef  
ef  
eg  
eg  
</code></pre>

<p>로 분리할 수 있다. 여기서 <code>abcd</code> 부분을 또 쪼개면 <code>a</code> <code>seq</code> <code>bcd</code> 로 쪼갤 수 있다. 마찬가지로 뒷부분도 <code>e</code> <code>seq</code> <code>fg</code> 로 쪼갤 수 있다. 뒷부분의 경우 <code>f xor g</code> 로 다시 쪼갤 수 있고. 이렇게 반복하면서 쪼개는 방법이다. 이 결과로 만들어지는 것이 <em>process tree</em> 다. 이를 <em>petri-net</em> 이나 <em>BPMN</em> 으로 변경할 수 있다. </p>

<p><em>ProM</em> 에도 플러그인이 있다고 함.</p>

<h3 id="introtoconformancechecking">Intro to Conformance Checking</h3>

<p><img src='http://www.win.tue.nl/' ~mpechen/projects/edm/images/framework.jpg" alt="" /></p>

<p align="center">(<a href='http://www.win.tue.nl/' >http://www.win.tue.nl</a>)</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-4-728.jpg?cb=1305062420'  alt="" />
<br/></p>

<p>다른 품질도 중요하긴 한데, <em>replay fitness</em> 가 주된 관심사라고 한다. <em>conformance checking</em> 의 주된 용도는</p>

<ul>
<li>Auditing and compliance</li>
<li>Evaluating process discovery algorithm</li>
<li>Conformance to specification (software, service)</li>
</ul>

<p><em>conformance checking</em> 은 <em>runtime</em> 에 할수도 있다.</p>

<h3 id="footprintsbasedconformancechecking">Footprints-based Conformance Checking</h3>

<p>알파 알고리즘을 사용할때 <em>footprints</em> 를 봤었다. 테이블에 각 <em>trace</em> 사이의 <em>direct succession, causality, parallel, choice</em> 를 표시한 것이다. </p>

<p>로그로 부터 <em>footprint</em> 가 나왔기 때문에 로그의 <em>footprint-based conformance</em> 는 항상 <code>1</code> 이다. 다시 말해서</p>

<blockquote>
  <p>footprints of log and model coincide</p>
</blockquote>

<p>그런데, 모델을 만들고 보니 다음과 같이 로그와 모델의 <em>footprint</em> 를 작성했다고 하자.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-34-728.jpg?cb=1305062420'  alt="" /></p>

<p><code>a - d, b - d</code> 부분이 다르다. 따라서 다른 부분을 파악해서 값으로 매기면</p>

<p><br/></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-35-728.jpg?cb=1305062420'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-36-728.jpg?cb=1305062420'  alt="" /></p>

<p><br/></p>

<p><em>flower model</em> 에서는 수 많은 조합이 가능하기 때문에 <em>footprint-based conformance</em> 가 떨어진다.</p>

<p><em>footprint-based conformance</em> 자체는 굉장히 유연하다. </p>

<ul>
<li><em>log to log</em></li>
<li><em>log to model</em></li>
<li><em>model to model</em></li>
</ul>

<p>모두 가능하다. 그러나</p>

<ul>
<li>frequencies are not used</li>
<li>behavior is only considered indiretcly (directly follows relation)</li>
<li>aims to capture fitness, precision and generalization in a single metric</li>
</ul>

<p>다양한 <em>metric</em> 으로 <em>fitness</em> 을 분류하고 싶을 수도 있는데, <em>footprint-based</em> 는 그러질 못한다. 이 때문에 <em>token-based conformance</em> 를 이용하기도 한다.</p>

<h3 id="tokenbasedreplay">Token-based Replay</h3>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-12-728.jpg?cb=1305062420'  alt="" /></p>

<p><em>traces</em> 를 모델에 실제 <em>replay</em> 해 보면서 <em>missing token</em>, <em>remaining token</em> 을 기록한다.</p>

<ul>
<li><code>p</code>, <em>produced tokens</em></li>
<li><code>c</code>, <em>consumed tokens</em></li>
<li><code>m</code>, <em>missing tokens</em></li>
<li><code>r</code>, <em>remaining tokens</em></li>
</ul>

<p><img src='http://latex.codecogs.com/gif.latex?fitness%28%5Csigma%2C%20N%29%20%3D%20%5C%5C%20%5C%5C%20%7B1%20%5Cover%202%7D%20%281%20-%20%7Bm%20%5Cover%20c%7D%29%20&plus;%20%7B1%20%5Cover%202%7D%281%20-%20%7Br%20%5Cover%20p%7D%29'  alt="" /></p>

<p>그리고, 어느 <em>place</em> 에서든 <em>invariants</em> 는</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5C%20%5C%5C%20p%20&plus;%20m%20%5Cgeq%20c%20%5Cgeq%20m%5C%20%5C%20%5Cmbox%7B%28at%5C%20any%5C%20time%29%7D%20%5C%5C%20r%20%3D%20p%20&plus;%20m%20-%20c%5C%20%5C%20%5Cmbox%7B%28at%5C%20the%5C%20end%29%7D'  alt="" /></p>

<p><em>replay</em> 의 시작과 끝을 생각해 보면</p>

<ul>
<li>In the beginning, a token is <strong>produced</strong> for the <em>source place</em> <code>p = 1</code></li>
<li>At the end, a token is <strong>consumed</strong> from the <em>sink place</em> (also if not there) <code>c' = c + 1</code></li>
</ul>

<p>뭔 소린가 했는데, <em>conformance checking</em> 을 위해 초기에 토큰을 하나 넣어주고, <em>replay</em> 가 끝났을 때 <em>sink place</em> 에서 <em>consume</em> 해서 <code>c</code> 값을 하나 증가시킨다는 이야기</p>

<p>왼쪽 위의 값을 주목하면서 따라가 보자.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-17-728.jpg?cb=1305062420'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-18-728.jpg?cb=1305062420'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-19-728.jpg?cb=1305062420'  alt="" /></p>

<p><br/></p>

<p>이번엔 좀 문제가 있는 <em>event log</em></p>

<p><br/></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-20-728.jpg?cb=1305062420'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-21-728.jpg?cb=1305062420'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-22-728.jpg?cb=1305062420'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-24-728.jpg?cb=1305062420'  alt="" /></p>

<p><br/></p>

<p>각 <em>log</em> 가 <em>transition</em> 에서 얼마나 실행되었는지 기록해서 모델에 어떤 문제가 있는지 파악할 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-30-728.jpg?cb=1305062420'  alt="" /></p>

<p><em>frequency</em> 는 <code>p, c, m, r</code> 에 곱해서 전체 <em>fitness</em> 값을 얻으면 된다. </p>

<p>만약 <em>consumed token</em> 이 모두 <em>missing token</em> 이고, <em>produced token</em> 이 모두 <em>remaining token</em> (미사용) 이면 <em>fitness</em> 는 <code>0</code> 이다.</p>

<h4 id="limitations">Limitations</h4>

<ul>
<li>Basic replay approache assumes <strong>visible, unique labeled</strong> transitions</li>
<li>ProM implementation uses <strong>heuristics</strong> to deal with slient transitions having same label</li>
<li>Conformance value is too optimistic due tu <strong>token flooding</strong></li>
<li>Local decision marking may misleading</li>
</ul>

<p>특히 마지막은 중요한데, 우리는 <em>value</em> 를 보고 싶은게 아니라 <em>closest path</em> 를 보고싶어 할수도 있다.</p>

<p>예를 들어 <code>&lt;a, c1, c2, c3, e1, e2, e3&gt;</code> 값이 <code>0.8</code> 로 나왔다 하면, "그럼 올바른 <em>path</em> 는 무얼까?" 하고 질문할 수 있다.</p>

<blockquote>
  <p>Replay technique does not provide corresponding path through model</p>
</blockquote>

<p>다음장에서 배울 <em>alignment</em> 를 이용하면 모델에서 가능한 <em>real path</em> 를 얻을 수 있다.</p>

<h3 id="alignmentbasedconformancechecking">Alignment-based Conformance Checking</h3>

<p>먼저 생각해 볼 거리는</p>

<blockquote>
  <p>Conformance checking <strong>should not impose restriction</strong> on the process notation e.g slient transitions and two transitions with same label should be possible</p>
  
  <p>Should provide <strong>closest maching path</strong> (required for <em>performance analysis</em>)</p>
</blockquote>

<p>특히 <em>closest maching path</em> 가 제공되면 <em>fitness</em> 를 넘어 <em>generalization</em>, <em>precision</em>, <em>bottle-neck</em> 등에 이용할 수 있다. 대략 이런 느낌이라고 보면 된다.</p>

<p><img src='http://image.slidesharecdn.com/alignmentbasedprecisionchecking-121013004859-phpapp01/95/alignment-based-precision-checking-5-728.jpg?cb=1350107718'  alt="" /></p>

<p>즉 <em>replay</em> 불가능한 로그에서 <em>replay</em> 가능한 로그와 차이점을 반영한 것이라 보면 된다. 그러면, 다음중 어떤 것이 더 <em>possible</em> 한 로그일까?</p>

<pre><code>a &gt;&gt; c1 c2 e1 e2 e3 // invalid path  
&gt;&gt; b c1 c2 e1 e2 e3 // valid path

a1 c1 c2 &gt;&gt; &gt;&gt; &gt;&gt; e1 e2 e3 // invalid  
a1 c1 c2 d1 d2 d3 &gt;&gt; &gt;&gt; &gt;&gt; // valid  
</code></pre>

<p>이건 <em>cost function</em> 에 따라 다르다. <em>standard cost function</em> 의 경우 <code>&gt;&gt;</code> (<em>move</em>) 의 수를 센다.</p>

<p>근데 몇 가지 생각해볼 거리가 있다. <code>-2</code> 와 <code>+2</code> 의 <em>cost</em> 가 있을 때 어떤 것을 택할건가 하는 문제들이다. 이 차이 때문에 루프가 있을수도 있다.    </p>

<h3 id="alignmentbasedfitness">Alignment-based Fitness</h3>

<p>1 에서 <em>optimal cost</em> / <em>worst cost</em> 를 빼면 된다. 강의에서 나오는 <em>log</em> 의 경우</p>

<pre><code>// optimal
a &gt;&gt; c1 c2 e1 e2 e3  
&gt;&gt; b c1 c2 e1 e2 e3

// worst
a1 c1 c2 e1 e2 e3 &gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt;  
&gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; b1 c1 c2 d1 d2 d3
</code></pre>

<p>따라서 <code>1 - (2 / 12) = 0.83</code></p>

<p><em>alignment-based conformance checking</em> 의 장점으로는 </p>

<ul>
<li>observed behavior is directly related to modeled behavior</li>
<li>very <strong>flexible</strong> (any cost structure)</li>
<li>detailed diagnostics</li>
<li>after aligning log and model, other quality dimensions can be investigated</li>
</ul>

<p>다른 장점으로는 <em>drilling down</em> 도 있다. 즉 <em>replay</em> 되는 것과 아닌 것을 분리해서 분석할 수 있다는 뜻이다. 분리 된 것중 이상한 로그를 <em>새로운</em> 로그처럼 취급해서 다양한 기법들을 적용할 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-32-728.jpg?cb=1305062420'  alt="" /></p>

<p><br/></p>

<p>지금까지 <em>fitness</em> 만 좀 봤지만 다른 퀄리티에 대해서도 적용 가능하다. 그리고 지금까지는 <em>control flow</em> 관점으로 좀 봤는데, <em>cost, time</em> 등 다른 기준으로도 볼 수 있다. 이를 위한 기법으로 <em>data-aware alignments</em> 가 있다.</p>

<h3 id="exploringeventdata">Exploring Event Data</h3>

<p><img src='http://image.slidesharecdn.com/processminingchapter07conformancechecking-110510153239-phpapp02/95/process-mining-chapter-7-conformance-checking-3http://image.slidesharecdn.com/processminingchapter08miningadditionalperspectives-110510153251-phpapp02/95/process-mining-chapter-8-mining-additional-perspectives-16-728.jpg?cb=13050623738-728.jpg?cb=1305062420'  alt="" /></p>

<p><del>멘탈이 터짐</del></p>

<p><em>model view</em>, <em>instance view</em>, <em>event view</em> 사이에 관계가 있다고 함.</p>

<p><br/></p>

<h4 id="dottedchart">Dotted Chart</h4>

<p>모든 이벤트를 볼 수 있는 일종의 <em>view</em> 인데 <em>dot</em> 과 <em>event</em> 사이에는 1:1 관계가 있다. 모든 <em>event</em> 에는 <em>timestamp</em> 가 있는데, 이것을 이용해 <code>X</code> 를 계산하고 다른 <em>attribute</em> 를 이용해서 <code>Y</code> 축을 잡는다. 액티비티나 리소스에 따라 다른 색을 가질 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter08miningadditionalperspectives-110510153251-phpapp02/95/process-mining-chapter-8-mining-additional-perspectives-16-728.jpg?cb=1305062373'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter08miningadditionalperspectives-110510153251-phpapp02/95/process-mining-chapter-8-mining-additional-perspectives-17-728.jpg?cb=1305062373'  alt="" /></p>

<p><br/></p>

<p>이게 중요한 이유가 <code>Y</code> 축과 컬러를 어떻게 하느냐에 따라 정말 다양한 <em>view</em> 를 얻을 수 있다. 그래서 강의에서 헬리콥터 뷰 라고 표현함. 심지어 <em>time</em> 을 <em>logical time</em> (step 1) 등으로 수정해서 볼 수도 있다. </p>

<p>다양한 뷰를 조절해 가면서 왜 <em>delayed</em> 되었는지, <em>decision</em> 이 없다면 이전 스텝이 무엇인지 등을 파악할 수 있다. </p>

<p><em>dotted chart</em> 를 이용하면 모델을 작업 하기 전에 <em>input</em> 만을 이용해 다양한 직관을 얻을 수 있다.</p>

<h3 id="references">References</h3>

<p>(1) <a href='http://issuu.com/wmpvanderaalst/docs/procminbook?e=14081202/9829483' >Book: Process Mining</a> <br />
(2) <a href='https://d396qusza40orc.cloudfront.net/procmin/lecture_slides/22-Petri%20Nets%20%281%29.pdf' >Slide</a> <br />
(3) <strong>Process Mining: Data science in Action</strong> by Wil van der Aalst <br />
(4) <a href='http://1ambda.github.io/www.processmining.org' >www.processmining.org</a> <br />
(5) <a href='http://fluxicon.com/' >http://fluxicon.com</a> <br />
(6) <a href='http://www.win.tue.nl/' ~mpechen/projects/edm/">http://www.win.tue.nl</a> <br />
(7) <a href='http://www.slideshare.net/caise2013vlc/ramezani-taghiabadi-temporal-compliance-checking-2' >Temporal Compliance Checking</a> <br />
(9) <a href='http://www.slideshare.net/aryaadriansyah/alignment-based-precision-checking' >Alignment-based onformance Checking</a></p>]]></description><link>http://1ambda.github.io/process-mining-week4/</link><guid isPermaLink="false">c0ec136c-9e68-46bc-b21f-0cd5f8661eb9</guid><category><![CDATA[coursera]]></category><category><![CDATA[process mining]]></category><category><![CDATA[conformance checking]]></category><category><![CDATA[token-based]]></category><category><![CDATA[footprint-based]]></category><category><![CDATA[alignment-based]]></category><category><![CDATA[dotted chart]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 17 Dec 2014 00:59:53 GMT</pubDate></item><item><title><![CDATA[R-way, Ternary Search Tries]]></title><description><![CDATA[<h3 id="stringsymboltable">String Symbol Table</h3>

<p>지난 시간에 <em>symbol-table</em> 의 구현으로 <em>red-black tree, hash table</em> 의 성능을 살펴봤었다.</p>

<p><em>red black tree</em> 는 <em>search, insertion, delete</em> 에 <code>compareTo</code> 를 이용해 <code>log N</code>, <em>hash table</em> 은 <code>equals, hashCode</code> 를 이용해 <code>1</code> (under uniform hashing assumption) 의 성능을 확인했다. </p>

<p><em>red black tree</em> 의 경우에는 <em>rank</em> 같은 다른 연산도 하는것도 봤다. 그런데, 이보다 더 빠르게 만들 순 없을까?</p>

<p>가능하다. 스트링 정렬처럼, <em>entire key</em> 를 모두 검사하지 않으면 더 빠르게 만들 수 있다. 먼저 시작 전에 <em>String symbol table API</em> 를 좀 보고가면</p>

<pre><code class="java">public class StringST&lt;Value&gt; {  
  ...

  void put(String key, Value value)
  Value get(String key)
  void delete(String key)

  ...
}
</code></pre>

<h3 id="tries">Tries</h3>

<p><em>red black tree</em> 나 <em>hash table</em> 과는 다르게 한 노드에 <em>key</em> 가 아니라 <em>character</em> 를 저장한다. 아래 짤방을 보는게 이해가 더 빠를듯. 끝 초록색 노드에 붙어있는 숫자가 바로 <em>value</em> 다.</p>

<p><img src='http://t2.hhg.to/V12-d3.png'  alt="" /></p>

<p align="center">(<a href='http://t2.hhg.to/' >http://t2.hhg.to</a>)</p>

<p>이름은 re<strong>trie</strong>val 에서 왔다고 한다. <em>try</em> 랑 똑같이 발음함. 허프만 코드랑 비슷하게도 보인다.</p>

<ul>
<li>For now, store <em>char</em> in nodes (not keys)</li>
<li>Each node has <code>R</code> children, one or each possible chars</li>
<li>Store values in nodes corresponding to last chars in keys</li>
</ul>

<p><em>value</em> 는 항상 끝에만 있을 수 있는건 아니고 <code>shell</code>, <code>she</code> 둘 다 저장했을때 <code>e</code> 에도 <code>she</code> 를 위한 <em>value</em> 를     저장할 수 있다.</p>

<h4 id="trieperformance">Trie Performance</h4>

<ul>
<li>Search hit</li>
</ul>

<p><code>L</code> 개의 문자를 모두 탐색해야 한다. 그리 긴 시간은 아님.</p>

<ul>
<li>Search miss</li>
</ul>

<p>첫 번째 문자부터 탐색에 실패할 확률도 있다. 전형적인 경우는 몇 개의 문자를 탐색하다 실패하는 경우이므로 <em>sublinear</em> 한 퍼포먼스를 보여준다.</p>

<p>각 <code>leaf</code> 마다 <code>R</code> 개의 널 링크가 필요한데, 그래도 <em>sublinear</em> 라고 말할 수 있는 것이 짧은 문자열들은 <em>common prefix</em> 를 공유한다.</p>

<blockquote>
  <p>Fast search hit and evn faster search miss, but waste spaces.</p>
</blockquote>

<p><em>search miss</em> 의 성능이 <code>log_R N</code> 으로 빨라져서 좋긴 한데, <em>space</em> 가 <code>(R + 1) * N</code> 이라 좀 부담이다. (<em>search hit, insert</em> 는 해시 테이블처럼 <code>L</code>)</p>

<p>유니코드면 <em>65536-way trie</em> 를 만들어야 한다.</p>

<p>유명한 <em>job interview</em> 로 <em>efficient spell checking</em> 의 자료구조를 구현하는 것이 있는데. <em>26-way tries</em> 를 만들면 된다. <em>value</em> 는 <em>bit</em> 로</p>

<h4 id="deletioninanrwaytrie">Deletion in an R-way Trie</h4>

<p>만약 마지막 노드가 <em>all null links</em> 를 가지고 있으면 제거하면 된다. 그리고 백트래킹 하면서 <em>value</em> 를 만나기 전 까지 삭제되면 됨.</p>

<h4 id="rwaytriesimplementation">R-way Tries Implementation</h4>

<pre><code class="java">public class TrieST&lt;Value&gt; {

    private static final int R = 256; // extended ASCII
    private Node root = new Node();
    private int N;

    private static class Node {
        private Object val;
        private Node[] next = new Node[R];
    }

    public TrieST() { N = 0; }

    public int size() { return N; }

    public boolean isEmpty() { return size() == 0; }

    public Value get(String key) {
        Node x = get(root, key, 0);

        if (x == null) return null;
        return (Value) x.val;
    }

    public void delete(String key) {
        root = delete(root, key, 0);
    }

    private Node delete(Node x, String key, int d) {
        if (x == null) return null;

        if (d == key.length()) {
            if (x.val != null) N--;
            x.val = null;
        } else {
            char c = key.charAt(d);
            x.next[c] = delete(x.next[c], key, d + 1);
        }

        // remove subtrie rooted at x if it is completely empty
        if (x.val != null) return x;
        for (int c = 0; c &lt; R; c++)
            if (x.next[c] != null) return x;

        return null;
    }

    private Node get(Node x, String key, int d) {
        if (x == null) return null;
        if (d == key.length()) return x;
        char c = key.charAt(d);
        return get(x.next[c], key, d + 1);
    }

    public boolean contains(String key) {
        return get(key) != null;
    }

    public void put(String key, Value val) {
        if (val == null) delete(key);
        else root = put(root, key, val, 0);
    }

    private Node put(Node x, String key, Value val, int d) {
        if (x == null) x = new Node();
        if (d == key.length()) {
            if (x.val == null) N++;
            x.val = val;
            return x;
        }

        char c = key.charAt(d);
        x.next[c] = put(x.next[c], key, val, d + 1);
        return x;
    }
}
</code></pre>

<h3 id="ternarysearchtries">Ternary Search Tries</h3>

<p>이전의 <em>R-way</em> 는 <code>R</code> 개의 자식들을 가졌지만, <em>ternary</em> 에서는 <code>3</code> 개만 가진다. <del>이것도 교수님이 만듬</del></p>

<ul>
<li>Store chars and values in nodes (not keys)</li>
<li>Each node has 3 children; smaller, equal, larger</li>
</ul>

<p><em>binary search</em> 와 거의 유사하다. 그냥 <em>key</em> 를 <em>string</em> 로 사용하고 효율적인 검색을 위해 노드에 <em>character</em> 를 저장한다는 점만 다르고. 이 차이점을 그냥 교수님은 <em>tree</em> 가 아니라 <em>trie</em> 라 부르는 것 같다.</p>

<p>어쨌든 <em>ternary</em> 는 <em>r-way</em> 보다 <em>null link</em> 자체가 훨씬 적다. 따라서 메모리 사용량에 부담 없고, <em>hash table</em> 보다 상당히 빠른 <em>search miss</em> 를 보여준다. 구현은 <a href='http://algs4.cs.princeton.edu/52trie/TST.java.html' >여기로</a></p>

<h4 id="tstimpelementation">TST Impelementation</h4>

<pre><code class="java">public class TernaryST&lt;Value&gt; {

    private int N;
    private Node root;

    private class Node {
        private char c;
        private Value val;
        private Node left, mid, right;
    }

    public TernaryST() { N = 0; }

    public int size() { return N; }
    public boolean isEmpty() { return size() == 0; }

    public boolean contains(String key) {
        return get(key) != null;
    }

    public Value get(String key) {
        if (key == null) throw new NullPointerException();
        if (key.length() == 0) throw new IllegalArgumentException("key shouldn't be empty");

        Node x = get(root, key, 0);
        if (x == null) return null;
        return x.val;
    }

    private Node get(Node x, String key, int d) {
        if (key == null) throw new NullPointerException();
        if (key.length() == 0) throw new IllegalArgumentException("key shouldn't be empty");
        if (x == null) return null;

        char c = key.charAt(d);
        if      (c &lt; x.c)               return get(x.left, key, d);
        else if (c &gt; x.c)               return get(x.right, key, d);
        else if (d &lt; key.length() - 1)  return get(x.mid, key, d + 1);
        else                            return x;
    }

    public void put(String key, Value val) {
        if (!contains(key)) N++;
        root = put(root, key, val, 0);
    }

    private Node put(Node x, String key, Value val, int d) {
        char c = key.charAt(d);

        if (x == null) {
            x = new Node();
            x.c = c;
        }

        if      (c &lt; x.c)               x.left = put(x.left, key, val, d);
        else if (c &gt; x.c)               x.right = put(x.right, key, val, d);
        else if (d &lt; key.length() - 1)  x.mid = put(x.mid, key, val, d + 1);
        else                            x.val = val;

        return x;
    }   
}
</code></pre>

<p>항상 느끼는건데, <em>imperative</em> 언어에서의 재귀가 더 어려운 것 같다.</p>

<h4 id="tstperformance">TST Performance</h4>

<p>(1) <strong>R-way trie</strong></p>

<ul>
<li><strong>search hit:</strong> <code>L</code></li>
<li><strong>search miss:</strong> <code>log_R N</code></li>
<li><strong>insert:</strong> <code>L</code></li>
<li><strong>space:</strong> <code>(R + 1) * N</code></li>
</ul>

<p>(2) <strong>Ternary trie(TST)</strong></p>

<ul>
<li><strong>search hit:</strong> <code>L + ln N</code></li>
<li><strong>search miss:</strong> <code>ln N</code></li>
<li><strong>insert:</strong> <code>L + ln N</code></li>
<li><strong>space:</strong> <code>4N</code></li>
</ul>

<p>메모리가 <code>4N</code> 밖에 안든다! 해싱은 모든 연산이 <code>L</code> 이겠지만, 대신 메모리가 <code>4N ~ 16N</code> 이다.</p>

<p>따라서 <em>ternary symbol table</em> 은 <em>hash table</em> 만큼 빠르고, 메모리도 덜 든다.</p>

<p>참고로 <em>rotation</em> 연산을 이용해서 <em>balanced TST</em> 를 만들면 <em>worst case</em> 에도 <code>L + logN</code> 이 나온다.</p>

<h4 id="tstwithr2branchingatroot">TST with R2 Branching at root</h4>

<p>꼭대기엔 <code>R^2-way</code> 로 짓고, 자식은 <em>TST</em> 로 지을 수 있다. 분석 결과로는 일반 <em>TST</em> 보다 더 빠르다고 한다.</p>

<h4 id="tstvshashing">TST vs Hashing</h4>

<p>(1) Hashing</p>

<ul>
<li>Need to examine entier key</li>
<li>Search hits and misses cost about the same</li>
<li>Performance relies on hash function</li>
<li>Does not support ordered symbol table operations.</li>
</ul>

<p>(2) TST</p>

<ul>
<li>Works only for strings (or digital keys)</li>
<li>Only examines just enough key characters</li>
<li>Search miss may involve only a few characters</li>
<li>Supports ordered symbol table operations (plus others!).</li>
</ul>

<p>정리하면, <em>TST</em> 는 해싱만큼 빠르고 <em>search miss</em> 는 더 빠르다. 그리고 <em>red-black BST</em> 보다 유연하다. 그러나 자료의 형태에 제한이 있다.</p>

<h3 id="characterbasedoperations">Character-Based Operations</h3>

<p><em>string symbol table</em> 의 경우에는 유용한 <em>chars-based operation</em> 을 제공한다. </p>

<ul>
<li><em>prefix match</em> </li>
<li><em>wildcard match</em> </li>
<li><em>longest prefix</em></li>
</ul>

<p><em>API</em> 를 보면</p>

<pre><code class="java">public class SymbolST&lt;Value&gt; {

  ...
  ...

  Iterable&lt;String&gt; keys()
  Iterable&lt;String&gt; keysWithPrefix  (String s)
  Iterable&lt;String&gt; keysThatMatch   (String s)
  String           longestPrefixOf (String s) 

  ...
  ...
}
</code></pre>

<p>이 외에도 <em>ordered ST</em> 를 위한 <em>floor, rank</em> 등의 연산도 추가할 수 있다.</p>

<h4 id="inordertraverseoftrie">Inorder Traverse of Trie</h4>

<p>탐색이 이진트리하고 좀 다른게, 매 문자열마다 시작점부터 시작해야 된다. <em>leaf</em> 까지 방문하는건 같은데</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Trie_example.svg/250px-Trie_example.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Trie' >http://en.wikipedia.org/wiki/Trie</a>)</p>

<pre><code class="java">public Iterable&lt;String&gt; keys() {  
  Queue&lt;String&gt; q = new Queue&lt;String&gt;();
  collect(root, "", q);
  return q;
}

public void collect(Node x, String prefix, Queue&lt;String&gt; q) {  
  if (x == null) return;
  if (x.val != null) q.enequeue(prefix);

  for (char c = 0; c &lt; R; c++)
    collect(x.next[c], prefix + c, q);
}
</code></pre>

<p><em>queue</em> 는 단순히 <code>she</code> 를 방문할때 <code>she</code> 를 저장하기 위한 용도다. <code>val != null</code> 일 때 저장하므로 <code>s, sh</code> 등은 저장하지 않는 다는 점에 유의하자.</p>

<p>그리고 여기서 큐는 <em>DFS, BFS</em> 처럼 로직에 쓰이지 않는다. 모든 노드를 방문하긴 하는데 <code>c = 0</code> 부터 시작하니 왼쪽부터 방문하는 재귀 순회라 보면 쉽다.</p>

<p>여기서 <code>collect</code> 함수는 인자로 받은 노드 <code>x</code> 를 기준으로 하위에 있는 <em>substring</em> 을 찾아낸다.</p>

<p>실제 구현에서는 <code>StringBuilder</code> 를 사용한다.</p>

<pre><code class="java">    private void collect(Node x, StringBuilder prefix, Queue&lt;String&gt; q) {
        // TODO Auto-generated method stub

        if (x == null) return;
        if (x.val != null) q.add(prefix.toString());

        for (char c = 0; c &lt; R; c++) {
            prefix.append(c);
            collect(x.next[c], prefix, q);
            prefix.deleteCharAt(prefix.length() - 1);
        }
    }

    public Iterable&lt;String&gt; keys() { return keysWithPrefix(""); }
</code></pre>

<h4 id="prefixmatchs">Prefix Matchs</h4>

<p>구글링 하면서 매일 사용하는 기능이다. 구현은 위의 <code>collect</code> 함수를 사용하면 쉽다. <code>keyWithPrefix("sh")</code> 라면, <code>sh</code> 까지 내려간 뒤 <code>collect</code> 를 호출하면 된다.</p>

<pre><code class="java">public Iterable&lt;String&gt; keysWithPrefix(String prefix) {  
  Queue&lt;String&gt; q = new Queue&lt;String&gt;();
  Node x = get(root, prefix, 0);
  collect(x, prefix, q);
  return q;
}
</code></pre>

<p>자바의 <code>Queue</code> 는 인터페이스이므로 실제 구현은</p>

<pre><code class="java">    public Iterable&lt;String&gt; keysWithPrefix(String prefix) {
        Queue&lt;String&gt; q = new LinkedList&lt;String&gt;();
        Node x = get(root, prefix, 0);
        collect(x, new StringBuilder(prefix), q);
        return q;
    }
</code></pre>

<h4 id="longestprefix">Longest Prefix</h4>

<p>라우터에서 자주 사용한다. 아이피를 문자열로 표현하고, 자기가 알고 있는 인접한 라우터중 어디로 보낼지를 결정하기 위해 <em>longest prefix</em> 를 알아내 보낸다. </p>

<pre><code class="java    ">longestPrefixOf("128.112.136.11")  
// 128.112.136
</code></pre>

<p>아이디어는 간단하다. <code>null</code> 이나 찾으려는 문자열의 마지막 문자를 만나기 전까지의 문자열을 모아 돌려주면 된다.</p>

<pre><code class="java">public String longestPrefixOf(String query) {  
  int length = search(root, query, 0, 0);
  return query.substring(0, length);
}

public int search(Node x, String query, int d, int length) {

  if (x == null) return length;
  if (x.val != null) length =  d;
  if (d == query.length) return length;

  char c = query.charAt(d);
  return search(x.next[c], query, d + 1, length);
}
</code></pre>

<h4 id="patriciatrie">Patricia Trie</h4>

<p><code>shells, shellfish</code> 를 넣으면 브랜칭이 길게 이루어진다. 메모리 낭비가 있을 수 있는데, <code>shell</code> 밑에 <code>s, fish</code> 를 자식으로 만들면 괜찮다.</p>

<p>그러나 이 강의의 범위를 넘어서는 것이라 안알려준다고 함 ㅠㅠ. 이미지를 구해서 첨부하면</p>

<p><img src='http://2.bp.blogspot.com/-0B8D2LHyQVc/USMklcwZnMI/AAAAAAAAAKc/UBmZnHflOa0/s640/radix_tries.png'  alt="" /></p>

<p><img src='http://3.bp.blogspot.com/-nQ0ZUeIpDrQ/USMkvNUKHBI/AAAAAAAAAKk/rrvVaYU4Pwo/s640/fractal+tries.png'  alt="" /></p>

<p align="center">(<a href='http://aketa.blogspot.kr/' >http://aketa.blogspot.kr</a>)</p>

<p>아마도 통짜로 삽입 후 이후에 비슷한 <em>suffix</em> 의 문자열이 들어오면 분리를 시키는 것 같다. </p>

<h4 id="suffixtree">Suffix Tree</h4>

<p><img src='http://marknelson.us/attachments/1996/suffix-trees/FIGURE2.gif'  alt="" /></p>

<p align="center">(<a href='http://marknelson.us/' >http://marknelson.us</a>)</p>

<p>문자열 <em>suffix</em> 의 <em>patricia trie</em> 인데 <em>linear time</em> 으로 만들 수 있다고 한다.</p>

<ul>
<li>longest repeated substring</li>
<li>longest common substring</li>
</ul>

<p>등에 쓸 수 있단다.</p>

<h3 id="summary">Summary</h3>

<p>(1) Red-Black BST</p>

<ul>
<li><strong>Performance guarantee:</strong> <code>lg N</code> key compares</li>
<li>Supports ordered symbol table API</li>
</ul>

<p>(2) Hash Table</p>

<ul>
<li><strong>Performance guarantee:</strong> <em>constant</em> number of probes</li>
<li>Requires good hash function for key type</li>
</ul>

<p>(3) R-way, TST</p>

<ul>
<li><strong>Performance guarantee:</strong> <code>lg N</code> <em>character</em> accessed </li>
<li>Supports <em>character-based</em> operations</li>
</ul>

<blockquote>
  <p>You can get at anything by examining 50-100 bits!</p>
</blockquote>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Part 2</em> by <strong>Robert Sedgewick</strong> <br />
(2) <a href='http://t2.hhg.to/V12-lausn.html' >http://t2.hhg.to</a> <br />
(3) <a href='http://en.wikipedia.org/wiki/Trie' >Wikipedia: Trie</a> <br />
(4) <a href='http://aketa.blogspot.kr/2013/02/squeezed-tries-fractal-compression-for.html' >Squeezed Tries, Fractal Compression</a> <br />
(5) <a href='http://marknelson.us/1996/08/01/suffix-trees/' >Mark Nelson</a></p>]]></description><link>http://1ambda.github.io/r-way-ternary-search-tries/</link><guid isPermaLink="false">68259e58-854a-4a4f-a621-ee864f210992</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[r-way trie]]></category><category><![CDATA[ternary trie]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 16 Dec 2014 08:49:07 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 10]]></title><description><![CDATA[<p>이번 주에는 <em>mini-batch, stochastic graident descent</em>, <em>online learning</em>, <em>map-reduce</em> 등의 개념에 대해 배운다.</p>

<h3 id="learningwithlargedatasets">Learning With Large Datasets</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361499744_2717.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>왜 그렇게 큰 데이터 셋이 필요할까? 좋은 퍼포먼스를 얻기 위한 한 가지 방법이, <em>low bias</em> 알고리즘에 <em>massive data</em> 를 활용해 훈련하는 것이기 때문이다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361499747_9327.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>그러나 커다란 데이터 셋을 연산하기 위해서는 연산비용이 정말 비싸다. 예를 들어 
<code>m = 100,000,000</code> 이라 하면 <em>gradient</em> 를 계산하기 위해 매번 <code>k * m</code> 의 연산이 필요하다.</p>

<p>따라서 모든 데이터를 이용해 알고리즘을 훈련하기 보다는, 랜덤하게 고른 작은 서브셋에 대해서 알고리즘을 개발하고, 이후에 전체 데이터에 대해서 훈련하는 방법을 쓰기도 한다.</p>

<p>그러면 <code>m</code> 이 작아도 알고리즘이 충분히 잘 훈련된다는 것을 어떻게 보장할까? 이는 <em>learning curve</em> 를 그려보면 된다.</p>

<p>위 슬라이드에서 우측 하단은 <em>high bias</em> 알고리즘인데 <code>m</code> 을 많이 투입해도 별다른 이득이 없으므로 적당한 수준에서 <code>m</code> 을 정하면 된다.</p>

<p>물론 만든 알고리즘이 우측처럼 <em>high bias</em> 로 나오면, 좀 더 자연스러운 생각은 <em>hidden layer</em> 를 추가한다거나, 새로운 <em>feature</em> 를 도입해서 <em>bias</em> 를 낮추는 것이다.</p>

<p><br/></p>

<h3 id="stochsticgradientdescent">Stochstic Gradient Descent</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361500908_4667.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>gradient descent</em> 를 이용하는 <em>linear regression</em> 에서</p>

<p><img src='http://latex.codecogs.com/gif.latex?h_%5Ctheta%28x%29%20%3D%20%5Csum_%7Bj%3D0%7D%5En%20%5C%20%5Ctheta_jx_j'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?J_%7Btrain%7D%28%5Ctheta%29%20%3D%20%7B1%20%5Cover%202m%7D%20%5Csum_%7Bi%3D1%7D%5Em%5C%20%28h_%5Ctheta%28x%29%5E%7B%28i%29%7D%20-%20y%5E%7B%28i%29%7D%29%5E2'  alt="" /></p>

<p>이미 언급했듯이 <em>batch gradient descent</em> 의 문제는, <code>m</code> 이 크면 <code>J</code> 의 연산이 어마어마하게 많아진다는 것이다. 매 스텝마다 <code>m</code> 을 읽고, 계산값을 저장하기 때문이다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361501694_2445.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>이 문제를 해결하기 위해 <em>stochastic gradient descent</em> 에서는 한 턴에 한 쌍의 <code>x, y</code> 에 대해서만 <em>gradient</em> 를 계산한다.</p>

<p><em>batch gradient decsent</em> 에서는 한 턴마다 모든 모든 쌍의 <code>x, y</code> 에 대해     <em>gradient</em> (= <code>theta_j</code>) 를 계산 했었다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?cost%28%5Ctheta%2C%20%28x%5E%7B%28i%29%7D%2C%20y%5E%7B%28i%29%7D%29%29%20%3D%20%7B1%20%5Cover%202%7D%5C%20%28h_%5Ctheta%28x%5E%7B%28i%29%7D%20-%20y%5E%7B%28i%29%7D%29%5E2'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?J_%7Btrain%7D%28%5Ctheta%29%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%20cost%28%5Ctheta%2C%20%28x%5E%7B%28i%29%7D%2C%20y%5E%7B%28i%29%7D%29%29'  alt="" /></p>

<p>라고 하면</p>

<pre><code>- Randomly shuffle dataset  
- Repeat for i = 1 to m
  - 0_j := 0_j - a * derivative of cost(0, (xi, yi)
</code></pre>

<p>즉 <code>J_train</code> 의 미분 대신에 <code>cost</code> 의 미분값을 이용해서 연산을 줄이는 방법이다. 이 때 데이터가 이미 랜덤하게 섞였다는 점을 기억하자. 기하학적으로 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361502040_9252.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>batch</em> 에서는 올바른 방향을 향해 가지만, 보폭이 좀 좁다. <em>stochastic</em> 은 이리 갔다, 저리 갔다 하지만 결국에는 최저점을 향해 간다. 다만 <em>global optima</em> 에 도달하지 못하고 그 근처에 도착할 수 있다.</p>

<p><code>m</code> 이 굉장히 크면, <em>repeat</em> 부분의 루프를 1번만 돌려도 될 테지만, 작으면 여러번 돌려서 최대한 좋은 퍼포먼스를 내도록 훈련시킬 수 있다.</p>

<p><br/></p>

<h3 id="minbatchgradientdescent">Min-Batch Gradient Descent</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361503946_9357.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<ul>
<li><strong>Batch gradient descent:</strong> Use all <code>m</code> examples in each iteration</li>
<li><strong>Stochastic gradient descent:</strong> Use <code>1</code> example in each iteration</li>
<li><strong>Batch gradient descent:</strong> Use <code>b</code> examples in each iteration</li>
</ul>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta_j%20%3A%3D%20%5Ctheta-j%20-%20%7B%5Calpha%20%5Cover%20b%7D%20%5Csum_%7Bk%20%3D%20i%7D%5E%7Bi%20&plus;%20b%20-%201%7D%20%28h_%5Ctheta%28x%5E%7B%28k%29%7D%29%20-%20y%5E%7B%28k%29%7D%29%20x_j%5E%7B%28k%29%7D'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361504164_4561.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><code>b</code> 는 보통 <code>2 - 100</code> 사이의 값이기 때문에 <em>batch</em> 보다 훨씬 빠르다. 또한 <em>vectorization</em> 을 이용하면 <em>gradient computation</em> 을 <em>partially parallelize</em> 할 수 있기 때문에 <em>stochastic</em> 보다 더 빠를 수 있다. <del>병렬화의 미덕</del></p>

<p>단점으로는 추가적인 파라미터 <code>b</code> 가 필요하다는 점이다. 그러나 <em>vectorization</em> 을 잘 이용하면 더 빨라지므로 문제 없다.</p>

<p><br/></p>

<h3 id="stochasticgradientdescentconvergence">Stochastic Gradient Descent Convergence</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361519060_5993.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>convergence</em> 를 검증하는 방법으로, 훈련시키는 동안 얻은 <code>cost(0, (xi yi)</code> 평균값을 이용해 플롯을 그릴 수 있다.     </p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361519096_5186.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>stochastic</em> 은 <em>global optimum</em> 을 찾아내지 못할 수도 있기 때문에, 그 주변에서 알짱거릴 수도 있다.</p>

<p>더 많은 <code>m</code> 을 투입하면, 까끌거리는 선보다 좀 매끄러운 곡선을 얻을 수도 있다.</p>

<p>때때로 알고리즘이 전혀 학습하지 못하는 것 처럼 보일수도 있는데, 그럴 경우 <code>m</code> 을 더 투입하면 좀 경사가 낮은 커브로 조금씩 <em>decreasing</em> 할 수 있다. 이를 보면 결국 훈련되긴 하는데, 평균값을 플랏으로 그리니 들쭉날쭉 해 보이는 것이다. (물론 학습하지 못하는 경우도 있다. <code>m</code> 을 더 늘려서 확인해 보자.)</p>

<p><code>cost</code> 값이 증가한다면 더 작은 <em>learning late</em> 값을 이용하자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361519184_7199.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>learning rate</em> 와 관련해서 위 슬라이드처럼 식을 만들면, 이터레이션 넘버가 천천히 증가하면서 <code>alpha</code> 가 감소해 <em>converge</em> 하는 결과를 얻을 수 있다.</p>

<blockquote>
  <p>If we reduce learning rate <code>alpha</code> (and run stochastic gradient descent long enough), it's possible that we may find a set of better parameters than with large <code>alpha</code></p>
</blockquote>

<p><br/></p>

<h3 id="onlinelearning">Online Learning</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361520551_7175.jpg'  alt="" /></p>

<p><em>online learning</em> 에서는 데이터를 얻어 <code>theta</code> 를 업데이트하는데 사용하고, 버린다. 큰 사이트라면 데이터가 지속적으로 들어오기 때문에, <em>trianing data</em> 를 볼 필요가 없다. 다시 말해 같은 데이터를 두번 이상 쓰지 않는다는 말이다.</p>

<p>또 다른 장점으로는 사용자의 취향 변화를 빠르게 반영할 수 있다는 점이다.</p>

<blockquote>
  <p>Can adopt to changing user preference</p>
</blockquote>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361520594_9988.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>product search</em> 에 <em>predicted CTR</em> 를 이용해, 검색어와 잘 매칭되는 상품을 결과로 돌려수 있다. 이때 매 검색마다 돌려주는 검색결과는 일종의 <em>training set</em> 이 된다.</p>

<ul>
<li>special offers</li>
<li>customized selection</li>
</ul>

<p>등에도 사용할 수 있다.</p>

<p><br/></p>

<h3 id="mapreduceanddataparallelism">Map Reduce and Data Parallelism</h3>

<p>데이터가 어마어마하게 많으면, 하나의 컴퓨터에서 머신러닝 알고리즘을 돌리기가 좀 힘들다. 어떻게 해결할까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361522176_1942.jpg'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/22/1361522180_7521.jpg'  alt="" /></p>

<p>쉽게 말하면, 분산해서 처리할 수 있는 결과는 <code>map</code> 으로 해결하고, 이 결과들을 이용해 전체적인 결과는 <code>reduce</code> 가 계산한다. (실제로는 <code>reduce</code> 도 여러개 일 수 있다)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361522184_5033.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<blockquote>
  <p>Many lenaring algorithms can be expressed as computing sums of functions over the training set</p>
</blockquote>

<p>이렇기 때문에 <em>map-reduce</em> 가 큰 데이터셋에 대한 계산 처리 방법으로 좋은 해결책이 될 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361522188_9650.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>요즘엔 대부분의 프로세서가 멀티코어이기 때문에, 하나의 컴퓨터에서도 병렬화를 이용해 계산을 빠르게 해 낼 수 있다. 이 경우는 <em>network latency</em> 등에 대해 생각을 안해도 된다. 참고로 좋은 라이브러리들은 자동으로 연산을 병렬화한다. </p>

<p><br/></p>

<h3 id="photoocrandpipeline">Photo OCR and Pipeline</h3>

<p>머신러닝 예제로 <em>Photo OCR</em> 을 알아보자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361935712_3407.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>Photo OCR pipeline</em> 은 </p>

<ul>
<li>Image</li>
<li>Text detection</li>
<li>Character segmentation</li>
<li>Character recognition</li>
</ul>

<p>의 단계를 거친다. 각 단계마다 머신러닝을 적용할 수 있다.</p>

<p><br/></p>

<h3 id="slidingwindows">Sliding Windows</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361936303_5994.jpg'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/27/1361936307_1350.jpg'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/27/1361937647_2708.jpg'  alt="" /></p>

<p>텍스트나, 보행자등 특정 패턴을 검색하기 위해 이동하는 <em>rectangle</em> 의 단위를 <em>step-size, slide</em> 라 부른다. <em>slide</em> 의 사이즈를 변경해 가면서 패턴을 파악하는 방법을 <em>sliding window</em> 라 부른다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361937654_3410.jpg'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/27/1361937664_2466.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>텍스트를 인식해서, 근처의 텍스트와 묶는 <em>expansion</em> 작업을 하고 <em>character segmentation</em> 단계로 넘어간다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361937671_6657.jpg'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/27/1361937676_4874.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><br/></p>

<h3 id="artificialdata">Artificial Data</h3>

<p><em>low bias</em> 에 <em>massive data set</em> 을 조합하면 좋은 퍼포먼스가 나오긴 하는데, 어디서 커다란 데이터셋을 구할까? 작은 데이터 셋으로 커다란 데이터셋을 인위적으로 만들 수 있을까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361948453_3756.jpg'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/27/1361948457_9107.jpg'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/27/1361948462_1113.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>스케일링, 로테이션, 디스토션, 백그라운드 수정 등 다양한 조합을 통해 진짜처럼 보이는 <em>synthetic data</em> 를 얻을 수 있다. 마찬가지로, <em>speech recognition</em> 에도 <em>synthetic data</em> 를 만들어 퍼포먼스를 높일 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361948466_5032.jpg'  alt="" /></p>

<ul>
<li><em>synthetic data</em> 를 만들기 전에 <em>low bias classifier</em> 인지 확인하자.</li>
<li>데이터를 조합하는데 들어가는 노력이 얼마나 들까 생각해보자</li>
<li><em>crowd source</em> 를 고려하자. (e.g. Amazon Mechanical Turk)</li>
</ul>

<p>10 초당 1개의 <em>example</em> 을 수동으로 얻는다면, 10000 개를 얻는데 대략 3.5일의 시간이 걸린다.</p>

<h3 id="ceilinganalysis">Ceiling Analysis</h3>

<p>이전의 <em>Photo OCR</em> 문제에서 퍼포먼스를 높이려면 파이프라인의 각 단계 중 어느 부분에 가장 많은 노력을 들여야할까? </p>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361952527_2269.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>각 단계에서 수동으로 정확도 100% 를 만들었을때와, 전체적인 정확도를 비교해서 어느 부분을 향상 시켰을때 가장 효율적일지를 파악할수 있다.  </p>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361952535_9451.jpg'  alt="" />
<img src='http://img.my.csdn.net/uploads/201302/27/1361952540_1528.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><br/></p>

<h3 id="summary">Summary</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361952938_3624.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><strong>supervised learning</strong> 의 종류로</p>

<ul>
<li>linear regresison</li>
<li>logistic regression</li>
<li>neural networks</li>
<li>SVM</li>
</ul>

<p><strong>unsupervised learning</strong> 으로</p>

<ul>
<li>k-means</li>
<li>PCA</li>
<li>anomaly detection</li>
</ul>

<p>또한 머신 러닝의 응용으로</p>

<ul>
<li>recommender system</li>
<li>large scale ML</li>
</ul>

<p>마지막으로 머신러닝에 도움이 되는 주제로</p>

<ul>
<li>bias vs variance</li>
<li>regularization</li>
<li>evaluation technique</li>
<li>learning curve</li>
<li>error analysis</li>
<li>ceiling analysis</li>
</ul>

<p>등을 배웠다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/27/1361953290_6926.jpg'  alt="" /></p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>  </p>]]></description><link>http://1ambda.github.io/machine-learning-week-10/</link><guid isPermaLink="false">5ffe5848-c50e-42ff-84ab-153d47f0c7d3</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine learning]]></category><category><![CDATA[stochastic gradient descent]]></category><category><![CDATA[mini-batch gradient descent]]></category><category><![CDATA[online learning]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Mon, 15 Dec 2014 03:14:52 GMT</pubDate></item><item><title><![CDATA[Radix Sort, Suffix Sort]]></title><description><![CDATA[<h3 id="stringsinjava">Strings in Java</h3>

<p>문자열은 <em>Character (문자)</em> 의 나열이다. C 에서 하나의 캐릭터는 <em>8-bit</em> 인데, 자바의 경우에는 <em>16-bit unsigned integer</em> 로 표시한다. </p>

<p>스트링의 길이를 얻기 위해 <code>length</code>, 인덱싱 하기 위해 <code>charAt</code>, 서브스트링을 얻기 위해 <code>substring</code> 의 메소드를 지원한다.</p>

<pre><code class="java">public final class String implements Comparable&lt;String&gt; {

  private char values;
  private int offset; // index of first char in array
  private int length;
  private int hash; // cache of hashCode()

  ...

  public char charAt(int i) {
    return value[i + offset];
  }

  ...
}
</code></pre>

<p>자바에서 문자열은 <em>immutable</em> 이다. 더 정확히는 <em>immutable</em> <code>char []</code> <em>array</em> 라 보면 된다. 길이 정보를 가지고 있고 배열이기 때문에 <code>length</code>, <code>charAt</code>, <code>substring</code> 등의 연산은 <code>O(1)</code> 임을 보장한다.</p>

<p><code>concat</code> 의 경우에는 새로운 문자열을 만들기 때문에 <code>O(N)</code> 이다. 메모리는 길이 <code>N</code> 의 문자열에 대해 <code>40 + 2N</code> 을 필요로 한다. 메모리를 아껴야 한다면 <em>byte, char</em> 을 이용할 수 있겠지만 여러 편리한 스트링의 메소드를 사용하지 못한다.</p>

<h3 id="stringbuilderstringbuffer">StringBuilder, StringBuffer</h3>

<p><code>StringBuilder</code> 는 <em>mutable</em> 이다. <code>char []</code> 배열을 <em>resizing</em> 하기 때문에 </p>

<ul>
<li><code>substirng</code> 의 경우 <code>O(N)</code> 이며 (새 스트링을 만든다)</li>
<li><code>concat</code> 은 <code>O(1*)</code> 이다. (<code>*</code> 는 amortized)</li>
</ul>

<p><code>length, charAt</code> 은 마찬가지로 <code>O(1)</code> 이다. 참고로 <code>StringBuffer</code> 는 <code>StringBuilder</code> 와 비슷하지만 <em>thread safe</em> 하고, 느리다.</p>

<p>그러면 <em>reverse</em> 를 구현 할 때 <code>String</code> 과 <code>StringBuilder</code> 중 어떤 것이 더 나을까?</p>

<pre><code class="java">// 1. use String
public static String reverse(String s) {  
  String rev = "";
  for (int i = s.length() - 1; i &gt;= 0; i--)
    rev += s.charAt(i);

  return rev;
}  

// 2. use StringBuilder
public static String reverse(String s) {  
  StringBuilder rev = new StringBuilder();
  for (int i = s.length() - 1; i &gt;= 0; i--)
    rev.append(s.charAt(i));

  return rev.toString();
}  
</code></pre>

<p><code>String</code> 을 이용한 버전은 <code>O(n^2)</code> 이고, <code>StringBuilder</code> 를 이용한 버전은 <code>O(n)</code> 이다. 이는 <code>+=</code> 와 <code>append</code> 의 차이 때문이다.</p>

<p><em>suffixes</em> 문제도 생각해 보자.</p>

<pre><code class="java">// input string
a a c a a g t t a c a a g c

// output
c     // suffixes 14  
g c   // suffixes 13  
a g c // suffixes 12  
...
...
a a c a a g t t a c a a g c // suffixes 0  
</code></pre>

<p><code>String</code> 과 <code>StringBuilder</code> 의 구현을 생각해 보면,</p>

<pre><code class="java">// 1. use String 
public static String[] suffixes(String s) {  
  int N = s.length();
  String[] suffixes = new String[N];

  for (int i = 0; i &lt; N; i ++)
    suffixes[i] = s.substring(i, N);

  return suffixes;
}

// 2. use StringBuilder 
public static String[] suffixes(String s) {  
  int N = s.length;
  stringBuilder sb = new StringBuilder(s);
  String suffixes = new String

  for (int i = 0; i &lt; N; i++)
    suffixes[i] = s.substring(i, N);

  return suffixes;
}
</code></pre>

<p>당연히 <code>substring</code> 은 <code>String</code> 이 메모리 사용량이 훨씬 더 적을꺼라 생각했는데 Java7 Update6 부터 좀 달라졌다고 한다.</p>

<p><em>Java 7 Update 6</em> 부터는 이전처럼 <code>String</code> 의 <code>char []</code> 가 공유되지 않는단다. 따라서 <code>String.substring</code> 은 더이상 <em>constance space, time</em> 이 아니라 <em>linear space, time</em> 의 비용이 든다. 자세한 내용은 <a href='http://java-performance.info/changes-to-string-java-1-7-0_06/' >Changes to String Java 1.7.0-06</a>로 </p>

<p>따라서 알고리즘 <code>1</code> 은 <em>linear time, space</em> <code>2</code> 는 <em>quadratic time, space</em> 의 알고리즘이다.</p>

<h4 id="longestcommonprefix">Longest common prefix</h4>

<pre><code class="java">public static int lcp(String s, String t) {  
  int n = Math.min(s.length(), t.length());

  for (int i = 0; i &lt; n; i++)
    if (s.charAt(i) != t.charAt(i))
      return i;

  return n;
}
</code></pre>

<p>러닝타임은 <code>s, t</code> 중 더 긴 문자열의 길이에 비례한다. 일반적으로는 <em>sublinear time</em> 이다. 따라서 <code>compareTo</code> 메소드를 <em>sublinear time</em> 으로 구현할 수 있다.</p>

<h4 id="radix">Radix</h4>

<p>알파벳을 다양한 형태로 표현할 수 있는데, <em>binary</em> 의 경우엔 <code>01</code> 이 될 것이다. 이때의 <em>radix</em> 는 2 다. <em>DNS</em> 는 <code>ACTG</code> 로 표현할 수 있으므로 <code>R = 4</code> 다.</p>

<h3 id="keyindexedcounting">Key-Indexed Counting</h3>

<p>정렬 알고리즘의 성능을 정리해 보면,</p>

<p>(1) <strong>Insertion Sort</strong></p>

<ul>
<li><strong>guarantee:</strong> <code>O(N^2 / 2)</code></li>
<li><strong>random:</strong> <code>O(N^2 / 4)</code></li>
<li><strong>extra space:</strong> <code>1</code></li>
<li><strong>stable:</strong> <code>yes</code></li>
</ul>

<p>(2) <strong>Merge Sort</strong></p>

<ul>
<li><strong>guarantee:</strong> <code>O(N log N)</code></li>
<li><strong>random:</strong> <code>O(N log N)</code></li>
<li><strong>extra space:</strong> <code>N</code></li>
<li><strong>stable:</strong> <code>yes</code></li>
</ul>

<p>(3) <strong>Quick Sort</strong></p>

<ul>
<li><strong>guarantee:</strong> <code>O(1.39 N log N)</code></li>
<li><strong>random:</strong> <code>O(1.39 N log N)</code></li>
<li><strong>extra space:</strong> <code>c log N</code></li>
<li><strong>stable:</strong> <code>no</code></li>
</ul>

<p>(4) <strong>Heap Sort</strong></p>

<ul>
<li><strong>guarantee:</strong> <code>O(2 N log N)</code></li>
<li><strong>random:</strong> <code>O(2 N log N)</code></li>
<li><strong>extra space:</strong> <code>1 log N</code></li>
<li><strong>stable:</strong> <code>no</code></li>
</ul>

<p>이런 <em>comparison based</em> 알고리즘은 <em>lower bound</em> 가 <code>N log N</code> 이다. 따라서 <em>key compare</em> 를 하지 않는다면 더 나은 성능을 낼 수 있다.</p>

<p><em>key-indexed counting</em> 에서는 <em>key</em> 가 <code>0</code> 부터 <code>R - 1</code> 사이의 정수라 가정한다. 따라서 키를 배열의 인덱스로 사용할 수 있다.</p>

<p>따라서 다음처럼 활용할 수 있다.</p>

<ul>
<li>Sort String by first letter</li>
<li>Sort class roster by section</li>
<li>Sort phone number by area code</li>
<li>Subroutine in a sorting algorithm</li>
</ul>

<p>알고리즘을 보자. </p>

<blockquote>
  <p><strong>Goal:</strong> Sort an array <code>a[]</code> of <code>N</code> integers between <code>0</code> and <code>R - 1</code></p>
</blockquote>

<p>(1) Count frequencies of each letter using key as index <br />
(2) Compute frequecy cumulates which specify destinations <br />
(3) Access cumulates using key as index to move items <br />
(4) Copy back into original array</p>

<pre><code class="java">int N = a.length();  
int[] count = new int[R + 1];

// step (1)
for (int i = 0; i &lt; N; i++)  
  count[a[i] + 1]++;

// step (2)
for (int r = 0; r &lt; R; r++)  
  count[r + 1] += count[r];

// step (3)
for (int i = 0; i &lt; N; i++)  
  aux[count[a[i]]++] = a[i];

// step (4)
for (int i = 0; i &lt; N; i++)  
  a[i] = aux[i];
</code></pre>

<ul>
<li><code>~11N + 4R</code> <em>array access</em></li>
<li><code>N + R</code> <em>extra space</em></li>
</ul>

<p><em>key-indexed counting</em> 은 <em>linear time, stable sorting</em> 이다.</p>

<h4 id="stable">Stable</h4>

<p>알고리즘이 <em>stable</em> 하다는 건 무슨 뜻일까? </p>

<blockquote>
  <p>A stable sort is one which preserves the original order of the input set while The unstable algorithm exhibits undefined behaviour when two elements are equal, it is perfectly possible that the order is sometimes preserved.</p>
</blockquote>

<p><img src='http://i.stack.imgur.com/hn6Rg.png'  alt="" /></p>

<p align="center">(<a href='http://programmers.stackexchange.com/' >http://programmers.stackexchange.com/</a>)</p>

<h3 id="lsdradixsort">LSD Radix Sort</h3>

<p><em>least-significant-digit-first string(radix) sort</em></p>

<p>아이디어는 간단하다. 우측부터 좌측으로 한 문자씩 <em>key-indexed couting</em> 을 하면 된다.</p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVpTjVFR1ozVWpNaVJHTzVZV0x4QXpZNDBpWjNJMk10WW1ZeEVUTHlZak5pVkdOMWN6TDJnRE14OHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(www.programering.com)</p>

<blockquote>
  <p>Which of the following is the most efficient algorithm to sort 1 million 32-bit integers?</p>
</blockquote>

<p>답은 <em>radix sort</em></p>

<h4 id="correctness">Correctness</h4>

<blockquote>
  <p>LSD sorts fixe-length strins in ascending order</p>
</blockquote>

<p>가설에 의해 <code>i</code> 번째 pass 후에는 뒤 부터 <code>i</code> 개의 문자들이 정렬되어 있다.  이 때 비교하려는 <code>i+1</code> 번째의 두 문자가 다르다면, <em>key-indexed sort</em> 가 두 개의 문자열을 정렬한다. 이 때 <em>key-indexed sort</em> 는 <em>stable</em> 하므로 이전 까지의 정렬했던 순서를 보존한다.</p>

<h4 id="implementation">Implementation</h4>

<pre><code class="java">    // W: fixed-length of strings
    public static void LSDsort(String[] a, int W) {
        int N = a.length;
        int R = 256;
        String[] aux = new String[N];

        // key indexed counting for each digit from right to left
        for (int d = W - 1; d &gt;= 0; d--) {
            int[] count = new int[R + 1];

            // count frequencies
            for (int i = 0; i &lt; N; i++) 
                count[a[i].charAt(d) + 1]++;

            for (int r = 0; r &lt; R; r++)     
                count[r + 1] += count[r];

            for (int i = 0; i &lt; N; i++)
                aux[count[a[i].charAt(d)]++] = a[i];

            for (int i = 0; i &lt; N; i++)
                a[i] = aux[i];
        }
    }
</code></pre>

<p><em>LSD sort</em> 퍼포먼스는 <code>2WN</code>, 랜덤하게 <code>2WN</code>, 공간은 <code>N + R</code>, <em>stable</em> 하다. 참고로, <code>4byte Int</code> 에 대해 <code>1Byte</code> 씩 <em>LSD sort</em> 를 적용하면 <code>Array.sort</code> 보다 2~3배 더 빠르다고 한다. <a href='http://algs4.cs.princeton.edu/51radix/LSD.java.html' >코드는 여기로</a></p>

<h3 id="msdradixsort">MSD Radix Sort</h3>

<p><em>most significant-digit-first string sort</em></p>

<ul>
<li>Partition array into <code>R</code> pieces according to first character</li>
<li>Recursively sort all strings that start with each character</li>
</ul>

<p>좌측 문자열 부터 시작하고, 현재 문자가 같은 문자열들 끼리 모아, 나머지 부분을 <em>sub-array</em> 취급해서 재귀적으로 정렬한다.</p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVDWjNNV001VW1ZaWhETTRjVExoTldONDBpTTJVMk10RVdaeEFUTHpVRFptZHpNaEYyTDVFVE14OHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(www.programering.com)</p>

<p><em>LSD</em> 는 다루지 못하는 <em>variable-length string</em> 을 정렬할 수 있다.</p>

<h4 id="implementation">Implementation</h4>

<p>참고로 자바에서는 <code>\0</code> 이 없다. 그래서 문자열의 길이를 넘어서는 인덱스에 대해 <code>-1</code> 을 돌려주는 <code>charAt</code> 을 만들자. 추가적인 문자가 없다면, 정렬된 것으로 보고 끝내면 된다. </p>

<pre><code class="java">private static int charAt(String s, int d) {  
  if (d &lt; s.length()) return s.charAt(d);
  else return -1;
}

    private static void msdSort(String[] a, String[] aux, int l, int h, int d) {

        if (h &lt;= l) return;

        int R = 256;
        int[] count = new int[R + 2];

        // count frequencies
        for (int i = l; i &lt;= h; i++) {
            int c = charAt(a[i], d);
            count[c + 2]++;
        }

        // accumulate
        for (int r = 0; r &lt; R + 1; r++)
            count[r + 1] += count[r];

        // sort
        for (int i = l; i &lt;= h; i++) {
            int c = charAt(a[i], d);
            aux[count[c + 1]++] = a[i];
        }

        // copy
        for (int i = l; i &lt;= h; i++)
            a[i] = aux[i - l];

        // solve sub-arrays
        for (int r = 0; r &lt; R; r++)
            msdSort(a, aux, l + count[r], l + count[r + 1] - 1, d + 1);
    }

    public static void MSDsort(String[] a) {
        String[] aux = new String[a.length];
        msdSort(a, aux, 0, a.length - 1, 0);
    }
</code></pre>

<p>그런데 이 구현은 몇 가지 문제가 있다.</p>

<p>(1) 매 재귀마다 <code>count</code> 배열을 만들고, 그 크기는 <code>R</code> 에 비례하기 때문에 <code>~11R + N</code> 의 성능을 갖는 <em>key-indexed counting</em> 연산이 <em>small subarray</em> 가 많아지면서 급격히 느려진다. </p>

<p>(2) 조그마한 <em>sub-array</em> 에 대해 많은 수의 재귀가 호출된다.</p>

<p>이 문제를 해결하기 위해 적은 수의 <em>small array</em> 에 대해 <em>insertion sort</em> 를 사용하자. </p>

<pre><code class="java">    // substring comparison is much faster than charAt comparison
    private static boolean less(String v, String w, int d) {
        return v.substring(d).compareTo(w.substring(d)) &lt; 0;
    }

    private static void isort(String[] a, String[] aux, int l, int h, int d) {
        // insertion sort
        for (int i = l; i &lt;= h; i++)
            for (int j = i; j &gt; l &amp;&amp; less(a[j], a[j - 1], d); j--) {
                // swap a[j - 1], a[j]
                String temp = a[j - 1];
                a[j - 1] = a[j];
                a[j] = temp;
            }

    }

    private static void msdSort(String[] a, String[] aux, int l, int h, int d) {

        int CUTOFF = 15;
        if (h &lt;= l + CUTOFF) {
            isort(a, aux, l, h, d);
            return;
        }
    ...
    ...
    ...
</code></pre>

<h4 id="performance">Performance</h4>

<p><em>MSD string sort</em> 는 필요한만큼 <em>character</em> 를 확인하기 때문에, 데이터에 따라 성능이 다르다. 그러나 대부분의 경우 <em>sublinear</em> 하고, 운이 나쁜 경우 <em>linear</em> 의 성능이 나온다. <em>duplicated key</em> 가 있는 경우에는 <em>nearly linear</em> 다.</p>

<p>재밌는 사실은 <code>compareTo</code> 를 이용하지만 <em>sublinear</em> 하게 성능이 나올 수도 있다는 점이다.</p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVpTWhkVFk0VXpZa2RqTmtaV0x3Z2paNTBpTTNZek10VWpNMFVUTGxSMlkxY1Raamx6TDRJVE14OHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(www.programering.com)</p>

<p><em>MSD string sort</em> 는 매 재귀마다 새로운 <code>count</code> 배열을 만들기 때문에 <code>N + DR</code> 만큼의 메모리가 필요하다., (<code>D</code> 는 재귀 호출의 수)</p>

<p><em>LSD</em> 에 비해서 가변길이 문자열을 정렬할 수 있고, <em>random</em> 데이터에 대해 <code>N log_R N</code> 의 성능을 보여준다. <em>LSD</em> 와 마찬가지로 <em>stable</em> 하다.</p>

<h4 id="msdvsquick">MSD vs quick</h4>

<p><em>MSD string sort</em> 는 <em>random access</em> 를 하기 때문에 <em>cache inefficient</em> 할 수 있고, <em>quicksort</em> 에 비해 <em>inner loop</em> 에 많은 명령어가 있다. 게다가 <code>count, aux</code> 등 추가적인 메모리가 필요하다.</p>

<p>반면 <em>quicksort</em> 는 <em>linear</em> 하지 않다. 그리고, 많은 수의 문자들을 다시 비교해야한다. 이 두가지를 합친 방법은 없을까?</p>

<h3 id="3wayradixquicksort">3-way Radix Quicksort</h3>

<p><del>무려 교수님이 만드신 알고리즘 1997년에 이 수업에서 만들었다고 함</del></p>

<p>기본적인 아이디어는</p>

<blockquote>
  <p>Do 3-way partitioning on the <code>d</code> th character</p>
</blockquote>

<ul>
<li>Less overhead than <code>R</code>-way partitioning in <em>MSD string sort</em></li>
<li>Does not re-examine characters equal to the partitioning char (but does re-examine characters not equal to the partitioning char)</li>
</ul>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVpTWhKVFpoTkRPMk1qWTRRV0xsTm1ZaTFDTjVFek10SVdNaVZUTHdZVFlsVldPbVoyTDBNVE14OHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(www.programering.com)</p>

<p>즉, 첫 문자열의 첫 번째 문자를 기준으로, 이것보다 큰 것, 작은 것, 같은 것 3개로 파티셔닝하면서 정렬하는 알고리즘이다. </p>

<h4 id="implementation">Implementation</h4>

<p>구현은 퀵소트랑 상당히 유사하다.</p>

<pre><code class="java">    // 3-Way Quicksort
    public static void Quicksort3way(String[] a) {
        qsort3way(a, 0, a.length - 1, 0);
    }

    // helper method for 3 way quicksort
    private static void swap(String[] a, int i, int j) {
        String temp = a[i];
        a[i] = a[j];
        a[j] = temp;
    }

    private static void qsort3way(String[] a, int l, int h, int d) {
        if (h &lt;= l) return;

        int lt = l, gt = h;
        int v = charAt(a[l], d);
        int i = l + 1;

        // partition
        while (i &lt;= gt) {
            int t = charAt(a[i], d);

            if      (t &lt; v) swap(a, lt++, i++);
            else if (t &gt; v) swap(a, i, gt--);
            else            i++;
        }
        // a[lo..lt-1] &lt; v = a[lt..gt] &lt; a[gt+1..hi]
        qsort3way(a, l, lt - 1, d);
        if (v &gt;= 0) qsort3way(a, lt, gt, d + 1);
        qsort3way(a, gt + 1, h, d);
    }
</code></pre>

<p><em>MSD string sort</em> 와 마찬가지로 <code>CUTOFF</code> 를 이용해서 작은 <em>sub-array</em> 를 <em>insetion sort</em> 로 정렬할 수 있다.</p>

<h4 id="3wayquicksortvsstandardquicksor">3-way quicksort vs standard quicksor</h4>

<p>일반적으로 <em>quicksort</em> 는 <code>compareTo</code> 를 기준으로 <code>~ 2N lnN</code> 의 성능을 보여주고, <em>long common prefixes</em> 가 있는 경우에 상당히 계산 비용이 비싸다. 이는 비교했던 문자열을 또 비교할 수 있기 때문이다.</p>

<p>그러나 <em>3-way string quicksort</em> 는 <code>charAt</code> 을 기준으로 <code>~ 2N lnN</code> 의 성능을 보인다. 그리고 같은 파티션에 대해 <code>d + 1</code> 로 재귀호출하기 때문에 같은 파티션 내에서는 비교했던 문자를 다시 계산하지 않는다. <del>갓 교수님</del></p>

<h4 id="3wayquicksortvsmsdsort">3-way quicksort vs MSD sort</h4>

<p>(1) <strong>MSD string sort</strong> 는</p>

<ul>
<li>같은 <code>count</code> 값을 가진 문자열에 뜬금없이 접근하기 때문에 <em>cache-inefficient</em></li>
<li>재귀마다 <code>count[]</code> 를 새로 만들어 너무 많은 메모리를 사용</li>
<li><code>count[], aux[]</code> 를 초기화하는데 너무 많은 오버헤드</li>
</ul>

<p>(2) <strong>3-way string quicksort</strong> 는</p>

<ul>
<li>더 짧은 <em>inner loop</em></li>
<li><code>while</code> 을 이용해 순차적으로 접근하므로 <em>cache-friendly</em></li>
<li><em>in-place</em></li>
</ul>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVTTTJFV09tZFRPakoyTTVjVEwxWW1ZNDBDTWtoek10UVRZMUlXTDVVRE8wWUdNd1UyTHhRVE14OHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(www.programering.com)</p>

<h3 id="suffixarrays">Suffix Arrays</h3>

<p><em>keyword-in-context search</em> 란</p>

<blockquote>
  <p>Given a text of <code>N</code> chars, preprocess i to enable fast substring search (find all occurrences of query string ocntext)</p>
</blockquote>

<p>쉽게 말해서 구글 검색창에 <em>world</em> 라고 치면 <em>hello world</em> 등이 자동으로 검색목록에 나오는것.</p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVDWmtkVFozRW1ZbFZtTmlGVEx6RVRPNDBTWTFZek10UVRNeFFXTGlKVFpqbERNekkyTHpRVE14OHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(www.programering.com)</p>

<p><em>suffixes</em> 를 만든다음에 문자열 정렬을 해서 중복된 <em>suffix</em> 가 있는지 보면 된다. <code>String</code> 의 경우 <code>substring</code> 을 얻는데 <code>O(1)</code> 이이므로 <em>suffixes</em> 를 만드는데 <code>O(n)</code> 이다. </p>

<p>그 후에 <em>binary search</em> 를 하면, 일치하는 문자열을 검색할 수 있다.</p>

<p>(1) <strong>Preprocess:</strong> <em>suffix sort</em> the text. <br />
(2) <strong>Query:</strong> <em>binary search</em> for query; scan until mismatch.  </p>

<h3 id="longestrepeatedsubstring">Longest repeated substring</h3>

<blockquote>
  <p>Gien a string of <code>N</code> characters, find the longest repeated substring.</p>
</blockquote>

<p>유전자 지도 <code>a g t t a a t c g ~</code> 에서 일치하는 가장 긴 유전자 문자열을 찾아내는데 활용할 수 있다.</p>

<p><em>data compression</em> 에도 활용 가능하다. 자주 반복되는 긴 패턴을 발견해 짧게 줄이면 용량을 상당히 줄일 수 있다.</p>

<p>악보를 이용해서 음악을 <em>visualization</em> 하는데도 활용할 수 있다.</p>

<h4 id="bruteforce">Brute Force</h4>

<p>문자열의 길이가 <code>N</code>, 가장 긴 패턴의 길이가 <code>D</code> 라면 <em>worst case</em> <code>DN^2</code> 이다. </p>

<h4 id="sortingsolution">Sorting solution</h4>

<p>(1) form suffixes (<code>O(n)</code>) <br />
(2) sort suffixes (<code>O(n log n)</code>) <br />
(3) compute longest prefix between adjacent suffixes (<code>O(kn)</code>)  </p>

<pre><code class="java">    // longrest common prefix
    public static String lcp(String v, String w) {

        int n = Math.min(v.length(), w.length());

        for (int i = 0; i &lt; n; i++) {
            if (v.charAt(i) != w.charAt(i)) return v.substring(0, i);
        }

        return v.substring(0, n);
    }

    // longest repeated substring
    public static String lrs(String s) {

        int N = s.length();
        String[] suffixes = new String[N];

        // form suffixes
        for(int i = 0; i &lt; N; i++)
            suffixes[i] = s.substring(i, N);

        // sort
        Arrays.sort(suffixes);

        // find longest repeated substring using lcp
        String lrs = "";

        for (int i = 0; i &lt; N - 1; i++) {
            String x = lcp(suffixes[i], suffixes[i + 1]);

            if (x.length() &gt; lrs.length()) lrs = x;
        }

        return lrs;
    }
</code></pre>

<p><em>suffix soring</em> 에 <em>3-way string quicksort</em> 를 이용하면 어마어마하게 빠르다.</p>

<p>한 가지 문제는 <em>lrs</em> 의 길이가 길어지면 <em>suffix sort</em> 의 성능이 급격히 떨어진다. <code>D</code> 를 <em>lrs</em> 의 길이라 했을때 적어도 <code>1 + 2 + ... + D</code> 의  문자열 비교가 필요하다. (자신과 자신의 서브스트링과의 비교)</p>

<p>따라서 <code>D</code> 가 길면 길수록 성능이 나빠진다. </p>

<blockquote>
  <p>Quadratic (or worse) in <code>D</code> for <em>LRS</em></p>
</blockquote>

<p>성능이 떨어지는 입력 데이터로, 반복되는 인풋이 있다. <code>twinstwins</code> 를 예로 들면</p>

<pre><code>ins  
instwins  
ns  
nstwins  
s  
stwins  
twins  
twinstwins  
wins  
winstwins  
</code></pre>

<p>그러면 더 빠른 알고리즘이 없을까? <em>Manber-Myers algorithm</em> 이란게 있는데, 요건 <em>linearithmic</em></p>

<p><em>suffix trees</em> 란 것도 있다. 이건 <em>linear</em></p>

<h4 id="manbermyersmsdalgorithm">Manber-Myers MSD Algorithm</h4>

<p>(1) sort on first character using key-indexed counting sort <br />
(2) given array of suffixes sorted on first <code>2^(i-1)</code> characters (phase <code>i</code>)  </p>

<p><em>worse-case</em> 퍼포먼스는 <code>N lgN</code></p>

<p><img src='http://www.programering.com/images/remote/ZnJvbT1pdGV5ZSZ1cmw9Y21idzVpWmtCVE9rZFRaMVFEWjVBVEwwY2paaTFTTjBjek10Z0RabU5XTGlSRE9qUkRNalIyTDNNak14OHlNNUFETXZRbmJsMUdhakZHZDBGMkxrRjJic0JYZHYwMmJqNVNaNVZHZHA1aU1zUjJMdm9EYzBSSGE.jpg'  alt="" /></p>

<p align="center">(www.programering.com)</p>

<p><em>key-indexed counting</em> 을 이용해 먼저 하나의 문자를 정렬하고, 그 이후에는 <code>2, 4, 6, 8, ...,</code> 개씩 정렬해 나간다. 이 과정에서 <code>inverse[]</code> 를 이용한 <em>index sort</em> 란걸 하는데, 아이디어는 이렇다.</p>

<p><em>suffixes</em> 에서 비교하려는 두 문자열의 뒷부분의 일부는 이미 이전 단계에 정렬 되었을 수 있다. (슬라이드의 빨간색 부분) 따라서 이미 정렬해 된 순서 <code>inverse[]</code> 를 이용해서 현재 비교하려는 두 문자열의 순서를 정할 수 있다. </p>

<h4 id="summary">Summary</h4>

<ul>
<li><em>linear-time</em> 문자열 정렬을 할 수 있다.</li>
</ul>

<p>왜냐하면 <em>key comparison</em> 이 아니라 <em>character comparison</em> 으로 해낼 수 있기 때문</p>

<ul>
<li><em>sublinear-time</em> 정렬도 만들 수 있다.</li>
</ul>

<p>모든 문자열을 비교할 필요가 없기 때문 (Input size is amount of data in keys, not number of keys.)</p>

<ul>
<li><em>3-way string quicksort is asymptotically optimal</em></li>
</ul>

<p><code>1.39 N lgN</code> 의 문자열 비교, <em>random data</em> 에 대해. 그러나 <em>suffix sort</em> 에 대해 <code>N lgN</code> 을 보장하려면(<em>worst case</em>) <em>Manber-Myer</em> 를 사용해야 한다.</p>

<ul>
<li>Long strings are rarely random in practice</li>
</ul>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Part 2</em> by <strong>Robert Sedgewick</strong> <br />
(2) <a href='http://programmers.stackexchange.com/questions/247440/what-does-it-mean-for-a-sorting-algorithm-to-be-stable' >What is a stable sorting algorithm?</a> <br />
(3) <a href='http://www.programering.com/a/MTOyYjNwATM.html' >www.programering.com</a></p>]]></description><link>http://1ambda.github.io/radix-sort-suffix-sort/</link><guid isPermaLink="false">e649e1bf-a946-4414-a54a-e3f1be9c1d66</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[radix sort]]></category><category><![CDATA[String]]></category><category><![CDATA[3 way radix]]></category><category><![CDATA[MSD]]></category><category><![CDATA[LSD]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 11 Dec 2014 06:59:33 GMT</pubDate></item><item><title><![CDATA[Process Mining, Week3]]></title><description><![CDATA[<h3 id="fourqualitycriteriaforprocessdiscovery">Four Quality Criteria For Process Discovery</h3>

<p><em>real process</em> 로 부터 <em>event log</em> 를 얻고 이것으로 <em>process model</em> 을 만든다. </p>

<p><em>process model</em> 을 평가하기 위해 해야하는 질문은</p>

<blockquote>
  <p>Is the process model a correct reflection of the real process?</p>
</blockquote>

<p>그러나 <em>real process</em> 를 모르기 때문에 판단하기가 쉽지 않다. 일반적으로 데이터마이닝에서 사용하는 평가 지표인 <em>confusion matrix</em> 를 도입하면</p>

<p><img src='http://lh3.ggpht.com/_qIDcOEX659I/SzjW6wGbmyI/AAAAAAAAAtY/Nls9tSN6DgU/contingency_thumb%5B3%5D.png?imgmax=800'  alt="" /></p>

<p align="center">(<a href='http://crsouza.blogspot.kr/' >http://crsouza.blogspot.kr</a>)</p>

<ul>
<li><strong>True Positive:</strong> traces possible in model and also possible in real process</li>
<li><strong>True Negative:</strong> traces not possible in model and also not possible in real process</li>
<li><strong>False Positive:</strong> traces possible in model and but not possible in real process</li>
<li><strong>False Negative:</strong> traces not possible in model and but possible in real process</li>
</ul>

<p>보통은 평가 지표로 <em>recall</em>, <em>precision</em>, <em>F1 score</em> 등을 이용하는데 프로세스마이닝에서의 문제는 <em>real process</em> 에서 일어나는 <strong>FN, TP</strong> 를 알 수가 없다는 것이다.</p>

<p>따라서 <em>event log</em> 의 <strong>FN', TP'</strong> 를 이용해서 <em>replay fitness</em> 를 이용한다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?replay%5C%20fitness%20%5C%5C%5C%5C%20%3D%20%7BTP%27%20%5Cover%20TP%27%20&plus;%20FN%27%7D'  alt="" /></p>

<p>이 외에도 다양한 문제를 마주칠 수 있는데,</p>

<ul>
<li>보통 이벤트로그로 부터는 <strong>FN'</strong> 이 무엇인지 알 수 없다.</li>
<li>로그가 <em>possible traces</em> 의 일부분만 담고 있다.</li>
<li>Almost vs poorly fitting traces</li>
<li>루프가 있으면 무한히 많은 <em>possible traces</em> 가 있다.</li>
<li>Murphy's law for process mining: <strong>Anything is possible, so pobabilities matter</strong></li>
</ul>

<p>이런 문제점들은 다음의 기준들 사이에서 균형을 맞춰야 함을 알려준다.</p>

<ul>
<li><strong>fitness:</strong> observed behavior fits</li>
<li><strong>simplicity:</strong>  Occam's razor</li>
<li><strong>precision:</strong> avoiding underfitting</li>
<li><strong>generalization:</strong> avoiding overfitting</li>
</ul>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-51-728.jpg?cb=1305062521'  alt="" /></p>

<p>여기서 <em>precision</em> 이 문제가 되는 경우라는 것은, <em>flower model</em> 처럼 필요 이상으로 가능한 모든 경우의 수를 도입한 모델이라 보면 된다. 다시 말해서 기존의 <em>log</em> 와는 완전히 다른 로그가 모델에 맞을 경우를 말한다. (<em>underfitting</em>) </p>

<p><br/> <br />
<img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-52-728.jpg?cb=1305062521'  alt="" /></p>

<p>반대로 <em>generalization</em> 이 낮은 모델은, 너무 <em>log</em> 에 맞추느라 복잡해진 경우를 말한다. (<em>overfitting</em>)</p>

<p>따라서 <em>traces</em> 의 수가 적은 경우에 너무 <em>overfitting</em> 하려고 하면 퍼포먼스가 낮아진다. 반대로 <em>traces</em> 수가 상당히 많다면, 다음에 들어올 <em>traces</em> 가 다른 형태일 확률이 낮아지므로 모델을 조금 더 <em>fitting</em> 하는 편이 낫다. (오히려 이 경우는 <em>overfitting</em> 이라 보기 어렵다.)</p>

<p><br/></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-43-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<h3 id="representationalbias">Representational Bias</h3>

<blockquote>
  <p>Modeling language provides a bias</p>
</blockquote>

<p>예를 들어 <em>petri net</em> 같은 경우는 <em>concurrency</em> 를 모델링하는데 문제가 없는 반면 <em>transition system</em> 은 어렵다.</p>

<p><em>concurrency</em> 에 대해서도 생각해 볼 것이, <code>k = 10</code> 의 <em>parallel activities</em> 가 있다면 가능한 <em>traces</em> 는 <code>10! ~= 3600000</code> 이다.</p>

<p>반면 알파 알고리즘이 이 모델을 발견하려면 단지 <code>k(k-1</code> 의 <em>direct succession</em> 만 필요하다.</p>

<p>그러나 알파 알고리즘은 <em>optional(skip)</em> 이 있는 모델을 발견하지 못한다. 그리고, <em>silent transition(OR-joins)</em> 이 있는 모델에서의 가능한 <em>traces</em> 수는</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum_%7Bi%20%3D%200%7D%5Ek%20%5Cbinom%7Bk%7D%7Bi%7D%20i%21'  alt="" /></p>

<p><em>WF-net</em> 같은 경우는 <em>unique label</em> 과 관련해서 문제가 있다.</p>

<p><code>L = [&lt;a, c, d&gt;^45, &lt;b, c, e&gt;^42, &lt;a, c, e&gt;^20]</code> </p>

<p>이 있을때, <em>WF-net</em> 은 <code>e</code> 두개인 모델을 발견할 것이다.</p>

<p>그리고 만약 <em>no indirected dependencies</em> 라면,</p>

<p><code>L = [&lt;a, c, d&gt;^45, &lt;b, c, e&gt;^42]</code> 에서 올바른 모델을 찾아내지 못할것이다.  (<code>a, b</code> 가 <code>d, e</code> 의 선택에 영향을 준다.)</p>

<blockquote>
  <p>Visualization of discovered model != representatoinal bias</p>
</blockquote>

<h4 id="whatisprocessdiscoverysodifficult">What is process discovery so difficult?</h4>

<ul>
<li>There are <strong>no negative examples</strong></li>
<li>Due to concurrency, loops, and choices the search space has a complex structure and the log typically contains only a fraction of all possible behaviors</li>
<li>There is no clear relation between the size of a model and its behavior</li>
</ul>

<p>특히 마지막 문제는, 일반적인 경우에선 작은 모델이 작은 로그를 만들어 내지만 프로세스 마이닝에선 작은 모델이라도 많은 로그를 만들 수 있다.</p>

<p>따라서 <em>representational bias</em> 를 잘 고려해서 모델을 선택해야 한다.</p>

<h3 id="businessprocessmodelandnotationbpmn">Business Process Model and Notation (BPMN)</h3>

<blockquote>
  <p>Representational bias impacts search space</p>
</blockquote>

<p><img src='http://upload.wikimedia.org/wikipedia/en/7/71/BPMN_gateway_types.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org/</a>)</p>

<p><em>exclusive OR</em> 은 둘 중 하나만 선택이고, <em>parallel</em> 은 모두로 분기한다. <em>inclusive OR</em> 은 하나 이상을 선택할 수 있다. 더 자세한 내용은 <a href='http://tynerblain.com/blog/2006/07/27/bpmn-gateways/' >BPMN Gateway</a> 를 참고하자.</p>

<p>보통 <em>inclusive OR join</em> 이 있으면 <em>synchronization</em> 이 된다. 그리고 앞쪽에 <em>inclusive OR split</em> 이 있고 뒤쪽에 <em>and join</em> 이 있으면 <em>deadlock</em> 이 있을 가능성이 높다.</p>

<p>일반적으로는 <em>OR join, split</em> 을 <em>AND join split</em> 을 결합해야 데드락이 없다.</p>

<p>참고로 <em>BPMN</em> 은 <em>UML</em> 이나 <em>Event-Driven Process Chains, EPCs</em> 와 비스무리하다. 아래는 <em>BPMN</em> 예제</p>

<p><img src='http://sehlhorst.smugmug.com/photos/84432593-M.jpg'  alt="" /></p>

<p align="center">(<a href='http://tynerblain.com/blog' >http://tynerblain.com/blog</a>)</p>

<p>보통은 <em>Petri net</em> 이나 <em>process tree</em> 로 작업하고 <em>BPMN</em> 으로 변환한다. <em>BPMN</em> 으로 바로 작업하는 경우는 흔하지 않다고 함.</p>

<h4 id="viciouscycleparadox">Vicious Cycle Paradox</h4>

<p>이부분은 당최 뭔 소린지 이해가.. 나중을 위해서 그림만 넣어놈.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-121219213500-phpapp02/95/process-mining-chapter02processmodelingandanalysis-14-638.jpg?cb=1355974557'  alt="" /></p>

<h3 id="dependencygraphs">Dependency Graphs</h3>

<p><img src='http://www.ijmijournal.com/cms/attachment/305569/1959182/gr6.gif'  alt="" /></p>

<p align="center">(<a href='http://www.ijmijournal.com/' >http://www.ijmijournal.com</a>)</p>

<p><em>footprint</em> 의 <em>casuality</em> 를 이용해서 <em>dependency graph</em> 를 만들 수 있다. <em>place</em> 가 없는 일종의 <em>Petri Net</em> 이라 볼 수 있다.</p>

<p>참고로 <em>casuality</em> 는</p>

<blockquote>
  <p>causality: <code>x -&gt; y</code>, iff <code>x &gt; y</code> and not <code>y &gt; x</code></p>
</blockquote>

<p><em>dependency graph</em> 는 의존성은 잘 보여주지만 <em>executable semantic</em> 이 없다. 각 노드는 <em>OR join, split</em> 의 <strong>fuzzy</strong> 로 볼 수 있다.</p>

<ul>
<li>Fuzzy models can be viewed as dependency graphs</li>
<li>No precise semantics  </li>
<li>Many ways to create dependency graphs often based on heuristics</li>
</ul>

<h3 id="casualnets">Casual Nets</h3>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-121219213500-phpapp02/95/process-mining-chapter02processmodelingandanalysis-15-638.jpg?cb=1355974557'  alt="" /></p>

<p><em>Casual nets, C-nets</em> 은 <em>dependency graph</em> 에 <em>inpt, output</em> 을 붙여 <em>possible behavior</em> 를 보여준다.</p>

<p><br/></p>

<p>왜 <em>C-nets</em> 을 이야기 할까?</p>

<ul>
<li>Output of several mining techniques, e.g., the well-known huritics miner</li>
<li>Fits well with mainsteam languages (BPMN, EPCs, YAWL, etc.)</li>
<li>Able to model <strong>XOR, AND, OR</strong> but <strong>no sidlent steps or duplicate activities needed</strong></li>
<li>Loose interpretation. <strong>focus on replay semantics rather then executing semantics</strong></li>
</ul>

<p><em>C-nets</em> 에서는 <em>obligation</em> 이 <em>token</em> 의 역할을 한다. </p>

<blockquote>
  <p>Semantics are declarative <br />
  Only valid binding sequences are considered</p>
</blockquote>

<p><em>C-nets</em> 은 <em>WF-nets</em> 으로 쉽게 변환될 수 있다. <em>WF-nets</em> 에선 <em>deadlock</em> 이 있을 수 있는 반면 <em>C-nets</em> 에선 <em>valid seq</em> 만을 논하기 때문에 <em>deadlock</em> 은 이야기 하지 않는다.</p>

<blockquote>
  <p>Valid binding seqence of <em>C-net</em> is, Valid firing sequence of <em>WF-net</em></p>
</blockquote>

<p>그리고 <em>C-net</em> 이 <em>WF-nets</em> 보다 좀 더 표현적이다. 강의에서 나온 <em>C-nets</em> 같은 경우, 무한한 수의 <code>b, c, d</code> 를 표현하면서도 <em>order</em> 가 유지되고, <code>b, c, d</code> 가 같은 수로 반복된다.</p>

<h3 id="heuristicmining">Heuristic Mining</h3>

<p>(1) Learn a dependency graph by counting freq => <strong>dependency graph</strong> <br />
(2) Learn splits and joins => <strong>C-nets</strong> <br />
(3) visualize (and convert if needed) => <strong>BPMN, etc.</strong>  </p>

<h3 id="learningdependencygraphs">Learning Dependency Graphs</h3>

<p>알파 알고리즘을 이용하면 별별 문제가 다 생기는데, 휴리스틱하게 모델을 만들면 이런 문제는 좀 피할 수 있다.</p>

<p>그리고 한 가지 더 생각해 볼 문제는</p>

<blockquote>
  <p>Freqencies matter</p>
</blockquote>

<p>무슨 말인고 하니, 빈번한 로그만 <em>valid</em> 취급하면 <em>overfitting</em> 을 피할 수 있다. 알파 알고리즘에 적용하면, 좀 빈도수가 많은 것들만 <em>valid casuality</em> 로 취급할 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-12-728.jpg?cb=1305062477'  alt="" /></p>

<p><br/></p>

<h4 id="dependencymeasure">Dependency Measure</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-15-728.jpg?cb=1305062477'  alt="" title="" />    </p>

<p><em>dependency measure</em> 값은 <code>-1 ~ 1</code> 인데, 1 에 가까울 수록 <em>casuality</em> 가 있다. 아래 그림은 <em>threshold</em> 를 넘는 <em>direct succession, casuality</em> 만 표시한 <em>dependency graph</em> 다. </p>

<p><em>threshold</em> 가 높아질 수록 그래프가 심플해진다.</p>

<p><br/></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-17-728.jpg?cb=1305062477'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-18-728.jpg?cb=1305062477'  alt="" /></p>

<p><em>dependency measure</em> <code>a =&gt; b</code> <em>direct succession</em> <code>a &gt; b</code> 값을 이용해서 <em>sequence, AND split, join, XOR join, split</em> 등의 패턴을 파악할 수 있다.</p>

<p>게다가 <code>a =&gt; a</code> 도 값을 세기 때문에 <em>loop pattern</em> 도 발견할 수 있다</p>

<h3 id="learningcnets">Learning C-nets</h3>

<p>휴리스틱 마이닝의 두번째 단계는 <em>split, join</em> 등을 파악해서 <em>C-nets</em> 을 만드는 것이다.</p>

<p>어떻게 <em>split, join</em> 을 파악할까? 자주 사용하는 두 가지 접근 법이 있다.</p>

<p>(1) <strong>Heuristics approaches:</strong> using a <strong>time window</strong> before and after each activity. By counting sets of input and output acivities the bindings can be determinded (local decision)  </p>

<p>(2) <strong>Optimization approaches:</strong> based on replay, Given a set of possible input and ouput bindings one can see whether reality can be <strong>replayed property</strong>. The set of possible input and output bindings are finite, so a "best set bindings" can be determined using some goal function.</p>

<h4 id="approach1basedonheuristics">Approach 1: Based on heuristics</h4>

<p><em>dependency graph</em> 에서 볼 수 있듯이 각 <em>activity</em> 는 가능한 <em>input, output</em> 이 있다. 얼마나 자주 나오는지 세면 된다. 이 때 어느 범위까지 셀지를 <em>window size</em> 라 부른다.</p>

<p>예를 들어 <em>window size</em> <code>= 4</code> 면</p>

<pre><code>1 ... klbg[a]dhek ...  
2 ... lkgc[a]hedl ...  
3 ... kblg[a]ehdk ...  
4 ... klgb[a]dehk ...  
5 ... klkc[a]dkeh ...  
</code></pre>

<p>이 때 <code>b, c</code> 에 대해서 <code>{b} = 3, {c} = 2</code> 다. 요게 <em>input binding</em></p>

<p><code>{d, e} = 5</code> 다. 요게 <em>output binding</em>. 이 값들을 <em>depdency graph</em> 를 표시하면 된다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-19-728.jpg?cb=1305062477'  alt="" /></p>

<p><br/></p>

<p>이걸로 끝나는것은 아니고 <em>refinement</em> 가 필요하다.</p>

<ul>
<li>What if there are no corresponding acivities in the input or output window?</li>
<li>Noise filtering (remove infreq bindings)</li>
<li>Handling repeating activities (cut off window size)</li>
<li>Details are out of scope, but be aware of such complications when interpreting result</li>
</ul>

<h4 id="approache2optimizationproblem">Approache 2: Optimization problem</h4>

<ul>
<li>Evaluate all possible acivity bindings and take best one.</li>
<li>Based on the idea that ideally a trace can be <strong>replayed from the initial input state to the final state</strong></li>
<li>This <strong>can be checked</strong> precisely using various replay approaches</li>
<li>Hence, one can use approaches that simply <strong>try bindings exhaustively</strong></li>
</ul>

<p>간단히 말해서 가능한 모든 조합을 구하고, 말이 될 만한 <em>input, output</em> 을 <strong>replay</strong> 를 통해 골라내면 된다.</p>

<p>여기서 평가 기준은 <em>fitness simplicity, precision, generalization</em> 등이다. 시간이 너무 걸린다면 <em>randomize</em>, <em>genetic algorithm</em> 등을 이용할 수 있다. (generic 이 아니고 <em>genetic</em> 이다.)</p>

<h3 id="learningtransitionsystem">Learning Transition System</h3>

<p>지금까지 모델을 만들기 위해 다음의 방법을 배웠다.</p>

<ul>
<li>Alpha algorithm</li>
<li>Heuristic mining <em>dep graph, C-net</em></li>
</ul>

<p>이번시간엔 <em>state-based regions</em> 를 배워보자.</p>

<p>(1) Learning a transition system using a state abstraction => <em>transition system</em>  </p>

<p>(2) Transform the transition system into an equivalent Petri net => <em>Petri net</em>  </p>

<p>(3) visualize (and convert if needed) => <em>BPMN, etc.</em></p>

<p>트랜지션 시스템을 학습하는 방법은, 현재 <em>state</em> 를 기준으로 <em>past, future</em> 를 보고 이 두가지를 합치면 된다. <del>말은 언제나 쉽다.</del> </p>

<p>예를 들어 <code>a b c d c d c d e ^ f a g h h h i</code> 를 기준으로, 현재 상태가 <code>^</code> 라 하면 </p>

<ul>
<li><strong>past:</strong> <code>a b c d c d c d e</code></li>
<li><strong>future:</strong> <code>f a g h h i</code></li>
</ul>

<p>여기서 <em>order</em> 는 무시하고 <em>frequency</em> 만 고려하면 <em>past</em> 는 </p>

<p><code>[a, b, c^3, d^3, e]</code> 가 된다. 만약에, 여기서 <em>time window</em> (<strong>k-tail</strong>) 를 이용하면 <code>[c, d^2, e]</code> 가 된다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-121219213521-phpapp01/95/process-mining-chapter06advancedprocessdiscoverytechniques-29-638.jpg?cb=1355974629'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-121219213521-phpapp01/95/process-mining-chapter06advancedprocessdiscoverytechniques-30-638.jpg?cb=1355974629'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-121219213521-phpapp01/95/process-mining-chapter06advancedprocessdiscoverytechniques-31-638.jpg?cb=1355974629'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-121219213521-phpapp01/95/process-mining-chapter06advancedprocessdiscoverytechniques-32-638.jpg?cb=1355974629'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-33-728.jpg?cb=1305062477'  alt="" /></p>

<h4 id="postprocessing">Postprocessing</h4>

<ul>
<li>remove <em>self-loop</em></li>
<li>imporve <em>diamond structure</em> (for missing interleavings)</li>
<li>merge <em>similar states</em> based on inputs</li>
</ul>

<h3 id="usingregionstodiscoverconcurrency">Using Regions to Discover Concurrency</h3>

<p>이제 <em>transition system</em> 을 <em>Petri net</em> 으로 변경하면 된다. </p>

<p>기본적인 아이디어는 <em>transition system</em> 의 <em>subset</em> 이 <em>Petri net</em> 의 <em>place</em> 의 해당한다는 것이다. 이는 당연한데 트랜지션 시스템에서 어떤 상태는, 이 전까지의 상태의 반영이고, 이건 <em>place</em> 다.</p>

<blockquote>
  <p>State-based regions correspond to places</p>
</blockquote>

<p><img src='http://image.slidesharecdn.com/processminingchapter06advancedprocessdiscoverytechniques-110510153227-phpapp02/95/process-mining-chapter-6-advanced-process-discoverytechniques-34-728.jpg?cb=1305062477'  alt="" /></p>

<p>이 때 <em>state-based region</em> 의 <em>enter, exit</em> 를 확인 하면 쉽게 <em>place</em> 를 만들 수 있다.</p>

<blockquote>
  <p>All states need to be reachable</p>
  
  <p>A region is a set of states, such that, if a transition <strong>exits</strong> the region, then all equally labeled trasition <strong>exit</strong> the region</p>
  
  <p>and If a transition <strong>enters</strong> the region, then all equally labeled transitions <strong>enter</strong> the region</p>
  
  <p>All events not entering or exiting the region <strong>do not cross</strong> the region</p>
</blockquote>

<p><code>n</code> 개의 <em>concurrent activity</em> 가 있으면 <code>2^n</code> 개의 <em>state</em> 가 생긴다. 이 때 몇 개의 <em>region</em> 이 생길까? </p>

<p>아무리 많아봐야 1 개의 트랜지션 라벨만 <em>crossing</em> 할 수 있으므로, <code>n</code> <em>split</em> 을 만들 수 있고 여기에 <em>empty</em> 까지 더하면 <code>2(n + 1)</code> 이다.</p>

<p>직선인 <em>petri net</em> 의 경우는 더 심각하다. 모든 <em>transition</em> 의 <em>subset</em> 이 <em>region</em> 이므로 <code>2^(n+1)</code> 이 된다. 따라서 <em>non-trivial minimal region</em> 만 포함해야 한다.</p>

<p><em>Petri net</em> 을 만드는 알고리즘은</p>

<p>(1) For each transition label in the transition system, a <strong>transition</strong> is added to the Petri net <br />
(2) The <strong>minimal non-trivial regions</strong> are computed <br />
(3) For each minimal non-trivial region in the transition system, a <strong>place</strong> is added to the Petri net. <br />
(4) The coressponding arcs are generated <br />
(5) A <strong>token</strong> is aded to each place that corresponds to a region containing the initial state</p>

<p><code>L = [&lt;a, c, d&gt;^45, &lt;b, c, e&gt;^42]</code></p>

<p>의 경우 알파 알고리즘은 <em>non directed dependency</em> 를 발견하지 못하는데, 트랜지션 시스템을 만들고, <em>state-based region</em> 을 이용하면 올바른 <em>petri net</em> 을 만들 수 있다.</p>

<h3 id="references">References</h3>

<p>(1) <a href='http://issuu.com/wmpvanderaalst/docs/procminbook?e=14081202/9829483' >Book: Process Mining</a> <br />
(2) <a href='https://d396qusza40orc.cloudfront.net/procmin/lecture_slides/22-Petri%20Nets%20%281%29.pdf' >Slide</a> <br />
(3) <strong>Process Mining: Data science in Action</strong> by Wil van der Aalst <br />
(4) <a href='http://1ambda.github.io/www.processmining.org' >www.processmining.org</a> <br />
(5) <a href='http://fluxicon.com/' >http://fluxicon.com</a> <br />
(6) <a href='http://crsouza.blogspot.kr/2009/12/performing-discriminant-power-analysis.html' >Confusion matrix</a> <br />
(7) <a href='http://en.wikipedia.org/wiki/Business_Process_Model_and_Notation' #mediaviewer/File:BPMN_gateway_types.png">Wikipedia - BPMN</a> <br />
(8) <a href='http://tynerblain.com/blog/2006/07/27/bpmn-gateways/' >BPMN Gateway</a> <br />
(9) <a href='http://www.ijmijournal.com/' >http://www.ijmijournal.com</a></p>]]></description><link>http://1ambda.github.io/process-mining-week3/</link><guid isPermaLink="false">43e49375-88bc-4ec0-aff0-93f098b34d10</guid><category><![CDATA[coursera]]></category><category><![CDATA[process mining]]></category><category><![CDATA[BPMN]]></category><category><![CDATA[dependency graph]]></category><category><![CDATA[C-nets]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 09 Dec 2014 10:44:29 GMT</pubDate></item><item><title><![CDATA[Intro to Computational Thinking and Data Science 4]]></title><description><![CDATA[<p>그래프는 네트워크를 표현하는 것 뿐만 아니라, <em>state</em> 를 표현할 수 있다.</p>

<ul>
<li>Nodes represent states of system</li>
<li>Edges represent actions that cause a change of state</li>
</ul>

<p>그러면 그래프 문제는 </p>

<ul>
<li>Finding sequence of actions to convert system to desired state</li>
</ul>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/8puzzle_example.svg/2000px-8puzzle_example.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<p><em>8 puzzle</em> 도 이렇게 그래프 문제로 변환할 수 있다. 그런데, <code>9! = 362880</code> 의 <em>node</em> 와 노드당 <code>2~4</code> 개의 <em>edge</em> 를 가지고 있으므로 문제의 사이즈가 어마어마하게 커진다. 거의 백만개의 <em>edge</em> 를 가진다.</p>

<h3 id="animplicitgraph">An Implicit Graph</h3>

<p>그래서, 처음부터 모든 <em>state</em> 를 만들기 보다는 초기 상태로부터 <em>action</em> 을 취해가면서 <em>desired state</em> 를 찾는 방식으로 해결하자.</p>

<p>퍼즐의 상태를 문자열로 표현하면</p>

<pre><code class="python">class puzzle(object):  
    def __init__(self, order):
        self.label = order

        for i in range(9):
            if order[i] == '0':
                self.spot = i
                return None

    def transition(self, to):
        currentLabel = self.label
        blank = self.spot
        # current slot value which will be filled with blank
        current = str(currentLabel[to]) 
        nextLabel = ''

        for i in range(9):
            if i == to:
                nextLabel += '0'
            elif i == blank:
                nextLabel += current
            else:
                nextLabel += str(currentLabel[i])

        return puzzle(nextLabel)

    def __str__(self):
        return "{0} {1} {2}\n{3} {4} {5}\n{6} {7} {8}\n".format(self.label[0],
                                                                self.label[1],
                                                                self.label[2],
                                                                self.label[3],
                                                                self.label[4],
                                                                self.label[5],
                                                                self.label[6],
                                                                self.label[7],
                                                                self.label[8])
</code></pre>

<p>그리고 각 슬롯의 이동 가능한 방향을 딕셔너리로 만들면</p>

<pre><code class="python">shiftDict = {}  
shiftDict[0] = [1, 3]  
shiftDict[1] = [0, 2, 4]  
shiftDict[2] = [1, 5]  
shiftDict[3] = [0, 4, 6]  
shiftDict[4] = [1, 3, 5, 7]  
shiftDict[5] = [2, 4, 8]  
shiftDict[6] = [3, 7]  
shiftDict[7] = [4, 6, 8]  
shiftDict[8] = [5, 7]  
</code></pre>

<p>이제 <em>state</em> 를 변경해 나아가면서 그래프를 만들 수 있다 <em>state</em>, 즉 <em>node</em> 를 변경해 나아가면서 그래프를 탐색하는 방법은 2개가 있는데, <em>BFS, DFS</em> 다. 코드는 거의 유사하다. 스택을 쓰냐 큐를 쓰냐의 차이다.</p>

<pre><code class="python">def notInPath(state, path):  
    for s in path:
        if s.label == state.label:
            return False

    return True


def BFS(start, end, q=[]):  
    initPath = [start]
    q.append(initPath)

    while len(q) != 0:
        currentPath = q.pop(0)
        lastState = currentPath[len(currentPath) - 1]

        if lastState.label == end.label:
            return currentPath

        for s in shifts[lastState.spot]:
            nextState = lastState.transition(s)

            if notInPath(nextState, currentPath):
                nextPath = currentPath + [nextState]
                q.append(nextPath)

    return None


def DFS(start, end, stack=[]):  
    initPath = [start]
    stack.insert(0, initPath)

    while len(stack) != 0:
        currentPath = stack.pop(0)
        lastState = currentPath[len(currentPath) - 1]

        if lastState.label == end.label:
            return currentPath

        for s in shifts[lastState.spot]:
            nextState = lastState.transition(s)

            if notInPath(nextState, currentPath):
                nextPath = currentPath + [nextState]
                stack.insert(0, nextPath)

    return None
</code></pre>

<p>테스트는</p>

<pre><code class="python">def test():  
    goal = puzzle('012345678')
    test1 = puzzle('125638047')
    answer = BFS(test1, goal)

    for state in answer:
        print state
</code></pre>

<p>비교해 보면 <em>BFS</em> 가 훨씬 빠르다.</p>

<h3 id="maximumcliques">Maximum Cliques</h3>

<blockquote>
  <p>For some problems, finding sugraphs of a graph that are complete can be important</p>
</blockquote>

<p>여기서 <em>complete</em> 란 노드가 다른 노드 모두와 연결되어 있다는 뜻이다.</p>

<ul>
<li>Finding sets of people in a social network that all know each other</li>
<li>Finin subjects in an infected population that all have had contact with one another</li>
</ul>

<p>두 번째 예제는 <em>complete subgraph</em> 를 찾는 것의 중요성을 잘 보여준다.</p>

<p><em>clique</em> 는 communication networks, gene expression data 등에도 이용할 수 있다.</p>

<h4 id="bruteforce">Brute Force</h4>

<p><em>maximum clique</em> 문제를 <em>brute force</em> 로 풀려면, 가능한 모든 서브 그래프를 찾고, <em>clique</em> 인지 판별하면서 큰 사이즈의 <em>clique</em> 를 유지하면 된다.</p>

<p>모든 서브 그래프를 찾을려면, <a href='http://1ambda.github.io/edx-600-2x-3/' >지난시간</a> 에 <em>knapsack problem</em> 을 풀 때 이용했던 <em>power set</em> 을 도입하면 된다.</p>

<p><em>knapsack</em> 문제도 <em>brute force</em> 로 풀기 위해서 가능한 모든 집합을 구했었다. 후에는 <em>search space</em> 를 줄이기 위해 <em>decision tree</em> 를 도입하고, 반복 계산을 피하기 위해 <em>memoization</em> 이용했었다.</p>

<p><em>clique</em> 문제도 마찬가지로 각 노드를 숫자로 표현할 수 있으므로 <code>n</code> 자리의 이진수를 만들어 <em>power set</em> 을 생성할 수 있다. 지난 시간에 이용했었던 대강의 로직은 </p>

<pre><code class="python">count = 2 ** len(nodes)

binStrs = []

for i in range(count):  
  binStrs.append(int2bin(i, len(nodes))

powerSet = []

for bs in binStrs:  
  subGraph = []

  for i range(len(bs)):
    if bs[i] == '1':
      subGraph.append(nodes[i])

  powerSet.append(subGraph)

return powerSet  
</code></pre>

<p>이번시간엔 재귀를 이용해서 <em>power set</em> 을 구해보자. 하스켈로 로직을 표현하면,</p>

<pre><code class="haskell">powerset [] = [[]]  
powerset (x:xs) = xs' ++ map (x:) xs'  
  where xs' = powerset xs
</code></pre>

<p>따라서 파이선 코드는</p>

<pre><code class="python">def powerSet(xs):  
    if len(xs) == 0:
        return [[]]

    else:
        # xs = head:tail
        head = xs[0]
        tail = xs[1:]

        prev = powerSet(tail)
        incl = map(lambda sub: sub + [head], prev)
        return prev + incl
</code></pre>

<p>이걸 이용해 모든 <em>sub graph</em> 를 만들고, <em>clique</em> 인지 검사하는 함수를 만들면</p>

<pre><code class="python">def powerGraph(graph):  
    nodes = []

    for n in graph.nodes:
        nodes.append(n)

    pSet = powerSet(nodes)
    return pSet


def isClique(graph, subGraph):  
    for n in subGraph:
        for m in subGraph:
            if not m == n:
                if n not in graph.childrenOf(m):
                    return False

    return True


def maxClique(graph):  
    maximum = None
    maxLen = 0
    subGraphs = powerGraph(graph)

    for sub in subGraphs:
        if isClique(graph, sub):
            if len(sub) &gt; maxLen:
                maximum = sub
                maxLen = len(sub)

    return maximum
</code></pre>

<p><a href='https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/clique.py' >지난시간에 작성했던 Graph 코드</a> 는 여기로, </p>

<p>테스트 코드는 </p>

<pre><code class="python">def testGraph():  
    nodes = []
    for name in range(5):
        nodes.append(Node(str(name)))
    g = Graph()
    for n in nodes:
        g.addNode(n)
    g.addEdge(Edge(nodes[0],nodes[1]))
    g.addEdge(Edge(nodes[1],nodes[2]))
    g.addEdge(Edge(nodes[2],nodes[0]))
    g.addEdge(Edge(nodes[2],nodes[4]))
    g.addEdge(Edge(nodes[4],nodes[3]))
    return g


trialGraph = testGraph()  
myClique = maxClique(trialGraph)  
</code></pre>

<p><code>myClique</code> 를 출력하면, <em>node</em> 가 3개 나와야 한다.</p>

<h3 id="machinelearning">Machine Learning</h3>

<blockquote>
  <p><strong>Automating automation</strong></p>
  
  <p>Computer programs can automatically follow rules. <br />
  How do we determine these rules automatically?</p>
  
  <p><strong>ML fources on getting computers to program themselves</strong></p>
  
  <p>Let the data do the work. <br />
  Automatically generate programs that create useful outputs from data</p>
</blockquote>

<p>전통적인 프로그래밍에선 <em>data</em> 와 <em>program</em> 을 넣고 <em>output</em> 을 기대했다면, </p>

<p><em>machine learning</em> 에서는 <em>data, output</em>  을 넣고 <em>program</em> 을 만든다. 이 프로그램은 다음번에 <em>data</em> 가 들어왔을 때 <em>output</em> 을 만들어 낸다. 다시 말해서 머신러닝은 일종의 <em>generalization</em> 이다.</p>

<blockquote>
  <p><strong>Supervised</strong></p>
  
  <p>Given a set of feature/label pairs, find a rule that predicts the label associated with a previously unseen input</p>
  
  <p><strong>Unsupervied</strong></p>
  
  <p>Given a set of feature vectors (without labels), group them into "natural clusters"</p>
</blockquote>

<p>예를 들어 다음은 <em>supervised learning</em> 이다.</p>

<blockquote>
  <p>A group of 1000 students are asked for a sample of their handwriting. Researchers make pairs of (handwritten text, typed text). Given a new handwriting sample from a new student, we want to determine what the typed version of the handwriting sample would be.</p>
</blockquote>

<h3 id="clustering">Clustering</h3>

<ul>
<li>Low intra-cluster dissimilarity</li>
<li>High inter-cluster dissimilarity</li>
</ul>

<p>간단하긴 한데, 연산 비용이 비싸다. <em>k-means</em> 와 <em>hierarchical clustering</em> 을 살펴보자.</p>

<h4 id="hierarchicalclustering">Hierarchical Clustering</h4>

<p>(1) Start by assigning each item to a cluster, so that if you have <code>N</code> items, you now have <code>N</code> clusters, each containing just one item.</p>

<p>(2) Find the closest (most similar) pair of clusters and merge them into a single cluster, so that now you have one cluster fewer.</p>

<p>(3) Continue the process until all items are clustered into a single cluster of size <code>N</code></p>

<p><img src='http://www.alanfielding.co.uk/multivar/images/dend5.gif'  alt="" /></p>

<p align="center">(<a href='http://www.alanfielding.co.uk/' >http://www.alanfielding.co.uk</a>)</p>

<blockquote>
  <p><strong>Linkage Criteria</strong></p>
  
  <p>in <strong>single-linkage</strong> clustering (also called the <em>connectedness</em> or <em>minimum</em> method), we consider the distance between one cluster and another cluster to be equal to the shortest distance from any member of one cluster to any member of th other cluster</p>
  
  <p>in <strong>complete-linkage</strong> clustering (also called the <em>diameter</em> or <em>maximum</em> method), we consider the distance between one cluster and another cluster to be equal to th greatest distance from any member of one cluster to any member of the other cluster</p>
  
  <p>in <strong>average-linkage</strong>, we consider the distance between one cluster and another cluster to be equal to th average distance from any member of one cluster to any member of the other cluster. A slight variant of this uses the median instead of the mean</p>
</blockquote>

<p><em>single-linkage</em> 클러스터 간 거리를 두 클러스터 사이의 최소 거리로, <em>complete-linkage</em> 는 최대 거리로, <em>average-linkage</em> 는 평균 거리로 본다.</p>

<pre><code class="python">    def singleLinkageDist(self, other):
        """ Returns the float distance between the points that 
        are closest to each other, where one point is from 
        self and the other point is from other. Uses the 
        Euclidean dist between 2 points, defined in Point."""
        minDist = float("inf")
        for p1 in self.points:
            for p2 in other.points:
                dist = p1.distance(p2)
                if dist &lt; minDist:
                    minDist = dist

        return minDist

    def maxLinkageDist(self, other):
        """ Returns the float distance between the points that 
        are farthest from each other, where one point is from 
        self and the other point is from other. Uses the 
        Euclidean dist between 2 points, defined in Point."""
        maxDist = float(0)
        for p1 in self.points:
            for p2 in other.points:
                dist = p1.distance(p2)
                if dist &gt; maxDist:
                    maxDist = dist

        return maxDist

    def averageLinkageDist(self, other):
        """ Returns the float average (mean) distance between all 
        pairs of points, where one point is from self and the 
        other point is from other. Uses the Euclidean dist 
        between 2 points, defined in Point."""
        dists = []
        for p1 in self.points:
            for p2 in other.points:
                dists.append(p2.distance(p1))

        return sum(dists) / float(len(dists))
</code></pre>

<h3 id="kmeansclustering">K-Means Clustering</h3>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum_%7Bc%3D1%7D%5EK%20%5Csum_%7Bx%5C%20%5Cin%5C%20c%7D%20%5Cleft%20%5C%7C%20x%20-%20%5Cmu_c%20%5Cright%20%5C%7C%5E2'  alt="" /></p>

<ul>
<li>Final result can depend upon initial centroids</li>
<li>Greedy algorihm can find different local optima</li>
<li>Choosing the <em>wrong</em> <code>K</code> can lead to nonsense</li>
</ul>

<p>따라서</p>

<ul>
<li>Use priori knowledge about application domain</li>
<li>Try multiple times</li>
</ul>

<p><em>hierarchical</em> 과 비교하면</p>

<blockquote>
  <p>Hierarchical looks at different numbers of clusters From 1 to n</p>
  
  <p>K-means looks at many ways of createing k clusters.</p>
</blockquote>

<p><em>hierarchical</em> 은 좀 느린편이고 <em>deterministic</em> 이다. 반면 <em>K-means</em> 는 비교적 빠르고, <em>stochastic</em> 이다.</p>

<p>아래는 <em>K-means</em> 로 분류하기 어려운 몇 가지 예제들</p>

<p><img src='https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/k1.png'  alt="" /></p>

<p><img src='https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/k3.png'  alt="" /></p>

<p align="center">(<a href='https://courses.edx.org/c4x/MITx/6.00.2_2x' >https://courses.edx.org/c4x/MITx/6.00.2_2x</a>)</p>

<h3 id="scaling">Scaling</h3>

<p><em>odd ratio</em> 는 <em>acutal / expected</em> 값인데, 1에 가까우면 클러스터링이 랜덤에 비해 별로 나을게 없다는 소리다. (좋은 클러스터링이 아니란 뜻)</p>

<p>강의에서 나온 환자 예제는 이 값이 1에 근접하는데, 이는 <em>HR, age</em> 값이 단위가 커서 이 <em>feature</em> 에 영향을 많이 받기 때문이다.</p>

<p>따라서 평균 0, 표준편차 1을 가지도록 모든 <em>feature</em> 를 스케일링 하고 다시 돌리면  <em>odd ratio</em> <code>0.18, 1.45</code> 의 두 클러스터를 얻을 수 있다. 하나는 <em>heart attack</em> 이 잘 안올 환자, 다른 하나는 위험한 환자.</p>

<p>아래 예제는 스케일링 하면 안되는 경우</p>

<blockquote>
  <p>The percent concentration of a virus in a random sampling of healthy and unhealthy people.</p>
  
  <p>The angle of refraction of light (degree that light bends) observed when entering water vs. glass vs a diamond.</p>
</blockquote>

<h3 id="statisticalfallacies">Statistical Fallacies</h3>

<p>세상에는 3 종류의 거짓말이 있다고 한다.</p>

<ul>
<li>LIES</li>
<li>DAMNED LIES</li>
<li><strong>STATISTICS</strong></li>
</ul>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/638px-Anscombe%27s_quartet_3.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Anscombe' s_quartet'>http://en.wikipedia.org/wiki/Anscombe's_quartet</a>)</p>

<p>보면 데이터가 정말 다르게 분포해 있지만, <em>mean, variance, correlation, linear regression</em> 이 동일하다.</p>

<p>흔한 오류 중 하나로, <em>correlation => causation</em> 도 있다. </p>

<p>학교가 문을 여는 시즌에, 독감이 많이 유행한다고 해서 상관 관계가 있다고 단정짓긴 어렵다. 어쩌면 다른 요인이 있을지도 모른다.</p>

<p><em>non response bias</em> 도 생각해봐야 한다. 예를 들어 전화조사에서, 응답자와 비응답자의 정치 성향이 다를 수도 있다는 것이다.</p>

<h3 id="dataenhancement">Data Enhancement</h3>

<p><em>texas sharpshotter fallacy (텍사스 명사수의 오류)</em> 란 것도 있다. <a href='http://en.wikipedia.org/wiki/Texas_sharpshooter_fallacy' >위키</a> 에서 인용하면</p>

<blockquote>
  <p>The Texas sharpshooter fallacy is an informal fallacy which is committed when differences in data are ignored, but similarities are stressed.</p>
</blockquote>

<p>텍사스의 총잡이가 헛간에 총을 마구마구 쏜 후, 밀집한 지역 중심으로 원을 그리면! 그 총잡이는 명사수처럼 보이게 된다는 것에서 유래한 오류다.</p>

<p>바꿔 말하면, 우연도 필연으로 해석한다는 것이다. (존재하지도 않는 패턴을 찾으려고 하는것에 비유하기도 함)</p>

<h3 id="references">References</h3>

<p>(1) <em>MIT 6.00.2 2x</em> in <strong>edx</strong> <br />
(2) <a href='http://en.wikipedia.org/wiki/Heuristic_function' >Wikipedia: Huristic Function</a> <br />
(3) <a href='http://www.alanfielding.co.uk/multivar/dend.htm' >http://www.alanfielding.co.uk</a> <br />
(4) <a href='http://en.wikipedia.org/wiki/Anscombe' s_quartet">Wikipedia - Anscombe's quartet</a></p>]]></description><link>http://1ambda.github.io/edx-600-2x-4/</link><guid isPermaLink="false">a07909c0-49d7-4a0a-9dd8-5e52550b331f</guid><category><![CDATA[edx]]></category><category><![CDATA[python]]></category><category><![CDATA[graph]]></category><category><![CDATA[hierarchical clustering]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 09 Dec 2014 03:23:13 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 9]]></title><description><![CDATA[<p>이번시간엔 <em>anomaly detection</em> 과 <em>recommender system</em> 을 배운다.</p>

<h3 id="anomalydectection">Anomaly Dectection</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236753_7590.png'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236757_2205.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>anomaly</em> 는 정상집단에서 떨어진 데이터라 보면 된다. 공장에서 품질이 떨어지는 제품을 골라낼때 사용할 수 있는데, 위 그림은 비행기 엔진 공장을 예로 들어 설명한다.</p>

<p>데이터로부터 <code>p(x)</code> 를 만들어, 검사할 데이터가 <em>threshold</em> 를 넘는지 안넘는지 검사해 <em>anomaly</em> 로 판정할 수 있다.</p>

<p>참고로, <em>anomaly</em> 가 너무 많으면, <em>false positive</em> 가 높은 것인데 이 때는  <em>threshold</em> 를 줄이면 된다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236761_2830.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>anomaly detection</em> 은 <em>fraud detection</em> 에 많이 사용된다. 데이터로부터 모델 <code>p(x)</code> 를 만들고 <em>unusual user</em> 를 검사하기 위해 <code>p(x) &lt; e</code> 인지 검사하면 된다.</p>

<p>이외에도 항공기 엔진 예제처럼 제품의 품질 관리나, 데이터 센터에서의 노드 과부하 탐지등에 사용할 수 있다.</p>

<h3 id="gaussiandistribution">Gaussian Distribution</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236829_8964.png'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236829_8964.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>gaussian density</em> 공식은</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%28x%3B%20%5Cmu%2C%20%5Csigma%5E2%29%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20%5Cexp%28-%20%7B%28x%20-%20%5Cmu%29%5E2%20%5Cover%202%5Csigma%5E2%7D%29'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236839_1788.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>평균과 분산은</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cmu%20%3D%20%7B1%20%5Cover%20m%7D%20%5C%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x%5E%7B%28i%29%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csigma%5E2%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29'  alt="" /></p>

<p><br/></p>

<h3 id="anomalydetectionalgorithm">Anomaly Detection Algorithm</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236899_7015.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>각 <em>feature</em> 가 가우시안 분포를 따른다고 하면, </p>

<p><img src='http://latex.codecogs.com/gif.latex?p%28x%29%20%5C%5C%20%5C%5C%20%3D%20p%28x_1%3B%20%5Cmu_1%2C%20%5Csigma_1%5E2%29%5C%20p%28x_2%3B%20%5Cmu_2%2C%20%5Csigma_1%5E2%29%20%5Ccdots%5C%20p%28x_n%3B%20%5Cmu_n%2C%20%5Csigma_1%5En%29%20%5C%5C%20%5C%5C%20%3D%20%5Cprod_%7Bj%20%3D%201%7D%5En%20p%28x_j%3B%20%5Cmu_j%2C%20%5Csigma_j%5E2%29'  alt="" /></p>

<p>이렇게 가정하려면, 각 <em>feature</em> 가 독립적이어야 하지만 실제로는 독립적이지 않더라도 어느정도 동작한다. 이 때 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cmu_j%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x_j%5E%7B%28i%29%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csigma_j%5E2%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%7B%28x_j%5E%7B%28i%29%7D%20-%20%5Cmu_j%29%5E2%7D'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236904_6921.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>따라서 <code>p(x)</code> 는 아래 식이 된다. <code>p(x)</code> 는 <em>feature</em> 가 나올 확률로 이해하면 된다. 이 때 <code>p(x)</code> 가 상당히 작으면, 평균에 가깝지 않은 <em>feature</em> 가 많이 나왔다는 뜻이므로 <em>anomaly</em> 라 볼 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?p%28x%29%20%5C%5C%20%5C%5C%20%3D%20%5Cprod_%7Bj%3D1%7D%5En%20%5C%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma_j%5E2%7D%7D%20%5C%20%5Cexp%28-%7B%28x_j%20-%20%5Cmu_j%29%5E2%20%5Cover%202%5Csigma_j%5E2%7D%29'  alt="" /></p>

<p><br/></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236907_7102.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>두 <em>feature</em> <code>x1, x2</code> 의 가우시안 분포를 3차원으로 조합하면 <code>p(x)</code> 가 좌측 하단 3차원 원뿔의 높이가 된다.</p>

<h3 id="evaluatinganomalydetection">Evaluating Anomaly Detection</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236992_3664.png'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236996_4034.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>anomaly</em> 를 잘 나타낼거 같은 <em>feature</em> 를 골라내고, 이를 이용해 모델을 만든다. </p>

<p>우리가 가진 데이터가 <em>anomaly</em> 를 알려주는 <code>y</code> 가 있다면, 위 그림처럼 <em>training set</em> 으로 <em>non-anomalous</em> 을 이용하고, <em>CV, Test Set</em> 으로 나머지를 반반씩 분할하면 된다.</p>

<p>즉 <em>good example</em> 로 모델을 만들고, <em>anomaly</em> 가 섞여있는 <em>cv, test set</em> 으로 평가한다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361237001_5250.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>이 때 <em>skewed classess</em> 이기 때문에 (<code>y = 0</code> 이 대다수, <code>y = 1</code> 은 희박) 단순히 정확도로 평가하긴 좀 무리가 있다. <em>precision, recall, f1 score</em> 등을 이용해 평가해야 한다.</p>

<p><em>threshold</em> 인 <code>e</code> (엡실론) 를 고르기 위해 <em>cross validation</em> 을 이용할 수 있다. <em>f1 score</em> 를 최대화 하는 <code>e</code> 를 고른다거나.</p>

<h3 id="anomalydectectionvssupervisedlearning">Anomaly Dectection vs Supervised Learning</h3>

<p><code>y</code> 값이 있는 데이터라면, 왜 <em>supervised learning</em> 을 이용하지 않을까? </p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361242897_8389.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<h4 id="anomalydetection">Anomaly Detection</h4>

<p><em>anomaly detection</em> <em>skewed class</em> 가 있을 때 사용한다.</p>

<blockquote>
  <p>Many different <strong>types</strong> of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like</p>
  
  <p>Future anomalies may look nothing like any of the anomalous examples we've seen so far</p>
</blockquote>

<p>보면 알겠지만 <em>anomaly</em> 가 굉장히 다양할 수 있기 때문에 <em>anomaly</em> 를 특정 형태로 구분짓는 알고리즘을 쓰긴 좀 힘들다.</p>

<p>게다가, 가지고 있는 데이터 셋에서 보지 못했던 새로운 종류의 <em>anomaly</em> 가 나올 수도 있다.</p>

<h4 id="supervisedlearning">Supervised Learning</h4>

<p><em>positive, negative example</em> 이 많을 때 사용한다.</p>

<blockquote>
  <p>Enough positive examples for algorithms to get a sense of what positive examples are like, futre positive example likly to be similar to ones in training set</p>
</blockquote>

<p><em>supervised learning</em> 에서 <em>positive example</em> 은 어떤 특정 형태기 때문에, 미래에 발견할 <em>positive example</em> 도 비슷한 형태라 생각될 때 사용한다.</p>

<p><em>SPAM filtering</em> 에서는 다양한 타입의 <em>positive example</em> 이 있어도, 우리가 충분한 양의 <em>positive example</em> 이 있기 때문에 커버할 수 있어 <em>supervised learning</em> 을 사용한다.</p>

<p><br/></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361243087_2169.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><br/></p>

<h3 id="choosingwhatfeaturestouse">Choosing What Features to Use</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361244210_3429.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>feature</em> 의 분포가 가우시안이면 고맙지만, 아닐경우 변환이 필요하다. 왼쪽 아래 분포에 로그를 씌우면, 가우시안 분포 비슷하게 보인다.</p>

<p>다른 방법으로는 <code>log(x_2 + c)</code>, <code>sqrt(x_3)</code> 등등이 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361245473_5316.png'  alt="" /></p>

<p>흔한 에러는 <code>p(x)</code> 가 <em>normal, anomalous</em> 에 대해서 모두 높은 경우인데, 슬라이드의 아래쪽에서 볼 수 있듯이 <code>x2</code> 라는 <em>feature</em> 를 만들어서 <em>anomaly</em> 를 발견하는 알고리즘을 만들 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361246077_9679.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>anomaly</em> 를 위한 <em>feature</em> 를 고를 때 특이하게 높거나, 낮을 수 있는 것을 고르면 된다. 데이터 센터 예제에서는 <em>CPU load / network traffic</em> 등이 있을 수 있다. 네트워크 트래픽이 낮은데 <em>CPU load</em> 가 높다면 확실히 <em>anomaly</em> 기 때문이다.</p>

<h3 id="multivariategaussiandistribution">Multivariate Gaussian Distribution</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361257865_7961.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>feature</em> 를 <em>CPU laod, memory use</em> 로 했을 때 낮은 CPU 부하에도 메모리 사용량이 높으면 <em>anomaly</em> 라 볼 수 있다.</p>

<p>그런데, 슬라이드의 왼쪽 그림에서 녹색으로 표시한 <em>anomaly</em> 는 지금까지 설명했던 알고리즘으로 찾기가 힘들다. 적당한 수준의 <em>memory use</em> 와 그리 낮지 않은 <em>cpu load</em> 를 가지기 때문이다.</p>

<p>실제 <em>normal example</em> 이 타원형이기 때문에, 원으로 <em>anomaly</em> 를 찾기는 어렵다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361258533_5107.png'  alt="" /></p>

<p>따라서 <code>p(x_1)p(x_2)...</code> 을 이용한 모델 말고 다른 방법으로 모델을 만들어야 한다. </p>

<p><code>u</code> 를 <code>n</code> 벡터라 하고, <code>Sigma</code> 를 <code>u</code> 의 <em>convariance matrix</em> 라 하자. 그러면</p>

<p><img src='http://latex.codecogs.com/gif.latex?p%28x%3B%20%5Cmu%2C%20%5CSigma%29%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%20%282%5Cpi%29%5E%7Bn/2%7D%20%5C%20%7C%5CSigma%7C%5E%7B1/2%7D%7D%20%5C%20%5Cexp%28-%7B1%5Cover%202%7D%28x%20-%20%5Cmu%29%5ET%20%5C%20%5CSigma%5E%7B-1%7D%28x%20-%20%5Cmu%29%29'  alt="" /></p>

<p>여기서 <code>|Sigma|</code> 는 <code>Sigma</code> 의 행렬식인데, 여기를 참고하자.</p>

<ul>
<li><a href='http://ghebook.blogspot.com/2011/06/matrix.html' >행렬</a></li>
<li><a href='http://ghebook.blogspot.com/2011/06/determinant.html' >행렬식</a></li>
<li><a href='http://ghebook.blogspot.kr/2011/06/geometric-meaning-of-determinant.html' >행렬식의 기하학적 의미</a></li>
<li><a href='http://darkpgmr.tistory.com/104' >행렬식과 기하학적 활용</a></li>
</ul>

<p>이제 위 식을 이용해서 나온 <code>p(x)</code> 를 3차원, 2차원으로 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259228_7695.png'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259243_2967.png'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259236_1052.png'  alt="" /></p>

<p><br/></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259583_5151.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cmu%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x%5E%7B%28i%29%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5CSigma%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%20%5C%20%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29%5ET'  alt="" /></p>

<p><br/></p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361259728_6035.png'  alt="" /></p>

<p><code>u, Sigma</code> 를 찾아 <code>p(x)</code> 를 만들고, 테스트 데이터에 대해 <code>p(x) &lt; e</code> 인지 비교한다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361260300_1768.png'  alt="" /></p>

<p><em>original model</em> 은 <em>multivariate model</em> 에서 각 <em>feature</em> 간 상관 관계가 없는 (독립), 즉 <em>covariance matrix</em> 가 <em>diagonal matrix</em> 인 경우다. (</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361260755_3407.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<ul>
<li><strong>Original model</strong></li>
</ul>

<p>수동으로 <em>feature</em> 를 만들때 사용할 수 있다. 또는 적은 연산을 원할때, 다시 말해서 <code>n</code> 이 커서 연산이 무지막지하게 클 때 좋다.</p>

<p><code>m</code> 이 작아도 쓸 수 있다.</p>

<ul>
<li><strong>Multivariate Gaussian</strong></li>
</ul>

<p>계산 비용이 비싸지만, 자동으로 <em>feature</em> 간 상관관계를 모델에 포함시킨다.</p>

<p><code>Sigma</code> 가 <em>invertible</em> 이기 위해서는 <code>m &gt; n</code> 이어야 한다. 실제로는 <code>m</code> 이 <code>n</code> 보다 훨씬 클 때 사용하는 경우가 많다. (e.g. <code>m &gt;= 10n</code>)</p>

<p>만약에 <code>m &gt; n</code> 인데, <code>Sigma</code> 가 <em>non-invertible</em> 이면 <em>redundant feature</em> 가 있는 경우니 확인해 보자. (흔한 오류라고 함)</p>

<h3 id="recommendersystem">Recommender System</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361324993_7588.png'  alt="" /></p>

<h3 id="contentbasedrecommendations">Content Based Recommendations</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361325560_4034.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>위 슬라이드는 유저 <code>j</code> 로 부터 <code>theta^(j)</code> 를 얻어, <em>feature</em> <code>x</code> 와 곱함으로써 <em>linear regression</em> 문제로 변경했다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361326084_2070.png'  alt="" /></p>

<p><code>theta^(j)</code> 는 어떻게 훈련시킬까?</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%7D%20%5C%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%7B1%20%5Cover%202m%5E%7B%28j%29%7D%7D%5C%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202m%5E%7B%28j%29%7D%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2'  alt="" /></p>

<p>여기서 <code>m^(j)</code> 는 유저 <code>j</code> 에 의해 점수를 받은 영화의 수인데, 어차피 상수이므로 제거하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%7D%20%5C%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%7B1%20%5Cover%202%7D%5C%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361326247_4648.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>이 때 각 유저마다의 <code>theta(j)</code> 를 합 해 최소화 시키는 방식으로 전체 <code>theta</code> 를 훈련시킬 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%2C%20%5Ccdots%20%5Ctheta%5E%7B%28n_u%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361326573_9477.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>gradient descent</em> 는</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28j%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28j%29%7D%20-%20%5Calpha%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%20%28%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%29x_k%5E%7B%28i%29%7D%20%5C%20%28for%5C%20k%20%3D%200%29'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28j%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28j%29%7D%20-%20%5Calpha%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%20%28%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%29x_k%5E%7B%28i%29%7D%20&plus;%20%5Clambda%5Ctheta_k%5E%7B%28j%29%7D%5C%20%28for%5C%20k%20%5Cneq%200%29'  alt="" /></p>

<h3 id="collaborativefiltering">Collaborative Filtering</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361327928_4438.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>content-based recommendation</em> 에서 <em>feature</em> 를 구하긴 사실 어려운 일이다. 누가 이 영화가 얼마만큼 로맨스고, 아닌지를 판별해줄까? </p>

<p>문제를 좀 변경해서, 만약에 유저로부터 <code>theta(j)</code> 를 얻어낼 수 있다면 그 정보로 부터 <em>feature</em> <code>x(i)</code> 를 추출할 수 있다. 왜냐하면 <code>(\theta^(j))^T * x^(i) ~ y^(i, j)</code> 이기 때문이다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361328443_4320.png'  alt="" /></p>

<p><code>x^(i)</code> 를 얻기 위해, </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7Bx%5E%7B%28j%29%7D%2C%20%5Ccdots%20x%5E%7B%28n_m%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%20%5Csum_%7Bi%3A%20%5C%20r%28i%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%5Csum_%7Bk%3D1%7D%5En%28x_k%5E%7B%28i%29%7D%29%5E2'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/20/1361330430_7394.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<ul>
<li><code>theta</code> 가 주어지면 <code>x</code> 를 훈련할 수 있고</li>
<li><code>x</code> 가 주어지면 <code>theta</code> 를 훈련할 수 있다.</li>
</ul>

<p>따라서 최초의 랜덤 <code>theta</code> 에 대해 <code>x</code> 를 훈련하고, 다시 <code>theta</code> 를 훈련하고, 반복하면 된다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361495687_3476.jpg'  alt="" /></p>

<p><code>theta</code> 와 <code>x</code> 를 반복해서 훈련시키는 것보다, 동시에 훈련시키는 것이 좀 더 효율적이다. 따라서</p>

<p><img src='http://latex.codecogs.com/gif.latex?J%28%7Bx%5E%7B%28j%29%7D%2C%20%5Ccdots%20x%5E%7B%28n_m%29%7D%2C%20%5Ctheta%5E%7B%28i%29%7D%2C%20%5Ccdots%20%5Ctheta%5E%7B%28n_u%29%7D%7D%29%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7B%28i%2C%20j%29%3A%20%5C%20r%28i%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%5Csum_%7Bk%3D1%7D%5En%28x_k%5E%7B%28i%29%7D%29%5E2%20&plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2'  alt="" /></p>

<p>를 최소화 시키면 된다. 참고로 <code>x_0</code> 은 <em>collaborative filtering</em> 에서 필요가 없다. 알고리즘 자체가 <em>feature</em> 를 직접 찾아내니 <em>hard coded</em> 된 <em>feature</em> 는 사용하지 않는다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361495692_7530.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p>(1) <code>x</code>, <code>theta</code> 를 작은 값으로 초기화 한다.</p>

<p>이는 <em>symmetry breaking</em> 을 하기 위함이다. 작은 랜덤값들로 초기화 하여 <code>x^(i)</code> 가 서로 다른 값들을 가지도록 도와준다.</p>

<p>(2) <em>cost function</em> <code>J</code> 를 <em>gradient descent</em> 등으로 최소화 시킨다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?x_k%5E%7B%28i%29%7D%20%3A%3D%20x_k%5E%7B%28i%29%7D%20-%20%5Calpha%20%5Csum_%7Bj%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5Ctheta_k%5E%7B%28j%29%7D%20&plus;%20%5Clambda%20x_k%5E%7B%28i%29%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28i%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28i%29%7D%20-%20%5Calpha%20%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5Cx_k%5E%7B%28i%29%7D%20&plus;%20%5Clambda%20%5Ctheta_k%5E%7B%28j%29%7D'  alt="" /></p>

<p>(3) 유저의 <em>parameter</em> <code>theta</code> 와 영화의 <em>feature</em> <code>x</code> 에 대해 <code>theta^T * x</code> 를 이용해 예측하면 된다.</p>

<h3 id="vectorizationlowrankmatrixfactorization">Vectorization: Low Rank Matrix Factorization</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361496844_8727.jpg'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361496849_5252.jpg'  alt="" /></p>

<p><em>collaborative filtering</em> 은 <em>low rank matrix factoriazation</em> 이라 부르기도 한다. 위 슬라이드처럼 <code>X, THETA</code> 를 구성하고 <code>X * THETA^T</code> 를 구하면 된다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361496854_2443.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>low rank matrix factorization</em> 을 이용해서 <em>feature</em> 를 찾으면, 두 영화 <code>i, j</code> 가 얼마나 유사한지 <code>||x^(i) - x^(j)||</code> 으로 판단할 수 있다.</p>

<h3 id="implementationdetailmeannormalization">Implementation Detail: Mean Normalization</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361497832_3797.jpg'  alt="" /></p>

<p>만약 위 슬라이드의 <code>Eve</code> 처럼 아무 영화도 평가 안한 사람에게는, <code>theta</code> 가 <code>0</code> 으로 나온다. (첫번째 <em>term</em> 이 <code>0</code> 이고, <em>regularization term</em> 은 <code>theta</code> 를 최소화한다.)</p>

<p>그렇게 되면, 어떤 영화도 높은 <em>rating</em> 을 받을 수 없으므로 (<code>theta^T * x</code>). 추천할 거리가 없다. 이건 별로 좋은 상황이 아닌데, <em>mean normalization</em> 을 이용하면 이 문제를 해결할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/22/1361497813_3878.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt1' >http://blog.csdn.net/linuxcumt1</a>)</p>

<p><em>mean normalized</em> 데이터를 이용하면, 추천 안한 사람이 <code>theta = 0</code> 을 갖더라도, 남들이 추천한 선호도 <code>u</code> 에 따라서 영화를 추천받을 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20&plus;%20%5Cmu_i'  alt="" /></p>

<p>잘보면 <em>feature scaling</em> 과는 다르게 특정 <em>range</em> 로 나누질 않는데, 이건 이미 <em>rating</em> 자체가 일정 범위 <code>1-5</code> 를 갖기 때문이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a> <br />
(4) <a href='http://ghebook.blogspot.com/2011/06/matrix.html' >http://ghebook.blogspot.com</a> <br />
(5) <a href='http://darkpgmr.tistory.com/104' >http://darkpgmr.tistory.com</a>  </p>]]></description><link>http://1ambda.github.io/machine-learning-week-9/</link><guid isPermaLink="false">0247c02a-4927-4ae8-957c-adf6590fac09</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine learning]]></category><category><![CDATA[anomaly detection]]></category><category><![CDATA[recommender system]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 07 Dec 2014 15:39:40 GMT</pubDate></item><item><title><![CDATA[A Poor Man's Concurrency Monad]]></title><description><![CDATA[<p><em>FP 101x</em> 의 최종 보스입니다. <del>Rose Tree 는 거들뿐</del> <em>Koen Claessen</em> 가 1999년에 발표한 <a href='http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.8039' ><em>Poor Man's Concurrenc Monad</em></a> 를 배경으로 하는 과제인데, 언어에 <em>primitive</em> 추가 없이 <em>concurrency</em> 를 모델링 하는 방법을 보여줍니다. </p>

<h3 id="continuation">Continuation</h3>

<p>먼저 용어부터 정의하고 가면, <em>continuation</em> 은 실행 가능한 <em>computation</em> 입니다. 필요할 때 사용할려고 미뤄둔 계산인데, 이게 프로세스를 모델링 하기에 적당합니다. 왜냐하면 프로세스도 멈추었다가, 나중에 다시 실행을 해야 하니까요!</p>

<p>나중에 쓰려고 미뤄둔 계산, 즉 <em>continuation</em> 을 지속적으로 넘겨가면서 사용하는 방식을 <em>continuation passing style</em> 이라 부릅니다. <em>CPS</em> 로 작성된 함수는 리턴하는 법이 없습니다. 다만 자신의 계산을 <em>continuation</em> 으로 만들어 넘겨줄 뿐이지요.</p>

<p>코드를 먼저 보시지요. 피타고라스 계산을 하스켈에서 <em>CPS</em> 로 작성하는 방법입니다. </p>

<pre><code class="haskell">square :: Int -&gt; Int  
square x = x * x

add :: Int -&gt; Int -&gt; Int  
add x y = x + y

square_cps :: Int -&gt; (Int -&gt; r) -&gt; r  
square_cps x = \cont -&gt; cont (square x)

add_cps :: Int -&gt; Int -&gt; (Int -&gt; r) -&gt; r  
add_cps x y = \cont -&gt; cont (add x y)

pythagoras_cps :: Int -&gt; Int -&gt; (Int -&gt; r) -&gt; r  
pythagoras_cps x y = \cont -&gt;  
  square_cps x $ \squared_x -&gt;
  square_cps y $ \squared_y -&gt;
  add_cps squared_x squared_y cont

&gt; square_cps 3 print
-- "9"

&gt; add_cps 3 4 print
-- "7"

&gt; pythagoras_cps 3 4 print
-- "25"
</code></pre>

<p>위 예제에서는 <code>print</code> 가 나중에 쓸려고 모셔둔 계산, 즉 <em>continuation</em> 입니다. 이 타입 <code>(Int -&gt; r) -&gt; r</code> 을 잘 기억해 두세요.</p>

<h3 id="processmodeling">Process Modeling</h3>

<p>프로세스를 모델링 하려면 상태와 작업 두 가지를 나타내야 합니다. 먼저 프로세스가 하는 작업에 대해서 모델링을 해 보겠습니다. 프로세스는 의 작업은 <code>Action</code> 이라 부르겠습니다. <code>Action</code> 은 <code>Atom</code> 이라 부르는 <code>IO</code> 연산일 수도 있고, 자식을 만드는 <code>Fork</code> 나, 프로세스를 멈추는 <code>Stop</code> 이 될 수 있습니다.</p>

<p><code>Atom</code> 은 <em>side-effect</em> 를 만드는 <em>atomic</em> 연산이라 보면 됩니다.</p>

<pre><code class="haskell">data Action =  
   = Atom (IO Action)
   | Fork Action Action
   | Stop
</code></pre>

<p>프로세스는 상태를 모델링 하기 위해 프로세스의 동작에 대해서 조금 논의해 봅시다. 프로세스는 자신의 작업이 있습니다. 우리는 <code>Action</code> 으로 표현했지요. 프로세스가 어떤 이유에서든지 중단된다면, 나중을 위해서 이 <code>Action</code> 을 기억해 둬야 합니다. 다시 작업을 해야하니까요!</p>

<p>아까 위에서 보았던 <code>(Int -&gt; r) -&gt; r</code> 기억 나시나요? <em>continuation</em> <code>Int - r</code> 을 이용해 결과 <code>r</code> 을 만들어 냈던 타입이지요. 이 타입을 잘 보면, <em>continuation</em> 이 공급될 때 <em>result <code>r</code></em>  을 얻을 수 있습니다. 여기서 결과인 <code>r</code> 은 다른 프로세스에게 밀려 중단된 작업 <code>Action</code> 이라 보시면 되고, 공급되는 <em>continuation</em> 은 <em>CPU</em> 와 같은 리소스라 보시면 됩니다. (그렇게 생각하는 편이 <del>정신건강에</del> 좋습니다.)</p>

<p>그러면, 비슷하게, 이런 타입을 생각해 볼 수 있습니다.</p>

<pre><code class="haskell">data Concurrent a = ((a -&gt; Action) -&gt; Action)  
</code></pre>

<p>이 타입은 <code>a -&gt; Action</code> <em>continuation</em> 을 받아, 결과 <code>Action</code> 을 돌려줍니다. </p>

<p>그러면 프로세스의 <strong>미뤄진 작업의 상태</strong>를 표현하는 <code>Concurrent</code> 에 <em>continuation</em> 을 공급해 <strong>미뤄진 작업</strong> <code>Action</code> 을 얻어내는 <code>action</code> 이란 함수를 만들 수 있습니다.</p>

<pre><code class="haskell">action :: Concurrent a -&gt; Action  
action (Concurrent concur) = concur (\a -&gt; Stop)  
</code></pre>

<p>또한 어떤 <em>continuation</em> 을 받던 무조건 멈추는 <code>Action</code> 을 돌려주는 <code>stop</code> 함수도 생각해 볼 수 있겠죠. 이건 <strong>멈춰진 작업의 상태</strong> 를 표현하는 <code>Concurrent</code> 라 보셔도 좋습니다.</p>

<pre><code>stop :: Concurrent  
stop = Concurrent (\cont -&gt; Stop)  
</code></pre>

<p>이제 <code>IO</code> 를 <code>Concurrent</code> 로 표현하기 위해 <code>IO a -&gt; Concurrent a</code> 로 변환해주는 <code>atom</code> 을 만들겁니다. 다시 말해서 이 함수는 <strong>멈춰진 <code>IO</code> 연산</strong> 을 돌려줘 하므로 <code>Concurrent</code> 내에 <code>Atom (IO Action)</code> 을 담아야 합니다. </p>

<p><code>cont a</code> 가 <code>Action</code> 이므로, <code>do</code> 내에서 <code>return (cont a)</code> 이면 <code>IO Action</code> 타입을 얻을 수 있겠죠? 쉽게 생각해서 <em>continuation</em> 인 <code>cont</code> 가 공급될 때 <code>IO</code> 를 수행한다 보면 되겠습니다.</p>

<pre><code class="haskell">atom :: IO a -&gt; Concurrent a  
atom \io -&gt; Concurrent $ \cont -&gt; Atom $ do a &lt;- io  
                                            return (cont a)
</code></pre>

<p>이제 프로세스를 분할하는 <code>Fork</code> 작업을 생각해 봅시다. 타입만 보면 <code>Fork Action Aciton</code>  입니다. 즉 두개의 <code>Action</code> 을 <code>Concurrent</code> 내에 담아야 합니다.</p>

<pre><code class="haskell">fork :: Concurrent a -&gt; Concurrent ()  
fork concur = Concurrent $ \cont -&gt; Fork (action concur) (cont ())  
</code></pre>

<p>보면, <code>action concur</code> 로 현재 미뤄진 작업에 대한 <code>Action</code> 을 추출하고, <em>continuation</em> 를 받아 <code>cont ()</code> 로 <em>continuation</em> 에 있는 다음 <code>Action</code> 을 뽑아냅니다. <em>continuation</em> 의 타입이 <code>a -&gt; Action</code> 인거 기억 나시죠?</p>

<p>비슷하게, 두개의 미루어진 작업을 받아 <code>Fork</code> 로 만드는 <code>par</code> 함수도 만들어 봅시다.</p>

<pre><code class="haskell">par :: Concurrent a -&gt; Concurrent a -&gt; Concurrent a  
par (Concurrent a) (Concurrent b) = Concurrent $ \cont -&gt; Fork (a cont) (b con))  
</code></pre>

<p>이제 <code>Concurrent</code> 간 <em>composition</em> 을 위해 <code>&gt;&gt;=</code>, <code>return</code> 을 구현하면</p>

<pre><code class="haskell">instance Monad Concurrent where  
    -- g :: \a -&gt; Concurrent b
    (Concurrent A) &gt;&gt;= g = 
      \contB -&gt; A (\contA -&gt; case g a of (Concurrent B) -&gt; B contB  
</code></pre>

<p>직관적인 이해는, <code>&gt;&gt;=</code> 자체는 두 <code>Concurrent</code> 간 연결입니다. 서로 다른 타입 <code>a, b</code> 에 대해서 <code>Concurrent</code> 가 어떻게 연결되야 하는지 생각해 보면 됩니다. </p>

<p><code>Concurrent a</code> 의 <code>Action</code> 을 얻기 위한  <em>continuation</em> 은, 다음 작업을 의미하는데 이 <em>continuation</em> <code>a' -&gt; Action</code> 에서의 <code>Action</code> 이 <code>Concurrent b</code> 의 <code>Action</code> 이라 보면 됩니다.</p>

<p>다시 말해서, <code>Concurrent a</code> 의 <code>Action</code> 의 다음 작업이 <code>Concurrent b</code> 의 <code>Action</code> 이란 뜻이지요. </p>

<p>마지막으로 <code>Action</code> 을 라운드 로빈 방식으로 스케쥴링하는 <code>roundRobin</code> 함수와, 실제로 <code>Concurrent a</code> 을 이용해 <code>roundRobin</code> 함수를 이용하는 <code>run</code> 함수를 보면,</p>

<pre><code class="haskell">roundRobin :: [Action] -&gt; IO ()  
roundRobin [] = return ()  
roundRobin (Atom x:xs) = x &gt;&gt;= \ac -&gt; roundRobin (xs ++ [ac])  
roundRobin (Fork x y : xs) = roundRobin (xs ++ [x, y])  
roundRobin (Stop : xs) = roundRobin xs

run :: Concurrent a -&gt; IO ()  
run x = roundRobin [action x]  
</code></pre>

<p>몇개의 헬퍼 함수와 테스트 코드도 좀 보겠습니다.</p>

<pre><code class="haskell">genRandom :: Int -&gt; [Int]  
genRandom 1337 = [1, 96, 36, 11, 42, 47, 9, 1, 62, 73]  
genRandom 7331 = [17, 73, 92, 36, 22, 72, 19, 35, 6, 74]  
genRandom 2600 = [83, 98, 35, 84, 44, 61, 54, 35, 83, 9]  
genRandom 42   = [71, 71, 17, 14, 16, 91, 18, 71, 58, 75]

loop :: [Int] -&gt; Concurrent ()  
loop xs = mapM_ (atom . putStr . show) xs

ex0 :: Concurrent ()  
ex0 = par (loop (genRandom 1337)) (loop (genRandom 2600) &gt;&gt; atom (putStrLn ""))

ex1 :: Concurrent ()  
ex1 = do atom (putStr "Haskell")  
         fork (loop $ genRandom 7331) 
         loop $ genRandom 42
         atom (putStrLn "")

myex0 = run $ (ho &gt;&gt; ho &gt;&gt; ho) &gt;&gt;  
              (hi &gt;&gt; hi &gt;&gt; hi) &gt;&gt; atom (putStr "\n")
  where ho = atom (putStr "ho")
        hi = atom (putStr "hi")

myex1 = run $ fork (ho &gt;&gt; ho &gt;&gt; ho) &gt;&gt;  
              (hi &gt;&gt; hi &gt;&gt; hi) &gt;&gt; atom (putStr "\n")
  where ho = atom (putStr "ho")
        hi = atom (putStr "hi")

myex2 = run $ fork (put3 "ba") &gt;&gt; fork (put3 "di") &gt;&gt;  
        put3 "bu" &gt;&gt; atom (putStr "\n")
  where put3 = sequence . take 3 . repeat . atom . putStr

myex3 = run $ par (put3 "ba") (put3 "di" &gt;&gt; stop) &gt;&gt;  
        atom (putStr "\n")
  where put3 = sequence . take 3 . repeat . atom . putStr

myex4 = run $ (par (put3 "ba") (put3 "di")) &gt;&gt;  
        atom (putStr "\n")
  where put3 = sequence . take 3 . repeat . atom . putStr

myex5 :: Concurrent ()  
myex5 = do fork (atom $ putStrLn "test")  
           atom $ putStrLn "hello"

myex6 :: Concurrent ()  
myex6 = do val &lt;- par (atom $ return "hi") (atom $ return "hello")  
           atom $ putStrLn val
</code></pre>

<h2 id="references">References</h2>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em> <br />
(3) <a href='http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.8039' >A Poor Man's Concurrency Monad</a></p>]]></description><link>http://1ambda.github.io/a-poor-mans-concurrency-monad/</link><guid isPermaLink="false">15feb78a-f5db-44ac-9bb6-acd63bdca8fd</guid><category><![CDATA[haskell]]></category><category><![CDATA[continuation]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 06 Dec 2014 15:35:51 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 8]]></title><description><![CDATA[<p>고차함수가 있는 다른언어와 비교했을 때 하스켈은 무슨 특징이 있을까요? 하스켈은 <em>expression</em> 을 평가하기 위해 디폴트로 <em>lazy evaluation</em> 을 사용한다는 점에서 다른 언어들과 다릅니다.</p>

<p>이번시간엔 <em>evaluation</em> 의 개념부터 시작해서, 다양한 종류의 <em>evaluation</em> 전략들을 살펴보겠습니다.</p>

<h3 id="evaluation">Evaluation</h3>

<ul>
<li>Avoid doing <strong>unnecessay evaluation</strong></li>
<li>Allows programs to be <strong>more modular</strong></li>
<li>Allows us to program with <strong>infinite lists</strong></li>
</ul>

<p>하스켈은 <em>lazy evaluation</em> 을 이용해 위에 나열한 것들을 제공합니다. <em>lazy evaluation</em> 을 이야기 하기 전에 먼저 <em>evaluation</em> 이 무엇인지 살펴봅시다.</p>

<blockquote>
  <p>Basically, expressions are evaluated or reduced by successively applying definitions until no further simplification is possible</p>
</blockquote>

<p>예를 들어서 <code>square n = n * n</code> 이란 <em>definition</em> 이 있을때, <em>expression</em> <code>square(3 + 4)</code> 는 이렇게 두 가지 방식으로 평가될 수 있습니다.</p>

<pre><code class="haskell">square (3 + 4)  
square 7  
7 * 7  
49

-- bad
square (3 + 4)  
(3 + 4) * (3 + 4)
7 * (3 + 4)  
7 * 7  
49  
</code></pre>

<p>만약에 아래 버전처럼 <code>(3 + 4) * (3 + 4)</code> 로 평가된다면, 똑같은 계산을 두번이나 하게 될 겁니다. 더 심각한 문제는 <em>side effect</em> 가 발생한다면 값이 달라질 수도 있다는 것이지요!</p>

<p>아래 예제를 한번 봅시다. <em>evaluation</em> 전략에 따라 값이 달라지는 것을 보여줍니다.</p>

<pre><code class="haskell">-- initially, n := 0

-- left first
n + (n := 1)  
0 + (n := 1)  
0 + 1  
1

-- right first
n + (n := 1)  
n + 1  
1 + 1  
2  
</code></pre>

<blockquote>
  <p><strong>FACT:</strong> In Haskell, two diffrent (but terminating) ways of evaluating the same expression will always give the same final result.</p>
</blockquote>

<p>다행히도 하스켈은 어떤 전략을 사용하든 <em>terminating expression</em> 에 대해서는 항상 같은 결과를 돌려줍니다. </p>

<h3 id="reductionstrategies">Reduction Strategies</h3>

<p>일반적으로 평가방법은 크게 두 가지로 나눌 수 있습니다. 어떤 <em>reducible subexpression (redex)</em> 를 선택하냐에 따라 </p>

<p>(1) <strong>Innermost reduction:</strong> An inner most redex is always reduced <br />
(2) <strong>Outermost reduction:</strong> An outermost redex is always reduced</p>

<pre><code class="haskell">loop = tail loop

// innermost reduction
fst (1, loop)  
fst (1, tail loop)  
fst (1, tail (tail loop))  
...

// outermost reduction
fst (1, lop)  
1  
</code></pre>

<p>위 결과를 보면 <em>innermost</em> 가 종료되지 않는 경우에도, <em>outermost</em> 는 결과를 돌려줄 수 있다는 사실을 알 수 있습니다. </p>

<p>또한 어느 하나의 <em>reduction sequence</em> 라도 종료된다면 <em>outermost reduction</em> 도 종료됩니다. 같은 결과를 돌려주면서요. 원문을 첨부하면,</p>

<blockquote>
  <p>For a given expression if there exists any reduction sequence that terminates, then outermost reduction <strong>also</strong> terminates, with the same result</p>
</blockquote>

<p><em>innermost</em> 에 비해 더 많은 경우에 종료되므로 <em>outermost</em> 가 좋다고 볼 수도 있겠습니다. 그러나, <em>outermost reduction</em> 은 좀 비효율적입니다.</p>

<pre><code class="haskell">// innermost
square (3 + 4)  
square 7  
7 * 7  
49

// outermost
square (3 + 4)  
(3 + 4) * (3 + 4)
7 * (3 + 4)  
7 * 7  
49  
</code></pre>

<p>따라서 하스켈에서는 <em>outermost</em> 에 <em>sharing</em> 을 더해 <em>lazy evalution</em> 이라 부르고 이 방법을 <em>evalution</em> 에 이용합니다.</p>

<pre><code class="haskell">square (3 + 4) -- sharing, n = (3 + 4)  
= n * n -- reduced shared expression `n` into 7
= 7 * 7
= 49
</code></pre>

<p><em>innermost, outermost</em> 예제를 좀 더 살펴봅시다.</p>

<pre><code class="haskell">mult :: (Int, Int) -&gt; Int  
mult (x, y) = x * y  
</code></pre>

<p>이제 <code>mult(1 + 2, 3 + 4)</code> 를 <em>innermost</em> 로 평가한다고 한다면,</p>

<pre><code class="haskell">mult(1 + 2, 3 + 4)  
mult(3, 3 + 4) -- conventionally, we select left innermost  
mult(3, 7)  
3 * 7 -- apply outermost  
24  
</code></pre>

<p><em>innermost</em> 는 <em>argument (인자)</em> 가 먼저 평가 되어야 하기 때문에, 인자가 <em>value</em> 인 경우 사용할 수 있습니다. 반대로 <em>outermost</em> 전략을 사용한다고 결정하려면 인자가 <em>name</em> 이어야 합니다. </p>

<p>어떤 함수들의 경우는 <em>outermost</em> 를 사용함에도 먼저 인자가 평가되어야 합니다. 예를 들어 <code>*, +</code> 같은 <em>built-in operator</em> 는 무조건 인자가 먼저 평가되야 합니다. 이런 함수들을 <em>strict</em> 하다고 말 합니다.</p>

<p>좀 더 엄밀한 정의는</p>

<blockquote>
  <p>A function f is said to be strict if, when applied to a nonterminating expression, it also fails to terminate.</p>
</blockquote>

<p><code>mult</code> 를 <em>curried function</em> 으로 재 작성해 봅시다.</p>

<pre><code class="haskell">mult :: Int -&gt; Int -&gt; Int  
mult x = \y -&gt; x * y

-- evaluation
mult (1 + 2) (3 + 4)  
mult 3 (3 + 4)  
(\y -&gt; 3 * y)(3 + 4)
(\y -&gt; 3 * y)(7)
3 * 7  
</code></pre>

<p>이제 인자가 한턴에 하나씩 계산됩니다. 이는 <code>mult 3 (3 + 4)</code> 에서 <em>left, innermost redex</em> 가 <code>mult 3</code> 이기 때문입니다. <code>mult (3, 3 + 4)</code> 에선 <code>3 + 4</code> 가 <em>left, innermost redex</em> 였지만요.</p>

<p>참고로 하스켈에서 <em>lambda expression</em> 내부의 <em>redex</em> 를 선택하는건 불가능합니다. 이는 람다도 함수이고, 함수 내부는 볼 수 없는 <em>black box</em> 이기 때문입니다.</p>

<blockquote>
  <p>Note that in Haskell, the selection of redexes within lambda expressions
  is prohibited. The rational for not “reducing under lambdas” is that functions are viewed as black boxes that we are not permitted to look inside.</p>
</blockquote>

<p>일반적으로 <em>innermost</em> 전략을 <em>call by value</em>, <em>outermost</em> 전략을 <em>call by name</em> 이라 부릅니다.</p>

<h3 id="infinitelist">Infinite List</h3>

<p>여기 <code>1</code> 의 무한한 나열을 표현하는 <code>ones</code> 에 대해 <em>expression</em> <code>head ones</code> 가 어떻게 평가되는지 <em>innermost</em> 와 <em>lazy evaluation</em> 의 두 가지 방법을 비교해 봅시다. </p>

<pre><code class="haskell">ones :: [Int]  
ones = 1 : ones

-- innermost
head one  
head (1 : one)  
head (1 : 1 : one)  
...

-- lazy evaluation
head one  
head (1: ones)  
1  
</code></pre>

<p><em>innermost</em> 의 경우에는 <em>evaluation</em> 이 끝나지 않습니다. 반면 <em>lazy evaluation</em> 은 식이 끝나면서 결과를 얻을 수 있죠.</p>

<blockquote>
  <p>Using <strong>lazy evaluation</strong>, expressions are only evaluated as much as required to produce the final result</p>
</blockquote>

<p>즉 필요한 만큼만 평가됩니다. 따라서 <em>lazy evaluation</em> 을 이용한 평가방법이 있으므로 <code>ones = 1 : ones</code> 처럼 무한할 <strong>가능성이 있는</strong> 데이터를 표현할 수 있습니다.</p>

<h3 id="modularprogramming">Modular Programming</h3>

<pre><code class="haskell">take 5 ones  
-- [1, 1, 1, 1, 1]
</code></pre>

<p>위의 예제에서 볼 수 있듯이 <em>lazy evaluation</em> 을 이용하면 <em>expression</em> 을 두 부분으로 나눕니다. </p>

<ul>
<li><strong>Control Part:</strong> <code>take 5</code></li>
<li><strong>Data:</strong> <code>ones</code></li>
</ul>

<p>인자를 받아 주어진 숫자만큼 복사하는 <code>replicate</code> 함수도 만들어 볼까요?</p>

<pre><code class="haskell">replicate' :: Int -&gt; a -&gt; [a]  
replicate' 0 _ = []  
replicate' n x = x : replicate' (n - 1) x  
</code></pre>

<h3 id="generateprimes">Generate Primes</h3>

<p>무한한 길이의 원소를 표현할 수 있다는 법을 배웠습니다. 이 방법을 이용해 존재하는 모든 소수의 집합을 표현하는 리스트를 만들어 볼까요? </p>

<p><em>Sieve of Eratosthenes (에라토스테네스의 체)</em> 란 방법을 사용하겠습니다. 알고리즘은 <a href='http://en.wikipedia.org/wiki/Sieve_of_Eratosthenes' >여기</a> 를 참조하세요.</p>

<pre><code class="haskell">primes :: [Int]  
primes = seive [2..]

seive :: [Int] -&gt; [Int]  
seive (p : xs) = p : [x | x &lt;- xs, x `mod` p /= 0]

take 10 primes  
-- [2,3,5,7,9,11,13,15,17,19]

takeWhile (&lt;15) primes  
-- [2, 3, 5, 7, 11, 13]
</code></pre>

<h3 id="strictapplication">Strict Application</h3>

<p>하스켈에선 <em>lazy evaluation</em> 이 기본이지만, <em>strict</em> 버전으로 함수를 적용할 수 있는 방법도 제공합니다. <code>$!</code> 키워드를 이용하면 되는데요, <code>f $! x</code> 같은 경우 <code>f</code> 를 적용하기 전에 <code>x</code> 가 모두 평가되야 합니다.</p>

<p>더 엄밀히 말하면 <em>top-level of evaluation</em> 이 이루어지는데요, 인자 <code>x</code> 의 타입이 <code>Int</code> 나 <code>Bool</code> 같은 <em>basic type</em> 일 경우는 <em>complete evaluation</em> 이 이루어집니다.</p>

<p>반대로, <code>(Int, Bool)</code> 같은 복합타입이라면 <em>pair of expression</em> 이 얻어질 때 까지만 평가가 이루어집니다. 유사하게 타입이 리스트라면 <code>[]</code> 나 <code>a : b</code> 같은 컨싱이 얻어질때까지만 평가가 이루어집니다.</p>

<blockquote>
  <p>More formally, an expression of the form <code>f $! x</code> is only a redex once evaluation of the argument x, using lay evaluaion as normal, has reached the point where it is known that the result is not an undefined value, at which point the expression can be reduced to the normal application <code>f x</code></p>
</blockquote>

<p>예를 들어 <code>square $! (1 + 2)</code> 의 경우</p>

<pre><code class="haskell">square $! (1 + 2)  
square $! 3  
square 3  
3 * 3  
9  
</code></pre>

<p>다수개의 인자를 갖는 <em>curried function</em> 과 <code>$!</code> 가 쓰일 경우에는 다양한 형태가 될 수 있습니다.</p>

<pre><code class="haskell">(f $! x) y    -- forces top-level evaluation of x
(f x) $! y    -- forces top-level evaluation of y
(f $! x) $! y -- forces top-level evaluation of x and y
</code></pre>

<p>하스켈에서 <em>strict application</em> 은 주로 프로그램의 <em>space performance</em> 을 개선하기 위해 사용됩니다. 예를 들어 다음과 같은 <code>sumWith</code> 함수가 있다고 합시다. </p>

<pre><code class="haskell">sumWith :: Int -&gt; [Int] -&gt; Int  
sumWith v [] = v  
sumWith v (x:xs) sumWith (v + x) xs  
</code></pre>

<p><em>lazy evaluation</em> 에서는</p>

<pre><code class="haskell">sumWith 0 [1, 2, 3]  
sumWith (0 + 1) [2, 3]  
sumWith ((0 + 1) + 2) [3]  
sumWith (((0 + 1) + 2) + 3) []  
(((0 + 1) + 2) + 3)
...
...
6  
</code></pre>

<p>계산 전에 <code>(((0 + 1) + 2) + 3)</code> 가 만들어 지는걸 볼 수 있습니다. <code>sumWith 0 [1.. 10000]</code> 같은 큰 수의 계산일 경우 공간이 좀 아까울 수 있지요.</p>

<p>따라서 <code>sumWith</code> 에 <code>$!</code> 를 이용하면</p>

<pre><code class="haskell">sumWith v [] = v  
sumWith v (x:xs) = (sumWith $! (v + x)) xs

sumWith 0 [1, 2, 3]  
sumWtih $! (0 + 1) [2, 3]  
sumWith $! 1 [2, 3]  
sumWith 1 [2, 3]  
...
</code></pre>

<p><code>sumWith</code> 뿐만 아니라 고차함수인 <code>foldl</code> 등에도 적용해 볼 수 있습니다.</p>

<pre><code class="haskell">foldl' :: (a -&gt; b -&gt; a) -&gt; a -&gt; [b] -&gt; a  
foldl' f v [] = v  
foldl' f v (x:xs) ((foldl' f) $! (f v x)) xs  
</code></pre>

<p>이러면, <code>sumWith</code> 를 <code>foldl' (+)</code> 로 정의할 수 있습니다.</p>

<h2 id="references">References</h2>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em>  </p>]]></description><link>http://1ambda.github.io/haskell-intro8/</link><guid isPermaLink="false">d903754f-78ce-4128-8c4f-51567d031c97</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[lazy evaluation]]></category><category><![CDATA[call by value]]></category><category><![CDATA[call by name]]></category><category><![CDATA[strict]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Thu, 04 Dec 2014 08:46:14 GMT</pubDate></item><item><title><![CDATA[Graph Challenges, Minimum Spanning Trees, Shortest Paths]]></title><description><![CDATA[<h3 id="graphprocesschallenge1">Graph Process Challenge 1</h3>

<h4 id="isagraphbipartite">Is a graph bipartite?</h4>

<p>그래프가 <em>bipartite</em> 인가 하는 문제는, 그래프의 노드를 이렇게 두 그룹으로 나눌 수 있느냐 하는 문제다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Simple-bipartite-graph.svg/330px-Simple-bipartite-graph.svg.png'  alt="" /></p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Biclique_K_3_5.svg/330px-Biclique_K_3_5.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<p>알고리즘이 얼마나 어려운가는 이렇게 나눠볼 수 있겠는데</p>

<ol>
<li>Any programmer could do it  </li>
<li>Typical diligen algorithms student could do it  </li>
<li>Hire an expert  </li>
<li>Intractable  </li>
<li>No one knows  </li>
<li>Impossile</li>
</ol>

<p><em>biparting</em> 문제는 <em>DFS-based solution</em> 을 이용할 수 있으므로, 난이도 2정도에 해당한다 볼 수 있겠다. </p>

<p>생각해 볼 수 있는 응용은, 질병의 전파 경로를 그래프로 그리고 <em>biparting</em> 이 가능한지 보는 것이다.</p>

<h4 id="findacycle">Find a cycle</h4>

<p>이것도 난이도 (2) 정도. 마찬가지로 <em>simple DFS-based solution</em> 을 이용하자.</p>

<p>잘 알려진 응용으로, <em>euler tour</em> 가 있다. 각 <em>edge</em> 를 단 한번씩만 방문하는 <em>cycle</em> 이 있는지를 검사하는 문제다. 여기서 시작점과 끝 점이 같으면 <em>euler circuit</em> 이고, 다르면 <em>euler path</em> 라 부른다.</p>

<p><a href='http://ko.wikipedia.org/wiki/%EC%98%A4%EC%9D%BC%EB%9F%AC_%EA%B2%BD%EB%A1%9C' >여기</a>에 의하면 그래프에 오일러 회로가 존재하려면 </p>

<p>(1) 연결된 그래프여야 하고 <br />
(2) 모든 꼭지점의 차수가 짝수여야 한다.</p>

<p>반면 오일러 경로라면, 연결그래프에서 정확히 두 개의 꼭지점만 홀수 차수여야 한다.</p>

<p>각 <em>node</em> 를 정확히 한번씩만 지나는 <em>cycle</em> 을 <em>traveling salesman problem, TSP</em> 혹은 <em>hamiltonian path problem</em> 이라 부른다.</p>

<p>오일러 순회와 경로처럼 시작점과 끝점이 같은지, 아닌지에 따라 구분할 수 있다. <em>hamiltonian cycle</em> 은 전형적인 <em>NP-complete problem</em> 으로 알려져있다. 난이도로 구분하자면 <em>(4) intractable</em> 정도 되시겠다.</p>

<h4 id="graphisomorphismproblem">Graph Isomorphism Problem</h4>

<blockquote>
  <p>Are two graphs identical except for vertex names?</p>
</blockquote>

<p>그래프의 형태가 같은지 묻는 문제다. 예를 들어 다음의 두 그래프는 같은 형태다.</p>

<p><img src='http://www.biodatamining.org/content/figures/1756-0381-4-10-3-l.jpg'  alt="" /></p>

<p align="center">(<a href='http://www.biodatamining.org/' >http://www.biodatamining.org/</a>)</p>

<p>두 그래프의 노드를 <code>n!</code> 으로 배열해 가면서 같은지 비교하는 단순한 방법은 그래프가 커지면 기하 급수적으로 성능이 느려진다. 더 나은 알고리즘이 있는지 연구자들이 노력하고 있지만, 아직 모른다. 난이도는 <em>(5) No one knows</em></p>

<h4 id="graphsplanarity">Graphs Planarity</h4>

<p>그래프를 <em>crossing edge</em> 가 없는 그래프로 그릴 수 있느냐 하는 문제다.</p>

<blockquote>
  <p>평면 그래프(planar graph)는 평면 상에 그래프를 그렸을 때, 두 변이 꼭지점 이외에 만나지 않도록 그릴 수 있는 그래프를 의미한다.</p>
</blockquote>

<p>이건 난이도 <em>(3) Hier an expert</em> 문제다. <em>DFS</em> 기반의 <em>linear time</em> 알고리즘이 1970년대에 발표되었다.</p>

<h3 id="minimumspanningtrees">Minimum Spanning Trees</h3>

<p><em>undirected, positive edge weights</em> 그래프에서 </p>

<p>(1) <em>connected, acyclic</em> <strong>(tree)</strong> <br />
(2) <em>includes all of the vertices</em> <strong>(spanning)</strong>   </p>

<p>인 서브 그래프를 <strong><em>spanning tree</em></strong> 라 부른다.</p>

<p><strong><em>minimum spanning tree</em></strong> 는 여기서 <em>min weight</em> 를 갖는 <em>spanning tree</em> 를 찾는 문제다.</p>

<h4 id="applications">Applications</h4>

<ul>
<li>dithering</li>
<li>cluster analysis</li>
<li>max bottleneck paths</li>
<li>network design</li>
</ul>

<p>등에 활용할 수 있다.</p>

<h3 id="mstgreedyalgorithm">MST: Greedy Algorithm</h3>

<p>간단한 설명을 위해서 그래프가 연결되어있고 <em>weight</em> 가 모두 다르다 하자. 그럼 <em>MST</em> 는 하나만 존재할 것이다.</p>

<p>먼저 <em>cut, crossing edge</em> 용어 정리를 하면</p>

<blockquote>
  <p><strong>Cut:</strong> A cut is a graph is a partition of its vertices into two (nonempty) sets</p>
  
  <p><strong>Crossing edge:</strong> A crossing edge connects a vertex in one set with a vertex in the other</p>
</blockquote>

<p>그러면, 이런 <em>cut property</em> 가 존재한다.</p>

<blockquote>
  <p>Given any <strong>cut</strong>, the crossing edge of min weight is in the MST</p>
</blockquote>

<p>증명은 <em>min-weight crossing edge</em> <code>e</code> 가 <em>MST</em> 내에 없다고 하자. <em>MST</em> 는 연결되야 하므로 다른 <em>crossing edge</em> <code>f</code> 가 대신 사용될 것이다. </p>

<p>(1) 다른 <em>crossing edge</em> <code>f</code> 가 없으면 <em>connected</em> 가 아니므로 <em>MST</em> 가 아니다. <br />
(2) 만약 <code>f</code> 가 있어서 <code>f</code> 를 대신 사용하는 <em>MST</em> 에 <code>e</code> 를 추가하면 사이클이 생긴다. 이 때 <code>f</code> 를 제거하면 <em>weight</em> 가 더 짧다. 따라서 <code>f</code> 가 포함되면 <em>MST</em> 가 아니다.</p>

<p>따라서 <em>min-weight crossing edge</em> 가 <em>MST</em> 내에 존재한다. 이 사실을 이용하면 <em>MST</em> 를 찾는 <em>greedy algorithm</em> 을 만들 수 있다.</p>

<pre><code>- Start with all edges colored gray
- Find cut with no black corssing edges; 
   color its min-weight edge black
- Repeat until V - 1 edges are colored black
</code></pre>

<p>즉 어떤 <em>cut</em> 에 대해서 <em>min-weight crossing edge</em> 가 <em>MST</em> 에 포함되므로, 이미 찾은 <em>MST edge</em> 를 포함하지 않는 <em>cut</em> 을 찾아, <em>min-weight crossing edge</em> 을 추가해 나가면 된다.</p>

<h4 id="correcteness">Correcteness</h4>

<p>(1) Any edge colored black is in the MST (vis cut property) <br />
(2) Fewer than <code>V - 1</code> black edges => cut with no black crossing edges</p>

<p>모든 <em>MST</em> 는 <code>V - 1</code> 개의 <em>edge</em> 로 구성된다. 따라서 <code>V - 1</code> 개의 <em>black edge</em>, 즉 <em>MST</em> 의 원소를 찾아내면 된다. </p>

<h3 id="edgeweightedgraphapi">Edge-Weighted Graph API</h3>

<pre><code class="java">public class Edge implements Comparable&lt;Edge&gt; {  
  Edge(int v, int w, double weight)
  int either()
  int other(int v)
  int compareTo(Edge that)
  ...
}

// allow self-loops and parallel edges
public class EdgeWeightedGraph {  
  EdgeWeightedGraph(int V) // V vertices
  void addEdge(Edge e)
  Iterable&lt;Edge&gt; adj(int v) // edges incident to v
  Iterable&lt;Edge&gt; edges() // all edges
  Int V() // # of vertices
  int E() // # of edges
}

public class MST {  
  MST(EdgeWeigtedGraph G)
  Iterable&lt;Edge&gt; edges()
  double totalWeight()
}
</code></pre>

<h4 id="removingassumptions">Removing assumptions</h4>

<ul>
<li>What if edge weights are not all distinct?</li>
</ul>

<blockquote>
  <p>Greedy MST algorithm still correct if equal weights are present. (our correctness proof fails, but that can be fixed)</p>
</blockquote>

<ul>
<li>What if graph is not connected?</li>
</ul>

<blockquote>
  <p>Compute MS forest = MST of each components</p>
</blockquote>

<h3 id="kruskalsalgorithm">Kruskal's Algorithm</h3>

<pre><code>- Sort edges in ascending order of weight. 
- Add next edge to tree T 
  unless doing so would create a cycle 
  (until V - 1 edges added) 
</code></pre>

<p><em>kruskal's algorithm</em> 은 <em>greedy MST</em> 의 일종이라 볼 수 있다.</p>

<p>선택된 <em>edge</em> <code>e = v &lt;-&gt; w</code> 라 하고 이것을 <em>crossing edge</em> (<em>cut</em> 이라 볼 수 있다), 하면 </p>

<p><em>black edge</em> 간 <em>no cycle</em> 인 <code>e</code> 를 선택한 것이므로 <code>v &lt;-&gt; w</code> 사이엔 <em>black crossing edge</em> 가 없다. </p>

<p>게다가 선택하는 <em>crossing edge</em> 는 가장 작은 <em>weight</em> 를 가진다. 이 전에 이미 더 작은 <em>weight</em> 의 <em>edge</em> 를 모두 선택했기 때문이다.</p>

<p>따라서 크루스칼 알고리즘은 <em>greedy MST</em> 의 일종이다.</p>

<h4 id="cyclecheck">Cycle Check</h4>

<p>어떻게 <em>Cycle check</em> 를 할까? 한 가지 방법은 <em>edge <code>e = v - w</code></em> 에 대해 <code>v - w</code> 가 연결되어있는지 <em>DFS</em> 를 돌리면 된다. 그러면 <code>O(V)</code> 로 사이클을 검사할 수 있다.</p>

<p>단순히 연결되어있는지만 검사하는 것이므로 <em>union find</em> 를 쓰면 <code>O(log* V)</code> 로도 가능하다. <a href='http://1ambda.github.io/union-find-algorithms-week-1/' >Union-find</a> 를 참고하자.</p>

<h4 id="kruskalmstimplementation">Kruskal MST Implementation</h4>

<pre><code class="java">EdgeWeightedGraph G;  
int V = G.V()  
UF uf = new UF(V);

Queue&lt;Edge&gt; mst = new Queue&lt;Edge&gt;();  
MinPQ&lt;Edge&gt; pq = new MinQP&lt;Edge&gt;();

for (Edge e : G.edges())  
  pq.enqueue(e);

while (!pq.isEmpty() &amp;&amp; mst.size() &lt; V - 1) {  
  Edge e = pq.dequeue();
  int v = e.either();
  int w = e.other(v);

  if (!uf.connected(v, w)) {
    uf.union(v, w);
    mst.enqueue(e);
  }
}
</code></pre>

<p><em>running time</em> 은 <code>E log E</code> 다. </p>

<ul>
<li>build <code>pq</code>: <code>1 * E</code></li>
<li>dequeue: <code>E * log E</code></li>
<li>union: <code>V * log* V</code></li>
<li>connected: <code>E * log* V</code> </li>
</ul>

<h3 id="primsalgorithm">Prim's Algorithm</h3>

<pre><code>- start with vertex 0 and greedily grow tree T
- add to T the min weight edge with exactly one endpoint in T
- repate until V - 1 edge
</code></pre>

<h4 id="correctness">Correctness</h4>

<p>마찬가지로 <em>prim's algorithm</em> 도 <em>greedy MST</em> 의 일종이다.</p>

<p>방문한 노드와 방문하지 않은 노드를 <em>cut</em> 해 거기서 <em>min-weight edge</em> 를 선택한다. 따라서 <em>cut</em> 자체가 방문하지 않은 노드와 방문한 노드 두 집합을 만드므로 <em>crossing edge</em> 중에는 <em>black edge</em> 가 없다. </p>

<h4 id="primmstimplementation">Prim MST Implementation</h4>

<p><em>lazy implementation</em> 으로 현재 선택할 수 있는 <em>edge</em> 를 <em>weight</em> 기준으로 <em>priority queue</em> 에 유지하는 방법이 있다.</p>

<p><em>queue</em> 에 있는 <em>edge</em> <code>e = (v, w)</code> 를 꺼낸 뒤</p>

<p>(1) <code>v, w</code> 둘 다 이미 방문했으면 패스하고, <br />
(2) <code>v</code> 혹은 <code>w</code> 둘 중 하나만 방문했을 경우에만 <code>w or v</code> 의 <em>edge</em> 를 추가하고, <code>w or w</code> 를 방문 처리 한다. </p>

<pre><code class="java">// lazy Prim MST

boolean[] marked // MST vertices  
Queue&lt;Edge&gt; mst = new Queue&lt;Edge&gt;();  
MinPQ&lt;Edge&gt; pq = new MinPQ&lt;Edge&gt;();  
WeightedGraph G;

visit(G, 0);

while (!pq.isEmpty()) {  
  Edge e = pq.dequeue();
  int v = e.either();
  int w = e.other(v);

  if (marked[v] &amp;&amp; marked[w]) continue;

  mst.enqueue(e);

  // add v or w
  if (!marked[v]) visit(G, v);
  if (!marked[w]) visit(G, w);
}

void visit(int v) {  
  marked[v] = true;
  for (Edge g : G.adj(v)) {
    if (!marked[e.other(v)]) pq.insert(e);
  }
}
</code></pre>

<p><em>running time</em> 은 <code>O(E log E)</code> 다.</p>

<p>좀 더 나은 알고리즘은 <em>MST</em> 에 <em>edge</em> <code>e = (v, w)</code> 를 추가할때, 이미 방문한 <code>w</code> 와 방문하지 않은 <code>v</code> 에 대해</p>

<p><code>v</code> 에서 갈 수 있는 모든 <em>edge</em> <code>e = (v, x)</code> 을 생각해 보면, </p>

<p>(1) <code>x</code> 가 이미 방문한 <em>vertex</em> 면 패스 <br />
(2) <em>queue</em> 에 <code>(k, x)</code> 가 없으면 추가 (<code>k</code> 는 이미 방문한 <em>vertex</em>) <br />
(3) <code>x</code> 까지의 거리가, <code>e = (v, x)</code> 가 더 짧으면 업데이트 (<em>decreaseKey operation</em>)</p>

<p>여기서 <code>decreaseKey</code> 연산을 빠르게 구현하기 위해 <em>indexed priority queue</em> 를 이용할 수 있다.</p>

<pre><code>void decreaseKey(int i, Key key)  
</code></pre>

<p>전체 러닝타임은 </p>

<ul>
<li><code>V</code> <em>insert</em></li>
<li><code>V</code> <em>delete min</em></li>
<li><code>E</code> <em>decrease key</em></li>
</ul>

<p>인데, <em>Priority Queue</em> 구현하는데 어떤 자료구조를 사용하느냐에 따라 각 연산의 시간이 달라진다.</p>

<p>(1) Array implementation optimal for dnse graph  </p>

<p>O(<code>V^2</code>)</p>

<p>(2) Binary heap much faser for sparse graphs  </p>

<p>O(<code>E log V</code>)</p>

<p>(3) 4-way heap worth the trouble in performance-critical situations  </p>

<p>O(<code>E log_(1/V) V</code>)</p>

<p>(4) Fibonacchi heap best in theor, but not worth implementing  </p>

<p>O(<code>E + V log V</code>)</p>

<h3 id="mstcontext">MST Context</h3>

<p><em>linear time MST</em> 알고리즘이 있을까? 1995년에 <em>linear time randomized MST</em> 가 발견 되었지만 <em>deterministic</em> 알고리즘은 여전히 연구중이다.</p>

<h3 id="shortestpathsapi">Shortest Paths API</h3>

<pre><code class="java">public class Directed Edge {

  DirectedEdge(int v, int w, deouble weight)
  int from()
  int to()
  double weight()
}

// allow self-loop, parallel
public class EdgeWeightedDigraph {

  EdgeWeightedDigraph(int V)
  void addEdge(DirectedEdge e)
  Iterable&lt;DirectedEdge&gt; adj(int v)
  int V() // # of vertices
}

// shortest path
public class SP {

  SP(EdgeWeightedDigraph G, int s)
  double distTo(int v)
  Iterable &lt;DirectedEdge&gt; pathTo(int v)
}
</code></pre>

<h3 id="shortestpathproperties">Shortest Path Properties</h3>

<p><em>directed, weighted graph</em> 에서 <em>shortest path tree, SPT</em> 가 존재하는데, 이는 <em>cycle</em> 이면 <em>shortest</em> 가 될 수 없기 때문이다.</p>

<p>위에서 본 <code>pathTo</code> 함수는 이렇게 구현할 수 있다.</p>

<pre><code class="java">// edgeTo[v] is last edge on shortest path from s to v
public Iterable&lt;DirectedEdge&gt; pathTo(int v) {  
  Stack&lt;DirectedEdge&gt; path = new Stack&lt;DirectedEdge&gt;();
  for (DirectedEdge e = edgeTo(v); e != null; e = edgeTo(e.from())
    path.push(e);

  return path;
}
</code></pre>

<h4 id="edgerelaxation">Edge relaxation</h4>

<p><em>relax edge <code>e = v -&gt; w</code></em>,</p>

<ul>
<li><code>distTo[v]</code> is length of shortest known path from <code>s</code> to <code>v</code></li>
<li><code>distTo[w]</code> is length of shortest known path from <code>s</code> to <code>w</code></li>
<li><code>edgeTo[w]</code> is last edge on shortest known path from <code>s</code> to <code>w</code></li>
</ul>

<p>여기서 만약 <code>e = v -&gt; w</code> 가 <code>w</code> 로의 더 짧은 거리라면, <code>distTo[w]</code> 와 <code>edgeTo[w]</code> 를 업데이트하면 된다.</p>

<p><img src='http://www.csupomona.edu/' ~ftang/courses/CS241/notes/images/graph/relax1.jpg" alt="" title="" />  </p>

<p><img src='http://faculty.ycp.edu/' ~dbabcock/PastCourses/cs360/lectures/images/lecture21/relaxation.png" alt="" /></p>

<p align="center">(<a href='http://www.csupomona.edu/' ~ftang'>http://www.csupomona.edu/~ftang</a>)</p>

<pre><code class="java">void relax(DirectedEdge e) {  
  int v = e.from();
  int w = e.to();

  if (distTo(w) &gt; distTo(v) + e.weight()) {
    distTo[w] = distTo[v] + e.weight();
    edgeTo[w] = e;
  }
}
</code></pre>

<h4 id="shortestpathsoptimalityconditions">Shortest-paths optimality conditions</h4>

<blockquote>
  <p>Let <code>G</code> be an edge-weighted digraph, then <code>distTo[]</code> are the shortest path distance from s iff:</p>
</blockquote>

<ul>
<li><code>distTo[s]</code> = 0</li>
<li>For each vertex <code>v</code>, <code>distTo[v]</code> is the length of some path from <code>s</code> to <code>v</code></li>
<li>For each edge <code>e = v -&gt; w</code>, <code>distTo[w] &lt;= distTo[v] + e.weight()</code></li>
</ul>

<p><strong>necessary condition</strong> </p>

<p>만약 어떤 <code>e = v -&gt; w</code>에 대해 <code>distTo[w] &gt; distTo[v] + e.weight()</code> 이면, <code>e</code> 를 이용한 <code>w</code> 까지의 거리가 <code>distTo[w]</code> 보다 더 짧다. 그러면 <code>distTo[w]</code> 는 <em>shortest path</em> 가 아니다.</p>

<p><strong>sufficient condition</strong></p>

<ul>
<li>Suppose <code>s = v0 -&gt; v1, ... -&gt; vk = w</code> is a shortest path from <code>s</code> to <code>v</code></li>
</ul>

<p>그러면</p>

<pre><code>distTo[v1] &lt;= distTo[v0] + e1.weight();  
...
distTo[vk] &lt;= distTo[v_k-1] + ek.weight(); 

// e_i is, i th edge on shortest path from s to w
</code></pre>

<p>이제 <code>distTo[v] = 0</code> 이라 하면</p>

<p><code>distTo[w] &lt;= e1.weight + ..., + ek.weight()</code></p>

<p>이 때 우변이 <em>shortest path</em> 위에 있는 <em>edge</em> 의 <em>weight</em> 값이므로, <code>distTo[w]</code> 는 <code>w</code> 까지의 <em>shortest path</em> 다.</p>

<p>(여기서는 필요충분조건 <code>p &lt;=&gt; q</code> 를 증명하기 위해 <code>p -&gt; q</code>, <code>q -&gt; p</code> 를 증명했다.)</p>

<h4 id="genericshortestpathsalgorithm">Generic Shortest-paths Algorithm</h4>

<pre><code>initialize distTo[s] = 0 and distTo[v] = infinity for all other vertices

Repeat until optimality conditions are satisfied,  
  Relax any edge
</code></pre>

<p>어떤 <em>edge</em> 를 고를까 하는 문제로 발전할 수 있다.</p>

<p>(1) <em>Dijkstra's algorithm</em>: <strong>non-negative weights</strong> <br />
(2) <em>Topological sort</em>: <strong>no directed cycles</strong> <br />
(3) <em>Bllman-Ford algorithm</em>: <strong>no negative cycles</strong></p>

<h3 id="dijkstrasalgorithm">Dijkstra's Algorithm</h3>

<pre><code>- Consider vertices in increasing order of dinstance from s
  (non-tree vertex with the lowest distTo[] value)

- Add vertex to tree and relax all edges pointing from that vertex
</code></pre>

<h4 id="correctness">Correctness</h4>

<blockquote>
  <p>Dijkstra's algorithm computes a SPT in any edge-weighted digraph with non-negative weights</p>
</blockquote>

<p>모든 <code>e = v -&gt; w</code> 는 단 한번씩만 <em>relaxed</em> 되기 때문에 알고리즘은 언젠간 종료된다. (<code>v</code> 가 <code>T</code> 에 추가되었을 때) </p>

<p>그리고 이 과정에서 <code>distTo[w] &lt;= distTo[v] + e.weight()</code> 가 유지된다. 왜냐하면 <code>distTo[w]</code> 는 줄어들기만 하고, <em>weight</em> 가 음수인 <em>edge</em> 가 없기 때문에 <code>distTo[v]</code> 는 변함이 없기 때문이다. </p>

<pre><code class="java">DirectedEdge[] edgeTo;  
double[] distTo;  
IndexMinPQ&lt;Double&gt; pq;

void DijkstraSP(EdgeWeightedDigraph G, int s) {  
  int V = G.V();
  edgeTo = new DirectedEdge[V];
  distTo = new double[V];
  pq = new IndexMinPQ&lt;Double&gt;(V);

  for(int v = 0; v &lt; V; v++) {
    distTo[v] = Double.POSITIVE_INFINITY;
  }

  distTo[s] = 0.0;
  pq.insert(s, 0.0);

  while (!ps.isEmpty()) {
    int v = pq.dequeue();
    for(DirectedEdge e: G.adj(v))
      relax(e);
  }
}

void relax(DirectedEdge e) {  
  int v = e.from();
  int w = e.to();

  if (distTo[w] &gt; distTo[v] + e.weight()) {
    distTo[w] = distTo[v] + e.weight();
    edgeTo[w] = e;

    if (pq.contains(w)) pq.decreaseKey(w, distTo[w]);
    else pq.insert(w, distTo[w]);
  }
}
</code></pre>

<p>프림 알고리즘과 마찬가지로 </p>

<p><code>T(n) = V insert + V delete-min + E decrease key</code> 인데, 이 연산들은 <em>Priority Queue</em> 구현에 따라 다를 수 있다. </p>

<p><em>undordered array</em> 라면 <code>V^2</code>, <em>binary heap</em> 이라면 <code>E log V</code> </p>

<p>따라서 <em>dense graph</em> 에서는 <em>array</em> 를, <em>sparse graph</em> 라면 <em>binary heap</em> 이 낫다.</p>

<h4 id="dijkstraandprim">Dijkstra and Prim</h4>

<p>둘 다 <em>spanning tree</em> 를 만들어 낸다. </p>

<ul>
<li>다익스트라는 <em>directed path</em> 에서 <em>source</em> 에서 가장 가까운 <em>vertex</em> 를 선택한다면, </li>
<li>프림 알고리즘은 <em>undirected edge</em> 내 에서 <em>tree</em> 에서 가장 가까운 <em>vertex</em> 를 선택한다.</li>
</ul>

<h3 id="edgeweighteddags">Edge-Weighted DAGs</h3>

<p><em>cycle</em> 이 없는 그래프는 <em>shortest path</em> 를 찾기 더 쉽다.</p>

<p><em>toplogical order</em> 순서로 <em>relaxing</em> 해 가면 된다. 어차피 방문 자체는 <em>topological order</em> 로 해야만 모든 <em>vertex</em> 를 방문할 수 있기 때문이다. </p>

<p>이 알고리즘에서 재미난 점은 음수 <em>weight</em> 가 있던 말던 상관이 없다는 것이다.</p>

<blockquote>
  <p>Topological sort algorithm computes SPT in <strong>any</strong> edge-weighted DAG in time proprotional to <code>E + V</code></p>
</blockquote>

<p>다익스트라와 마찬가지로 모든 <em>edge <code>e = v -&gt; w</code></em> 는 단 한번만 <em>relaxed</em> 되고, 이 과정에서 <code>distTo[w] &lt;= distTo[v] + e.weight()</code> 다.</p>

<p>(1) <code>distTo[w]</code> 는 줄어들기만 하고, <br />
(2) <em>topological order</em> 이기 때문에 한번 방문된 <code>v</code> 에 대해 이후의 <em>vertex</em> 에서 <code>v</code> 로 갈 수 없다. 있다면 <em>cycle</em> 이고 그럼 <em>toplogical order</em> 가 안된다. 따라서 <code>distTo[v]</code> 는 변하지 않는다. 따라서 <em>weight</em> 가 음수든 양수든 상관이 없다.</p>

<pre><code class="java">DirectedEdge[] edgeTo;  
double[] distTo;

public AcyclicSP(EdgeWeightedDigraph G, int s) {  
  int V = G.V();
  edgeTo = new DirectedEdge[V];
  distTo = new double[V];

  for(int v = 0; v &lt; V; v++) {
    distTo[v] = Double.POSITIVE_INFINITY;
  }

  distTo[s] = 0.0;

  Topological t = new Topological(G);

  for (int v : t.order()) {
    for (DirectedEdge e : G.adj(v)) {
      relax(e);
    }
  }
}
</code></pre>

<p>응용으로 <em>seam carving</em> 이 있다. 수직이나 수평으로 <em>shortest path</em> 를 찾아서 제거하면 된다.</p>

<p><img src='http://rahuldotgarg.appspot.com/data/SeamCarvingWeb/evaluation_files/image002.jpg'  alt="" /></p>

<p align="center">(<a href='http://rahuldotgarg.appspot.com/' >http://rahuldotgarg.appspot.com</a>)</p>

<p><em>longest path</em> 를 찾는법은 모든 <em>weight</em> 를 <em>negate</em> 하고, 찾고, 다시 결과의 <em>weight</em> 에 마이너스를 붙이면 된다. 이게 가능한 이유는 <em>no cycle</em> 이기 때문에 <em>weight</em> 가 음수든, 양수든 상관이 없기 때문이다.</p>

<p>응용해서 <em>Critical path method, CPM</em> 에 활용할 수 있다.</p>

<p>작업간 의존관계가 있으므로 이를 이용해서 <em>DAG</em> 를 그리면 된다. 각 <em>job</em> 당 <em>start vertex, finish vertex</em> 가 되며, 그 <em>weight</em> 는 <em>duration</em> 으로 하고 한 작업과 다음 작업의 <em>weight</em> 는 <code>0</code> 으로 했을때의 <em>longest path</em> 를 찾으면 된다. </p>

<p><img src='http://algs4.cs.princeton.edu/44sp/images/scheduling-critical-path.png'  alt="" /></p>

<p align="center">(<a href='http://algs4.cs.princeton.edu/44sp/' >http://algs4.cs.princeton.edu/44sp/</a>)</p>

<h3 id="negativeweights">Negative Weights</h3>

<p>다익스트라 알고리즘은 <em>negative weight</em> 에 대해서 작동하지 않는다. 모든 <em>weight</em> 에 일정 수 <code>n</code> 을 더해 모두 양수로 만들어도 똑같다. 심지어 이 경우는  <em>shortest path</em> 자체가 바뀐다. 따라서 다른 알고리즘이 필요하다.</p>

<p>진도를 빼기 전에 용어를 좀 정의하고 가면</p>

<p><em>negative cycle</em> 은, <em>directed cycle</em> 내의 모든 <em>weight</em> 를 더했을 때 음수인 경우를 말한다. 이 경우 <em>SPT</em> 는 없다. 이는 쉽게 보일 수 있는데</p>

<p><em>negative cycle</em> 이 존재하면 한번 이 사이클을 돌면, 전체 값이 음수이므로 어느 경로를 택해도 이전보다 더 짧아진다.</p>

<p>따라서 이 사이클을 돌면 내부 <em>vertex</em> 를 무한정 <em>relaxing</em> 할 수 있다.  </p>

<h4 id="bellmanfordalgorihm">Bellman-Ford Algorihm</h4>

<p><em>Bellman-Ford Algorihm</em> 은 <em>negative cycle</em> 이 있는지 검사할 수 있다.</p>

<ul>
<li>Initialize <code>distTo[s] = 0</code> and <code>distTo[v] = inf</code> 
for all other vertice</li>
<li>Repeat V times, relax each Edge</li>
</ul>

<pre><code>for (int i = 0; i &lt; G.V(); i++)  
  for(int v = 0; v &lt; G.V(); v++)
    for(DirectedEdge e: G.adj(v)) // pass i
      relax(e);     
</code></pre>

<p>벨만 포드 알고리즘은 <em>negative cycle</em> 이 없을때 <code>O(E * V)</code> 로 <em>shortest path</em> 를 찾아낸다. </p>

<p>증명은 <a href='http://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm' #Proof_of_correctness">여기</a>를 참조하도록 하자.</p>

<p>알고리즘을 잘 보면, 한 <em>pass</em> 에서 <code>distTo[v]</code> 가 변하지 않으면 그 이후에도 안 변한다. </p>

<blockquote>
  <p>If <code>distTo[v]</code> does not change during pass <code>i</code>, no need to relax any edge pointing from <code>v</code> in pass <code>i + 1</code></p>
</blockquote>

<p>따라서 <code>distTo[]</code> 가 변화한 <code>v</code> 의 리스트를 유지해서, 이것 대상으로 <em>relax</em> 하면 성능을 더 개선할 수 있다.</p>

<h4 id="findinganegativecycle">Finding a negative cycle</h4>

<p>벨만 포드 알고리즘은 <em>negative cycle</em> 을 찾아내는데 사용할 수도 있다. <em>negative cycle</em> 이 있을 경우 무한히 <em>relax</em> 를 해 내기 때문이다.</p>

<p>따라서 <code>V - 1</code> 까지 진행 한 후 <code>V</code> 번째에서 어느 <em>vertex</em> <code>v</code> 라도 업데이트 된다면, <em>negative</em> 사이클이 있다.</p>

<p><em>negative cycle</em> 은 <em>arbitrage detection</em> 에 사용할 수 있다.</p>

<h3 id="shortestpathcostsummary">Shortest Path Cost Summary</h3>

<p>(1) <strong>Topological Sort:</strong> No directed cycles</p>

<p>다익스트보다 더 빠르고, <em>negative weight</em> 도 문제 없다.</p>

<ul>
<li>typical: <code>E + V</code></li>
<li>worst: <code>E + V</code></li>
<li>extra space: <code>V</code></li>
</ul>

<p>(2) <strong>Dijkstra(binary heap):</strong> No negative weights</p>

<p>거의 <em>linear time</em> 이다.</p>

<ul>
<li>typical: <code>E logV</code></li>
<li>worst: <code>E logV</code></li>
<li>extra space: <code>V</code></li>
</ul>

<p>(3) <strong>Bellman Ford:</strong> No negative cycles</p>

<ul>
<li>typical: <code>E * V</code></li>
<li>worst: <code>E * V</code></li>
<li>extra space: <code>V</code></li>
</ul>

<p>(4) <strong>Bellman Ford(queue):</strong> No directed Cycles</p>

<ul>
<li>typical: <code>E + V</code></li>
<li>worst: <code>E * V</code></li>
<li>extra space: <code>V</code></li>
</ul>

<p><em>SPT</em> 를 정리하면</p>

<p><em>directed cycle</em> 은 문제를 더 어렵게 만들고,
<em>negative weight</em> 도 문제를 더 어렵게 만들고,
<em>negative cycles</em> 는 문제를 풀 수 없게 만든다. (내가 배운 한도 내에서는)</p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Part 2</em> by <strong>Robert Sedgewick</strong> <br />
(2) <a href='http://en.wikipedia.org/wiki/Bipartite_graph' >Wikipedia: Bipartite Graph</a> <br />
(3) <a href='http://www.biodatamining.org/content/4/1/10/figure/F3?highres=y' >http://www.biodatamining.org/</a> <br />
(4) <a href='http://ko.wikipedia.org/wiki/%ED%8F%89%EB%A9%B4_%EA%B7%B8%EB%9E%98%ED%94%84' >Wikipedia: 평면그래프</a> <br />
(5) <a href='http://www.csupomona.edu/' ~ftang">CS241 Lecture Notes: Graph Algorithms</a> <br />
(6) <a href='http://rahuldotgarg.appspot.com/data/SeamCarvingWeb/evaluation.htm' >Seam Carving for Content-Aware Image Resizing</a> <br />
(7) <a href='http://algs4.cs.princeton.edu/44sp/' >Algorithms: Shortest Path</a> <br />
(8) <a href='http://stackoverflow.com/questions/19760077/what-does-bellman-ford-algorithm-detects-negative-weight-or-negative-cycle' >What does bellman ford algorithm</a></p>]]></description><link>http://1ambda.github.io/graph-challenges-minimum-spanning-trees/</link><guid isPermaLink="false">22c06085-7f5c-45eb-8efc-31870d3ed425</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[graph]]></category><category><![CDATA[minimum spanning tree]]></category><category><![CDATA[shortest-path]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 03 Dec 2014 06:01:51 GMT</pubDate></item><item><title><![CDATA[Hash Table, Universal Hashing, Bloom filters]]></title><description><![CDATA[<h3 id="hashtable">Hash Table</h3>

<p>해시 테이블의 연산은 <em>key</em> 를 이용해 이런 작업들을 한다.</p>

<p>(1) <strong>insert:</strong> add new record <br />
(2) <strong>delete:</strong> delete existing record <br />
(2) <strong>lookup:</strong> check for a particular record</p>

<p>가끔 사람들이 <em>dictionary</em> 라 부르기도 하는데, 해시테이블은 알파벳 순서같은 특정 <em>order</em> 로 데이터를 저장하진 않는다.</p>

<p>이 3가지 연산이 거의 <code>O(1)</code> 라 보면 된다. 물론 이건 해시테이블을 잘 설계 했을때다. 슬프게도, 해시테이블은 <em>잘못</em> 구현하기 쉽다. 해시테이블이 <code>O(1)</code> 성능이 나오려면</p>

<ul>
<li>properly implemented</li>
<li>non-pathological data</li>
</ul>

<p>여기서 <em>non-pathological</em> 이란 <em>collision</em> 을 만들지 않는 데이터를 말한다.</p>

<h4 id="application">Application</h4>

<p>(1) 주어진 <em>object stream</em> 을 <em>de-duplication</em> 하기 위해 해시테이블을 쓸 수 있다. 해시테이블에 들어오는 객체를 <em>lookup</em> 해 보고 없으면 채워 넣고, 있으면 무시한다.</p>

<p>(2) <em>2-Sum Problem</em> 에도 해시테이블을 쓸 수 있다. <em>2-Sum</em> 을 푸는 <code>O(n logn)</code> 방법은, (<code>x + y = t</code>)</p>

<p>먼저 정렬 후 <code>A</code> 의 원소 <code>x</code> 에 대해 <code>t - x</code> 를 이진탐색하는 방법이다. 이렇게 하면 <code>O(n logn)</code> 으로 해결할 수 있다.</p>

<p>해시테이블을 이용하면 정렬 할 필요도 없고, 이진탐색 대신 <em>lookup</em> 으로 <code>O(1)</code> 시간에 원소를 검색할 수 있으므로 더 빨라진다.     </p>

<p>해시 테이블을 만드는데 <code>O(n)</code>, 탐색에 <code>O(1 * n)</code> 에서, <code>O(n)</code> 만에 <em>2-Sum</em> 을 해결할 수 있다.</p>

<p>(3) 이외에도</p>

<ul>
<li>symbol tables in compilers</li>
<li>blocking network traffic</li>
<li>search algorithm (e.g <strong>game tree exploration</strong>)</li>
</ul>

<h3 id="hashtableimplementation">Hash Table Implementation</h3>

<p>모든 집합을 의미하는 <em>universe <code>u</code></em> 에 대해 a reasonable size* 의 <em>evolving set</em> <code>s &lt;= u</code>* 을 유지하면 된다.</p>

<ul>
<li>배열로 구현할 경우 <em>lookup</em> 은 <code>O(1)</code> 이지만 메모리가 <code>O(|u|)</code> 다.</li>
<li>리스트로 구현할 경우 <code>O(|s|)</code> 의 메모리를 차지하지만, <em>lookup</em> 이 <code>O(|s|)</code> 다.</li>
</ul>

<p>더 나은 방법은 없을까?</p>

<p>(1) <em>bucket size</em> 인 <code>n ~ |s|</code> 인 <code>n</code> 을 고른다. 이 때 <code>|s|</code> 는 그렇게 많이 안 변한다고 가정하자. <br />
(2) 그 후 <em>hash function</em> <code>h: u -&gt; {0, 1, ..., n-1}</code> 인 <code>h</code> 를 고르면 된다. <br />
(3) 길이 <code>n</code> 의 배열 <code>A</code> 에, <code>A[h(x)]</code> 위치에 <code>x</code> 를 저장하면 된다.</p>

<p>이제 충돌 문제를 고민해 보자. 한 방에 <code>23</code> 명만 있어도, 생일이 같은 2명이 존재할 확률이 <code>50%</code> 가 넘으므로, </p>

<p><code>n</code> 에 비해 그리 크지 않은 <em>input size</em> 에 대해서도 충돌이 발생할 확률이 꽤 높다.</p>

<blockquote>
  <p><strong>Collision:</strong> dinstinct <code>x, y in u</code> such that <code>h(x) = h(y)</code></p>
</blockquote>

<h3 id="resolvingcollisions">Resolving Collisions</h3>

<p>충돌을 해결하기 위한 첫 번째 방법은</p>

<p>(1) <strong>Chaining:</strong></p>

<p><code>A[h(x)]</code> 을 리스토로 만들어 충돌이 발생하는 원소를 리스트에 저장한다.</p>

<p>(2) <strong>Open Addressing:</strong></p>

<p>충돌이 발생하면 새로운 <em>bucket</em> 을 찾도록 해 하나의 <em>bucket</em> 당 하나의 원소만 들어갈 수 있도록 한다.</p>

<blockquote>
  <p>hash function now specifies probe sequence <code>h_1(x), h_2(x), ...</code> keep trying til find open slot.</p>
</blockquote>

<p><br/></p>

<p><em>open addressing</em> 에서는 <em>probing, 탐사</em> 방식을 통해 비어있는 <em>bucket</em> 을 찾는다. 몇 가지 방법이 있는데</p>

<ul>
<li><strong>linear probing:</strong> 순차적으로 탐색한다. 캐쉬 히트는 높으나, 클러스터링에 취약하다.</li>
<li><strong>double hashing probing:</strong> 해쉬 함수 충돌이 발생하면 2차 해쉬 함수를 이용한다. 계산 비용이 비싸고, 캐쉬효율도 낮지만, 클러스터링에 영향을 받지 않는다.</li>
<li><strong>quadratic probing:</strong> 2차 함수를 이용해서 탐색을 위치를 찾는데, 캐싱과 클러스터링에서 두 방식의 중간정도의 성능을 보여준다.</li>
</ul>

<h4 id="clustering">Clustering</h4>

<p><em>key <code>k</code></em> 에 대한 최초의 해쉬 함수 값 <code>h(k)</code> <em>home position</em> 이라 부르는데, 같은 <em>home position</em> 를 갖는 <em>key</em> 들을 모아 <em>cluster</em> 라 부른다. <em>cluster</em> 가 커지면 커질수록, 클러스터의 중간을 <em>home position</em> 으로 하는 키가 들어올 확률도 높아지고, 인접한 클러스터와 합쳐지는 속도도 빨라진다.</p>

<p>결국 <em>linear probing</em> 의 경우 <em>load factor</em> 가 높아질수록 해쉬 테이블의 성능이 <code>O(n)</code> 으로 떨어진다.</p>

<h4 id="chainingvsopenaddessing">Chaining vs Open-addessing</h4>

<p><a href='http://sweeper.egloos.com/viewer/925740' >여기</a>를 인용하면</p>

<p><em>chaining</em> 은 <em>open addressing</em> 에 비해 다음의 장점을 가진다.</p>

<blockquote>
  <p>삭제 작업이 간단하다. 삭제 작업이 빈번하다면 <em>open addressing</em> 보다는 <em>chaining</em> 이 낫다.</p>
  
  <p><strong>chaining</strong> 은 클러스터링에 거의 영향을 받지 않아 충돌의 최소화만 고려하면 된다. 반면 <strong>open addressing</strong> 은 클러스터링까지 피해야 하므로 해쉬함수를 구현하기가 쉽지 않다.</p>
  
  <p><em>load factor</em> 가 높아져도 성능 저하가 선형적이다. 아래 그림에서 볼 수 있듯이, <em>open-addressing</em> 방법처럼 급격히 <em>lookup time</em> 이 늘지 않는다. 따라서 테이블 확장을 상당히 늦출 수 있다.</p>
</blockquote>

<p><img src='http://pds5.egloos.com/pds/200702/14/32/d0014632_11023351.jpg'  alt="" /></p>

<blockquote>
  <p>데이터의 크기가 <em>5 words and more</em> 이면, <em>open addressing</em> 보다 메모리 사용량이 적다. </p>
</blockquote>

<p>반면 <em>open addressing</em> 은</p>

<blockquote>
  <p>어떠한 포인터도 저장할 필요가 없고, 테이블 외부에 추가적인 공간이 필요 없으므로 메모리 효율이 높다.</p>
  
  <p>특히 <em>linear probing</em> 에서 뛰어난 <em>locality</em> 때문에 데이터가 캐쉬라인을 채울 정도로 크지 않다면 좋은 성능을 낼 수 있다.</p>
</blockquote>

<p>정리하자면,</p>

<blockquote>
  <p>open-addressing 방식은 테이블에 모두 저장될 수 있고 캐쉬 라인에 적합할 수 있을 정도로 데이터의 크기가 작을수록 성능이 더 좋아진다. 메모리 비용을 아끼려면, 이 방법이 적합하다.</p>
  
  <p>반면 테이블의 높은 load factor가 예상되거나, 데이터가 크거나, 데이터의 길이가 가변일 때 chained 해쉬 테이블은 open-addressing 방식보다 적어도 동등하거나 훨씬 더 뛰어난 성능을 보인다. 삭제가 중요하고, 빈번한 연산이라면 <em>chianing</em> 이 더 낫다.</p>
</blockquote>

<h3 id="whatmakesagoodhashfunction">What Makes a Good Hash Function?</h3>

<p><em>chaining</em> 을 생각해 보자. </p>

<ul>
<li><strong>insert:</strong> <code>O(1)</code></li>
<li><strong>lookup, delete:</strong> <code>O(list length in the bucket)</code></li>
</ul>

<p>이때 하나의 버켓에 들어있는 <em>list length</em> 는 <code>m/n</code> 부터 <code>m</code> 까지 일 수 있기 때문에 (<code>m</code> 개의 오브젝트에 대해), 해쉬 함수에 따라 성능이 정말 달라진다.</p>

<p>이로부터 좋은 해쉬함수의 기준을 알 수 있다.</p>

<blockquote>
  <ol>
  <li>Should lead to good performance => <em>"spread data out"</em> <br />
  (gold standard: completely random hashing)</li>
  <li>Should be easy to store / very fast to evaluate  </li>
  </ol>
</blockquote>

<h3 id="quickanddirtyhashfunction">Quick and Dirty Hash Function</h3>

<p>좋은 해쉬함수를 설계할 수 있다면 좋겠지만, 시간이 없을때 객체 <code>u</code> 를 받아 정수 <code>n</code> 으로 만들어 <em>bucket</em> 을 찾는 해쉬함수를 이렇게 디자인할 수 있다.</p>

<ul>
<li><code>u -&gt; n</code>: <em>hash code</em></li>
<li><code>n -&gt; bucket</code>: <em>compression function</em> using <code>mod</code></li>
</ul>

<p>여기서 <code>n</code> 은 어떻게 고를까? </p>

<p>(1) 우리가 <em>compression function</em> 으로 <code>mod</code> 를 사용하기 때문에 소수여야 한다. 소수가 아니라면, <code>n</code> 으로 나누어지는 모든 수는 <code>mod n == 0</code> 이 되어, 같은 <em>bucket</em> 에 할당될 것이다. 물론 이 수는 너무 커서는 안되고, 객체를 담을 수 있을만한 적당한 숫자여야 한다.</p>

<p>(2) <em>input data</em> 의 패턴을 고려해 <code>n</code> 을 정해야 한다. 예를 들어 <em>memory location</em> 이 4의 배수일 때, 테이블 사이즈 <code>n</code> 을 <code>2^j</code> 로 정해버리면, <code>mod n == 0</code> 이 되는 경우가 많아 <em>empty bucket</em> 이 많이 생길 것이다.</p>

<p>그리고 <code>n</code> 을 <code>2^k, 10^k</code> 로 정해버리는 경우 <code>mod</code> 연산이 시프팅으로 쉽게 구현되는데 이는 나머지 데이터를 고려하지 않고 일부의 데이터만으로 버킷을 찾아가므로 별로 좋은 선택이 아니다.</p>

<h3 id="loadfactor">Load Factor</h3>

<p><em>evenly spread out</em> 에 대해 고민해 보았으니, 이제 <em>non-pathological</em> 을 생각해 보자.</p>

<p>용어부터 정의하고 가면 <em>load factor</em> 는 해시테이블에 들어있는 오브젝트 수를, 버킷 수로 나눈 것이다.</p>

<p><em>open addressing</em> 의 경우에는 <em>load factor</em> 가 1보다 클 수 없지만 <em>chaining</em> 은 가능하다.</p>

<p>(1) <em>load factor</em> <code>a = O(1)</code> 이어야 연산이 <em>constant time</em> 이다. <br />
(2) <em>open addressing</em> 이라면 <code>x &lt;&lt; 1</code> 이어야 한다.</p>

<p>따라서 해시 테이블의 성능을 위해서는 <em>load factor</em> 를 조절해야 한다.</p>

<h3 id="pathologicaldatasets">Pathological Data Sets</h3>

<p>모든 데이터에 대해 <em>evenly spread out</em> 할 수 있는 해시함수가 있다면 좋겠지만, <strong>그런 해시 함수는 없다.</strong></p>

<p>모든 해시 함수는 자신만의 <em>pathological data set</em> 이 있다. 이는 쉽게 보일 수 있는데, <em>universe <code>u</code></em> 와 대해 버켓 수 <code>n</code> 에 대해 해시함수 <code>h: u -&gt; {0, 1, ..., n-1}</code> 이 있다고 하자.</p>

<p>비둘기 집 원리에 의해 모든 <em>bucket</em> 은 적어도 <code>|u|/n</code> 개의 데이터를 담고 있다. 따라서 <code>u</code> 중에서 어느 한 <em>bucket</em> 에만 담을 수 있는 데이터 셋을 고르면, 그것이 바로 <em>pathological data set</em> 이다.</p>

<p>이런 <em>pathological data set</em> 은 <em>service attack</em> 에 쓰이기도 한다. 따라서 오픈소스라면 리버스엔지니어링 하기 쉽지 않게끔 해시함수를 설계하는 것도 필요하다.</p>

<p>그럼 모든 해시 함수가 이런 데이터 셋을 가지고 있고, 심지어 공격에도 이용할 수 있다면 어떻게 해시함수를 설계해야 이런 문제를 조금이나마 피할 수 있을까?</p>

<p>(1) <strong>use a cryptographic hash function</strong> (e.g., <strong>SHA-2</strong>)  </p>

<p>infeasible to reverse engineer a pathological data set</p>

<p>(2) <strong>use randomization</strong>  </p>

<p>design a family <code>H</code> of hash funcitons such that data sets <code>S</code>, "almost all" functions <code>h in H</code> spread <code>S</code> out "pretty evenly" (compare to quicksort guarantee)</p>

<p>이제 <em>universal hashing</em> 이 무엇인지 알아보자</p>

<h3 id="universalhashingfunctions">Universal Hashing Functions</h3>

<blockquote>
  <p>Let <code>H</code> be a set of hash functions from <code>u</code> to <code>{0, 1, ..., n-1}</code></p>
  
  <p><code>H</code> is <strong>universal</strong> if and only if,</p>
  
  <p>for all <code>x, y in u (x != y)</code> <code>P[h(x) = h(y)] &lt;= 1/n</code> when <code>h</code> is chosen unifomly at random from <code>H</code> where <code>n</code> is the number of buckets. </p>
</blockquote>

<h4 id="hashingipaddresses">Hashing IP Addresses</h4>

<p><em>IP Address</em> 를 예로 들어 설명해보면 <em>IP</em> 를 <code>(x1, x2, x3, x4)</code> (<code>xi = 0 to 255</code>), <em>bucket</em> 수 <code>n</code> 을 소수라 하자.</p>

<p><em>tuple <code>a = (a1, a2, a3, a4), where ai in {0, ..., n-1}</code></em> 에 대해서</p>

<p><code>h_a</code> 를 이렇게 정의하자. 이러면 <code>h_a</code> 는 <code>n^4</code> 개 존재한다.</p>

<p><code>h_a(x1, x2, x3, x4) = (a1x2 + a2x2 + a3x3 + a4x4) mod n</code></p>

<p>이제 <code>h_a</code> 의 집합 <code>H</code> 는 <em>universal</em> 이다.</p>

<p><code>H = { h_a | a1, a2, a3, a4 in {0, 1, ..., n-1} }</code></p>

<h4 id="proof">Proof</h4>

<p>서로 다른 <em>IP</em> <code>(x1, x2, x3, x4), (y1, y2, y3, y4)</code> 를 생각해보자.</p>

<p>만약 <code>x4 != y4</code> 라면, 충돌이 일어날 확률은 얼마일까? 충돌에 대한 식을 좀 정리하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?collision%5C%20means%20%5C%5C%20%5C%5C%20%28a_1x_1%20&plus;%20a_2x_2%20&plus;%20a_3x_3%20&plus;%20a_4x_4%29%20%5Cmod%20n%20%3D%20%28a_1y_1%20&plus;%20a_2y_2%20&plus;%20a_3y_3%20&plus;%20a_4y_4%29%20%5Cmod%20n%20%5C%5C%20%5C%5C%20so%2C%20%5C%5C%20%5C%5C%20a_4%28x_4-y_4%29%20%5Cmod%20n%20%3D%20%5Csum_%7Bi%20%3D%201%7D%5E3%20a_i%28y_i%20-%20x_i%29%20%5Cmod%20n'  alt="" /></p>

<p>이 때 <code>a1, a2, a3</code> 를 고정하면 얼마나 많은 <code>a4</code> 에 대해 아래 식이 성립할까? </p>

<p><img src='http://latex.codecogs.com/gif.latex?a_4%28x_4-y_4%29%20%5Cmod%20n%20%3D%20%5Csum_%7Bi%20%3D%201%7D%5E3%20a_i%28y_i%20-%20x_i%29%20%5Cmod%20n'  alt="" /></p>

<p><code>xi, yi, a1, a2, a3</code> 가 <em>fixed</em> 기 때문에 우변은 <code>{0, ..., n-1}</code> 사이의 숫자고 <code>a4</code> 만 랜덤이다.</p>

<p>이 때</p>

<ul>
<li><code>x4 != y4</code> 이므로 <code>x4 - y4 != 0</code> 이다</li>
<li><code>n</code> 이 <code>ai</code> 의 최대값보다 큰수이면서 동시에 소수인데다가</li>
<li><code>a4</code> 가 <em>uniform at random</em> 이기 때문에</li>
</ul>

<blockquote>
  <p>left-hand side equally likely to be any of <code>{0, 1, ..., n-1}</code>.</p>
</blockquote>

<p>따라서 좌변이 특정 숫자인 우변과 같을 확률은 <code>1/n</code> 이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5Bh_a%28x%29%20%3D%20h_a%28y%29%5D%20%3D%20%7B1%20%5Cover%20n%7D'  alt="" /></p>

<h3 id="analysisofchaining">Analysis of Chaining</h3>

<p><em>universal hash functions</em> 의 정의를 한번 더 보고 넘어가면,</p>

<p><code>H</code> 가 해시함수 <code>u -&gt; {0, ..., n-1}</code> 의 집합일때 <code>H</code> 가 다음을 만족하면 <em>universal</em> 하다.</p>

<ul>
<li><code>x != y</code> 인 <code>u</code> 내의 <code>x, y</code> 에 대해 충돌이 일어날 확률 <code>P &lt;= 1/n</code> 이고</li>
<li><code>H</code> 내에서 <code>h</code> 가 <em>uniformly at random</em> 하게 선택될때</li>
</ul>

<p>만약 해시 테이블이 <em>chaining</em> 을 이용해 구현되었을때, <em>universal family</em> <code>H</code> 로부터 해시함수 <code>h</code> 가 <em>uniformly a random</em> 하게 선택되면 모든 연산이 <code>O(1)</code> 이다.</p>

<p>그리고, <code>|S| = O(n)</code> 다시 말해 <em>load factor</em> <code>alpha = |S| / n = O(1)</code> 임을, 해시 함수를 평가하는데 <code>O(1)</code> 임을 가정한다.</p>

<h4 id="proof">Proof</h4>

<p><em>unsuccessful lookup</em> 을 분석할건데, 다른 연산이 이보다는 항상 더 빠르므로 다른 연산의 <em>upper bound</em> 라 보면 된다.</p>

<p><code>S</code> 를 <code>|S| = O(n)</code> 인 데이터셋이라 하자. <code>x not in S</code> 인 <code>x</code> 를 <em>lookup</em> 한다 하면 <em>running time</em> 은</p>

<p><code>O(1) + O(list length in A[h(x)])</code> 다. 즉 <code>h(x)</code> 를 평가하는데 걸리는 시간과 해당 버킷 내의 리스트를 순회하는 시간의 합이다.</p>

<p>그런데 여기서 <code>A[h(x)]</code> 버킷의 리스트 길이를 <code>L</code> 이라 하면 이 <code>L</code> 은 <code>h</code> 선택에 따라 달라지는 <em>random variable, 확률변수</em> 다.</p>

<p>그럼 <em>average list length</em> 를 구해, <code>O(L)</code> 을 구해보자. 기대값의 선형성을 이용할건데, <code>E(L)</code> 을 위한 <code>1 or 0</code> 의 확률변수를 도입하자.</p>

<p><code>x != y</code> 인 <code>y in S</code> 에 대해 <code>z_y</code> 를 충돌이 날경우 <code>1</code> 로, 아닐 경우를 <code>0</code> 으로 하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?z_y%3D%20%5Cbegin%7Bcases%7D%201%2C%20%26%20%5Cmbox%7Bif%20%7Dh%28x%29%20%3D%20h%28y%29%20%5C%5C%200%2C%20%26%20%5Cmbox%7Bif%20%7Dh%28x%29%20%5Cneq%20h%28y%29%20%5Cend%7Bcases%7D'  alt="" /></p>

<p>이 때 해시함수가 무엇이든, 충돌이 날 경우에만 같은 버킷으로 들어가므로 버킷의 길이는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?L%20%3D%20%5Csum_%7By%5C%20%5Cin%5C%20S%7D%20z_y'  alt="" /></p>

<p>따라서</p>

<p><img src='http://latex.codecogs.com/gif.latex?E%28L%29%20%5C%5C%20%5C%5C%20%3D%20E%5B%5Csum_%7By%5C%20%5Cin%5C%20S%7D%20z_y%5D%20%5C%5C%20%5C%5C%20%3D%20%5Csum_%7By%5C%20%5Cin%5C%20S%7D%20E%28z_y%29%20%5C%20%5C%20%5Cmbox%7B%28apply%20linearity%20of%20expectation%29%7D%20%5C%5C%20%5C%5C%20%3D%20%5Csum_%7By%5C%20%5Cin%20%5C%20S%7D%20%7B1%20%5Cover%20n%7D%20%5C%5C%20%5C%5C%20%5Cleq%20%7CS%7C%20' *%20%7B1%20%5Cover%20n%7D%20%5C%5C%20%5C%5C%20%3D%20O%281%29" alt="" /></p>

<p>중간에 <code>H</code> 가 <em>universal</em> 이므로 <code>P[h(y) = h(x)] &lt;= 1/n</code> 이다.</p>

<h3 id="openaddressingperformance">Open Addressing Performance</h3>

<p><em>open addressing</em> 퍼포먼스를 계산할건데, <em>quick and dirty idealized analysis</em> 를 위해 <em>heuristic assumtion</em> 을 도입하면,</p>

<blockquote>
  <p>All <code>n!</code> probe sequences equally likely    </p>
</blockquote>

<p>이상적인 경우를 가정하면 얻어지는 것은</p>

<blockquote>
  <p>expected insertion time ~= <code>1 / (1 - a)</code> where <code>a = load factor</code></p>
</blockquote>

<p>다시 말해서, <code>a = 0.5</code> 라면 새로운 데이터를 집어넣기 위해 <code>2</code> 만큼 <em>probe</em> 해야한다는 소리다. 반면 <code>a ~= 1</code> 이면 (<code>1</code>에 가까워지면) <em>insertion</em> 타임은 어마어마하게 커진다.</p>

<blockquote>
  <p>A random probe finds an empty slot with probability <code>1 - a</code></p>
</blockquote>

<p>이 문제를 "<em>head</em> 를 얻기 위해 동전을 몇번 뒤집어야 하는가" 로 치환할 수 있다. 여기서 <code>Pr[heads] = 1 - a</code> 라 보면</p>

<p><em>head</em> 를 얻기 위해 동전을 뒤집는 수 <code>N</code> 에 대해 기대값 <code>E[N]</code> 은</p>

<p><img src='http://latex.codecogs.com/gif.latex?E%5BN%5D%20%3D%201%20&plus;%20%5Calpha%20%5C%20E%5BN%5D'  alt="" /></p>

<p>식을 풀면</p>

<p><img src='http://latex.codecogs.com/gif.latex?E%5BN%5D%20%3D%20%7B1%20%5Cover%201-%20%5Calpha%7D'  alt="" /></p>

<h4 id="linearprobing">Linear Probing</h4>

<p><em>open addressing</em> 방법으로 <em>linear probing</em> 을 사용할 경우, 아까의 <em>heuristic assumption</em> 자체가 성립하지 않는다.</p>

<p>따라서 다른 가정으로</p>

<blockquote>
  <p>initial probe uniformly random, independent for different keys.</p>
</blockquote>

<p>그러면 가정아래,  <em>expected insertion time</em> 은 <code>1 / (1 - a)^2</code> 에 가까워진다. (<em>D.E Knuth</em> 가 발견했다고 한다.)</p>

<h3 id="bloomfilter">Bloom Filter</h3>

<p>하던대로 <em>supported operation</em> 부터 이야기 하자.</p>

<p>블룸 필터는 해시테이블과 비슷하게 빠른 삽입, 탐색을 지원한다. 해시테이블과 비교했을때 메모리가 덜 든다. 반면 단점은</p>

<p>(1) Can't store an associated object <br />
(2) No deletions <br />
(3) small <strong>false positive</strong> pobability (but no false negative)</p>

<p>블룸 필터는 다양한 곳에 사용한다. </p>

<ul>
<li>early spell checkers (original)</li>
<li>list of forbidden passwords (canonical)</li>
<li>network routers (mordern)</li>
</ul>

<p>만약 메모리가 아주 비싸고, <em>false positive</em> 를 참을만 하다면 블룸필터는 좋은 선택이다. 연산도 아주 빠르다.</p>

<p>블룸 필터의 구성요소를 보자.</p>

<p>(1) 자료구조는 <code>n</code> 비트의 배열이다. <br />
(2) <code>k</code> 개의 해시 함수가 필요하다. (<code>k</code> 는 <em>small constant</em>)</p>

<p><em>insertion</em> 은 <code>i = 1, ..., k</code> 에 대해 <code>A[h_i(x)] = 1</code> 로 세팅하면 된다. 이미 <code>1</code> 이어도 덮어쓴다. 참고로 덮어쓰기때문에 <em>false positive</em> 는 있어도 <em>false negative</em> 는 없다. 자그마한 종양만 보여도 무조건 암이라 주장하는 소심한 의사라 보면 이해가 쉽다.</p>

<p><em>lookup</em> 은 <code>i = 1, ..., k</code> 에 대해 모든 <code>A[h_i(x)] = 1</code> 이면 찾으려는 <code>x</code> 가 존재한다.</p>

<p><em>false positive</em> 는 <code>A[h_i(x)]</code> 가 다른 <em>insertion</em> 에 의해 <code>1</code> 로 세팅 되었을때 발생한다.</p>

<p>블룸필터를 이미지로 보면</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Bloom_filter.svg/720px-Bloom_filter.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<p>블룸필터를 쓰는 것이 합리적인 선택이 되려면</p>

<p>(1) <code>n / |S|</code> 즉, 오브젝트당 비트 수가 충분히 작아야 한다. <br />
(2) <em>false positive</em>, 즉 에러 확률이 작아야한다.</p>

<p>동시에 두 조건을 작은 값으로, 모두 만족시키지 못한다면 그냥 해시 테이블을 쓰는 것이 더 낫다. </p>

<p>근데, 자세히 살펴보면 <em>space</em> 와 <em>error prob</em>, 이 두 조건은 <em>trade-off</em> 다.  </p>

<h3 id="bloomfilterheuristicanalysis">Bloom Filter: Heuristic Analysis</h3>

<p><em>heuristic assumption</em> 은</p>

<blockquote>
  <p>all <code>h_i(x)</code>' is uniformly random and independent (across different <code>i</code>'s and <code>x</code>'s</p>
</blockquote>

<p><code>k</code> 개의 해시함수를 가지는 <code>n</code> 비트 블룸 필터에 데이터셋 <code>S</code> 를 먼저 넣어놓자. 이제 블룸필터 <code>A</code> 의 각 비트가 1일 확률은,</p>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%281%20-%7B1%20%5Cover%20n%7D%29%5E%7Bk%7CS%7C%7D'  alt="" /></p>

<p>인데 이것은 한 비트가 <code>0</code> 일 확률을 <code>1</code> 에서 뺀 것이다. <code>0</code> 일 확률은 <code>k</code> 개의 해쉬 함수를 <code>|S|</code> 개의 모든 원소를 다 집어 넣은 후에도 <code>0</code> 인 확률이므로 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%281%20-%20%7B1%20%5Cover%20n%7D%29%5E%7Bk%7CS%7C%7D'  alt="" /></p>

<p>이 때 <code>e^x</code> 가 <code>1 + x</code> 의 <em>upper bound</em> 임을 이용하면, 각 비트가 1일 확률은</p>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%281%20-%7B1%20%5Cover%20n%7D%29%5E%7Bk%7CS%7C%7D%20%5C%5C%20%5C%5C%20%5Cleq%201%20-%20e%5E%7B-k%7CS%7C%20%5Cover%20n%7D%20%5C%20%5Cmbox%7B%5C%20%5C%20%281/n%20%5Csim%200%29%7D'  alt="" /></p>

<p>이 때 <code>n / |S| = b</code>, <code>b</code> 는 오브젝트당 비트 수 이므로</p>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%281%20-%7B1%20%5Cover%20n%7D%29%5E%7Bk%7CS%7C%7D%20%5C%5C%20%5C%5C%20%5Cleq%201%20-%20e%5E%7B-k%7CS%7C%20%5Cover%20n%7D%20%5C%5C%20%5C%5C%20%3D%201%20-%20e%5E%7B-k%20/%20b%7D'  alt="" /></p>

<p>이제 블룸필터에 한번도 입력되지 않은 데이터에 대해 <em>false positive</em> 확률 <code>P[FP]</code> 를 계산하면,</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5BFP%5D%20%5C%5C%20%5C%5C%20%5Cleq%20%281%20-%20e%5E%7B-k%20/%20b%7D%29%5Ek%20%5C%5C%20%5C%5C'  alt="" /></p>

<p>이 때 고정된 수 <code>b</code> 에 대해 에러일 확률 <code>P[FP]</code> 를 최소화 하는 <code>k</code> 를 찾으면</p>

<p><code>k ~ (ln2) * b</code> 다. 로그를 계산하면, <code>k ~ 0.693 * b</code> </p>

<p>따라서 </p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5BFP%5D%20%5Csim%20%28%7B1%20%5Cover%202%7D%29%5E%7B%28ln2%29b%7D'  alt="" /></p>

<p>이므로 오브젝트당 비트수 <code>b</code> 에 따라서 <em>false positive</em>, 즉 에러 확률이 <em>exponentially</em> 작아진다.</p>

<p>식을 거꾸로 풀면</p>

<p><img src='http://latex.codecogs.com/gif.latex?b%20%5Csim%201.44%20' *%20log_2%7B1%20%5Cover%20P%5BFP%5D%7D" alt="" /></p>

<p>이 두 식은 오브젝트당 비트수 <code>b</code> 와 <em>false positive</em> 의 <em>trade off</em> 를 보여준다.</p>

<p>만약 <code>b = 8</code> 이고 <code>k = 5, 6</code> 이면 에러 확률은 <code>2%</code> 정도다. </p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong> <br />
(2) <a href='http://sweeper.egloos.com/viewer/925740' >Hash Table</a> <br />
(3) <a href='http://www.slideshare.net/tanmaytan21/application-of-hashing-in-better-alg-design-tanmay' >http://www.slideshare.net/tanmaytan21</a> <br />
(4) <a href='http://en.wikipedia.org/wiki/Hash_table' >Wikipedia: Hash Table</a> <br />
(5) <a href='http://www.slideshare.net/sajidmarwatt/advance-algorithm-hashing-lec-ii' >http://www.slideshare.net/sajidmarwatt</a> <br />
(6) <a href='http://en.wikipedia.org/wiki/Primary_clustering' >Wikipedia: Primary Clustering</a> <br />
(7) <a href='http://en.wikipedia.org/wiki/Bloom_filter' >Wikipedia: Bloom Filter</a>    </p>]]></description><link>http://1ambda.github.io/hash-table-universal-hashing-bloom-filters/</link><guid isPermaLink="false">883e3230-b261-4993-9b7c-566513bcf026</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[universal hashing]]></category><category><![CDATA[bloom filter]]></category><category><![CDATA[open addressing]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Mon, 01 Dec 2014 07:44:37 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 8]]></title><description><![CDATA[<p>이번시간에는 <em>PCA</em> 와 <em>clustering</em> 을 배운다. <em>PCA</em> 가 어떻게 돌아가는지 알기위해 <em>covariance matrix</em>, <em>eigen decomposition</em>, <em>singular value decomposition</em> 등의 배경지식도 익혀보자. <del>K-means 는 거들뿐</p>

<h3 id="unsupervisedlearningintro">Unsupervised Learning Intro</h3>

<p><em>clustering</em> 은 다양한 분야에 활용할 수 있다.</p>

<ul>
<li>Market Segmentation</li>
<li>Social Network Analysis</li>
<li>Organize Computing Clusters</li>
<li>Astronomical Data Analysis</li>
</ul>

<h3 id="kmeans">K-Means</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360978231_7390.png'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360978245_9923.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>랜덤한 위치에 <em>centroid</em> 를 잡고, 가까운 점들을 색칠 한뒤 그 점들의 중심으로 <em>centroid</em> 를 옮겨가면서 집단을 만들어 낸다.</p>

<p><em>k-means</em> 의 인풋은 <em>centroid</em> 의 수인 <code>k</code> 와 <code>x1, x2, ... , xm</code> 의 트레이닝 셋이다. 구체적인 알고리즘은</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360978315_1086.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>매 이터레이션마다 <code>i to m</code> 까지 루프를 돌면서 클러스터링된 원소들의 배열인 <code>c^(i)</code> 에 <code>1 to K</code> 사이의 값을 넣는다. 이때 <code>c^(i)</code> 에 삽입될 값은, 해당 원소로부터 가장 가까운 <em>centroid</em> 의 인덱스다.</p>

<blockquote>
  <p><code>c^(i)</code> is index of cluster <code>(1, ..., K)</code> to which example <code>x^(i)</code> is currently assigned</p>
</blockquote>

<p>따라서 각 원소로부터의 거리를 최소로 하는 <code>k</code> 에 대해 <code>c^(i) = k</code> 다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_k%20%5Cleft%20%7B%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20%5Cmu_k%20%5Cright%20%5C%7C%20%7D%20%5C%5C%20%5C%5C%20%5CRightarrow%20c%5E%7B%28i%29%7D%20%3D%20k'  alt="" /></p>

<h3 id="optimizationobjective">Optimization Objective</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360979250_8035.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>k-means</em> 에서 최소화 하려는 <em>cost function</em> 은</p>

<p><img src='http://latex.codecogs.com/gif.latex?J%28c%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%29%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20%5Cmu_%7Bc%5E%7B%28i%29%7D%7D%20%5Cright%20%5C%7C'  alt="" /></p>

<p>다시 말해서 각 점에서 <em>centroid</em> 까지의 거리를 최소화 하는 것이 목표다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%7Bc%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%7D%20%5C%20%5C%20J%28c%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%29'  alt="" /></p>

<p>이 함수 <code>J</code> 를 다른말로는 <em>distortion function</em> 이라 부른다. 알고리즘을 다시 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360979289_8146.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>(1) <em>clustering assignment step</em> 에서는 <code>mu</code> 를 고정시키고 <code>c^(i)</code> 에 대해서 <code>J</code> 를 최소화 한다. <br />
(2) <em>move centroid step</em> 에서는 <code>c^(i)</code> 를 고정시키고 <code>mu</code> 에 대해서 <code>J</code> 를 최소화 한다.</p>

<h3 id="randominitialization">Random Initialization</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360980200_9803.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위쪽 예제는 <em>centroid</em> 의 랜덤 초기화에서 좋게 배치된 경우이고, 아래쪽은 운이 나쁜 경우를 설명하는 그림이다. 이것이 설명하는 바는 <em>centroid</em> 의 초기화에 따라 결과가 달라질 수 있다는 것이다. 아래 그림을 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360980222_7891.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>따라서 <em>local optima</em> 를 피가히 위해, 그리고 좋은 <em>clustering</em> 을 얻기 위해 <em>random initialization</em> 이용하여 <em>k-mean</em> 를 여러번 돌릴 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360980246_7140.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>여러번 <em>k-mean</em> 를 돌려 얻은 <code>J</code> 에 대해 최소값을 가지는 <code>J</code> 를 이용해 클러스터링을 얻을 수 있다.</p>

<p>그러나 <code>K</code> 가 매우 크다면, <em>random initialization</em> 들어가는 계산 비용에 비해 별로 좋은 결과를 돌려주지 못할 것이다. </p>

<p><em>random initialization</em> 을 하는 방법으로</p>

<blockquote>
  <p>Pick <code>k</code> distinct random integers <code>i_1, ..., i_k</code> from <code>{1, ..., m}</code>. <br />
  Set <code>mu_1 = x^(i_1), ..., mu_k = x^(i_k)</code></p>
</blockquote>

<h3 id="choosingthenumberofcluster">Choosing the Number of Cluster</h3>

<p><code>K</code> 값을 선택하기 위해 <em>Elbow method</em> 를 이용할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/16/1360981609_7528.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><code>K</code> 값의 변화에 따라 <em>distortion function</em> <code>J</code> 값이 급격히 감소하는 지점을 선택하는 방법이다. 그런데 <code>J</code> 값이 오른쪽 그림처럼 좀 애매하게 감소하면 어떻게 할까?</p>

<blockquote>
  <p>Sometimes, you are running K-means to get clusters to use for some later / downstream purpose. Evaluate K-means based on a metric for hwo well it perfomrs for that later purpose.</p>
</blockquote>

<p>예를 들어서, 몸무게 / 키 에 따라 집단을 분류해 그에 맞추어 티셔츠를 만든다고 할 때 <code>K = 3 or 5</code> 에 대해서는 단순히 좋은 클러스터링을 얻는것은 물론  어떤 <code>K</code> 가 수지타산이 더 맞을지 티셔츠 비즈니스적인 관점에서 생각을 해봐야 한다.</p>

<p><img src='http://my.csdn.net/uploads/201208/28/1346132804_2121.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<h3 id="dimensionalityreduction">Dimensionality Reduction</h3>

<p>이번엔 <em>unsupervised learning</em> 의 또 다른 기법인 <em>dimensionality reduction</em> 을 알아보자. 이 기법의 <em>motivation</em> 은 2가지다.</p>

<p>(1) Data Compression <br />
(2) Data Visualization  </p>

<h3 id="datacompression">Data Compression</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361235893_4367.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>두 축을 보면 하나는 인치로, 다른 하나는 센치다. <em>highly redundant data</em> 이기 때문에 하나의 차원으로 축소할 수 있다.</p>

<p>중복된 <em>feature</em>만 차원을 줄일 수 있는 것은 아니다</p>

<p>예를 들어 데이터의 한 축을 <em>pilot skill</em> 다른 축을 <em>pilot enjoyment</em> 라 하고 두 <em>feature</em> 간 관계를 거의 직선으로 나타낼 수 있다고 하자. 이 새로운 직선을 <em>pliot aptitude</em> 라 부르고 두개의 <em>feature</em> 를 대신하는 새로운 <em>feature</em> 로 사용할 수 있다.</p>

<p><em>feature</em> 가 한 두개면 중복되는 것을 걸러내거나, 새로운 <em>feature</em> 로 만들기 쉬운데 만약 수백개라면 이것도 일이다.</p>

<p>위 그림을 다시 보면 <code>x_1, x_2</code> 를 <code>z_1</code> 으로 대신하고 있다. <em>feature</em> 의 수가 줄어든 것이다.</p>

<p>이렇게 차원을 줄이면 연산량이 줄어들의 전체 알고리즘의 성능도 빨라진다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361235907_7086.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위 그림이 <em>dimensionality reduction</em> 에 대한 <em>intuition</em> 을 제공한다. 3차원의 데이터를 2차원의 평면으로 투영해 새로운 <em>feature set</em> 인 <code>z</code> 를 사용해 데이터를 나타낼 수 있다.</p>

<p>그림은 3차원 -> 2차원 이지만, 만약 10000 개를 1000 개를 줄일 수 있다면 어마어마한 중복을 줄일 수 있다.</p>

<p>조금 더 이해가 잘되는 3차원 그림을 가져오면</p>

<p><img src='http://scipy-lectures.github.io/_images/pca_3d_axis.jpg'  alt="" />
<img src='http://scipy-lectures.github.io/_images/pca_3d_aligned.jpg'  alt="" /></p>

<p align="center">(<a href='http://scipy-lectures.github.io/' >http://scipy-lectures.github.io</a>)</p>

<h3 id="datavisualization">Data Visualization</h3>

<p><em>dimensionality reduction</em> 의 두 번째 <em>motivation</em> 은 바로 <em>data visualization</em> 이다. </p>

<p><em>GDP</em>, <em>Country size</em> 등 다양한 <em>feature</em> 500개를 2개로 줄여 그래프에 그려보면 데이터에 대한 어떤 <em>intuition</em> 을 얻을 수도 있다. 즉 데이터가 주로 어떤 종류의 <em>feature</em> 에 의해 많이 영향을 받는지 파악할수 있다는 것이다.</p>

<p>강의에 나온 예제에서는 <code>z_1</code> 은 <em>country size / GDP</em>, <code>z_2</code> 는 <em>per person GDP</em> 였다.</p>

<p><em>visualization</em> 을 위한 경우 <code>2, 3</code> 개 정도로 차원을 줄일 수 있다.</p>

<h3 id="principalcomponentanalysisproblemformulation">Principal Component Analysis Problem Formulation</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236095_4842.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>2개의 <em>feature</em> <code>x_1, x_2</code> 를 하나로 줄인다고 하자. 이 경우 <em>projection error</em> (파란선의 길이) 를 최소로 하는 선 (빨강)을 찾으려고 할 것이다. 반면 자주색 선의 경우 <em>projection error</em> 가 가장 큰 선이라 볼 수있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236100_6448.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>따라서 <code>n</code> 차원을 <code>k</code> 차원으로 축소할때는 각 데이터를 <code>k</code> 개의 벡터 <code>u</code> 에 대해 투영시켰을때의 <em>projection error</em> 를 최소로 하는 벡터 <code>u</code> 를 찾으면 된다. </p>

<blockquote>
  <p>Reduce from <code>n</code>-dimension to <code>k</code>-dimension, find <code>k</code> vectors <code>u^1, ..., u^k</code> onto wihch to project the data, so as to minimized the projection error</p>
</blockquote>

<p>쉽게 생각하면 <code>k</code> 개의 <em>direction</em> 을 찾는다고 생각하면 된다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236106_9904.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>왼쪽 그림은 <em>linear regression</em> 에서 찾아내는 오차, 즉 <code>y</code> 값과 <em>prediction</em> 간의 거리이고 </p>

<p>우측 그림은 <em>PCA</em> 로 찾아낸 선과 각 점사이의 <em>projection error</em> 를 파란샌으로 나타냈다. </p>

<p>두 그림에서 볼 수 있듯이 <em>PCA</em> 는 <em>linear regression</em> 이 아니다. <em>PCA</em> 에서는 <code>y</code> 값이란 개념이 없다. </p>

<h3 id="pcaalgorithm">PCA Algorithm</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236182_1422.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>PCA</em> 전에는 <em>preprocessing step</em> 을 거친다. 이는 다양한 <em>feature</em> 간 스케일이 다르기 때문에 비교할만한 스케일을 얻기 위함이다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>그 후에는 <code>n</code> 차원으로부터 <em>projection error</em> 가 최소인 <code>k</code> 개의 벡터를 얻는 계산을 수행한다.</p>

<p>(1) 먼저 <code>Sigma</code> 라 부르는 <em>covariance matrix</em> 를 계산하고 (작은 시그마) <br />
(2) 그 후에 <code>Sigma</code> 의 <em>eigenvectors</em> 를 계산한다.  </p>

<p>여기서 <code>svd</code> 는 <em>sigular value decomposition</em> 을 의미한다. </p>

<p><code>Sigma</code> 를 얻기 위한 <em>vectorization</em> 은 <code>(1/m) * X' * X</code> 다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236425_3920.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><code>svd</code> 함수의 리턴값으로 <code>U</code> 매트릭스가 나오는데, 이건 <code>n x n</code> 매트릭스다. 여기서 첫 <code>k</code> 개의 컬럼을 취한다. 이 매트릭스를 <code>Y</code> 라 부르면 새로운 <em>feature vector</em>  <code>z</code> 는</p>

<p><code>z = Y^T * x</code></p>

<p>정리하면 아래 그림과 같다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236428_5117.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h3 id="pcadetails">PCA Details</h3>

<p>넘어가기 전에 잠깐 <em>PCA</em> 에서 다룬 <em>covariance matrix</em> 나 <em>eigen vector</em> 를 좀 보고 넘어가자.</p>

<h4 id="covariance">Covariance</h4>

<p>두 확률 변수 <code>X</code>, <code>Y</code> 에 대해서 <em>covariance</em> 는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csigma%28X%2C%20Y%29%20%3D%20E%5B%28X%20-%20E%28X%29%29%28Y%20-%20E%28Y%29%29%5D%20%5C%5C%20%5C%5C%20%3D%20E%28XY%29%20-%20E%28X%29E%28Y%29%20%5C%20%7B%5Ccolor%7BBlue%7D%20%28by%5C%20linearity%5C%20of%5C%20expectation%29%7D'  alt="" /></p>

<p>보면 알겠지만, 독립이면 <em>covariance</em> 값이 <code>0</code> 이다. 따라서 두 변수간 상관정도라 보면 된다. 공분산이 양수면 양의 상관관계를, 음수이면 음의 상관관계를 가진다. </p>

<p>이해를 위해서 <a href='http://darkpgmr.tistory.com/110' >여기</a>로 부터 인용을 하자면</p>

<blockquote>
  <p>x의 분산은 x들이 평균을 중심으로 얼마나 흩어져 있는지를 나타내고, x와 y의 공분산은 x, y의 흩어진 정도가 얼마나 서로 상관관계를 가지고 흩어졌는지를 나타낸다. 예를 들어, x와 y 각각의 분산은 일정한데 x가 E(x)보다 클때 y도 E(y)보다 크면 공분산은 최대가 되고, x가 E(x)보다 커질때 y는 E(y)보다 작아지면 공분산은 최소(음수가 됨), 서로 상관관계가 없으면 공분산은 0이 된다.</p>
</blockquote>

<p>공분산은 몇 가지 성질이 있는데 </p>

<p>(1) <code>X, Y</code> 가 독립이면 <em>covariance = <code>0</code></em> 이다. 그러나 역은 <em>gaussian random variable</em> 일때만 성립한다.  </p>

<p>(2) <img src='http://upload.wikimedia.org/math/0/6/0/060cda617e0812f174f5f75b6032b3dd.png'  alt="" title="" /></p>

<p>(3) <img src='http://upload.wikimedia.org/math/5/e/9/5e9674eac71398dcb022fc5cb76e2717.png'  alt="" title="" />  </p>

<p>(4) <img src='http://upload.wikimedia.org/math/8/2/3/823d4a54cac228efe1658718bfa7707a.png'  alt="" title="" />  </p>

<p>공분산마다 값이 다르기 때문에 비교를 위해 <code>X</code>, <code>Y</code> 의 표준편차로 나눈 것을 <em>correlation, 상관계수</em> 라 부른다.</p>

<p><img src='http://upload.wikimedia.org/math/0/7/6/076d3820a46afe55ee680f3c85e34c76.png'  alt="" /></p>

<p><br/></p>

<h4 id="covariancematrix">Covariance Matrix</h4>

<p>이제 <em>covariance matrix</em> 를 알아보자. 공분산 행렬은 데이터 <code>X</code> (벡터) 에 대해 <code>X</code> 의 두 원소 <code>X^(i), X^(j)</code> 간 공분산을 구한 행렬이다. <code>X</code> 를 <code>n</code> 벡터라 하면, <code>X</code> 의 공분산 행렬은 <code>n x n</code> 행렬이다. 그리고 <code>Cov(X, Y) = Cov(Y, X)</code> 이므로 <em>symmetric matrix, 대칭행렬</em> 이기도 하다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h4 id="eigenvectoreigenvalue">Eigen vector, Eigen value</h4>

<p>아까 슬라이드에서 잠깐 <em>eigen vector</em> 가 나왔는데, 우리말로 <em>고유벡터</em> 라 부른다. 고유벡터 <code>v</code> 는 행렬 <code>A</code> 곱했을때 상수 <code>λ</code> 와 다음의 관계를 가진다. (<code>A</code> 는 <code>n x n</code> 매트릭스)</p>

<p><img src='http://latex.codecogs.com/gif.latex?Av%20%3D%20%5Clambda%20v'  alt="" /></p>

<p>이해를 위해 <a href='http://darkpgmr.tistory.com/105' >여기</a>서 인용하면</p>

<blockquote>
  <p><em>square matrix</em> <code>A</code> 를 선형변환으로 봤을 때, 선형 변환 <code>A</code> 에 의한 변환 결과가 자기 자신의 상수배 <code>λ</code> 가 되는 <code>0</code> 이 아닌 벡터 <code>v</code> 를 <em>eigen vector</em> 라 하고, 이 <code>λ</code> 를 <em>eigen value</em> 라 한다.</p>
</blockquote>

<p>기하학적으로 보면</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Eigenvalue_equation.svg/375px-Eigenvalue_equation.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<h4 id="diagonalization">Diagonalization</h4>

<p><em>SVD</em> 에 대해 이야기 하기 전에 <em>matri diagonalizaion, 행렬 대각화</em> 도 좀 보자. </p>

<p>대각행렬은 <em>principal diagonal</em> 원소를 제외한 모든 원소가 0 인 <em>sqaure matrix</em> 인데, <em>sqaure matrix, 정방행렬</em> <code>A</code> 에 대해서</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5E%7B-1%7DAP%20%3D%20D'  alt="" /></p>

<p>인 <code>P</code> 와 <code>D</code> 가 존재하면 <code>A</code> 는 <em>diagonalizable matrix, 대각화 가능 행렬</em> <code>P</code> 를 <em>diagonalizing matrix, 대각화하는 행렬</em> 이라 부른다. </p>

<p>위 식에서 <code>D</code> 는 <em>diagonal matrix</em> 인데, </p>

<p><img src='http://latex.codecogs.com/gif.latex?D%20%3D%20%5Cbegin%7Bbmatrix%7D%20%5Clambda_1%20%26%200%20%26%20...%20%26%200%5C%5C%200%20%26%20%5Clambda_2%20%26%20...%20%26%200%5C%5C%20%5Cvdots%20%26%20%5Cvdots%20%26%20%5C%20%26%20%5Cvdots%5C%5C%200%20%26%200%20%26%20%5Ccdots%20%26%20%5Clambda_n%20%5Cend%7Bbmatrix%7D'  alt="" /></p>

<p>저 식에서 <code>A</code> 위주로 정리하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?A%20%3D%20PDP%5E%7B-1%7D'  alt="" /></p>

<p>이 때 <code>P</code> 가 고유벡터를 열벡터로 하는 행렬이고, <code>D</code> 가 고유값들을 대각 원소로 하는 대각행렬이면 <em>eigen decomposition</em> 이라 부른다.</p>

<p>위에서 <em>covariance matrix</em> 는 대칭행렬이라 말했는데, (<code>A = A^T</code>) 이 대칭행렬은</p>

<p>(1) 항상 <em>eigen decomposition</em> 이 가능하며 <br />
(2) <em>orthogonal matrix</em> 로 대각화가 가능하다. (<code>P^-1 = P^T)</code>  </p>

<h3 id="singularvaluedecomposition">Singular Value Decomposition</h3>

<p>이제, <em>Sigular Value Decomposition, 특이값 분해</em> 에 대해 이야기 하자. <em>SVD</em> 도 행렬을 대각화 하는 한 방법인데, <em>eigen decomposition</em> 과 달리 <code>m x n</code> 행렬에 적용 가능하다.</p>

<p><code>m x n</code> 행렬 <code>A</code> 에 대해 <em>SVD</em> 는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?A%20%3D%20U%20%5CSigma%20V%5ET'  alt="" /></p>

<p>여기서 <code>m x m</code> 의 <code>U</code> 는 <code>AA^T</code> 를 <em>eigen decomposition</em> 해서 얻은 <em>orthogonal matrix</em> 고, <code>U</code> 의 열벡터를 <code>A</code> 의 <em>left singular vector</em> 라 부른다. </p>

<p>이 때 <code>U</code> <em>eigen decomposition</em> 해서 나온 <em>diagonalizing matrix</em> 이므로 <code>U</code> 의 열벡터는 <code>AA^T</code> 의 <em>eigen vectors</em> 다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?AA%5ET%20%3D%20U%28%5CSigma%20%5CSigma%5ET%29U%5ET'  alt="" /></p>

<p><code>n x n</code> 의 <code>V</code> 는 <code>A^TA</code> 를 <em>eigen decomposition</em> 해서 얻은 <em>orthogonal matrix</em> 고 <code>V</code> 의 열벡터를 <code>A</code> 의 <em>right singular vector</em> 라 부른다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?A%5ETA%20%3D%20V%28%5CSigma%5ET%20%5CSigma%29V%5ET'  alt="" /></p>

<p>마찬가지로 <code>V</code> 도 <em>eigen decomposition</em> 의 결과로 얻은 <em>diagonalizing matrix</em> 이므로 <code>V</code> 의 열벡터는 <code>A^TA</code> 의 <em>eigen vectors</em> 다 </p>

<p><code>\\Sigma</code> 는 <code>AA^T, A^TA</code> 를 <em>eigen decomposition</em> 해서 얻은 <em>eigen value</em> 의 <em>square root</em> 를 대각원소로 하는 <code>m x n</code> 의 직사각 대각행렬이다. 이 때 대각 원소들이 <code>A</code> 의 <em>singular value, 특이값</em> 이다.</p>

<p><img src='http://cfile5.uf.tistory.com/image/277E3949525F5A872F520E'  alt="" /></p>

<p>(관련 그림과 설명은 <a href='http://darkpgmr.tistory.com/106' >여기</a>서 참조했습니다.)</p>

<p>이 때 <code>AA^T</code> 와 <code>A^TA</code> 의 고유값 <code>λ</code> 는 동일하며 0 이상이다. 그렇기 때문에 <em>square root</em> 를 씌우고, 동일한 행렬 <code>\\Sigma</code> 로 표현할 수 있다. (자세한 설명은 <a href='http://darkpgmr.tistory.com/106' >여기</a> 참조)</p>

<p><code>AA^T</code> 와 <code>A^TA</code> 의 공통의 고유값에 대해 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csigma_1%5E2%20%3E%3D%20%5Csigma_2%5E2%20%3E%3D%20%5Ccdots%20%3E%3D%20%5Csigma_s%5E2%20%3E%3D%200%20%5C%20%5C%20%28s%20%3D%20min%28m%2C%20n%29%29'  alt="" /></p>

<p>이고 여기에 <em>square root</em> 를 취한 것이 <code>A</code> 의 <em>singular value, 특이값</em> 이며, 이 특이값들을 대각원소로 하는 <code>m x n</code> 행렬이 <code>\\Sigma</code> 다.</p>

<p>이 때 <code>A</code> 의 특이값과 <em>left singular value</em> <code>u_i</code>, <em>right singular value</em> <code>v_i</code> 에 대해 </p>

<p><img src='http://latex.codecogs.com/gif.latex?Av_i%20%3D%20%5Csigma_i%20u_i'  alt="" /></p>

<p><em>SVD</em> 의 기하학적 의미는 <a href='http://darkpgmr.tistory.com/106' >여기</a>를 인용하면</p>

<blockquote>
  <p>행렬을 x' = Ax와 같이 좌표공간에서의 선형변환으로 봤을 때 직교행렬(orthogonal matrix)의 기하학적 의미는 회전변환(rotation transformation) 또는 반전된(reflected) 회전변환, 대각행렬(diagonal maxtrix)의 기하학적 의미는 각 좌표성분으로의 스케일변환(scale transformation)이다.</p>
  
  <p>행렬 R이 직교행렬(orthogonal matrix)이라면 RRT = E이다. 따라서 det(RRT) = det(R)det(RT) = det(R)2 = 1이므로 det(R)는 항상 +1, 또는 -1이다. 만일 det(R)=1라면 이 직교행렬은 회전변환을 나타내고 det(R)=-1라면 뒤집혀진(reflected) 회전변환을 나타낸다.</p>
  
  <p>따라서 식 (1), A = UΣVT에서 U, V는 직교행렬, Σ는 대각행렬이므로 Ax는 x를 먼저 VT에 의해 회전시킨 후 Σ로 스케일을 변화시키고 다시 U로 회전시키는 것임을 알 수 있다.</p>
</blockquote>

<p><img src='http://cfile2.uf.tistory.com/image/2725C84C5260AA5F28DFCA'  alt="" /></p>

<p align="center">(<a href='http://darkpgmr.tistory.com/106' >http://darkpgmr.tistory.com/106</a>)</p>

<p><br/></p>

<p>다시 처음의 슬라이드로 돌아가면 </p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>여기서 <code>svd</code> 함수의 인자 <code>Sigma</code> 가 <em>covariant matrix</em> 고 리턴값 <code>U, S, V</code> 가 각각 위에서 본 <code>U, \\Sigma, V</code> 다. </del>변수 이름을 헷갈리게 지으심;~~</p>

<p>마지막 질문이다. <em>PCA</em> 에서 데이터 매트릭스 <code>X</code> 에 대해 <em>covariant matrix</em> <code>XX^T</code> 로 구한 <em>eigen vector</em> 의 열벡터가, 왼쪽부터 순서대로 분산을 최대로 하는 벡터(방향)인데, (<a href='http://darkpgmr.tistory.com/110' >여기</a>참조)</p>

<p>왜 우리는 <em>SVD</em> 의 <code>U</code> 를 택하는 것일까? 다시 말해 <em>PCA</em> 와 <em>SVD</em> 는 무슨 관계일까?</p>

<p><a href='http://math.stackexchange.com/questions/3869/what-is-the-intuitive-relationship-between-svd-and-pca' >What is the intuitive relationship between SVD and PCA</a> 를 참조하면,</p>

<p>데이터 매트릭스 <code>X</code> 에 대해서, 공분산 매트릭스 <code>XX^T</code> 에 대해</p>

<p><img src='http://latex.codecogs.com/gif.latex?XX%5ET%20%3D%20WDW%5ET'  alt="" /></p>

<p>이 때 <code>X</code> 의 <em>SVD</em> 는</p>

<p><img src='http://latex.codecogs.com/gif.latex?X%20%3D%20U%20%5CSigma%20V%5ET'  alt="" /></p>

<p><code>U, V</code> 는 위에서 언급했듯이 <code>XX^T, X^TT</code> 의 고유값 분해로 얻은 대칭행렬 이므로 <code>VV^T = I, UU^T = I</code> 이다. 따라서</p>

<p><img src='http://latex.codecogs.com/gif.latex?XX%5ET%20%3D%20%28U%20%5CSigma%20V%5ET%29%28U%20%5CSigma%20V%5ET%29%5ET%20%5C%5C%20%5C%5C%20%3D%20%28U%20%5CSigma%20V%5ET%29%28V%20%5CSigma%20U%5ET%29%20%5C%5C%20%5C%5C%20%3D%20U%20%5CSigma%5E2%20U%5ET'  alt="" /></p>

<p>이므로 분산이 큰 순서대로의 벡터를 열벡터로 담고 있는 <code>XX^T = WDW^T</code> 에서의 <code>W</code> 가 바로 <em>SVD</em> 의 결과인 <code>U</code> 다.</p>

<p>실제로 <em>PCA</em> 를 하기 위해 <em>SVD</em> 를 이용하는건 <em>numerically</em> 더 낫다고 한다.</p>

<blockquote>
  <p>In fact, using the SVD to perform PCA makes much better sense numerically than forming the covariance matrix to begin with, since the formation of XX⊤ can cause loss of precision. This is detailed in books on numerical linear algebra, but I'll leave you with an example of a matrix that can be stable SVD'd, but forming XX⊤ can be disastrous</p>
</blockquote>

<p>다 정리하고 보니 드는 생각이, </p>

<blockquote>
  <p>"왜 공분산 행렬을 <em>eigen decomposition</em> 한 결과 <code>XX^T = WDW^T</code> 에서 <code>W</code> 가 공분산 행렬, 즉 데이터간 상관관계, 즉 데이터 그 자체를 설명하는 걸까?"</p>
</blockquote>

<p><a href='http://math.stackexchange.com/questions/23596/why-is-the-eigenvector-of-a-covariance-matrix-equal-to-a-principal-component' >여기</a> 에서 얻은 답은,</p>

<p>공분산 매트릭스 자체는 <em>diagonal matrix</em> 가 아니다. 다시 말해 데이터 <code>X</code> 의 각 변수간 상관 관계를 담고 있다. </p>

<p>그런데, 공분산 매트릭스를 대각화 한다면 변수간 상관관계는 사라진다. 다시 말해</p>

<p><code>XX^T = WDW^T</code> 에서 <code>D</code> 자체에는 본래 데이터 <code>X</code>의 변수간 상관 관계가 포함되어 있지 않다. 그러면, 그 데이터는 다 <code>W</code> 와 <code>W^T</code> 에 들어있다는 소리인데, <code>W^T</code> 는 <code>W</code> 로 표현 가능하므로 <code>W</code> 에 데이터간 상관 관계가 모두 담겨있다는 소리다.</p>

<blockquote>
  <p>Covariance matrix Cy (it is symmetric) encodes the correlations between variables of a vector. In general a covariance matrix is non-diagonal (i.e. have non zero correlations with respect to different variables).</p>
  
  <p>But it's interesting to ask, is it possible to diagonalize the covariance matrix by changing basis of the vector?. In this case there will be no (i.e. zero) correlations between different variables of the vector.</p>
  
  <p>Diagonalization of this symmetric matrix is possible with eigen value decomposition.</p>
</blockquote>

<p>그러면 마지막 질문, <code>W</code> 의 좌측열부터가 왜 높은 분산을 가질까? </p>

<h3 id="choosingthenumberofpca">Choosing the number of PCA</h3>

<p>적절한 <code>k</code> 의 수는 어떻게 구할까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236222_7050.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위에서 언급했듯이 <em>PCA</em> 가 하는 일은 <em>projection error</em> 를 최소화 하는 것이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B1/m%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20x_%7Bapprox%7D%5E%7B%28i%29%7D%20%5Cright%20%5C%7C%20%5Cover%201/m%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20%5Cright%20%5C%7C%20%7D%20%5Cleq%200.01'  alt="" /></p>

<p>인 <code>k</code> 를 구하면 99% 의 <em>variance</em> 가 유지된다. 적당한 <em>treshold</em> 값에 해당하는 <code>k</code> 값을 찾으면 된다.</p>

<p>알고리즘은 이런데 (좌측),</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236236_2278.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>매번 계산하는건 굉장히 비 효율적이다. 따라서 우측처럼 데이터에 대한 <em>singular value</em> 를 이용하면 더 계산이 쉬워진다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B%5Csum_%7Bi%20%3D%201%7D%5Ek%20%5Cover%20%5Csum_%7Bi%20%3D%201%7D%5En%20%7D%20%5Cgeq%200.99'  alt="" /></p>

<h3 id="reconstructionfromcompressedrepresentation">Reconstruction from Compressed Representation</h3>

<p>잘 보면 <em>PCA</em> 가 하는 일은 높은 차원의 데이터를 최대한 보존하면서 차수를 줄이는 일이다. 압축 알고리즘과 비슷하다. (실제로 이미지 압축에 쓴다고 한다.)</p>

<p>그럼 압축된 차원 <code>z</code> 에서 다시 본래의 데이터 차원 <code>x</code> 를 복구하려면 어떻게 해야할까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236299_8368.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위 그림처럼 <code>z = U^T * x</code> 라 할때 좌변에 <code>U</code> 를 곱하면 <code>x_app = U * z</code> 에서 <code>x_app</code> 는 거의 <code>x</code> 에 가까워진다.</p>

<h3 id="adviceforapplypca">Advice for Apply PCA</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236320_8959.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>supervised learning</em> 의 속도를 올리는데도 쓸 수 있다. 이미지가 <code>100 x 100</code> 이면 <code>10000</code> 개의 <em>feature</em> 인데, 이건 어마어마하다.</p>

<p>먼저 <em>input</em> <code>x</code> 를 뽑아내 여기에 대해 <em>PCA</em> 를 실행하면 차원을 줄인 <em>training set</em> 을 얻을 수 있다.</p>

<p>주의할점은 <code>U</code> 를 찾을때 <em>training set</em> 에만 하고 <em>cross validation</em> 이나 <em>test</em> 까지 포함해서 <code>U</code> 를 찾으면 안된다. 나중에 <em>training set</em> 으로만 찾아낸 <code>U</code> 를 이용해서 <em>CV, test</em> 에 대해 다시 <em>PCA</em> 하자.</p>

<p><br/></p>

<p>다른 <em>PCA</em> 응용으로는 </p>

<ul>
<li>Reduce memory, disk needed to store data</li>
<li>Speed up learning algorithm</li>
<li>Visualization (<code>k = 2 or 3</code>)</li>
</ul>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236325_5356.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>PCA</em> 를 이용하면 <em>feature</em> 의 수가 줄기 때문에 <em>overfitting</em> 을 방지하기 위해 사용할 수 있다고 생각하겠지만, 별로 좋은 생각은 아니다.</p>

<p>작동은 할지 모르겠지만 <em>regularization</em> 을 이용하는 편이 낫다. </p>

<p>왜냐하면 <em>PCA</em> 는 <code>y</code> 값이 없는 상태에서 작동하기 때문에 <code>y</code> 를 고려하지 않은 데이터가 손실이 발생할 수 있다. <code>1%</code> 만 손실된다 하더라도, 그 <code>1%</code> 가 <code>y</code> 와 관련해 굉장히 중요한 정보일 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/19/1361236329_4045.png'  alt="" /></p>

<p align="cener">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>또 다른 잘못된 <em>PCA</em> 의 사용으로는, 그냥 무작정 <em>PCA</em> 를 사용하는 것이다.</p>

<p><em>original data</em> <code>x</code> 에 대해 알고리즘을 구현도 안해보고, 바로 <em>PCA</em> 의 결과인 <code>z</code> 를 이용하려는건 좋은 생각이 아니다.</p>

<p><code>x</code> 대해 작업 해보고 결과가 별로일때 <em>PCA</em> 를 고려하자.</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a> <br />
(4) <a href='http://scipy-lectures.github.io/' >http://scipy-lectures.github.io</a> <br />
(5) <a href='http://en.wikipedia.org/wiki/Correlation_and_dependence' >Wiki: Correlation and dependence</a> <br />
(6) <a href='http://en.wikipedia.org/wiki/Covariance' >http://en.wikipedia.org/wiki/Covariance</a> <br />
(7) <a href='http://darkpgmr.tistory.com/110' >http://darkpgmr.tistory.com/110</a> <br />
(8) <a href='http://darkpgmr.tistory.com/105' >http://darkpgmr.tistory.com/105</a> <br />
(9) <a href='http://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors' >Wiki: Eigenvalues and Eigenvectors</a> <br />
(10) <a href='http://www.ktword.co.kr/abbr_view.php?m_temp1=4695&amp;id=762' >http://www.ktword.co.kr</a> <br />
(11) <a href='http://darkpgmr.tistory.com/106' >http://darkpgmr.tistory.com/106</a> <br />
(12) <a href='http://math.stackexchange.com/questions/3869/what-is-the-intuitive-relationship-between-svd-and-pca' >What is the intuitive relationship between SVD and PCA</a></p>]]></description><link>http://1ambda.github.io/machine-learning-week-8/</link><guid isPermaLink="false">7890e1dc-6d1c-4bc9-89a7-809af5f1ec82</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine lerning]]></category><category><![CDATA[k-means clustering]]></category><category><![CDATA[unsupervised learning]]></category><category><![CDATA[PCA]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 30 Nov 2014 05:39:31 GMT</pubDate></item><item><title><![CDATA[Intro to Computational Thinking and Data Science 3]]></title><description><![CDATA[<h3 id="optimizationproblems">Optimization Problems</h3>

<p>일반적으로 최적화 문제는 크게 두 파트로 구성된다.</p>

<blockquote>
  <ol>
  <li>An objective funciton that is to be maximized or minimized</li>
  <li>A set of constraint (possibly empty) that must be honored</li>
  </ol>
</blockquote>

<p>최적화 문제의 예로는</p>

<ul>
<li>Shortest path</li>
<li>Traveling salesman</li>
<li>Bin packaing</li>
<li>Sequence alignment</li>
<li>Knapsack</li>
</ul>

<p>이런 알려진 문제들을 공부함으로써 <em>problem reduction</em> 을 이용할 수 있다. </p>

<h3 id="knapsackproblem">Knapsack Problem</h3>

<p>먼저 <em>greedy approach</em> 를 사용해 보자. 이 방법을 적용하기 위해서는 무엇이 <em>best</em> 인지 정해야 한다. <em>value</em> 가 높은것이나, <em>value/weight</em> 가 높은것 등 다양한 기준을 세울 수 있다.</p>

<p>문제를 모델링 해보자. 아이템부터</p>

<pre><code class="python">class Item(object):  
    def __init__(self, n, v, w):
        self.name = n
        self.value = v
        self.weight = w

    def getName(self):
        return self.name

    def getValue(self):
        return self.value

    def getWeight(self):
        return self.weight

    def __str__(self):
        result = '&lt;' + self.name + ', ' + str(self.value)\
                 + ", " + str(self.weight) + '&gt;'

        return result

def buildItems():  
    names = ['clock', 'painting', 'radio',
             'vase', 'book', 'computer']

    vals = [175, 90, 20, 50, 10, 200]
    weights = [10, 9, 4, 2, 1, 20]

    Items = []

    for i in range(len(vals)):
        Items.append(Item(names[i], vals[i], weights[i]))

    return Items
</code></pre>

<p><em>greedy algorithm</em> 을 구현하면</p>

<pre><code class="python">def greedy(Items, maxWeight, predicate):  
    assert type(Items) == list and maxWeight &gt;= 0

    orderedItems = sorted(Items, key=predicate, reverse=True)

    result = []
    totalVal = 0.0
    totalWeight = 0.0
    i = 0

    while totalWeight &lt; maxWeight and i &lt; len(Items):
        if (totalWeight + orderedItems[i].getWeight()) &lt;= maxWeight:
            result.append(orderedItems[i])
            totalWeight += orderedItems[i].getWeight()
            totalVal += orderedItems[i].getValue()

        i += 1

    return (result, totalVal)

# predicate
def value(item):  
    return item.getValue()


def weightInverse(item):  
    return 1.0 / item.getWeight()


def density(item):  
</code></pre>

<p><em>predicate</em> 를 받아, 이 순서대로 <em>items</em> 를 정렬 한 뒤 반복문을 돌면서 아이템을 집어넣는다. <code>sorted</code> 함수는 <em>predicate</em> 에 따라 정렬 한 뒤 새로운 리스트를 생성한다.</p>

<pre><code class="python">orderedItems = sorted(Items, key=predicate, reverse=True)  
</code></pre>

<p>이제 테스트 코드를 작성하자.</p>

<pre><code class="python"># test
def testGreedy(Items, constraint, pred):  
    items, val = greedy(Items, constraint, pred)
    print ('Total value of items taken = ' + str(val))
    for item in items:
        print ' ', item

def simulation():  
    maxWeight = 20
    Items = buildItems()
    print ('Items to choose from')
    for item in Items:
        print ' ', item

    print 'by value'
    testGreedy(Items, maxWeight, value)
    print 'by 1 / weight'
    testGreedy(Items, maxWeight, weightInverse)
    print 'by density'
    testGreedy(Items, maxWeight, density)

simulation()  
</code></pre>

<p>결과는</p>

<pre><code>Items to choose from  
  &lt;clock, 175, 10&gt;
  &lt;painting, 90, 9&gt;
  &lt;radio, 20, 4&gt;
  &lt;vase, 50, 2&gt;
  &lt;book, 10, 1&gt;
  &lt;computer, 200, 20&gt;

by value  
Total value of items taken = 200.0  
  &lt;computer, 200, 20&gt;

by 1 / weight  
Total value of items taken = 170.0  
  &lt;book, 10, 1&gt;
  &lt;vase, 50, 2&gt;
  &lt;radio, 20, 4&gt;
  &lt;painting, 90, 9&gt;

by density  
Total value of items taken = 255.0  
  &lt;vase, 50, 2&gt;
  &lt;clock, 175, 10&gt;
  &lt;book, 10, 1&gt;
  &lt;radio, 20, 4&gt;
</code></pre>

<p>보면 알겠지만 탐욕적으로 접근했을때 항상 최적의 답안을 찾으리라는 보장이 없다. <del>패가망신</del></p>

<p>전체적인 성능은 <code>sorted</code> + <code>while</code> 에서, <code>O(n logn)</code> 이다. (<code>n</code> 은 아이템 갯수)</p>

<h3 id="01knapsackproblem">0/1 Knapsack Problem</h3>

<p><em>greedy</em> 는 최적의 답을 제공해 주지 않는다. 어떻게 해야할까? 한가지 방법은,</p>

<p>벡터 <code>L</code> 을 각 아이템의 가중치로 채우고, 벡터 <code>V</code> 를 각 아이템이 선택되었는지, 선택되지 않았는지를 <code>1/0</code> 으로 표시 한 뒤 <code>V * L</code> 이 최대가 되는 <code>V</code> 를 찾으면 된다. 물론 이 값은 무게의 최대치인 <code>W</code> 를 넘을 수 없다.</p>

<p>그럼 이제 문제는 다양한 종류의 <code>V</code> 를 만드는 문제로 치환된다. 일반적으로는 <code>V</code> 의 수는 <code>2^n</code> 이겠지만, 여기서는 <code>W</code> 란 제약조건이 있으므로 그것보다는 작은 수가 될 것이다.</p>

<p>넘어가기 전에 잠깐! 수의 크기에 대해 감을 잡고 넘어가자. 요즘 <em>CPU</em> 는 <code>1GHz</code> 는 그냥 넘으니까, 1초의 10억번이 넘는 연산을 할 수 있다. 한 작업에 대해 수백개의 명령이 필요하므로, 1초에 수백만의 작업을 할 수 있다. </p>

<p>수백만은 얼마나 큰 수일까? <code>10! = 3628800</code> 이다. 대략 11 ~ 10 개를 배열해도 백만가지의 순열이 만들어진다. 그리고 <code>2^20 = 1048576</code> 이므로 원소가 스무개인 집합의 부분집합이 백만개정도라 보면 된다. </p>

<p>따라서 최적해를 찾고자 할때는 <code>10!</code>, <code>2^22</code> 정도가 몇초 내외의 감당할만한 계산시간이라 볼 수 있다. </p>

<p><br/></p>

<h3 id="bruteforceapproach">Brute Force Approach</h3>

<p><em>power set</em> 을 만들어 보자.</p>

<pre><code class="python"># brute force
def int2bin(n, digit):  
    assert type(n) == int and type(digit) == int
    assert n &gt;= 0 and n &lt; 2 ** digit

    # binary string
    binStr = ''

    while n &gt; 0:
        binStr = str(n % 2) + binStr
        n = n // 2

    while digit - len(binStr) &gt; 0:
        binStr = '0' + binStr

    return binStr


def powerSets(Items):  
    count = 2 ** len(Items)
    binStrs = []

    for i in range(count):
        binStrs.append(int2bin(i, len(Items)))

    powerSet = []
    for bs in binStrs:
        elem = []
        for i in range(len(bs)):
            if bs[i] == '1':
                elem.append(Items[i])
        powerSet.append(elem)

    return powerSet
</code></pre>

<p>이제 테스트 함수를 작성하자.</p>

<pre><code class="python">def optimalItems(powerSet, constraint, getValue, getWeight):  
    optimalSet = None
    optimalValue = 0.0

    for Items in powerSet:
        ItemsValue = 0.0
        ItemsWeight = 0.0

        for item in Items:
            ItemsValue += getValue(item)
            ItemsWeight += getWeight(item)

        if ItemsWeight &lt;= constraint and ItemsValue &gt; optimalValue:
            optimalValue = ItemsValue
            optimalSet = Items

    return (optimalSet, optimalValue)


def bruteForceSolution():  
    Items = buildItems()
    pset = buildPowerSet(Items)

    items, value = optimalItems(pset, 20,
                                Item.getValue,
                                Item.getWeight)

    print ('brute force : ' + str(value))
    for item in items:
        print ' ', item
</code></pre>

<p>돌려보면</p>

<pre><code class="python">bruteForceSolution()

brute force : 275.0  
  &lt;clock, 175, 10&gt;
  &lt;painting, 90, 9&gt;
  &lt;book, 10, 1&gt;
</code></pre>

<p>다 좋은데, 아이템의 개수가 많아지면 <code>2^n</code> 으로 숫자가 커지므로 계산 비용이 어마어마하게 커진다. 다른 방법을 찾아보자.</p>

<h3 id="decisiontree">Decision Tree</h3>

<p>트리의 각 <em>depth</em> 를 아이템으로 표현하고, <em>left node</em> 를 <code>1 (selected)</code>, <em>right node</em> 를 <code>0 (unselected)</code> 로 정해 각 노드마다 전체 <em>value, weight</em> 를 기록하도록 하면 <em>search space</em> 를 상당히 줄일 수 있다. 왜냐하면 특정 아이템을 선택 한 후 무게를 초과하면, 그 하위 트리는 살펴보지 않아도 되기 때문이다.</p>

<p>이 트리를 <strong>decision tree</strong> 라 부른다.</p>

<pre><code class="python"># decision tree

def maxVal(items, avail):  
    if items == [] or avail == 0:
        result = (0, ())
    elif items[0].getWeight() &gt; avail:
        # do not take
        result = maxVal(items[1:], avail)
    else:
        current = items[0]
        # left branch : take the item
        leftValue, leftItems = maxVal(items[1:],
                                      avail - current.getWeight())
        leftValue += current.getValue()

        # right branch : do not take the item
        rightValue, rightItems = maxVal(items[1:],
                                        avail)

        if leftValue &gt; rightValue:
            result = (leftValue, leftItems + (current,))
        else:
            result = (rightValue, rightItems)

    return result


def decisionTreeSolution():  
    Items = buildItems()
    value, selected = maxVal(Items, 20)

    for item in selected:
        print item

    print ('decisition tree value : ' + str(value))
</code></pre>

<p>실행하면</p>

<pre><code class="python"># decisionTreeSolution()

&lt;book, 10, 1&gt;  
&lt;painting, 90, 9&gt;  
&lt;clock, 175, 10&gt;  
decisition tree value : 275  
</code></pre>

<p>모든 <em>power set</em> 을 살펴보지 않는다는 점에서 맘에 들지만, 가방의 용량이 상당히 크다면 <em>power set</em> 처럼 <code>2^n</code> 으로 증가할 수 있다.</p>

<h3 id="tradeoff">Trade Off</h3>

<p><em>greedy</em> 는 매 선택마다 최선을 택함으로써 <em>locally optimal</em> 을 찾지만 이게 <em>global optimal</em> 을 의미하진 않는다. 대신, 상당히 납득할만한 답안을 빠른 시간 안에 줄 수 있다.</p>

<h3 id="memoization">Memoization</h3>

<p><em>decision</em> 트리를 잘 보면 <em>sub-problem</em> 에서 같은 계산을 여러번 하는걸 볼 수 있다. 예를 들어 <code>{a, b, c, d}</code> 의 아이템이 있을때 <code>{a, c, d}</code> 와 <code>{b, c, d}</code> 는 다른 분기인데, 둘 다 <code>{c, d}</code> 를 계산하고 있다.</p>

<p>이 문제는 피보나치에서도 발견할 수 있는데,</p>

<pre><code class="python">def fib(n):  
    assert type(n) == int and n &gt;= 0

    if n == 0 or n == 1:
        return 1
    else:
        return fib(n-1) + fib(n-2)
</code></pre>

<p><code>fib(n-1)</code> 에서 <code>fib(n-2)</code> 를 계산하니까, <code>fib(n-2)</code> 를 두번 계산하는 셈이다.</p>

<p><img src='https://www.cs.cmu.edu/' ~adamchik/15-121/lectures/Recursions/pix/fib.bmp" alt="" /></p>

<p align="center">(<a href='https://www.cs.cmu.edu/' ~adamchik'>https://www.cs.cmu.edu/~adamchik</a>)</p>

<p>한번 계산한 결과는 저장해 놓고 다음에 쓰는 <em>memoization</em> 을 이용해 보자.</p>

<blockquote>
  <p><strong>Memoization:</strong> the first time we compute a function, keep track of the value; any subsequent time, just look up the value</p>
</blockquote>

<pre><code class="python">def fastFib(n, memo):  
    assert type(n) == int and n &gt;= 0

    if n == 0 or n == 1:
        return 1

    if n in memo:
        return memo[n]

    result = fastFib(n-1, memo) + fastFib(n-2, memo)
    memo[n] = result
    return result


def testFastFib(n):  
    assert type(n) == int and n &gt;= 0

    for i in range(n):
        print ('fast fib of', i, '=', fastFib(i, {}))
</code></pre>

<p><em>memoization</em> 은 <em>dynamic programming</em> 등에 사용할 수 있다. </p>

<h3 id="graph">Graph</h3>

<p><em>optimization problem</em> 은 <em>search problem</em> 이라 볼 수 있다. 다양한 탐색 공간 속에서 최적의 답을 검색해 나가는 문제와 동일하기 때문이다.</p>

<p>그래프를 모델링 해 보자.</p>

<pre><code class="python">class Node(object):  
    def __init__(self, name):
        self.name = str(name)

    def getName(self):
        return self.name

    def __str__(self):
        return self.name


class Edge(object):  
    def __init__(self, src, dest):
        self.src = src
        self.dest = dest

    def getSrc(self):
        return self.src

    def getDest(self):
        return self.dest

    def __str__(self):
        return str(self.src) + ' -&gt; ' + str(self.dest)


class WeightedEdge(Edge):  
    def __init__(self, src, dest, weight=1.0):
        self.src = src
        self.dest = dest
        self.weight = weight

    def getWeight(self):
        return self.weight

    def __str__(self):
        return str(self.src) + ' -&gt; ('\
            + str(self.weight) + ')'\
            + str(self.dest)


class Digraph(object):  
    def __init__(self):
        self.nodes = set([])
        self.edges = {}

    def addNode(self, node):
        if node in self.nodes:
            raise ValueError('duplicated node')
        else:
            self.nodes.add(node)
            self.edges[node] = []

    def addEdge(self, edge):
        src = edge.getSrc()
        dest = edge.getDest()

        if not(src in self.nodes and dest in self.nodes):
            raise ValueError('unknown node')

        self.edges[src].append(dest)

    def childrenOf(self, node):
        return self.edges[node]

    def hasNode(self, node):
        return node in self.nodes

    def __str__(self):
        res = ''

        for src in self.edges:
            for dest in self.edges[src]:
                res = res + str(src) + ' -&gt; ' + str(dest) + '\n'

        return res[:-1]


# undirected
class Graph(Digraph):  
    def addEdge(self, edge):
        Digraph.addEdge(self, edge)
        rev = Edge(edge.getDest(), edge.getSrc())
        Digraph.addEdge(self, rev)
</code></pre>

<p>그래프 최적화 문제의 예는</p>

<ul>
<li>Shortest path</li>
<li>Shortest weighted path</li>
<li>Cliques</li>
<li>Min cut</li>
</ul>

<p>이제 테스트 그래프를 만들어 보자.</p>

<pre><code class="python">def makeEdge(nodes, src, dest):  
    return Edge(nodes[src], nodes[dest])


def testGraph():  
    nodes = []

    # index will be the name of each node
    for idx in range(6):
        nodes.append(Node(idx))

    g = Digraph()

    for n in nodes:
        g.addNode(n)

    srcs = [0, 1, 2, 2, 3, 3, 0, 1, 3, 4]
    dests = [1, 2, 3, 4, 4, 5, 2, 0, 1, 0]

    for (s, d) in zip(srcs, dests):
        g.addEdge(makeEdge(nodes, s, d))

    print g
</code></pre>

<p>실행하면 이런 그래프를 얻을 수 있다.</p>

<p><img src='https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/L19_graph.png'  alt="" /></p>

<pre><code class="python">testGraph()

0 -&gt; 1  
0 -&gt; 2  
1 -&gt; 2  
1 -&gt; 0  
2 -&gt; 3  
2 -&gt; 4  
3 -&gt; 4  
3 -&gt; 5  
3 -&gt; 1  
4 -&gt; 0  
</code></pre>

<h3 id="dfs">DFS</h3>

<pre><code class="python"># assumes graph is a directed graph
def DFS(graph, start, end, path=[]):  
    path = path + [start]

    if start == end:
        return path

    for node in graph.childrenOf(start):
        if node not in path:
            newPath = DFS(graph, node, end, path)

            if newPath is not None:
                return newPath
</code></pre>

<p>테스트 코드를 돌려보면 알겠지만, 최단경로를 돌려주진 않는다.</p>

<pre><code class="python">def makeEdge(nodes, src, dest):  
    return Edge(nodes[src], nodes[dest])


def testGraph():  
    nodes = []

    # index will be the name of each node
    for idx in range(6):
        nodes.append(Node(str(idx)))

    g = Digraph()

    for n in nodes:
        g.addNode(n)

    srcs = [0, 1, 2, 2, 3, 3, 0, 1, 3, 4]
    dests = [1, 2, 3, 4, 4, 5, 2, 0, 1, 0]

    for (s, d) in zip(srcs, dests):
        g.addEdge(makeEdge(nodes, s, d))

    return g, nodes

def visit():  
    g, nodes = testGraph()
    path = DFS(g, nodes[0], nodes[5], [])

    for p in path:
        print p

visit()

0  
1  
2  
3  
5  
</code></pre>

<p>처음 찾은 목적지까지의 거리보다 더 짧은 목적지까지의 거리만을 탐색하는 알고리즘을 고려해보자. 가장 먼저 찾은 목적지까지거리를 <code>shortest</code> 에 저장하고, 이것보다 짧은 경로만 탐색한다.</p>

<pre><code class="python"># assumes graph is a directed graph
def shortestDFS(graph, start, end, path=[], shortest=None):  
    path = path + [start]

    if start == end:
        return path

    for node in graph.childrenOf(start):
        if node not in path:
            if shortest is None or len(path) &lt; len(shortest):
                newPath = shortestDFS(graph, node, end, path, shortest)
                if newPath is not None:
                    shortest = newPath

    return shortest
</code></pre>

<p>이부분이 핵심이다</p>

<pre><code class="python">if shortest is None or len(path) &lt; len(shortest):  
</code></pre>

<p>실제로 돌려보면 <code>0, 2, 3, 5</code> 로 최단경로를 돌려준다.</p>

<h3 id="clique">Clique</h3>

<p>각 점이 나머지 모든 점과 연결된 그래프를 <em>clique</em> 라 부르는데, 재미난 특징이 몇 개 있다.</p>

<p>(1) 모든 <em>edge</em> 의 수는 <code>n * (n - 1) / 2</code> 다. <br />
(2) 임의의 두 점 <code>A, B</code> 에 대해 길이가 <code>1 &lt;= m &lt;= (n-1)</code> 인 모든 경로는 <code>(n-2)! / (n-m-1)!</code> 이다. <br />
(3) <code>(2)</code> 를 이용하면, 모든 경로를 탐색할 경우의 퍼포먼스는 <code>O((n-2)!)</code> 이다. 여기서 <code>1/0! + 1/1! + 1/2! ... + 1/n! &lt;= e</code>, <code>e</code> 는 상수</p>

<h3 id="bfs">BFS</h3>

<pre><code class="python">def BFS(graph, start, end, q=[]):  
    init = [start]
    q.append(init)

    while len(q) != 0:
        # get a path from q
        current = q.pop(0)
        lastNode = current[len(current) - 1]
        if lastNode == end:
            return current

        for nextNode in graph.childrenOf(lastNode):
            if nextNode not in current:
                path = current + [nextNode]
                q.append(path)

    return None
</code></pre>

<h3 id="references">References</h3>

<p>(1) <em>MIT 6.00.2 2x</em> in <strong>edx</strong> <br />
(2) <a href='https://www.cs.cmu.edu/' ~adamchik/15-121/lectures/Recursions/recursions.html">https://www.cs.cmu.edu/</a></p>]]></description><link>http://1ambda.github.io/edx-600-2x-3/</link><guid isPermaLink="false">7426f518-4562-4acc-b98f-2d07e03a4ef4</guid><category><![CDATA[edx]]></category><category><![CDATA[decision tree]]></category><category><![CDATA[knapsack problem]]></category><category><![CDATA[memoization]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 28 Nov 2014 01:42:47 GMT</pubDate></item></channel></rss>