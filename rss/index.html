<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Old Lisper]]></title><description><![CDATA[Lisp, Emacs, Scala]]></description><link>http://1ambda.github.io/</link><generator>Ghost 0.5</generator><lastBuildDate>Wed, 26 Nov 2014 16:42:57 GMT</lastBuildDate><atom:link href="http://1ambda.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[하스켈로 배우는 함수형 언어 7]]></title><description><![CDATA[<p><em>the countdown problem</em> 은 프랑스 퀴즈 프로그램에서 유래한 문제입니다. 주어진 양수를 단 한번씩만 이용하여 특정 숫자를 만드는 문제입니다. 사용가능한 연산자는 <code>+, *, -, /</code> 입니다.</p>

<p>예를 들어 <code>(25 - 10) * (50 + 1) = 765</code> 입니다. </p>

<p>사람이 풀기엔 <em>search space</em> 가 좀 넓어서 답을 한번에 찾기 어렵지만, 컴퓨터는 무한한 인내심을 가지고 있기 때문에 풀기에 적합한 문제입니다.</p>

<h3 id="evaluatingexpressions">Evaluating Expressions</h3>

<p>이번시간엔 <em>bottom-up</em> 으로 접근해 볼까요? 먼저 연산자타입과 이를 적용하는 함수 <code>apply</code> 를 만들어보면</p>

<pre><code class="haskell">data Op = Add | Sub | Mul | Div

apply :: Op -&gt; Int -&gt; Int -&gt; Int  
apply Add x y = x + y  
apply Sub x y = x - y  
apply Mul x y = x * y  
apply Div x y = x `div` y  
</code></pre>

<p>그리고 우리가 가진건 양수이기 때문에, 연산의 결과가 양수인지 체크하기 위한 <code>valid</code> 함수를 만들어 보겠습니다. </p>

<pre><code class="haskell">valid :: Op -&gt; Int -&gt; Int -&gt; Bool  
valid Add _ _ = True  
valid Sub x y = x &gt; y  
valid Mul _ _ = True  
valid Div x y = x `mod` y == 0  
</code></pre>

<p>이제 수식을 나타내는 <code>Expr</code> 타입과 평가하기 위한 <code>eval</code> 함수를 만들면</p>

<pre><code class="haskell">data Expr = Val Int = App Op Expr Expr

eval :: Expr -&gt; [Int]  
eval (Val n) = [n | n &gt; 0]  
eval (App o l r) = [apply o x y | x &lt;- eval l,  
                                  y &lt;- eval r,
                                  valid o x y]
</code></pre>

<p>여기선 연산이 실패했음을 나타내기 위해 <code>[]</code> 를 사용했습니다. <code>Maybe</code> 타입 대신 리스트를 쓸 때의 장점은, <em>list comprehension</em> 을 이용할 수 있다는 점이지요!</p>

<h3 id="formalizingtheproblem">Formalizing The Problem</h3>

<p>우리가 풀어야할 문제는 가능한 모든 조합을 탐색해야하기 때문에 다양한 조합을 만들기 위한 <code>choices</code> 함수를 만들겠습니다.</p>

<pre><code class="haskell">-- subs [1, 2] -&gt; [[], [1], [2], [1, 2]]
subs :: [a] -&gt; [[a]]  
subs [] = [[]]  
subs (x:xs) = yss ++ map (x:) yss  
  where yss = subs xs

-- interleave 1 [2, 3] -&gt; [[1, 2, 3], [2, 1, 3], [2, 3, 1]]
interleave :: a -&gt; [a] -&gt; [[a]]  
interleave x [] = [[x]]  
interleave x (y:ys) = (x:y:ys) : map (y:) (interleave x ys)

-- perm [1, 2, 3] = [[1, 2, 3], [1, 3, 2], [2, 3, 1], ..]
perm :: [a] -&gt; [[a]]  
perm [] = [[]]  
perm (x:xs) = concat (map (interleave x) (perm xs))

-- choices [1, 2] -&gt; [[], [1], [2], [1, 2], [2, 1]]
choices :: [a] -&gt; [[a]]  
choices xs = concat (map (perm) (subs xs))  
</code></pre>

<p>여기서 <code>subs</code> 함수는 순서를 고려하지 않은 부분집합을, <code>perm</code> 는 순열을 돌려줍니다. <code>choices</code> 는 이 두 함수를 조합하여 부분집합의 순열리스트를 돌려줍니다.</p>

<p>이제 입력한 수식이 정답인지 알려주는 <code>solution</code> 함수를 볼까요? 입력한 수식의 결과가 주어진 수 <code>n</code> 과 같아야 하고, 수식에 있는 숫자가 주어진 숫자들의 나열 <code>ns</code> 와 같아야 합니다.</p>

<pre><code class="haskell">values :: Expr -&gt; [Int]  
values (Val n) = [n]  
values (App _ l r) = values l ++ values r

solution :: Expr -&gt; [Int] -&gt; Int -&gt; Bool  
solution e ns n = elem (values e) (choices ns) &amp;&amp; eval e == [n]  
</code></pre>

<h3 id="bruteforce">Brute Force</h3>

<p>브루트 포스 방법으로 풀려면, 사용가능한 수들을 받아, 가능한 모든 수식을 돌려주면 됩니다.</p>

<pre><code class="haskell">-- brute force
split :: [a] -&gt; [([a], [a])]  
split xs = [splitAt i xs | i &lt;- [1..(n-1)]]  
  where n = length xs

exprs :: [Int] -&gt; [Expr]  
exprs [] = []  
exprs [n] = [Val n]  
exprs ns = [e | (ls, rs) &lt;- split ns  
              , l &lt;- exprs ls
              , r &lt;- exprs rs
              , e &lt;- combine l r]

combine :: Expr -&gt; Expr -&gt; [Expr]  
combine l r = [App o l r | o &lt;- [Add, Sub, Mul, Div]]

-- brute force solutions
bSolutions :: [Int] -&gt; Int -&gt; [Expr]  
bSolutions ns n = [e | ns' &lt;- choices ns  
                     , e &lt;- exprs ns'
                     , eval e == [n]]
</code></pre>

<p>아주아주아주아주 느립니다. 제 컴퓨터에서는 2분이 지나도 답이 안나오네요.</p>

<pre><code class="haskell">&gt; length (Bolutions [1, 3, 7, 10, 25, 50] 765)
</code></pre>

<h3 id="fastversion">Fast version</h3>

<p>어느부분을 고쳐야 더 빨라질까요? 한가지 개선할 부분은, <code>valid</code> 가 너무 늦게 호출된다는 점입니다. 우리가 어마어마한 식을 만드는 반면, 답이 780개란 사실은 대부분의 식이 값보다는 형태에 의해 필터링 된다는 뜻입니다. 따라서 <code>valid</code> 를 좀 더 땡길 수 있다면 계산이 훨씬 빨라질겁니다.</p>

<pre><code class="haskell">eval :: Expr -&gt; [Int]  
eval (Val n) = [n | n &gt; 0]  
eval (App o l r) = [apply o x y | x &lt;- eval l,  
                                  y &lt;- eval r,
                                  valid o x y]

exprs :: [Int] -&gt; [Expr]  
exprs [] = []  
exprs [n] = [Val n]  
exprs ns = [e | (ls, rs) &lt;- split ns  
              , l &lt;- exprs ls
              , r &lt;- exprs rs
              , e &lt;- combine l r]

bSolutions :: [Int] -&gt; Int -&gt; [Expr]  
bSolutions ns n = [e | ns' &lt;- choices ns  
                     , e &lt;- exprs ns'
                     , eval e == [n]]
</code></pre>

<p>이 부분을 좀 고쳐보겠습니다. </p>

<pre><code class="haskell">results :: [Int] -&gt; [Result]  
results [] = []  
results [n] = [(Val n, n) | n &gt; 0]  
results ns = [res | (ls, rs) &lt;- split ns  
                  , lx &lt;- results ls
                  , ry &lt;- results rs
                  , res &lt;- combine' lx ry]

combine' :: Result -&gt; Result -&gt; [Result]  
combine' (l,x) (r, y) =  
  [(App o l r, apply o x y) | o &lt;- [Add, Sub, Mul, Div]
                            , valid o x y]

fastSolutions :: [Int] -&gt; Int -&gt; [Expr]  
fastSolutions ns n = [e | ns' &lt;- choices ns  
                       , (e, m) &lt;- results ns'
                       , m == n]
</code></pre>

<p>값을 평가하기 전에 먼저 <code>valid</code> 를 호출하고 계산된 값을 튜플에 저장해 놓았다가 나중에 비교합니다.</p>

<pre><code class="haskell">&gt; length (Bolutions [1, 3, 7, 10, 25, 50] 765)
-- 780
</code></pre>

<p>더 개선할 수 있을까요? 음.. 생각해보니 <code>x * y = y * x</code> 이기도 하고 <code>x * 1</code> 은 <code>x</code> 이기도 하네요. 이런것들을 좀 줄일수 있을겁니다. <code>valid</code> 함수를 고쳐보도록 하지요.</p>

<pre><code class="haskell">valid :: Op -&gt; Int -&gt; Int -&gt; Bool  
valid Add _ _ = True  
valid Sub x y = x &gt; y  
valid Mul _ _ = True  
valid Div x y = x `mod` y == 0

-- modified
valid :: Op -&gt; Int -&gt; Int -&gt; Bool  
valid Add x y = x &lt;= y  
valid Sub x y = x &gt; y  
valid Mul x y = x &lt;= y &amp;&amp; x /= 1 &amp;&amp; y /= 1  
valid Div x y = x `mod` y == 0 &amp;&amp; y /= 1  
</code></pre>

<p><code>x &lt;= y</code> 로 만들어 중복을 제거하고 <code>x /= 1</code> 을 이용해 1을 곱한 수식을 제거했습니다. 결과가 정말 빠르게 나옵니다. </p>

<p>책에서 말하기를 브루트 포스 방법은 44초, 그 다음버전은 4초, 마지막 버전은 0.44 초 만에 계산이 끝난다고 합니다. 연산 시간이 어마어마하게 줄어들었죠?</p>

<pre><code class="haskell">&gt; length (Bolutions [1, 3, 7, 10, 25, 50] 765)
-- 49
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em>  </p>]]></description><link>http://1ambda.github.io/haskell-intro7/</link><guid isPermaLink="false">334d7896-68cf-4d8b-943c-0a31e6ce3dfb</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 26 Nov 2014 16:22:28 GMT</pubDate></item><item><title><![CDATA[Process Mining, Week2]]></title><description><![CDATA[<p>지난 주 수업을 듣고 보니, 이벤트 로그를 만들어서 악성 사용자나, 비 정상적인 유저의 행동으로 부터 모델을 만들어서 어뷰징을 막거나, 부족한점을 개선해 서비스의 품질을 높일수도 있겠단 생각이 들었다.</p>

<p>근데 프로세스 마이닝에서 사용하는 이벤트 로그를 만들려면 <em>activity</em> 가 어떤 데이터가 되야할지 부터 정해야 하는데, 쉽지가 않다. 2주차에는 이런 고민들을 좀 해 보고, 프로세스 마이닝에서 사용하는 모델 표기법과 알파 알고리즘에 대해 논의한다.</p>

<p><img src='http://www.triua.com/wp-content/uploads/business-process-modeling-automation.jpg'  alt="" /></p>

<p align="center">(<a href='http://www.triua.com/' >http://www.triua.com/</a>)</p>  

<p><br/></p>

<h3 id="eventlogsandprocessmodels">Event Logs and Process Models</h3>

<p>지난 시간에 <strong>Play-in</strong>, <strong>Play-out</strong>, <strong>Replay</strong> 에 대해 잠깐 언급했는데, 이 중에서 <strong>Play-in</strong> 은 사람들이 정해진 규칙에 의해서가 아니라, 실제로 따르는 프로세스를 찾아낼 수 있다.</p>

<blockquote>
  <p><strong>Process discovery:</strong> learning de facto process models from observed behavior</p>
</blockquote>

<p>그리고 <strong>Replay</strong> 는 <em>conformance checking</em>, <em>prediction</em>, <em>bottleneck analysis</em> 에 사용할 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-17-728.jpg?cb=1305062721'  alt="" /></p>

<p align="center">(www.procesmining.org)</p>

<p>결국 <em>observed behavior</em> 의 기록인 <em>event-log</em> 를 모으는 것이 중요하다. 그런데, 모든 이벤트를 바로 <em>case id, activity name, timestamp</em> 로 매핑하긴 쉬운 일이 아니다.</p>

<p>예를 들어 이메일에서 <em>activity</em> 는 무엇일까? <del>어렵다.</del> 다양한 답이 나올 수 있지만, 딱 맘에 드는 답을 찾기 어렵다.</p>

<p><em>transactional information</em> 에서는 <em>event</em> 가 다양한 <em>state (상태)</em> 로 나타날 수 있다.</p>

<p><img src='http://www.cubrid.org/files/attach/images/220547/971/295/thread-state-diagram.png'  alt="" /></p>

<p align="center">(<a href='http://architects.dzone.com/' >http://architects.dzone.com</a>)</p>

<p>한 가지 더 생각해 볼 문제는 <em>case vs event</em> 다. <em>case</em> 는 <em>birth date</em> 처럼 변하지 않는 것이고, <em>event</em> 는 프로세스를 거치면서 변하는 속성들이다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter04gettingthedata-110510153210-phpapp01/95/process-mining-chapter-4-getting-the-data-6-728.jpg?cb=1305062568'  alt="" /></p>

<p>이벤트를 정의하는데 다양한 방법이 있어 혼란스러울 수 있겠지만, 다행히도 프로세스 마이닝에서 사용되는 표준 포맷이 있다. <em>eXtensible Event Stream, XES</em> 인데,</p>

<p><img src='http://fluxicon.com/blog/wp-content/uploads/2010/09/XES-Schema.png'  alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/' >http://fluxicon.com</a>)</p>

<p><br/> <br />
<em>control flow</em> 를 표현하는데는 다양한 방법이 있다. <em>BPMN, UML, Patri net</em> 등등..</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Animated_Petri_net_commons.gif/330px-Animated_Petri_net_commons.gif'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Petri_net' >http://en.wikipedia.org/wiki/Petri_net</a>)</p>

<p>이 표기법들을 선택하는데 2가지 기준을 세울 수 있다. </p>

<p>(1) <strong>search space:</strong> finding a model that captures reality well <br />
(2) <strong>visualization:</strong> what do end-users need to see?  </p>

<p>선택된 표기법이 <em>reality</em> 를 잘 반영하지 못할 수 있기 때문에, 다양한 표기법들을 알고, 사용해 보는것이 정말 중요하다.</p>

<h3 id="petrinets">Petri Nets</h3>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Animated_Petri_net_commons.gif/330px-Animated_Petri_net_commons.gif'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Petri_net' >http://en.wikipedia.org/wiki/Petri_net</a>)</p>

<p><em>Petri Net</em> 은 <code>token</code>, <code>place</code>, <code>transition</code>, <code>arc</code> 로 구성되어있다. 토큰은 한 <code>place</code> 에서 다음 <code>place</code> 로 이동할 수 있다. <em>petri net</em> 의 상태를 <em>marking</em> 이라 부른다. </p>

<p><em>transition</em> 의 경우 <em>input place</em> 가 토큰을 담고 있어야만 다음 <em>place</em> 로 토큰을 옮긴다. 다시 말해서 <em>transition</em> 이 <em>token</em> 을 <em>input places</em> 로 부터 <em>consume</em> 해서 <em>output place</em> 에 <em>token</em> 을 <em>produce</em> 한다.</p>

<p>독립적인 <em>transition</em> 이 있을때 모든 <em>transition</em> 은 동시에 작동할 수도, 하나씩만 작동할 수도 있다. </p>

<p>신호등을 모델링 해보면 <em>place</em> 는 <code>red, green,orange</code> 이고 <em>transition</em> 은 <code>rg, go, or</code> 이다. </p>

<p><img src='http://www.bpm-book.com/foswiki/pub/BpmBook/Exercise4-23/ex4-23.png'  alt="" /></p>

<p align="center">(<a href='http://www.bpm-book.com/' >http://www.bpm-book.com</a>)</p>

<p>하나의 신호등은 정말 그리기 쉬운데, 두개의 신호등을 모델링 하려면 좀 골치가 아프다. 우선 두개의 <em>petri net</em> 을 따로따로 사용할건가, 토큰만 두개로 늘릴건가를 생각해보자.</p>

<p>토큰이 두개인 경우는 하나의 신호등이 <code>green</code> 이고 다른 신호등이 <code>red</code> 인 경우, 어떤 신호등이 <code>green</code> 인지를 알려주지 않는다. <em>marking</em> 이 6가지가 나온다.</p>

<p>반면 두개의 <em>petri net</em> 을 사용하면 <em>marking</em> 이 9 가지가 되어 순서가 보존된다. 순열과 조합의 차이라 보면 되겠다.</p>

<p>근데, 두개의 <em>petri net</em> 을 사용하면 두 토큰이 동시에 <code>green</code> 에 있을 수 있다. 이건 교차로라면 교통사고를 야기할 수 있다.</p>

<p>그리고 한가지 더 생각해 볼 문제는 신호등의 순서다. <em>non-deterministic</em> 이면 한 신호등만 주구장창 파란불, 빨간불, 파란불, 이 될 수 있다. 따라서 한 신호등이 변하면 다음 신호등이 변하는 모델을 만들어야한다.</p>

<h4 id="reachabilitygraph">Reachability Graph</h4>

<p><em>transition</em> 에 따라 <em>marking</em> 이 변하는 그래프를 그릴 수 있는데, 이것을 <strong>reachability graph</strong> 라고 부른다. 이 그래프 내에서 각 상태가 <em>reachable marking</em> 이다.</p>

<h3 id="transitionsystemsandpetrinetproperties">Transition Systems and Petri Net Properties</h3>

<p><em>reachability graph</em> 는 한 상태에서 다른 상태로의 전환을 표현하므로 <em>transition system</em> 이라 볼 수 있다. 그리고, <em>reachability graph</em>는 <em>finite or infinite</em> 모두 가능하다.</p>

<h4 id="boundednesssafeness">Boundedness, Safeness</h4>

<p>어떤 <em>place</em> 에 <code>k</code> 이상의 토큰이 존재하는 <em>reachable marking</em> 이 없으면 <em><code>k</code>-bounded place</em> 라 부른다. 쉽게 생각하서 <em>upper bound</em> 라 보면 된다.</p>

<p>만약에 <em>petri net</em> 의 모든 <em>place</em> 가 <em>k-bounded</em> 면, 그 <em>petri net</em> 도 <em>k-bounded</em> 다. </p>

<p>이런 <code>k</code> 가 <em>petri net</em> 이나 <em>place</em> 가 있을수도 있고, 없을때도 있는데, 있을때만 <em>bounded petri net, bounded place</em> 라 부른다.</p>

<p>만약에 어떤 <em>petri net</em> 이 <em><code>1</code>-bounded</em> 면 <em>safe</em> 하다고 말한다.</p>

<h4 id="deadlock">Deadlock</h4>

<p>그리고, <em>dead marking</em> 은 더이상 적용 가능한 <em>transition</em> 이 없을때다. 그리고 <em>petri net</em> 에 <em>reachable dead marking</em> 이 있으면 잠재적으로 <em>deadlock</em> 이 발생할 수 있다.</p>

<p>따라서 모든 <em>reachable marking</em> 이 적어도 하나의 <em>transition</em> 이 있을때 <em>deadlock free</em> 하다고 말할 수 있다.</p>

<h4 id="safeness">Safeness</h4>

<p>어떤 <em>transition</em> <code>t</code> 대해, 어느 <em>reachable marking</em> 에서도 <code>t</code> 를 적용가능하면 <code>t</code> 는 <em>live</em> 하다. 그리고 모든 트랜지션이 <em>live</em> 면, <em>petri net</em> 은 <em>live</em> 다. </p>

<p><em>live petri net</em> 에서는 모든 트랜지션이 적용 가능하므로 <em>deadlock-free</em> 하다고 말할 수 있다.</p>

<h4 id="transitionsystem">Transition System</h4>

<p>이전에 보았던 <em>reachability graph</em> 는 <em>transition system</em> 의 특별한 종류다. 트랜지션 시스템은 <em>state</em> 와 <em>transitions</em> 로 구성되는데, 하나 이상의 <em>initial state</em> 와 0 개 이상의 <em>final states</em> 가 있다.</p>

<p>이 때 <em>initial state -> final state</em> 로의 <em>path</em> 를 <strong>complete trace</strong> 라 부른다.</p>

<p>모델로 부터 <em>transition system</em> 을 만들고 이것으로 부터 <em>complete trace</em> 를 만들 수 있는데, 문제는 트랜지션 시스템이 엄청나게 거대해 질 수 있거나 심지어는 무한할수도 있다는 사실이다.</p>

<p>단순히 <code>(token) -&gt; a1 -&gt; ()</code> 이란 간단한 모델에서 <code>a1, ..., ak</code> 만 해도 <code>2^k</code> 개의 트랜지션 시스템이 나온다. 어마어마하다</p>

<h3 id="workflownetsandsoundness">Workflow Nets and Soundness</h3>

<p><em>Petri net</em> 은 간편하긴 한데, 위에서 말했듯이 무한한 트랜지션 시스템이 나올 수 있고, 데드락이 발생할 수도 있다.</p>

<p>따라서 프로세스 마이닝에서는 모델을 만들기 위해 <em>end state</em> 가 있고, 위에서 언급한 <em>anomalies</em> 가 없는 <em>Petri net</em> 의 일종인 <em>Workflow Nets, WF-Nets</em> 를 사용하기도 한다.</p>

<p><img src='http://www.bpm-book.com/foswiki/pub/BpmBook/Exercise6-02/ex6-02.png'  alt="" /></p>

<p align="center">(<a href='http://www.bpm-book.com/' >http://www.bpm-book.com</a>)</p>

<p>본래 <em>WF-nets</em> 은 <em>BPM</em> 에서 쓰이던 것이다. <em>BPM</em> 은 IT 와 비즈니스를 연결해 주는 학문인데, </p>

<p><img src='http://bpmcenter.org/wp-content/uploads/BPM-lifecycle1.jpg'  alt="" /></p>

<p align="center">(<a href='http://bpmcenter.org/' >http://bpmcenter.org/</a>)</p>

<p><em>model-based analysis</em> 와 <em>data-based analysis</em> 를 반복하면서 모델을 개선한다.</p>

<p><em>BPM</em> 에서 모델의 역할은</p>

<p>(1) reason about processes (<strong>redesign</strong>) <br />
(2) make decisions inside processes (<strong>planning and control</strong>)  </p>

<p>안타깝게도 모델을 표현하는데 다양한 <em>notation</em> 이 있다. (언급 했듯이 <em>search space</em> 와 <em>visualization</em> 때문) 이 수업에서는 3 가지 표기를 사용한다.</p>

<ul>
<li>Business Process Model and Notation (<strong>BPMN</strong>)</li>
<li>Event-Driven Process Chains (<strong>EPCs</strong>)</li>
<li>Petri nets (Workflow nets)</li>
</ul>

<p>아래 이미지는 각각, <em>BPMN, EPCs</em> 다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-110510153158-phpapp01/95/process-mining-chapter-2-process-modeling-and-analysis-12-728.jpg?cb=1305062671'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-110510153158-phpapp01/95/process-mining-chapter-2-process-modeling-and-analysis-13-728.jpg?cb=1305062671'  alt="" /></p>

<p><br/></p>

<h4 id="goodmodel">Good Model</h4>

<p>좋은 모델이란 일반적으로 <em>sound WF-net</em> 을 말한다.</p>

<p><strong>Workflow net</strong> 이란</p>

<blockquote>
  <p>A <strong>Workflow net</strong> has one source place(start) and one sink place(end) and all other nodes are on a path from source to sink.</p>
</blockquote>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-110510153158-phpapp01/95/process-mining-chapter-2-process-modeling-and-analysis-10-728.jpg?cb=1305062671'  alt="" /></p>

<p><em>Workflow net</em> 이 <em>sound</em> 라는건</p>

<blockquote>
  <p>A workflow net is <strong>sound</strong> if and only if the following properties hold:</p>
  
  <p>(1) <strong>safeness:</strong> places cannot hold multiple tokens at the same time <br />
  (2) <strong>proper completion:</strong> if the sink place is marked, all other places are empty <br />
  (3) <strong>option to complete:</strong> it is always possible to reach the marking that marks just the sink place <br />
  (4) <strong>absence of dead parts:</strong> for any transition there is a firing sequence enabling it  </p>
</blockquote>

<p>작은 모델은 <em>soundness</em> 를 검사하기 쉬울지 모르지만, 모델이 커지만 좀 힘들 수도 있다. 여기에 사용할 수 있는 몇 가지 테크닉이 있다.</p>

<p>(1) 우선 <em>option to complete</em> 와 <em>proper completion</em> 을 보면, <em>proper completion</em> 이 거짓이면 <em>option to complete</em> 도 거짓이므로 검사할 필요가 없다. 반대로 <em>option to complete</em> 가 참이면 I<em>proper completion</em> 도 참이다.</p>

<blockquote>
  <p>option to complete impiles proper completion</p>
</blockquote>

<p>(2) 만약 <em>WF-net</em> 의 <em>end</em> 에서 <em>start</em> 로 트랜지션을 만든 <em>short-circuited petri net</em> 이 <em>live, bounded</em> 면 <em>WF-net</em> 은 <em>sound</em> 다.</p>

<blockquote>
  <p>A WF-net is <strong>sound</strong> if and only if the corresponding "short circuted" Petri net is <strong>live</strong> and <strong>bounded</strong></p>
</blockquote>

<h4 id="modelbasedanalysis">Model-based Analysis</h4>

<p>위에서 본 <em>soundness checking</em> 같은 검증이나 <em>performance analysis</em> 같은 시뮬레이션이 모델-베이스드 분석해서 주로 하는 일이다. 근데, 이런 검증이나 시뮬레이션은 모델이 높은 퀄리티를 가져야만 한다는 한계가 있다. 프로세스 마이닝은 이런 모델기반 분석과 실제 데이터를 연관시킨다. </p>

<p><img src='http://image.slidesharecdn.com/processminingchapter02processmodelingandanalysis-110510153158-phpapp01/95/process-mining-chapter-2-process-modeling-and-analysis-24-728.jpg?cb=1305062671'  alt="" /></p>

<p><br/></p>

<h3 id="alphaalgorithm">Alpha Algorithm</h3>

<p><em>alpha algorithm</em> 을 이용해서 모델을 발견할 수 있다. 즉 아래 그림에서, <em>discovery</em> 에 해당하는 과정이다. 이벤트로그로 부터 모델을 만드는 과정을 <em>play-in</em> 이라 부르기도 한다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-3-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>이벤트 로그를 간략화 하면 <em>activity</em> 의 <em>order</em> 가 된다. 즉, <em>timestamp</em> 가 <em>order</em> 로 표현되고, 한 묶음의 <em>ordered activity</em> 가 모여서 <em>trace</em> 가 된다. 예를 들어서 다음은 이벤트 로그라 볼 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-5-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/> <br />
알파 알고리즘의 목적은 이렇게 간략화된 이벤트 로그를 이용해 모델을 뽑아내는 것이다.</p>

<h4 id="operations">Operations</h4>

<p>몇 가지 연산자를 알고 넘어가자</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-11-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/> <br />
(1) <strong>direct succession:</strong> <code>x &gt; y</code>, iff for some case x is directly followed by y <br />
(2) <strong>causality:</strong> <code>x -&gt; y</code>, iff <code>x &gt; y</code> and not <code>y &gt; x</code> <br />
(3) <strong>parallel:</strong> <code>x || y</code>, iff <code>x &gt; y</code> and <code>y &gt; x</code> <br />
(4) <strong>choice:</strong> <code>x # y</code>, iff not <code>x &gt; y</code> and <code>y &gt; x</code></p>

<p><br/></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-18-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>그러면 이 연산자를 조합해 패턴을 발견할 수 있다.</p>

<p>(1) <em>sequence:</em> <code>a -&gt; b</code> <br />
(2) <em>XOR split:</em> <code>a -&gt; b</code>, <code>a -&gt; c</code>, <code>b # c</code> <br />
(3) <em>XOR join:</em> <code>b -&gt; d</code>, <code>c -&gt; d</code>, <code>b # c</code> <br />
(4) <em>AND split:</em> <code>a -&gt; b</code>, <code>a -&gt; c</code>, <code>b || c</code> <br />
(5) <em>AND join:</em> <code>b -&gt; d</code>, <code>c -&gt; d</code>, <code>b || c</code></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-15-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<h4 id="footprint">Footprint</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-16-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>각 트랜지션 사이에 테이블을 하나 만들면 이처럼 생겼는데, <em>footprint</em> 라 부른다. 우리가 로그를 이용해 만든 모델과, 로그의 풋 프린트는 동일하다. </p>

<blockquote>
  <p>Log and model agree on footprint</p>
</blockquote>

<p><br/></p>

<h4 id="logics">Logics</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-19-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>알파 알고리즘은 이렇게 생겼는데, 너무 개략적으로 설명해 주셔서 나도 개략적으로 밖에 알지 못한다. 간략히 설명하면</p>

<p>(1) <em>activity</em> 를 <em>transition</em> 으로 매핑한다 <br />
(2) 첫 번째 트랜지션을 찾는다 <br />
(3) 마지막 트랜지션을 찾는다</p>

<p>두 인접한 트랜지션 사이에 있는 것은 <em>place</em> 이므로, 두 인접한 트랜지션을 찾아보자. 먼저</p>

<p>(4) <code>(A, B)</code> 를 계산한다  </p>

<p>이 때 <code>A</code> 내에 있는 모든 <code>a</code> 와 <code>B</code> 내에 있는 모든 <code>b</code> 에 대해 <code>a &gt; b</code> 이고, <code>a1 # a2</code>, <code>b1 # b2</code> 인 <code>(A, B)</code> 를 찾는다.</p>

<blockquote>
  <p>Find paris <code>(A, B)</code> of sets of activities such as that every element <code>a</code> in <code>A</code> and every element <code>b</code> in <code>B</code> are causally related, all element in <code>A</code> are independent and all elements in <code>B</code> are independent</p>
</blockquote>

<p>(5) <em>non-maximal pair</em> 를 제거한다. </p>

<p><code>(4)</code> 에서 찾은 <code>(A, B)</code> 는 부분집합을 가질 수 있다. 이러면 <em>sub-pair</em> 로 인해 <code>place</code> 가 또 생길 수 있으므로 제거한다.</p>

<p>예를 들어 <code>[({b}, {d}), ({b, e}, {d})]</code> 이 있다면 <em>sub-pair</em> <code>({b}, {d})</code> 를 제거한다.</p>

<blockquote>
  <p>Delete from set <code>X_L</code> all paris <code>(A, B)</code> that are not maximal</p>
</blockquote>

<p>(6) <em>place</em> <code>P_(A, B)</code> 의 위치를 결정한다. </p>

<blockquote>
  <p>Determine the place set. Each element <code>(A, B)</code> is a place. To ensure the workflow structure, add a source place and target place</p>
</blockquote>

<p>(7) <code>(2)</code> 와 <code>(3)</code> 에서 찾은 출발점과 끝점과 <code>(6)</code> 에서 찾은 <em>place</em> 의 <em>source transition</em> 과 <em>target transition</em> 과 잇는다.</p>

<blockquote>
  <p>Determine the flow relation. Connect each place P(A, B) with each element <code>a</code> of its set <code>A</code> of source transitions and with each element of its set <code>B</code> of target transitions. In addition, draw an arc from the source place to each start transition and an arc from each end transition to the sink place</p>
</blockquote>

<p>따라서 전체적인 알고리즘은</p>

<ul>
<li>먼저 <em>footprint</em> 를 만들고</li>
<li>여기서 집합 내부적으로 <code>#</code> 이고 집합간 <code>&gt;</code> 를 가지는 <code>(A, B)</code> 를 구한뒤  </li>
<li>중복을 제거하기 위해 <em>non-maximal pair</em> 를 제거한다  </li>
<li><code>(A, B)</code> 에서 하나씩 <em>pair</em> 를 뽑아서 잇고, 이것들과 초기 트랜지션 <code>T_I</code>, 마지막 트랜지션 <code>T_O</code> 와 잇는다.</li>
</ul>

<h4 id="intuition">Intuition</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-21-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>알파 알고리즘은 간단하지만 <em>loop</em>, <em>choice</em>, <em>concurrenc</em> 등 꽤 많은 연산을 찾아낸다. 그러나 한계가 있다.</p>

<h4 id="limitation">Limitation</h4>

<h4 id="implicitplaces">implicit places</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-29-728.jpg?cb=1305062521'  alt="" /></p>

<p>여기서 초록색 <em>place</em> 는 아무일도 하지 않음에도 <em>alpha algorithm</em> 이 찾아냈다. </p>

<h4 id="loopsoflength12">Loops of length 1, 2</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-30-728.jpg?cb=1305062521'  alt="" /></p>

<p>이벤트 로그를 보면 실제로는 <code>b</code> 가 <em>self-loop</em> 가 있음에도 알파 알고리즘은 찾아내지 못한다.</p>

<p><br/></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-31-728.jpg?cb=1305062521'  alt="" /></p>

<p>길이가 2인 루프도 마찬가지로 찾아내지 못한다.</p>

<h4 id="nonlocaldependency">Non-local dependency</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-32-728.jpg?cb=1305062521'  alt="" /></p>

<p>여기서 알파 알고리즘을 돌리면 <code>p1, p2</code> 를 못찾는다. 아래 그림은 알파 알고리즘이 찾기 힘든 모델이다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-33-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<h4 id="representationbias">Representation Bias</h4>

<p>알파 알고리즘이 가지는 표현적인 한계 때문에 다음과 같은 경우도 발생한다.</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-38-728.jpg?cb=1305062521'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-39-728.jpg?cb=1305062521'  alt="" /></p>

<h4 id="noiseandincompleteness">Noise and Incompleteness</h4>

<p>알파 알고리즘은 아주 기본적인 알고리즘이기 때문에 패턴을 잘못 인식하는 경우가 많다. </p>

<p>게다가, 이벤트 로그 자체가 완벽한 <em>trace</em> 가 아닐수도 있다는 것도 고려해야한다.</p>

<blockquote>
  <p><strong>Noise:</strong> the event log contains rare and infrequent behavior not representative for the typical behavior of the process</p>
  
  <p><strong>Incompleteness:</strong> the event log contains too few events to be able to discover some of the underlying control-flow structures</p>
</blockquote>

<p>즉 이벤트 로그 자체가 어떤 패턴을 발견하기엔 너무 적거나, 좀 노이지할 수가 있다는 뜻이다.</p>

<h4 id="fitnessvsprecisionsimplicityvsgeneralization">Fitness vs Precision, Simplicity vs Generalization</h4>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-43-728.jpg?cb=1305062521'  alt="" /></p>

<p><br/></p>

<p>아래의 두 모델중 어떤게 더 이벤트 로그를 잘 반영한 것일까? 빈도가 적은 로그는 표현하지 않는것이 더 좋은가?</p>

<p><img src='http://image.slidesharecdn.com/processminingchapter05processdiscovery-110510153220-phpapp01/95/process-mining-chapter-5-process-discovery-47-728.jpg?cb=1305062521'  alt="" /></p>

<h4 id="summary">Summary</h4>

<p>루프가 있거나, 모델에 <em>parallel</em> 이 있는 경우에 가능한 <em>trace</em> 의 수는 기하 급수적으로 많아진다. </p>

<p>그러나 우리가 가진 이벤트 로그는 일부분이다. 따라서 이런 로그로 만드는 모델은 어느정도 틀릴 수 밖에 없다. </p>

<p>알파 알고리즘의 단점을 좀 정리해 보면,</p>

<p>(1) <strong>implicit places:</strong> harmless and be solved through preprocessing <br />
(2) <strong>loops of length 1:</strong> can be solved in multiple ways <br />
(3) <strong>loops of length 2:</strong> idem. <br />
(4) <strong>non-local dependencies:</strong> challenging <br />
(5) <strong>representational bias:</strong> cannot discover transtions with duplicate or invisible labels. other algorithms may have a different bias. <br />
(6) <strong>discovered model does not need to be sound:</strong> some algorithm ensure this. <br />
(7) <strong>noise, incompleteness:</strong> challenging  </p>

<h3 id="references">References</h3>

<p>(0) <a href='http://issuu.com/wmpvanderaalst/docs/procminbook?e=14081202/9829483' >Book: Process Mining</a> <br />
(1) <a href='https://d396qusza40orc.cloudfront.net/procmin/lecture_slides/22-Petri%20Nets%20%281%29.pdf' >Slide</a> <br />
(2) <strong>Process Mining: Data science in Action</strong> by Wil van der Aalst <br />
(3) <a href='http://1ambda.github.io/www.processmining.org' >www.processmining.org</a> <br />
(4) <a href='http://fluxicon.com/' >http://fluxicon.com</a> <br />
(5) <a href='http://en.wikipedia.org/wiki/Petri_net' >http://en.wikipedia.org/wiki/Petri_net</a> <br />
(6) <a href='http://www.bpm-book.com/' >http://www.bpm-book.com</a> <br />
(7) <a href='http://bpmcenter.org/' >http://bpmcenter.org/</a></p>]]></description><link>http://1ambda.github.io/process-mining-week2/</link><guid isPermaLink="false">51bbba08-c9ac-44ee-9593-85f5b62054fb</guid><category><![CDATA[coursera]]></category><category><![CDATA[process mining]]></category><category><![CDATA[alpha algorithm]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 26 Nov 2014 04:30:43 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 6]]></title><description><![CDATA[<p>이번시간엔 어떻게 <em>type</em> 과 <em>class</em> 를 정의하는지 배울겁니다. 이렇게 <em>commonality</em> 를  추출해서 <em>type</em> 과 <em>class</em> 로 만듦으로써 작업의 양을 줄일 수 있습니다. 이 과정을 추상화라 부르기도 합니다.</p>

<p>마지막엔 이제까지 배운바를 적용해 봅시다. 항상 참인 명제를 검사하는 <strong>tautology checker</strong> 와 평가 시점을 조절하는 <strong>abstract machine</strong> 을 만들어 보겠습니다.</p>

<h3 id="typedeclarations">Type Declarations</h3>

<p>하스켈에선 존재하는 타입을 이용해서 새로운 타입을 만들 수 있습니다.</p>

<pre><code class="haskell">type String = [Char]  
</code></pre>

<p>지난시간에 2차원 좌표계를 구현할 때 만들었던 <code>Pos</code> 타입 기억 나시죠?</p>

<pre><code class="haskell">type Pos = (Int, Int)

origin :: Pos  
origin = (0, 0)

left :: Pos -&gt; Pos  
left (x, y) = (x-1, y)  
</code></pre>

<p><em>type</em> 은 함수와 마찬가지로 다양한 타입을 사용할 수 있습니다.</p>

<pre><code class="haskell">type Pair a = (a, a)

mult :: Pair Int -&gt; Int  
mult (a, b) = a * b

copy :: Int -&gt; Pair Int  
copy a = (a, a)  
</code></pre>

<p>여러개의 타입도 사용할 수 있습니다.</p>

<pre><code class="haskell">type Assoc k v = [(k, v)]

find :: Eq k =&gt; k -&gt; Assoc k v -&gt; v  
find k xs = head [v | (k', v) &lt;- xs, k == k']

&gt; find 2 [(1, 'a'), (2, 'c'), (3, 'f')]
-- 'c'
</code></pre>

<p>그리고 <em>nested (중첩)</em> 될 수 있습니다.</p>

<pre><code class="haskell">type Trans = Pos -&gt; Pos

left :: Trans  
left (x, y) = (x-1, y)  
</code></pre>

<p>하지만 <em>recursive</em> 로 정의될 수는 없습니다. 왜냐하면 <em>type</em> 이 단지 <em>synonym</em> 이기 때문입니다.</p>

<pre><code class="haskell">-- doesn't work
type Tree = (Int, [Tree

-- ghci

Cycle in type synonym declarations:  
  lecture9.hs:22:1-25: type Tree = (Int, [Tree])
Failed, modules loaded: none.  
</code></pre>

<p>그러나 하스켈에선 재귀적으로 타입을 정의할 수 있는 방법이 있긴 있습니다! 다만 <em>nominal type</em> 을 이용해야 합니다.(<code>data</code> 키워드를 사용합니다.) 많은 언어들이 이와 비슷한 제약조건을 가지고 있습니다.</p>

<p><em>object-oriented language</em> 에서는 전형적으로 <em>nominal type system</em> 을 사용합니다. 이는 <em>"두 타입이 같은지"</em>, <em>"한 타입이 다른 타입의 서브타입인지"</em> 검사하기 쉽기 때문입니다. 반면 <em>purely sructural type system</em> 에서는 이게 조금 어려워집니다. (참고로 <em>nominal vs structure</em> 은, <em>dynamic static</em> 과는 다른 문제입니다.)</p>

<h3 id="datadeclarations">Data Declarations</h3>

<p>기존타입과 관련없는 새로운 타입을 만들려면 <code>data</code> 키워드를 사용하면 됩니다.</p>

<pre><code class="haskell">data Bool = False | True  
</code></pre>

<p>이제 <code>Bool</code> 은 새로운 <em>type</em> 이고, 여기에 <code>False, True</code> 의 <em>value</em> 를 사용할 수 있습니다.</p>

<p>여기서 <code>False</code>, <code>True</code> 를 <em>type</em> <code>Bool</code> 을 위한 <em>constructor</em> 라 부릅니다. <em>type constructor</em> 의 이름은 반드시 대문자로 시작해야합니다.</p>

<p>새로운 타입을 조금 더 만들어 봅시다.</p>

<pre><code class="haskell">data Answer = Yes | No | Unknown

answers :: [Answer]  
answers = [Yes, No, Unknown]

flip :: Answer -&gt; Answer  
flip Yes = No  
flip No = Yes  
flip Unknown = Unknown  
</code></pre>

<p>좌표의 움직임을 추상화한 타입 <code>Move</code> 도 만들어 봅시다.</p>

<pre><code class="haskell">data Move = Left | Right | Up | Down

move :: Move -&gt; Pos -&gt; Pos  
move Up (x, y) = (x, y-1)  
move Left (x, y) = (x-1, y)  
move Down (x, y) = (x, y+1)  
move Right (x, y) = (x+1, y)

moves :: [Move] -&gt; Pos -&gt; Pos  
moves [] p = p  
moves (m:ms) p = moves ms (move m p)

&gt; move Left (1, 1)
-- (0,1)

&gt; moves [Left, Right, Up, Down, Left] (0, 0)
--(-1,0)
</code></pre>

<p><em>data declaration</em> 내에 있는 <em>constructor</em> 는 파라미터를 가질 수 있습니다.</p>

<pre><code class="haskell">data Shape = Circle Float  
           | Rect Float Float

square :: Float -&gt; Shape  
square n = Rect n n

area :: Shape -&gt; Float  
area (Circle r) = pi * r^2  
area (Rect x y) = x * y  
</code></pre>

<p>여기서 <em>constructor</em> 를 함수라 볼 수도 있습니다.</p>

<pre><code class="haskell">Circle :: Float -&gt; Shape  
Rect :: Float Float -&gt; Shape  
</code></pre>

<p><em>constructor</em> 뿐만 아니라 <em>data declaration</em> 그 자체도 파라미터를 가질 수 있습니다.</p>

<pre><code class="haskell">data Maybe a = Nothing | Just a

safediv :: Int -&gt; Int -&gt; Maybe Int  
safediv _ 0 = Nothing  
safediv x y = Just (x `div` y)

safehead :: [a] -&gt; Maybe a  
safehead [] = Nothing  
safehead (x:xs) = Just x  
</code></pre>

<h3 id="recursivetypes">Recursive Types</h3>

<p>재귀적인 타입의 예를 한번 볼까요?</p>

<pre><code class="haskell">data Nat = Zero | Succ Nat  
</code></pre>

<p>여기서 <code>Zero :: Nat</code>, <code>Succ :: Nat -&gt; Nat</code> 라 보면 됩니다. 따라서 다음처럼 확장이 가능하지요.</p>

<pre><code class="haskell">Zero -- 0  
Succ Zero -- 1  
Succ (Succ Zero) -- 2  
</code></pre>

<p>보시면 알겠지만, 우리는 단 한 줄로 자연수를 표현하는 데이터 타입 <code>Nat</code> 를 만들었습니다. 숫자와 <code>Nat</code> 타입을 변환하는 함수를 만들어 봅시다.</p>

<pre><code class="haskell">data Nat = Zero | Succ Nat

nat2int :: Nat -&gt; Int  
nat2int Zero = 0  
nat2int (Succ nat) = 1 + nat2int nat

int2nat :: Int -&gt; Nat  
int2nat 0 = Zero  
int2nat n = Succ (int2nat (n-1))

&gt; nat2int (int2nat 10)
-- 10
</code></pre>

<p>재귀를 이용하면 <code>Nat</code> 간 덧셈을 위에서 만든 변환함수 없이도 만들수 있습니다.</p>

<pre><code class="haskell">add :: Nat -&gt; Nat -&gt; Nat  
add Zero n = n  
add (Succ n) s = Succ (add n s)

&gt; nat2int (add (int2nat 2) (int2nat 3))
-- 5
</code></pre>

<h3 id="list">List</h3>

<p>임의의 타입을 갖는 리스트를 나타내는 <code>List</code> 타입을 만들어 보죠.</p>

<pre><code class="haskell">data List a = Nil | Cons a (List a)

len :: List a -&gt; Int  
len Nil = 0  
len (Cons h t) = 1 + len t

&gt;  len (Cons 4 (Cons 3 Nil))
-- 2

&gt; len Nil
-- 0
</code></pre>

<h3 id="arithmeticexpressions">Arithmetic Expressions</h3>

<p>기본적인 <code>+, *</code> 과 정수와 연산 <em>expression (식)</em> 을 타입으로 만들면 어떻게 될까요?</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Exp-tree-ex-11.svg/375px-Exp-tree-ex-11.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<pre><code class="haskell">data Expr = Val Int  
          | Add Expr Expr
          | Mul Expr Expr          
</code></pre>

<p>이제 <em>expression</em> 의 사이즈와, 계산 결과를 돌려주는 함수 <code>size</code>, <code>eval</code> 을 만듭시다.</p>

<pre><code class="haskell">size :: Expr -&gt; Int  
size (Val n) = 1  
size (Add l r) = size l + size r  
size (Mul l r) = size l + size r

eval :: Expr -&gt; Int  
eval (Val n) = n  
eval (Add l r) = eval l + eval r  
eval (Mul l r) = eval l * eval r

&gt; eval (Add (Val 3) (Val 2))
-- 5

&gt; size (Add (Val 3) (Val 2))
-- 2
</code></pre>

<p>이번엔 이진트리를 표현해 볼까요?</p>

<pre><code class="haskell">data Tree = Leaf Int  
          | Node Tree Int Tree
</code></pre>

<p>이제 트리에서 원하는 숫자가 존재하는지 검사하는 <code>occurs</code> 함수를 만들면</p>

<pre><code class="haskell">occurs :: Int -&gt; Tree -&gt; Bool  
occurs n (Leaf k) = n == k  
occurs n (Node l k r) =  
  (n == k) 
  || occurs n l
  || occurs n r

&gt; occurs 3 (Node (Leaf 3) 4 (Leaf 5))
-- True

&gt; occurs 6 (Node (Leaf 3) 4 (Leaf 5))
-- False  
</code></pre>

<p>트리의 모든 원소를 리스트로 돌려주는 <code>flatten</code> 함수도 만들어 봅시다.</p>

<pre><code class="haskell">flatten :: Tree -&gt; [Int]  
flatten (Leaf k) = [k]  
flatten (Node l k r) = flatten l ++ [k] ++ flatten 

&gt; flatten (Node (Leaf 3) 4 (Leaf 5))
-- [3,4,5]

&gt; flatten (Node (Leaf 6) 4 (Leaf 7))
-- [6,4,7]
</code></pre>

<p>여기서 재미난 결과를 볼 수 있습니다. <code>flatten</code> 함수는 매 재귀마다 왼쪽부터 방문하고, 현재 노드를 방문하고, 마지막으로 오른쪽 노드를 방문합니다. </p>

<p>그래서 <code>flatten</code> 함수의 결과가 <em>ordered</em> 이면 트리는 한 노드를 기준으로 한쪽은 현재 노드보다 작고, 다른쪽은 큰 <em>search-tree</em> 가 됩니다.</p>

<p><em>search-tree</em> 에서는 만약 찾으려는 수가 현재 노드보다 크면 <em>right sub-tree</em> 만, 현재 노드보다 작으면 <em>left sub-tree</em> 만 검색하면 됩니다. 따라서 <code>occurs</code> 함수를 </p>

<pre><code class="haskell">-- occurs for search-ree
occurs' :: Int -&gt; Tree -&gt; Bool  
occurs' n (Leaf k) = k == n  
occurs' n (Node l k r) | n == k = True  
                       | n &lt; k = occurs' n l
                       | otherwise = occurs' n r


&gt; occurs' 3 (Node (Leaf 3) 4 (Leaf 5))
-- True

&gt; occurs' 5 (Node (Leaf 3) 4 (Leaf 5))
-- True
</code></pre>

<p>실제로 트리는 값을 어디에 저장하냐에 따라 다양한 형태가 될 수 있습니다.</p>

<pre><code class="haskell">data Tree a = Leaf a | Node (Tree a) (Tree a)  
data Tree a = Leaf | Node (Tree a) a (Tree a)  
data Tree a b = Leaf a | Node (Tree a b) b (Tree a b)  
data Tree a = Node a [Tree a]  
</code></pre>

<p>위에서 부터</p>

<p>(1) <em>leaf</em> 에만 값을 저장 <br />
(2) <em>node</em> 에만 값을 저장 <br />
(3) <em>leaf</em>, <em>node</em> 에 모두 값을 저장 <br />
(4) 한 <em>node</em> 에 값과 복수개의 트리를 저장  </p>

<h3 id="tautologychecker">Tautology checker</h3>

<p>항상 참인 명제를 <em>tautology</em> 라고 합니다. 논리학에 대해서는 다음 글을 참조해주세요.</p>

<p>(1) <a href='http://imnt.tistory.com/91' >명제논리의 기초 1 : 소개</a> <br />
(2) <a href='http://imnt.tistory.com/91' >명제논리의 기초 2 : 진리표</a> <br />
(3) <a href='http://imnt.tistory.com/91' >명제논리의 기초 3 : tautology, contradiction</a>  </p>

<p><em>tautology</em> 는 여러가지가 있습니다. 한 가지 예를 보면, 참 또는 거짓일 수 있는 명제 <code>p</code>, <code>q</code> 에 대해 <code>p -&gt; q ^ q -&gt; p</code> 는 항상 참입니다.</p>

<p><img src='http://s1.hubimg.com/u/3891828_f520.jpg'  alt="" /></p>

<p align="center">(<a href='http://julieburke.hubpages.com/' >http://julieburke.hubpages.com</a>)</p>

<p>이번에 만들 프로그램에서는 논리학 연산자를 <code>Not</code>, <code>And</code>, <code>Imply</code>, <code>Or</code> 4가지로 제한하겠습니다. <em>proposition (명제)</em> 는 <code>A, ..., Z</code> 이고 각각 <code>True / False</code> 일 수 있습니다.</p>

<pre><code class="haskell">data Prop =  Const Bool  
          | Var Char
          | Not Prop
          | Or Prop
          | And Prop Prop
          | Imply Prop Porp
</code></pre>

<p>검사할 4개의 명제를 만들어 보죠.</p>

<pre><code class="haskell">-- A and ~A
p1 :: Prop  
p1 = And (Var 'A') (Not (Var 'A'))

-- A and B -&gt; A
p2 :: Prop  
p2 = Imply (And (Var 'A') (Var 'B')) (Var 'A')

-- A -&gt; A and B
p3 :: Prop  
p3 = Imply (Var 'A') (And (Var 'A') (Var 'B'))

-- (A and (A -&gt; B)) -&gt; B
p4 :: Prop  
p4 = Imply (And (Var 'A') (Imply (Var 'A') (Var 'B'))) (Var 'B')  
</code></pre>

<p>각 명제가 참인지 거짓인지 알 수 있는 테이블을 나타내는 타입 <code>Subst</code> 를 만듭시다. 진리표라고 생각하면 됩니다. 그리고 여기서 값을 찾는 함수 <code>find</code> 도 만들면</p>

<pre><code class="haskell">type Assoc k v = [(k, v)]  
type Subst = Assoc Char Bool

find :: Eq k =&gt; k -&gt; Assoc k v -&gt; v  
find k t = head [v | (k', v) &lt;- t, k' == k]  
</code></pre>

<p>이제 <code>Prop</code> 를 평가하는 함수 <code>eval</code> 을 만들면</p>

<pre><code class="haskell">eval :: Subst -&gt; Prop -&gt; Bool  
eval _ (Const b) = b  
eval s (Var x) = find x s  
eval s (Not p) = not (eval s p)  
eval s (Or p1 p2) = eval s p1 || eval s p2  
eval s (And p1 p2) = eval s p1 &amp;&amp; eval s p2  
eval s (Imply p1 p2) = eval s p2  
</code></pre>

<p>어떤 명제 <code>Prop</code> 가 <em>tautologt</em> 인지 검사하려면, 명제를 이루는 문장의 모든 참/거짓 경우에 대해 살펴봐야 합니다. 따라서 현재 가진 변수 <code>A, ..., Z</code> 에 대해서 참 / 거짓의 모든 경우를 포함한 테이블이 필요합니다. 이 함수를 만들기 위해 작은 함수부터 차근차근 조립해 갑시다.</p>

<p>먼저 현재 <code>Prop</code> 에서 모든 변수를 찾는 함수 <code>vars</code> 와 중복을 제거하는 함수 <code>uniq</code> 를 만들겠습니다.</p>

<pre><code class="haskel">vars :: Prop -&gt; [Char]  
vars (Const _) = []  
vars (Var x) = [x]  
vars (Not p) = vars p  
vars (And p1 p2) = vars p1 ++ vars p2  
vars (Or p1 p2) = vars p1 ++ vars p2  
vars (Imply p1 p2) = vars p1 ++ vars p2

&gt; vars p1
-- "AA"

&gt; vars p2
-- "AA"

&gt; vars p3
-- "ABA"

&gt; vars p4
--"AAB"

uniq :: Eq a =&gt; [a] -&gt; [a]  
uniq = foldr (\x xs-&gt; if elem x xs then xs else x:xs) []

&gt; uniq (vars p4)
-- "AB"
</code></pre>

<p>길이를 받으면 해당 길이 만큼 <code>True, False</code> 의 모든 조합을 리턴하는 <code>bools</code> 함수도 만들죠. 조합이므로 다음 재귀 단계에, 가능한 모든 경우를 더하면 됩니다.</p>

<pre><code class="haskell">bools :: Int -&gt; [[Bool]]  
bools 0 = [[]]  
bools n = map (False:) prev ++ map (True:) prev  
  where prev = bools (n - 1)
</code></pre>

<p>이제 마지막 퍼즐을 완성하겠습니다. <code>Prop</code> 를 받아, <code>[Subst]</code> 를 돌려주는 함수 <code>substs</code> 와, <code>Prop</code> 를 받아 <em>tautology</em> 인지 검사하는 함수 <code>isTaut</code> 는</p>

<pre><code class="haskell">substs :: Prop -&gt; [Subst]  
substs p = map (zip vs) (bools (length vs))  
  where vs = uniq (vars p)

isTaut :: Prop -&gt; Bool  
isTaut p = and [eval s p | s &lt;- substs p]

&gt; isTaut p1
-- True

&gt; isTaut p2
--False

&gt; isTaut p3
--True

&gt; isTaut p4
--False

&gt; isTaut p5
-- True
</code></pre>

<h3 id="abstractmachine">Abstract Machine</h3>

<p>간단한 수식 계산을 위한 <em>expression</em> 타입을 생각해 봅시다.</p>

<pre><code class="haskell">data Expr = Val Int  
          | Add Expr Expr

value :: Expr -&gt; Int  
value (Val n) = n  
value (Add l r) = value l + value r  
</code></pre>

<p>이제 덧셈을 실제로 해 보면, 계산이 왼쪽부터 이루어지는걸 확인할수 있습니다.</p>

<pre><code class="haskell">-- 2 + 3 + 4
value (Add (Add (Val 2) (Val 3)) (Val 4))  
...
...
(2 + value (Val 3)) + value (Val 4)
</code></pre>

<p>위에서 알 수 있듯이 왼쪽 인자가 오른쪽 인자보다 먼저 평가됩니다. 이건 우리가 지정한게 아니고, 하스켈이 왼쪽 인자부터 평가하기 때문입니다.</p>

<p><em>expression</em> 에서 평가 시점을 결정하는 <em>abstract machine</em> 을 만들어서 해결할 수 있습니다.</p>

<blockquote>
  <p>If desired, however, such control information can be made explicit by defining an abstract machine for expressions,
  which specifies the step-by-step process of their evaluation.</p>
</blockquote>

<p>컨트롤 스택을 위한 타입을 만들고, 값을 평가하는 <code>eval</code> 과 실제로 덧셈을 수행하는 <code>exec</code> 함수를 만들겠습니다.</p>

<pre><code class="haskel">-- expression
data Expr = Val Int  
          | Add Expr Expr

-- control stack
type Cont = [Op]  
data Op = EVAL Expr  
        | ADD Int

eval :: Expr -&gt; Cont -&gt; Int  
eval (Val n) c = exec c n -- eval n  
eval (Add x y) c = eval x (EVAL y : c) -- eval x before y

exec :: Cont -&gt; Int -&gt; Int  
exec [] n = n  
exec (EVAL y : c) n = eval y (ADD n : c)  
exec (ADD n : c)  m = exec c (n + m)

value :: Expr -&gt; Int  
value e = eval e []  
</code></pre>

<p><code>eval (Add x y)</code> 에 대해서 <code>EVAL y</code> 가 먼저 스택에 들어가고, <code>x</code> 가 먼저 평가됩니다. 그 이후에 <code>exec</code> 로 넘어오면서 <code>ADD</code> 명령이 스택에 들어가고, 그 이후에야 <code>y</code> 가 평가됩니다. 마지막으로 컨트롤 스택에 들어간 <code>ADD</code> 명령이 끝납니다.</p>

<p>간단한 예제를 통해 평가되는 과정을 보면</p>

<pre><code class="haskell">eval (Add (Val 3) (Val 5)) []  
eval (Val 3) [EVAL (Val 5)]  
exec [EVAL (Val 5)] 3  
eval (Val 5) [ADD 3]  
exec [ADD 3] 5  
exec [] (3 + 5)  
</code></pre>

<h3 id="classandinstancedeclaration">Class and Instance declaration</h3>

<p>마지막으로 <code>class</code> 대해 알아보겠습니다. 아참 시작하기 전에 먼저 아셔야 할 사실은, 하스켈에선 기술적인 이유로 <code>data</code> 를 이용해 만든 타입만 클래스의 인스턴스가 될 수 있습니다. </p>

<blockquote>
  <p>For technical reasons, only types declared using the data mechanism can be made into instances of classes.</p>
</blockquote>

<p>하스켈에선 <code>Eq</code> 클래스가 있는데요, 이렇게 정의되어 있습니다.</p>

<pre><code class="haskell">class Eq where  
 (==), (/=) :: a -&gt; a -&gt; Bool
 x /= y = not (x == y) 
</code></pre>

<p>이 말은 <code>Eq</code> 의 인스턴스가 되는 <code>a</code> 는 <code>(==)</code> 연산을 지원해야 한다는 뜻입니다. (<code>/=</code> 연산은 디폴트로 정의되어 있습니다.)</p>

<p>그래서 <code>Eq</code> 의 인스턴스인 <code>Bool</code> 의 경우</p>

<pre><code class="haskell">instance Eq Bool where  
  False == False = True
  True == True = True
  _ == _ = False
</code></pre>

<p>물론 기본 연산은 <em>overrided</em> 될 수 있습니다. 어떤 인스턴스의 경우 비교를 위해 <code>==</code> 를 재정의해서 사용할 수 있을겁니다.</p>

<p>클래스는 확장될 수 있습니다. 다른언어의 상속처럼요.</p>

<pre><code class="haskell">class Eq a =&gt; Ord a where  
  (&lt;), (&lt;=), (&gt;), (&gt;=) :: a -&gt; a -&gt; Bool
  min, max :: a -&gt; a -&gt; a

  min x y | x &lt;= y = x
          | otherwise = y

  max x y | x &lt;= y = y
          | otherwise = x
</code></pre>

<p>상대적인 크고 작음을 의미하는 <code>Ord</code> 클래스의 경우 <code>Eq</code> 의 연산에 추가적으로 크기 비교를 위한 연산을 가지고 있습니다. <code>&lt;, &lt;=, &gt;, &gt;=</code> 4개의 연산을 <code>Ord</code> 의 인스턴스는 정의해야 하는데요, 이것만 정의하면 디폴트로 정의된 <code>min, max</code> 도 사용할 수 있습니다.</p>

<p>아까 <code>Imply</code> 구현할 때 <code>p &lt;= q</code> 연산 보셨죠? <code>Bool</code> 은 <code>Ord</code> 의 인스턴스이기도 한데요</p>

<pre><code class="haskell">instance Ord Bool where  
  False &lt; True = True
  _ &lt; _ = False

  b &gt; c = c &lt; b
  b &lt;= c = (b &lt; c) || (b == c)
  b &gt;= c = c &lt;= b
</code></pre>

<h3 id="derivedinstances">Derived instances</h3>

<p>타입을 만들때 <em>built-in</em> 클래스의 인스턴스로 만들기 위해 <code>deriving</code> 키워드를 사용할 수 있습니다. 그래서 <code>Bool</code> 같은 경우 콘솔에 출력도 되고, 문자열에서 변경도 가능하고, 비교도 가능하죠.</p>

<pre><code class="haskell">data Bool = False | True  
          deriving (Eq, Ord, Show, Read)

&gt; False == False
--True

&gt; False &lt; True
-- True

&gt; show False
-- "False"

&gt; read "False"::Bool
--False
</code></pre>

<p>한가지 재밌는 사실은 <code>Bool</code> 의 <em>constructor</em> 중에서 <code>False</code> 가 <code>True</code> 보다 먼저 나오기 때문에 <code>False &lt; True</code> 라는 사실입니다.</p>

<pre><code class="haskell">data Shape = Circle Float | Rect Float Float  
data Maybe a = Nothing | Just a  
</code></pre>

<p>그리고 <code>Float</code> 가 <code>Eq</code> 의 인스턴스이기 때문에 결과적으로 이것을 파라미터로 가지는 <em>constructor</em> <code>Circle</code>, <code>Rect</code> 도 <code>Eq</code> 의 인스턴스입니다.</p>

<pre><code class="haskell">&gt; Rect 1.0 4.0 &lt; Rect 2.0 3.0
True

&gt; Rect 1.0 4.0 &lt; Rect 1.0 3.0
False  
</code></pre>

<p>마찬가지로 <code>Maybe a</code> 가 <code>Eq</code> 의 인스턴스가 되려면 <code>a</code> 가 <code>Eq</code> 의 인스턴스여야 합니다.</p>

<h3 id="examples">Examples</h3>

<p>몇개의 예제들입니다. 참고해보세요</p>

<pre><code class="haskell">import Data.List  
import Data.Char  
import Unsafe.Coerce

data Nat = Zero  
         | Succ Nat
         deriving Show

nat2int :: Nat -&gt; Integer  
nat2int = \n -&gt; genericLength [c | c &lt;- show n, c == 'S']

int2nat 0 = Zero  
int2nat n = Succ (int2nat (n-1))

add :: Nat -&gt; Nat -&gt; Nat  
add n Zero = n  
add n (Succ m) = Succ (add m n)

mult m Zero = Zero  
mult m (Succ n) = add m (mult m n)

-- tree
data Tree1 = Leaf Integer  
          | Node Tree Tree

leaves (Leaf _) = 1  
leaves (Node l r) = leaves l + leaves r  
balanced :: Tree -&gt; Bool  
balanced (Leaf _) = True  
balanced (Node l r) = abs (leaves l - leaves r) &lt;= 1 &amp;&amp; balanced l &amp;&amp; balanced r

balance :: [Integer] -&gt; Tree  
halve xs = splitAt (length xs `div` 2) xs  
balance [x] = Leaf x  
balance xs = Node (balance ys) (balance zs)  
  where (ys, zs) = halve xs
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em> <br />
(3) <a href='http://en.wikipedia.org/wiki/Binary_expression_tree' >Wiki - Binary Expression</a> <br />
(4) <a href='http://imnt.tistory.com/' >http://imnt.tistory.com</a>  </p>]]></description><link>http://1ambda.github.io/haskell-intro6/</link><guid isPermaLink="false">51837e71-0662-427c-b231-b63c47edf5b7</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[type]]></category><category><![CDATA[constructor]]></category><category><![CDATA[class]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 25 Nov 2014 07:56:35 GMT</pubDate></item><item><title><![CDATA[Dijkstra, Heap, Red-Black Tree]]></title><description><![CDATA[<h3 id="dijkstrasshortestpathalgorithm">Dijkstra's Shortest-Path Algorithm</h3>

<p><em>BFS</em> 는 <em>undirected graph</em> 에서 최단 경로를 찾지만, 이건 모든 <em>edge</em> 의 길이가 1일때만 그렇다. </p>

<p>다익스트라(<em>dijkstra</em>, <em>데이크스트라</em>) 알고리즘은 <em>directed graph</em> 에서 <em>non-negative length</em> 에 대한 최단 경로를 찾아낼 수 있다.</p>

<p>각 <em>edge</em> 가 음수라면, 모든 수에 특정 수를 더해 양수로 만들어도, 아니면 음수 그 자체로 다익스트라 알고리즘을 돌려도 최단 경로를 찾지 못한다. 다음의 그래프가 한 예다.</p>

<pre><code>1 -&gt; 2 // length: 1  
2 -&gt; 3 // length: -6  
1 -&gt; 3 // length: -2  
</code></pre>

<p>금융거래를 보면 특정 거래를 <em>edge</em> 라 보고 대해 여기에 대하 이득과 손실을 각각 양수, 음수의 가중치를 가지는 그래프라 생각할 수 있는데, 여기엔 음수 가중치가 있으므로 다익스트라 알고리즘을 쓸 수 없다.</p>

<p><a href='http://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm' >벨만 포드</a> 알고리즘을 써야한다.</p>

<p>길이가 <code>n</code> 인 <em>edge</em> 를 길이가 <code>1</code> 인 <code>n</code> 개의 <em>edge</em> 로 늘려 <em>BFS</em> 를 쓸 수 없느냐 질문할 수도 있겠는데, 가중치가 상당히 크면 연산이 비효율적이 된다. (e.g 150000)</p>

<h4 id="algorithm">Algorithm</h4>

<p>사실 다익스트라 알고리즘은 방문한 점 <code>v</code> 와 방문하지 않은 점 <code>w</code> 에 대해  <em>edge</em> <code>(v -&gt; w)</code> 를 고르는 문제다. <code>l_vw</code> 를 <code>v -&gt; w</code> 의 거리라 하고 <code>A[v]</code> 를 시작점 부터 <code>v</code> 까지의 최단거리라 하면 <code>A[v] + l_vw</code> 를 최소로 하는 <em>edge</em> 를 고르면 된다.</p>

<p>알고리즘은 이렇다. 시작점을 <code>s</code> 라 하면</p>

<pre><code>X = {s} // vertices process so far  
A = [s] // computed shortest path distances

// V is not visited vertices set  

while X != V  
  // v in X, w not in X
  // select the edge minimizing [A]v + l_vw
  pick (v, w) 
  X + w
  A[w] = A[v] + l_vw
</code></pre>

<h4 id="correctness">Correctness</h4>

<p>다익스트라 알고리즘이 <em>non-negative edge length</em> 를 가진 <em>directed graph</em> 에 대해 최단경로를 찾아낸다는 것을 증명하자. </p>

<p><code>A</code> 를 다익스트라 알고리즘이 찾아 낸 경로, <code>L</code> 을 실제 최단거리라 할 때 <code>A[w*] = L[w*]</code> 임을 보이면 된다.</p>

<p>귀납법을 이용해 먼저 가설을 세우면</p>

<blockquote>
  <p>Inductive hypothesis: all previous iterations correct</p>
</blockquote>

<p><em>base case</em> 인 시작점 <code>s</code> 에 대해 참임을 보이면 <code>A[s] = L[s] = 0</code> 이다.</p>

<p>현재 <em>iteration</em> 에서 찾아낸 <em>edge</em> 를 <code>v* -&gt; w*</code> 라 하면, <code>A[w*] = L[v*] + l_v*w*</code> 이다.</p>

<p>이 때 그래프 안에 있는 모든 <code>s -&gt; w*</code> 의 경로의 길이가 <code>L[v*] + l_v*w*</code> 보다 큼을 보이면 된다.</p>

<p>그래프 내에 있는 <code>s -&gt; w*</code> 의 모든 경로 <code>p</code> 는 다음 형태를 가진다.</p>

<p><code>s -&gt; y | -&gt; z -&gt; w*</code>
<br/></p>

<p>여기서 <code>s, y</code> 는 방문한 점이고 <code>z, w*</code> 는 방문하지 않은 점이다. </p>

<p><code>s -&gt; y | -&gt; z -&gt; w*</code> 에 대해 <code>p</code> 의 길이는 다음 3개를 더한 것이다.</p>

<p>(1) <code>l_sy &gt;= A[y] = L[y]</code> (<em>by induction hypothesis</em>) <br />
(2) <code>l_yz</code> <br />
(3) <code>l_zw &gt;= 0</code> </p>

<p>즉, 모든 경로 <code>p</code> 의 길이 <code>l_sy + l_yz + l_zw*</code> 는 <code>L[y] + l_yz</code> 보다 크다. </p>

<p>그런데, 다익스트라 알고리즘으로 고른 경로 <code>A[v*] + l_v*w*</code> 는 <code>L[y] + l_yz</code> 보다 작거나 같다. 왜냐하면 <code>A[v*], L[y], l_v*w*</code> 는 최단경로인데, <code>l_yz</code> 는 최단경로일 수도, 아닐수도 있다. </p>

<p>따라서 우리 알고리즘으로 구한 거리가, 모든 경로 <code>p</code> 의 <em>lower bound</em> 보다 작거나 같다.</p>

<h4 id="runningtime">Running time</h4>

<p><em>naive implementation</em> 의 성능은 <code>O(mn)</code> 이다. <code>n - 1</code> 의 모든 <em>vertex</em> 를 살펴봐야 하고, 루프 내에서 러프하게 모든 <em>edge</em> 를 검사한다고 보면 된다.</p>

<p>다익스트라 알고리즘은 <code>O(n)</code> 정도까지 개선할 수 있다. 알고리즘의 변경이 아니라, 자료구조를 <em>heap</em> 으로 변경함으로써! <em>heap</em> 은 <em>extract-min</em> 연산에 대해 <code>O(log n)</code> 이다.</p>

<p>힙의 구조나 특성은 뒤에서 알아보기로 하고, 여기선 다익스트라 알고리즘에 어떻게 적용할지를 논의하자.</p>

<p>(1) <em>heap</em> 내부 원소들은 방문하지 않은 원소들의 집합 <code>V - X</code> 라 하자. <code>X</code> 는 방문한 원소들의 집합. <br />
(2) <code>V - X</code> 내의 원소 <code>v</code> 에 대해서 <code>key[v]</code> 는 <em>edge</em> <code>(u, v)</code> 에 대한 다익스트라 알고리즘의 스코어다. (<code>u</code> 는 방문한 점)</p>

<p>따라서 <code>v</code> 의 키 값은 <code>X</code> 와 <code>V - X</code> 의 <em>crossing edge</em> <code>u -&gt; v</code> 중에서 가장 작은 <em>edge</em> 길이다.</p>

<p>이때 <code>X</code> 내에 있지 않은 점 <code>v</code> 를 <code>X</code> 로 옮기면서 <code>v -&gt; w</code> 로 새로운 <em>crossing edge</em> 가 생기고, 이로인해 <code>w</code> 의 <em>key</em> 값이 변할 수 있다. 이를 해결하기 위한 <em>key</em> 업데이트 로직은</p>

<pre><code>// v is extracted from heap and added to X
for each edge (v, w)  
  if w in heap
    delete w from heap
    recompute key[w] = min(key[w], A[v] + l_vw)
    reinsert w into heap
</code></pre>

<p><em>running time</em> 은 <em>heap operation</em> 의 수로 결정되는데 각 연산 <code>O(log n)</code> 을</p>

<p>(1) <code>n - 1</code> <em>extract min</em> -> <code>n</code> <br />
(2) 그리고 <em>edge</em> 중심으로 보면, <code>(v, w)</code> 이 <em>edge</em> 가 재 계산될때는 <code>v</code> 가 <code>X</code> 에 추가될때다. 그 이후에는 <code>(v, w)</code> 는 <em>crossing edge</em> 가 되므로 <em>delete, insertion</em> 연산과 관련이 없어진다. 다시 말해 한 <em>edge</em> 당 <em>at most one insertion and deletion</em> 이 있다. -> <code>m</code>  </p>

<p>따라서 <em>heap operation</em> 수는 <code>O(n + m)</code> 이다. 그런데, <em>path</em> 자체는 <em>weakly connected undirected graph</em> 이므로 <code>m ~= n</code> 이고 <code>O(m + n) = O(m)</code> 이라 볼 수 있다.</p>

<p>결국 힙을 이용한 다익스트라 알고리즘은 <code>O(m log n)</code> 이다. 이건 <code>O(m * n)</code> 보다 어마어마하게 빠르다.</p>

<h3 id="whatdatastructureshouldiuse">What data structure should I use?</h3>

<p>위 예제에서도 봤듯이, 적절한 데이터 구조의 사용은 알고리즘의 성능을 개선하는데 도움이 된다.</p>

<p>익히 아는 리스트, 큐 부터 시작해서 <em>bloom filter</em>, <em>union find</em> 등이 있는데, 이렇게 다양한 자료구조가 있는 이유는 우리가 하려는 <em>task</em> 가 다양하기 때문이다.</p>

<p>많은 데이터 구조중 무엇을 선택해야 할까? <em>rule of thumb</em> 는</p>

<blockquote>
  <p><em>Choose the "minimal" data structure that supports all the operations that need.</em></p>
</blockquote>

<p>내게 필요한 것 이상의 과도한 연산을 제공하는 자료구조를 사용할 필욘 없다. 복잡한 연산이 있을수록, 자료구조는 더 복잡해지기 마련이다.</p>

<h3 id="heap">Heap</h3>

<p>자료구조에서 가장 먼저 생각해야 할 것은  <em>"어떤 operation 을 제공하는가?"</em>, <em>"running time 은 얼마인가?"</em> 다.</p>

<p><em>Heap</em> 은 <em>key</em> 를 가진 <em>object</em>를 위한 <em>container</em> 다. <em>employer records</em>, <em>network edges</em>, <em>event manager</em> 등에 이용할 수 있다.</p>

<p>힙의 기본 연산은 <em>insert</em> 와 <em>extract-min (or max)</em> 연산이다. 이 연산의 러닝타임은 <code>O(log n)</code> 이다. <code>n</code> 은 힙 내에 있는 오브젝트의 수다.</p>

<p><code>n</code> 개의 <em>batch insertion</em> 에 대해 <em>heapify</em> 는 <code>O(n)</code>, 임의의 원소를 제거하는 <em>delete</em> 는 <code>O(log n)</code> 이다. 정리하면</p>

<p>(1) <strong>insertion:</strong> <code>O(log n)</code> <br />
(2) <strong>extract-min (or max):</strong> <code>O(log n)</code> <br />
(3) <strong>heapify (batch):</strong> <code>O(n)</code> <br />
(4) <strong>remove (arbitrary):</strong> <code>O(n)</code>  </p>

<h4 id="application">Application</h4>

<p>힙을 어디에 쓸까? 먼저 생각해 볼 수 있는건 <em>min value</em> 가 연속적으로 필요한 작업에 쓸 수 있다. </p>

<p>(1) <em>heap sort</em> 는 힙에서 지속적으로 <em>min-value</em> 를 뽑아내서 정렬하는 방법이다. <code>O(n logn)</code> 의 성능을 보여준다. 이건 <em>merge sort</em> 나 <em>randomized quick-sort</em> 만큼 빠르다.</p>

<p>잠깐 생각해 볼 거리가 있다. <em>quicksort</em> 챕터에서 언급 했듯이 <em>comparison-based sorting</em> 은 <code>O(n logn)</code> 보다 더 빠를 수 없다. 힙 또한 비교를 이용해 정렬을 하므로 이보다 좋은 성능을 내기는 어렵다.</p>

<p>(2) 아까 힙을 <em>event manager</em> 에도 이용할 수 있고 했는데, <em>priority queue</em> 가 바로 그것이다. 각 게임 이벤트가 큐에 들어있다고 하면 여기서 <em>key</em> 는 각 <em>event</em> 의 발생시간이다. 다시 말해 발생시간이 먼저인 이벤트가 먼저 발생되도록 큐를 이용할 수 있다.</p>

<p>(3) <em>median maintanence</em> 에도 힙을 이용할 수 있다. <code>x1, x2, ..., xn</code> 의 배열에 대해 <code>i</code> 번째 스텝에서는 <code>x1, ..., xi</code> 의 중앙값을 돌려주는 문제다. <code>O(i)</code> 로 하면 정말 쉽지만, 조건이 하나 있다. 바로 <code>O(log i)</code> 의 퍼포먼스를 내야하는것. 어떻게 할까?</p>

<p>두개의 힙을 이용하면 쉽게 풀 수 있다. 데이터를 절반씩 나누어 <em>max heap</em>, <em>min heap</em> 각각에 나눠 담으면 된다. 그러면 각 힙의 루트가 중앙값이 될 수 있다.</p>

<p>(4) 마지막으로 힙은 다익스트라 알고리즘의 성능을 개선하는데 사용할 수 있다. 위에서 보았듯이 <code>O(m logn)</code> 의 퍼포먼스를 보여준다.</p>

<h4 id="implementationdetails">Implementation Details</h4>

<p>힙을 배열 또는 트리로 보는 관점이 있는데, 여기선 쉬운 이해를 위해 트리로 설명한다. <em>rooted, binary, as complete as possible tree</em> 로 보면 된다. </p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/6/69/Min-heap.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Binary_heap' >http://en.wikipedia.org/wiki/Binary_heap</a>)</p>

<p><em>min heap</em> 을 예로 들면, 부모는 항상 자식보다 작거나 같다. 따라서 루트는 모든 원소중 가장 작은 값을 가진다.</p>

<p>힙을 배열로 구현한다고 하자. 인덱스가 1부터 시작할때 <code>parent(i)</code> 는 <code>i</code> 가 짝수면 <code>i/2</code>, 홀수면 <code>[i/2]</code> 가 될 것이다. 자식을 구하는건 더 쉽다. <code>i * 2</code> 와 <code>i * 2 + 1</code> 이다.</p>

<p><em>insert</em> 의 구현을 생각해 보자. 힙은 가능한 <em>complete tree</em> 기 때문에, 위 그림에서 새로운 숫자가 입력했을때 새로 생길 노드의 위치는 <code>19</code> 의 왼쪽 자식이다. </p>

<p>이렇게 완전 이진트리를 만드는 위치에 새로운 값을 삽입하고, 부모와 값을 비교해 가면서 값의 위치를 올려간다. 이 방법을 <em>bubble-up</em> 이라 부른다. 
정리하면,</p>

<p>(1) stick <code>k</code> at end of last level <br />
(2) <strong>bubble-up</strong> <code>k</code> until heap property is restored  </p>

<p><em>extract-min</em> 연산은 루트에 있는 수를 뽑아낸다. 이 위치에 마지막 노드를 넣고, <em>bubble-down</em> 함으로써 구현할 수 있다. 새롭게 루트가 된 노드를 내려가는 과정에서 왼쪽 자식, 오른쪽 자식과 모두 비교하여 가장 작은 수를 새로운 부모로 만들면 된다. 정리하면</p>

<p>(1) delete <code>root</code> <br />
(2) move last leaf to be new root <br />
(3) iterlatively <strong>bubble-down</strong> until heap property has been restored  </p>

<p>이 두 연산은 이진트리의 <code>n</code> 번째 깊이까지 내려갈 수 있으므로 퍼포먼스는 <code>O(log_2 n)</code> 이다.</p>

<h3 id="balancedsearchtree">Balanced Search Tree</h3>

<p><strong>sorted array</strong> 에 대한 연산을 먼저 생각해 보자. 이로부터 <em>balanced search tree</em> 로 이끌어 낼 수 있는 연산들이 있을테다. 참고로 <strong>sorted array</strong> 는 <em>static</em> 이기 때문에 <em>insertion, deletion</em> 이 없다.</p>

<p>(1) <strong>Search:</strong> <code>O(logn)</code> <br />
(2) <strong>Select:</strong> <code>O(1)</code> (given order statistic <code>i</code>) <br />
(3) <strong>Min / Max:</strong> <code>O(1)</code> <br />
(4) <strong>Predecessor / Successor:</strong> <code>O(1)</code> <br />
(5) <strong>Rank:</strong> <code>O(logn)</code> <br />
(6) <strong>Output in sorted order:</strong> <code>O(n)</code></p>

<p>여기서 주어진 데이터가 몇 번째 데이터인지를 찾는 <em>rank</em> 는 <em>search</em> 와 똑같은 문제다. <em>binary search</em> 처럼 찾아가면서, 인덱스를 찾아내면 되기 때문이다.</p>

<p>이제 <strong>balanced search tree</strong> 를 생각해보자. </p>

<p>(1) <strong>Search:</strong> <code>O(logn)</code> <br />
(2*) <strong>Select:</strong> <code>O(logn)</code> <br />
(3*) <strong>Min / Max:</strong> <code>O(logn)</code> <br />
(4*) <strong>Predecessor / Successor:</strong> <code>O(logn)</code> <br />
(5) <strong>Rank:</strong> <code>O(logn)</code> <br />
(6) <strong>Output in sorted order:</strong> <code>O(n)</code> <br />
(7+) <strong>Insert:</strong> <code>O(logn)</code> <br />
(8+) <strong>Delete:</strong> <code>O(logn)</code>  </p>

<p><strong>sorted array</strong> 에 비해 <em>select, min or max, pred or succ</em> 연산이 <code>O(logn)</code> 이 되었고 <em>insert, delete</em> 연산이 새롭게 추가됐다. 쉽게 기억하려면 <em>sorted array</em> + <em>logarithmic insert, delete</em> 라 생각하면 된다.</p>

<p>힙과 비교해보면, 두 자료구조 모두 <em>insert, delete</em> 를 <code>O(logn)</code> 이란 빠른 시간에 제공한다. 차이점은, 힙은 <em>min or max</em> 둘 중 하나만 매우 빠르게 제공한다는 것이다. 따라서 <em>priority queue, scheduler</em> 같은 기능을 구현한다면 <em>balanced search tree</em> 보단 힙이 더 좋은 선택이다.</p>

<h3 id="binarysearchtree">Binary Search Tree</h3>

<p><strong>binary search tree</strong> 를 쉽게 기억하는 방법은 <em>dynamic sorted array</em> 라 기억하는 것이다. <strong>sorted array</strong> 가 제공하는 풍부하고 빠른 연산에 <em>insert, delete</em> 를 추가한 것이 바로 <strong>binary search tree, BST</strong> 다.</p>

<p>힙이 <em>vertically sorted</em> 라면 BST 는 <em>horizontally sorted</em> 다. 즉 왼쪽자식은 부모보다 항상 작고, 우측 자식은 부모보다 항상 크다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Binary_search_tree.svg/300px-Binary_search_tree.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org/</a>)</p>

<p>이런 구조적 특성때문에 <em>search (탐색)</em> 을 <code>O(logn)</code> 으로 빠른 시간 내에 해낼 수 있다. 근데, 최악의 경우 노드가 일렬로 주-욱 이어져 있다면 <code>O(n)</code> 의 퍼포먼스를 보여준다.</p>

<p><img src='http://epaperpress.com/sortsearch/images/fig33.gif'  alt="" /></p>

<p align="center">(<a href='http://epaperpress.com/' >http://epaperpress.com</a>)</p>

<h4 id="implementation">Implementation</h4>

<p>이제 연산의 구현을 좀 생각해 보자. </p>

<p>(1) <em>insert, search</em> 는 비슷하다. 자신의 자리를 찾아 내려가다가, 해당 원소가 있으면 돌려주고 아니면 <code>NULL</code> 을 돌려주는 방법으로 <em>search</em> 를 구현할 수 있다. <em>insert</em> 도 값을 비교하면서 내려가다가 적절한 자리에 삽입하면 된다.</p>

<p>(2) <em>max, min</em> 연산은 가장 좌측 노드, 가장 우측 노드를 돌려줌으로써 쉽게 구할 수 있다. </p>

<p>(3) <em>pred, succ</em> 은 자신 다음으로 적거나, 자신 다음으로 큰 원소를 돌려주는 연산인데, 자신 기준으로 왼쪽 부트리에서 가장 우측에 있는 노드, 그리고 자신 기준으로 우측 부트리에서 가장 좌측에 있는 노드를 돌려주면 된다.</p>

<p>(4) <em>in-order traversal</em> 연산은 노드를 오름차순 순서로 방문하는 연산이다. 이것 역시 쉽게 구현할 수 있는데</p>

<pre><code>let r = root of search tree

recurse left sub-tree  
print current node  
recurse right sub-tree  
</code></pre>

<p>노드당 한번만 출력하므로, 퍼포먼스는 <code>O(n)</code> 이다</p>

<p>(5) <em>delete</em> 는 조금 복잡한데 3가지 경우를 고려해야 한다.</p>

<ul>
<li>자식이 없을 경우</li>
<li>왼쪽 또는 오른쪽 자식만 있을 경우</li>
<li>양쪽 자식이 다 있을 경우</li>
</ul>

<p>앞의 두 가지 경우는 어렵지 않은데, 양쪽 자식이 다 있을 경우는 조금 까다롭다. 이 경우는 지우려는 노드의 <em>successor</em> 나 <em>predecessor</em> 을 <code>l</code> 이라 하자. 지우려는 노드와 <code>l</code> 을 뒤 바꾸면, 이전 <code>l</code> 자리에 있던 노드는 <em>left</em> 또는 <em>right</em> 자식이 없으므로 하나의 자식만 있는 알고리즘을 이용해 제거하면 된다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Binary_search_tree_delete_3.svg/620px-Binary_search_tree_delete_3.svg.png'  alt="" /></p>

<p align="center">(<a href='http://commons.wikimedia.org/' >http://commons.wikimedia.org/</a>)</p>

<p>(6) <em>select, rank</em> 연산은 트리에 추가적인 정보를 기록함으로써 쉽게 구할 수 있다.  각 트리마다 자기를 포함한 자식들의 노드 수를 저장하면 된다.</p>

<p><img src='http://www.tcs.auckland.ac.nz/' ~georgy/teaching/1998/98-231FC/231-hand/btr-rank.gif" alt="http://www.tcs.auckland.ac.nz/~georgy/" /></p>

<p align="center">(<a href='http://www.tcs.auckland.ac.nz/' ~georgy/'>http://www.tcs.auckland.ac.nz/~georgy/</a>)</p>

<p>매 삭제와 삽입 연산마다 각 트리의 사이즈를 변경해야 하는데 어렵지 않다. 삽입이나 삭제시 마지막 노드 혹은 <em>predecessor, successor</em> 를 찾아가면서 매번 노드를 방문해야 하므로 이 때 마다 새롭게 값을 변경하면 된다.</p>

<p><em>select, rank</em> 알고리즘은</p>

<pre><code>start at root x  
let y = left sub-tree  
let z = right sub-tree  
let a = size of y

if a = i - 1 return x  
if a &gt;= i, recurse y, i'th statistic  
if a &lt; i, recurse z, (i - a - 1)'th statistic  
</code></pre>

<p>러닝타임은 <code>O(height)</code> 다.</p>

<h3 id="redblacktree">Red-Black Tree</h3>

<p>이진트리는 운이 나쁠경우 <code>O(n)</code> 의 연산 성능이 나오기 나온다. 따라서 트리의 높이를 최대 <code>O(logn)</code> 으로 제한해 연산 성능을 개선할 수 있다.</p>

<p>이렇게 구조적인 제한을 이용해 성능을 개선하는 트리는 <em>red-black tree</em> 이외에도 <em>AVL tree</em>, <em>splay tree</em>, <em>B tree</em> 등이 있다. </p>

<h4 id="invariants">Invariants</h4>

<p><em>red-black tree</em> 는 다음의 제약 조건을 제외하면 이진트리와 동일하다.</p>

<p>(1) each node is red or <code>black</code> <br />
(2) root is <code>black</code> <br />
(3) no 2 <code>reds</code> in a row  -> <code>red</code> node has only <code>black</code> children <br />
(4) every <code>root - NULL</code> path  has same number of black nodes  </p>

<p>여기서 <code>(4)</code> 는 <em>unsuccessful search</em> 를 생각하면 쉽다. 검색이 제대로 되지 않았을 경우 <code>NULL</code> 에서 중단하는데, 그때 까지의 모든 블랙 노드의 수가 다른 <em>unsuccessful search</em> 가 방문한 블랙 노드 수와 동일하다는 것이다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Red-black_tree_example.svg/750px-Red-black_tree_example.svg.png'  alt="http://en.wikipedia.org" /></p>

<p align="center">(<a href='http://en.wikipedia.org/' >http://en.wikipedia.org</a>)</p>

<p>예제를 통해 좀 살펴보자. <code>1 -&gt; 2 -&gt; 3</code> 의 이진트리가 있을 때, <code>2</code> 가 레드 노드라 하자. 그러면 규칙 <code>(4)</code> 를 위반한다. <em>unsuccessful search</em> 의 경우인 <code>0</code> 과 <code>4</code> 를 찾을때 블랙 노드의 개수가 다르다.</p>

<h4 id="heightguarantee">Height Guarantee</h4>

<p>위에서 언급한 제약조건이 실제로는 트리의 높이를 <code>height &lt;= 2 log_2(n + 1)</code> 로 보장한다. </p>

<p>우선 살펴봐야 할 것은, 모든 <code>root-null</code> 경로가 <code>&gt;= k</code> 인 노드를 가지고 있다면, 그 트리는 <code>k</code> 깊이 까지는 완전 이진트리다.</p>

<blockquote>
  <p>If every <code>root-null</code> path has <code>&gt;= k</code> nodes, then tree includes (at the top) a perfectly balanced search tree of depth <code>k - 1</code></p>
</blockquote>

<p>이 것은 레드블랙트리만이 아니라 모든 이진트리에 적용된다. 이제 전체 노드 <code>n</code> 과 관계를 살펴 보자. </p>

<p>이진트리이므로 노드의 수 <code>n &gt;= 2^k - 1</code> 과 <code>k</code> 에 대해 <code>k &lt;= log_2 (n+1)</code> 이다. </p>

<p>아까 <code>k</code> 는 <code>root-null</code> 경로의 노드의 수 라고 했었다. 그리고 레드블랙트리의 (3), (4) 조건을 다시 생각해보면</p>

<blockquote>
  <p>(3) no 2 <code>reds</code> in a row  -> <code>red</code> node has only <code>black</code> children <br />
  (4) every <code>root - NULL</code> path  has same number of black nodes  </p>
</blockquote>

<p>레드 블랙트리에서 모든 노드가 블랙이면, (4) 에 의해서 <code>root-null</code> 경로의 블랙 노드가 최대이므로 블랙 노드의 <em>upper bound</em> 는 <code>&lt;= log_2 (n+1)</code> 이다. 그리고 레드 블랙 트리에서 <code>root-null</code> 경로의 노드수가 깊이가 되므로 이때의 높이는 <code>log_2 (n+1)</code> 이다.</p>

<p>다른 경우를 생각해 보자. 레드블랙트리의 <code>root-null</code> 경로에는 중간 중간 레드 노드가 낄 수 있는데, 레드 노드가 최대로 끼어있을때는 (3) 조건에 의해 블랙노드만큼이다. 이 때 블랙노드는 <em>upper bound</em> 에 의해 <code>&lt;= log_2 (n+1)</code> 이므로, 레드노드도 최대 <code>&lt;= log_2 (n+1)</code> 이다.</p>

<p>따라서 레드블랙트리의 깊이는 최대 <code>&lt;= 2 * log_2 (n + )1</code> 이므로, 연산에 대해 <code>O(log n)</code> 을 보장한다.</p>

<h4 id="rotation">Rotation</h4>

<p>이진트리의 삽입, 삭제 연산은 레드블랙트리에서의 제약조건을 망가트릴 수 있다. 따라서 삭제와 삽입 연산에 부가적으로 구조를 유지하기 위한 작업이 필요하다. </p>

<p>레드블랙트리 뿐만 아니라 <em>AVL tree</em> 나 다른 <em>balanced search tree</em> 도 구조를 유지해야 하는데, 여기에 공통적으로 사용하는 연산이 <em>rotation</em> 이다. 한번 알아보자.</p>

<blockquote>
  <p>Idea: locally rebalance sub-trees at a node in <code>O(1)</code> time.</p>
</blockquote>

<p>먼저 <em>left roation</em> 만 생각하자. 다음 그림에서 우측에 있는 트리를 좌측처럼 변경하는 것이다. <code>P</code> 가 <code>Q</code> 의 자식이 되도록 하는것이다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/2/23/Tree_rotation.png'  alt="http://en.wikipedia.org/wiki/Tree_rotation" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Tree_rotation' >http://en.wikipedia.org/wiki/Tree_rotation</a>)</p>

<p>여기서 <code>B</code> 의 원소는 <code>P</code> 보단 크고 <code>Q</code> 보다 작다. 따라서 <code>Q</code> 와 <code>P</code> 의 위치를 변경하면 <code>B</code> 는 <code>P</code> 의 오른쪽에 와야 한다. 이것이 <em>left rotation</em> 이다. 경로를 따라 왼쪽으로 한칸씩 밀려갔다고 생각하면 기억하기 쉽다.</p>

<p><em>right rotation</em> 은 이것을 정확히 반대로 수행하면 된다. 좌측에 있는 트리에서 <code>P</code>, <code>Q</code> 를 경로를 따라 하나씩 우측으로 밀고, <code>B</code> 는 <code>C</code> 의 왼쪽으로 이동하면 된다.</p>

<p>모든 연산은 포인터 변경으로 끝나므로 <code>O(1)</code> 이다. </p>

<h4 id="insertion">Insertion</h4>

<p>이제 <em>rotation</em> 을 이용해 <em>red-black tree</em> 에서 삽입 연산을 구현해 보자. 삽입과 삭제의 기본적인 아이디어는</p>

<p>(1) 이진트리에서의 <em>insert</em> / <em>remove</em> 연산을 수행 한다. <br />
(2) 레드, 블랙을 다시 색칠한다. <br />
(3) <em>rotation</em> 을 수행한다.</p>

<p>여기 (2) 단계에서 레드블랙트리의 구조가 망가질 수 있다. 새로운 노드를 레드로 만들면, 한 로우 내에 2개의 레드가 있을 수 없다는 규칙을 위반할 수 있고, 블랙으로 칠하면 <code>root-null</code> 경로의 블랙 노드의 수가 같아야 한다는 제약조건에 위배될 수 있다.</p>

<p>두 가지 경우중, 레드로 칠하는 경우가 더 가벼운 작업일 것 같으니</p>

<blockquote>
  <p>새로운 노드가 들어오면 먼저 레드로 칠해본다.</p>
</blockquote>

<p>부모가 블랙이면 문제가 없다.</p>

<blockquote>
  <p>부모가 레드면?</p>
</blockquote>

<p>몇 가지 경우를 생각해봐야 한다. 우선 부모 <code>B</code> 가 레드면, 부모의 부모 <code>C</code> 는 블랙임이 확실하다. 이 때 만약,</p>

<p>(1) <code>C</code> 가 <code>B</code> 말고 다른 자식 <code>D</code> 가 있다면 <code>B, C, D</code> 의 색을 반전시키면 된다. 그리고 새롭게 색을 반전시켰을 때 <code>C</code> 의 부모도 레드일 수 있다. 마찬가지로 <em>recoloring</em> 을 반복하면 된다. 색을 반전시켜도 (3) 또는 (4) 의 규칙을 위반하지 않는다. </p>

<p>아주 만약에, 루트까지 반복해서 루트가 레드가 되었다면 루트를 블랙으로 다시 칠하면 된다. 루트는 모든것의 부모이므로 블랙이 되어도 <code>root-null</code> 경로 조건을 위반하지 않는다.</p>

<p>따라서 연산비용은 <code>O(log n)</code> 이다.</p>

<p><img src='http://cs.lmu.edu/' ~ray/images/rbtrecoloring.png" alt="" /></p>

<p align="center">(<a href='http://cs.lmu.edu/' ~ray/notes/redblacktrees/'>http://cs.lmu.edu/~ray/notes/redblacktrees/</a>)</p>

<p>그런데, 반복해서 이 방법을 사용하다가 <code>C</code> 가 다른 자식 <code>D</code> 를 가지고 있지 않거나, <code>D</code> 가 블랙일 수 있다. 그럴땐 다음 경우로 넘어가야 한다.</p>

<p>(2) <code>C</code> 가 <code>B</code> 말고 다른 자식이 없거나 블랙인 자식을 가지면 <code>A</code> 가 좌측이냐 우측이냐에 따라 <code>right rotation</code>, <code>left-right rotation</code> 으로 해결할 수 있다. 마찬가지로 (3) 또는 (4) 를 위반하지 않는다.</p>

<p><img src='http://cs.lmu.edu/' ~ray/images/rbrestructuring.png" alt="" /></p>

<p align="center">(<a href='http://cs.lmu.edu/' ~ray/notes/redblacktrees/'>http://cs.lmu.edu/~ray/notes/redblacktrees/</a>)</p>

<p>이 경우는 몇번의 로테이션으로 해결할 수 있으므로 <code>O(1)</code> 이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong> <br />
(2) <a href='http://en.wikipedia.org/wiki/Binary_heap' >Wiki - Binary heap</a> <br />
(3) <a href='http://en.wikipedia.org/wiki/Binary_search_tree' >Wiki - Binary search tree</a> <br />
(4) <a href='http://epaperpress.com/sortsearch/bin.html' >http://epaperpress.com</a> <br />
(5) <a href='http://commons.wikimedia.org/wiki/File:Binary_search_tree_delete_3.svg' >http://commons.wikimedia.org/</a> <br />
(6) <a href='http://www.tcs.auckland.ac.nz/' ~georgy/teaching/1998/98-231FC/231-hand/test231.html">http://www.tcs.auckland.ac.nz/~georgy/</a> <br />
(7) <a href='http://en.wikipedia.org/wiki/Red%E2%80%93black_tree' >Wiki - Red-black tree</a> <br />
(8) <a href='http://upload.wikimedia.org/wikipedia/commons/2/23/Tree_rotation.png' >Wiki - Tree rotation</a></p>]]></description><link>http://1ambda.github.io/dijkstra-heap-balanced-tree/</link><guid isPermaLink="false">8d4c00c5-78fc-4a4d-97a1-cf0829c53396</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[coursera]]></category><category><![CDATA[heap]]></category><category><![CDATA[dijkstra]]></category><category><![CDATA[red-black tree]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sun, 23 Nov 2014 14:23:37 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 7]]></title><description><![CDATA[<p>이번시간에 <em>Support Vector Machine, SVM</em> 을 배운다.</p>

<h3 id="optimizationobjective">Optimization Objective</h3>

<p>먼저 직관을 얻기 위해 <em>logistic regression</em> 의 <em>sigmoid function</em> 을 좀 보자.</p>

<p><img src='http://my.csdn.net/uploads/201208/09/1344525027_7041.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><code>y = 1</code> 이면 <code>0^Tx &gt;&gt; 0</code> 이어야 <code>h(x)</code> 가 <code>1</code> 에 가까워 진다. </p>

<p>이제 <em>cost function</em> 에 <code>h(x)</code> 를 넣자. 그리고 <code>m = 1</code> 인 트레이닝 셋에 대해서 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360809698_1212.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>파란 그래프에서 볼 수 있듯이 <code>y = 1</code> 일때 <code>0^Tx &gt;&gt; 0</code> 이면 <em>cost</em> 가 상당히 낮아지는걸 볼 수 있다. 이 그래프를 좀 단순화 해서 <em>자주색</em> 그래프를 만들어 보자. 두개의 직선으로 만들었는데, 이 <em>cost function</em> 을 계산하면 상당히 근접한 값을 얻을 수 있고, 동시에 그래프가 단순해져 <em>computational advantage</em> 를 얻을 수 있다.</p>

<p>각각 좌측, 우측에 있는 <em>cost function</em> 을 이렇게 쓴다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5C%20%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29'  alt="" /></p>

<p><em>logistic regression</em> 식 에서 <code>-log h(x)</code> 를 <code>cost_1(z)</code> 로, <code>-log(1 - h(x)))</code> 를 <code>cost_0(z)</code> 로 바꾸면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%20m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7D%28-log%5C%20h_%5Ctheta%28x%5E%7B%28i%29%7D%29%29%5C%20&plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28-log%281%5C%20-%5C%20h_%7B%5Ctheta%7D%28x%5E%7B%28i%29%7D%29%29%29%5D%5C%20&plus;%20%5C%20%7B%5Clambda%20%5Cover%202m%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2%20%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29%20%5C%5C%20min_%5Ctheta%20%5C%20%7B1%20%5Cover%20m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29%5D%5C%20&plus;%20%5C%20%7B%5Clambda%20%5Cover%202m%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2'  alt="" /></p>

<p>이 때, <code>1/m</code> 은 상수이므로 제거해도 어차피 똑같은 <code>0(theta)</code> 를 얻을 수 있다.</p>

<p>그리고 식을 좀 간략히 적어보면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20A%20&plus;%20%5Clambda%20B'  alt="" /></p>

<p>여기서 <code>lambda</code> 가 하는 일은 <em>low cost ('A')</em> 와 <em>small parameter ('B')</em> 를 조절하는 일이다. 식을 좀 변경하면 이렇게도 볼 수 있다. 여기서 <code>C</code> 는 <code>1 / lambda</code> 과 같은 역할이라 보면 된다. </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20&plus;%20%5Clambda%20B'  alt="" /></p>

<p>아주 작은 수의 <code>lambda</code> 를 사용하면 파라미터 <code>B</code> 가 커지는데, 이것은 <code>C</code> 가 커져 <code>A</code> 를 낮추고 <code>B</code> 를 높이는 것과 똑같다. 반대로 <code>C</code> 가 작으면 <code>A</code> 가 커지고, <code>B</code> 가 작아진다.</p>

<p>결국 <code>C</code> 를 쓰느냐 <code>lambda</code> 를 쓰느냐는, 어떤 항을 옵티마이제이션의 중심으로 두느냐다. 최적화된 파라미터를 찾는건 똑같다.</p>

<p>식을 마지막으로 정리하면,</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20%5C%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29%5D%5C%20&plus;%20%5C%20%7B1%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2'  alt="" /></p>

<p>결국 위 식 (<em>cost</em>) 를 최소화 하면, <code>y = 1</code> 일때 <code>0^Tx &gt;&gt; 0</code> 이 되므로 <code>h(x) == 1</code> 이란 뜻이다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360809865_3224.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<h3 id="largeminginintuition">Large Mingin Intuition</h3>

<p><em>SVM</em> 은 <em>large margin classifier</em> 라 부르도 한다. 왜 그런게 한번 살펴보자.</p>

<p>두 집단을 구분하는 초록색, 자주색, 검은색 직선을 생각해 보자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360811170_6003.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>검은색 선이 가장 낫고, 자주색과 초록색은 두 집단을 분리하긴 하는데 썩 만족할만하게는 아니다. 검은 선과 평행하고 각 점까지의 거리가 최소인 파란선을 그리자. 이걸 <em>margin</em> 이라 부른다. 다시 말해서 <em>margin</em> 이 클수록 좋은 <em>classification</em> 이다.</p>

<p><em>large margin</em> 하고 <em>SVM</em> 하고 무슨 상관일까? 그 전에 먼저 <code>C</code> 를 좀 살펴보자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360811018_1834.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><code>z == 0^T x</code>, 의 범위를 생각해 보면 <code>y = 1</code> 일때 <code>z &gt;= 1</code> 이길 바란다. 반대로 <code>y = 0</code> 이면 <code>z &lt;= -1</code> 이면 <code>h(x)</code> 로 충분히 만족할 만한 값을 얻을 수 있다.</p>

<p>이 때 <code>C</code> 가 매우 크면 <code>A</code> 즉, 아래의 식은 굉장히 작아진다. 거의 0 에 가깝게</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29'  alt="" /></p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360811206_9816.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>두 집단에 대해서 <code>C</code> 가 매우 크면, 다시 말해 <code>A</code> 가 <code>0</code> 에 가까우면 <em>overfitting</em> 된다 볼 수 있으므로 자주색과 비슷한 라인을 찾아낸다. 자주색 선은 모든 샘플에 대해 <em>large margin</em> 을 가지고 있지만 그렇게 썩 좋은 <em>classification</em> 이라 볼 수는 없다.</p>

<p>그러나 <code>C</code> 가 그렇게 크지 않으면 비 정상적인 샘플들은 조금 무시하고 검은색 선을 찾아낸다. 이게 <em>SVM</em> 이 작동하는 방식이다.</p>

<h3 id="mathematicsbehindlargemarginclassification">Mathematics Behind Large Margin Classification</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360893984_1771.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360893988_7434.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>결국 <code>C</code> 가 아주 클 때 <code>A = 0</code> 이므로 <em>SVM</em> <em>cost fucntion</em> 을 최소화 하는 것은 아래 식과 동일하다. 그런데 이 식을 풀어 보면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%20%5Cleft%20%5C%7C%20%5Ctheta%20%5Cright%20%5C%7C%5E2'  alt="" /></p>

<p>그리고 <code>0(theta)</code> 와 <code>x</code> 를 벡터이므로 <code>0^T x^(i) = p^(i) * ||0||</code> 라 볼 수 있다. (여기서 <code>p^(i)</code> 는 <code>x</code> 의 <code>0</code> 로의 <em>projection</em> 된 선의 길이)</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta%5ETx%20%5C%5C%20%5C%5C%20%3D%20p%5E%7B%28i%29%7D%20%5Cleft%20%5C%7C%20%5Ctheta%20%5Cright%20%5C%7C'  alt="" /></p>

<p>이제 이 식을 좀 활용해 보자. <code>C</code> 가 매우 클때는 <code>B</code> 만 최소화 하면 되는데</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2'  alt="" /></p>

<p>이 식 자체가 <em>large margin</em> 을 찾아낸다. 왜 그런가 보면</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360893992_3213.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>왼쪽 그래프의 계산 과정을 보면 <code>x1</code> 을 <code>0</code> 에 <em>projection</em> 해서 얻은 <code>p1</code> 이 매우 작다. 따라서 <code>p1 * ||0|| &gt;= 1</code> 에서 <code>||0||</code> 가 커야 전체 식이 1보다 커지는데, 이러면 식 <code>B</code> 를 최소화 할 수 없다. 마찬가지로 <code>p2</code> 는 매우 작은 음수고, <code>p2 * ||0|| &lt;= -1</code> 에서, <code>||0||</code> 가 매우 큰 음수여야 한다. 이 또한 <code>0</code> 를 크게 만드므로 식 <code>B</code> 가 작아지는 <code>0</code> 를 찾지 못한다. </p>

<p>결국 <code>p</code> 가 커야만 <code>0</code> 가 작아지기 때문에 <code>p</code> 를 크게 하는 <code>0</code> 만 찾고, 이것은 <em>large margin</em> 이다. 따라서 초록색 같은 <em>low margin</em> 의 <code>0</code> 는 선택되지 않는다. </p>

<p>정리하자면 <code>C</code> 가 매우 클때 <em>SVM</em> 은 <em>large magin</em> 을 찾고, 여기서 <code>C</code> 를 낮춤으로써 적당한 수준의 <em>classification</em> 을 얻을 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2'  alt="" /></p>

<h3 id="kernels">Kernels</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895849_6087.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><em>SVM</em> 으로 <em>non-linear decision boundary</em> 를 어떻게 찾아낼까? 단순히 <em>high polynomial features</em> 를 사용하는 것보다 더 나은 방법은 없을까? 고차 다항식은 이미지 처리 예제에서도 봤지만, 계산 비용이 너무 비싸다.</p>

<p><em>kernel</em> 이란 개념이 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895854_4557.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>수동으로 몇몇 <em>landmark</em> <code>l1, l2, ...</code> 을 고른후 이 <em>landmark</em> 사이와의 거리로 새로운 <em>feature</em> <code>f</code> 를 만든다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?f_1%20%3D%20similarity%28x%2C%20l%5E%7B%281%29%7D%29%20%3D%20exp%20%28-%20%7B%7C%7Cx-l%5E%7B%281%29%7D%7C%7C%5E2%20%5Cover%202%5Csigma%5E2%7D%29'  alt="" /></p>

<p>dl <em>similarity function</em> 을 <em>kernel function</em> 특히 여기서 사용한 수식은 <em>gaussian kernel</em> 이라 부른다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895859_5163.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><code>x</code> 와 <code>l</code> 이 상당히 가까우면 <code>f</code> 는 <code>1</code> 에 근접하고, 상당히 멀면 <code>0</code> 에 가까워진다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895862_8544.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>위 그림은 시그마에 따른 <code>f</code> 값의 변화를 보여주는데, 시그마가 작으면 작을수록 조금만 멀어도 <code>f</code> 값은 <code>0</code> 에 가까워진다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360895867_6739.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>데이터가 <em>landmark</em> 중 하나에 라도 가까우면 적어도 하나의 <code>f</code> 가 1이 되어, <code>h(x)</code> 가 1 이되고 반면 모든 <em>landmark</em> 에 멀면 모든 <code>f</code> 가 0 이 되어 <code>h(x)</code> 가 0 이된다.</p>

<p>그럼 이제, 문제는 어떻게 <em>landmark</em> 를 정할 것인가?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360899128_1431.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360899133_9301.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><code>l1, ..., lm</code> 을 <code>x1, ..., xm</code> 라 하자. 즉 각 <em>training example</em> 이 <em>landmark</em> 가 된다. 이를 이용해 구한 <em>feature vector</em> <code>f^(i)</code> 중 하나는 <code>sim(x^i, l^i)</code> 이므로 1이 된다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360899136_2691.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>따라서 주어진 <code>x</code> 에 대해 <code>m + 1</code> 의 벡터 <code>f</code> 를 구해 <code>0^Tf &gt;= 0</code> 이면 <code>y = 1</code> 이다. 그리고 이 때 <em>feature</em> 수가 <code>m</code> 이 되므로 </p>

<p><img src='http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20%5C%20%5Csum_%7By%3D1%7D%5Emcost_1%28%5Ctheta%5ETf%5E%7B%28i%29%7D%29%20&plus;%20%281-y%5E%7B%28i%29%7D%29cost_0%28%5Ctheta%5ETf%5E%7B%28i%29%7D%29%29%20&plus;%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5Em%5Ctheta_j%5E2'  alt="" /></p>

<p>마지막 항을 좀 자세히 보면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum_%7Bj%3D1%7D%5Ctheta_j%5E2%20%5C%5C%20%5C%5C%20%3D%20%5Ctheta%5ET%20%5Ctheta'  alt="" /></p>

<p>인데 <em>SVM</em> 실제 구현에서는 가운데 <code>M</code> 매트릭스를 삽입해 좀더 효율적으로 돌아가도록 한다. 이 <code>M</code> 은 어떤 <em>kernel</em> 을 사용하는지에 따라 다르다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Ctheta%5ET%20M%20%5C%20%5Ctheta'  alt="" /></p>

<p><em>logistic regression</em> 에 <em>kernel</em> 을 사용할 수도 있겠지만, 상당히 느리다. 반면 <em>SVM</em> 에서는 마지막 항을 위 처럼 수정할 수 있기에 빠르게 동작한다.</p>

<h3 id="biasvsvarianceinsvm">Bias vs Variance in SVM</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360899140_2255.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>(1) <code>C</code> 가 크면 <em>low bias</em>, <em>high variance</em>  (== <em>small <code>lambda</code></em>) <br />
(2) <code>C</code> 가 작으면 <em>high bias</em>, <em>low variance</em>  (== <em>large <code>lambda</code></em>)  </p>

<p><code>sigma</code> 가 크면 <code>f</code> 가 적게 변하기 때문에 인풋 <code>x</code> 에 대해서도 <em>high bias</em>, <em>low variance</em> 다.</p>

<h3 id="usingansvm">Using an SVM</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360901245_9359.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>라이브러리를 사용하더라도 <code>C</code> 와 어떤 <em>kernel</em> 을 사용할지는 골라야 한다.</p>

<p><em>feature</em> 가 크고, 트레이닝셋이 작을때는 <em>overfitting</em> 될 수 있으므로 <em>linear kernel</em> 을 사용하는 편이 낫다.</p>

<p>반면 <code>n</code> 이 작고, <code>m</code> 이 클 경우에는 <em>non-linear</em> 가설일 수 있으므로 <em>gaussian kernel</em> 을 사용할 수 있다. 그러면 <code>sigma</code> 를 골라야 한다. </p>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360901242_6422.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><em>SVM</em> 라이브러리를 이용할때는 <code>kernel function</code> 을 직접 구현해야 한다. 이걸 이용해서 라이브러리는 <code>x</code> 에 대해 <code>f1, ..., fl</code> 을 계산한다.</p>

<p>만약에 <em>feature</em> 의 스케일이 다르면, <code>x1 = 10000, x2 = 5, ...</code> <code>||x-l||^2</code> 값이 숫자가 큰 항에 의해 좌우될 수 있으므로 <em>feature scailing</em> 을 하는편이 좋다.</p>

<h4 id="otherchoicesofkernel">Other choices of kernel</h4>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360901245_9359.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><em>SVM</em> 구현들이 계산을 최적화 하기위해 다양한 트릭을 이용한다. 이로 인해 모든 <em>similarity function</em> 유효한 커널이 되는건 아니고, <em>"Mercer's Theorem"</em> 을 만족해야만 한다. <del>인용하려 했는데 무슨말인지 모르겠음</del></p>

<p>그렇다고 커널이 <em>linear</em> 와 <em>gaussian</em> 만 있는건 아니고 다양한 커널이 있다. 그림을 참조하자.</p>

<h4 id="multiclassclassification">Multi-class classification</h4>

<p><img src='http://img.my.csdn.net/uploads/201302/15/1360901253_5022.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>대부분의 <em>SVM</em> 라이브러리들은 <em>multi-class</em> 에 대한 함수를 제공한다. 그러나 이것들을 사용하는 대신 <em>one-vs-all</em> 방법을 사용할 수도 있다. <code>k</code> 개의 클래스가 있다면 <code>k</code> 개의 <em>SVM</em> 훈련시키면 된다.</p>

<h4 id="logisticregressionvssvm">Logistic regression vs SVM</h4>

<p><img src='http://my.csdn.net/uploads/201208/12/1344759226_6088.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>(1) <code>n &gt;= m</code> 이면 <em>logistic regression</em> 이나 <em>linear kernel</em> 이 낫다. <br />
(2) <code>n</code> 이 작고, <code>m</code> 이 중간 사이즈면 <em>gaussian kernel</em> 을 <br />
(3) <code>n</code> 이 작고 <code>m</code> 이 크면 <em>gaussian</em> 은 상당히 느려진다. <em>feature</em> 를 좀 수정하고, <em>logistic</em> 이나 <em>linear kernel</em> 을 이용한다.</p>

<p><em>SVM</em> 의 장점은 다양한 <em>kernel</em> 을 <em>non-linear function</em> 을 훈련시키기 위해 사용할 수 있다는 점이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>  </p>]]></description><link>http://1ambda.github.io/machine-learning-week-7/</link><guid isPermaLink="false">61eb3656-6495-48e4-a92f-2ba44cf1416d</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine lerning]]></category><category><![CDATA[SVM]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 22 Nov 2014 06:23:25 GMT</pubDate></item><item><title><![CDATA[Intro to Computational Thinking and Data Science 2]]></title><description><![CDATA[<blockquote>
  <p>Computational systems are so very convenient for modeling behaviors of noisier, uncertain systems, <strong>especially in estimating the values of parameters of those systems</strong>.</p>
</blockquote>

<h3 id="montecarlosimulation">Monte Carlo Simulation</h3>

<blockquote>
  <p>Monte Carlo simulation is a method of <strong>estimating the value of an unknown quantity using the principles of inferential statistics</strong></p>
</blockquote>

<p>이전에 잠깐 <em>deterministic model</em> 과 <em>stochastic model</em> 언급 했었는데, 다시 한번 알아보자면</p>

<blockquote>
  <p>In <strong>deterministic models</strong>, the output of the model is  fully determined by the parameter values and the
  initial conditions.</p>
  
  <p><strong>Stochastic models</strong> possess some inherent randomness. The same set of parameter values and initial conditions will lead to an ensemble of different outputs</p>
</blockquote>

<p>때때로 사람들이 <em>deterministic model</em> 은 <em>uncertainty</em> 를 다루지 않는다고 말하곤 하는데 이건 엄밀히 말하면 틀렸다. <em>deterministic model</em> 내부적으로는 <em>randomness</em> 가 없지만, 모델 외부에 <em>uncertainty</em> 가 있을 수 있다.  </p>

<p>몬테 카를로 시뮬레이션이 바로 <em>deterministic model</em> 에 대해 <em>random input</em> 을 이용해 분포를 얻어내는 방법이다. </p>

<blockquote>
  <p>I have heard people say that "a stocahstic model handles uncertainty, a deterministic model doesn't". This is not strictly correct. The correct statement should be: 
  a stochastic model has the capacity to handle then uncertainty in the inputs built into it, for a deterministic model, the uncertainties are extenal to the model. The uncertainties in the inputs to a deterministic model can be handled through use of a Monte Carlo simulation (note that this does not make it a stochastic model). This is computationally inefficient however.</p>
</blockquote>

<h3 id="findingpi">Finding PI</h3>

<pre><code class="python">def stdDev(X):  
    mean = sum(X) / float(len(X))
    total = 0.0
    for x in X:
        total += (x - mean) ** 2
    return (total / len(X)) ** 0.5


def dropNeedles(num):  
    inCircle = 0
    for needles in xrange(1, num + 1, 1):
        x = random.random()
        y = random.random()

        if (x*x + y*y) ** 0.5 &lt;= 1.0:
            inCircle += 1

    return 4 * (inCircle / float(num))


def estimate(numOfNeedles, trials):  
    estimates = []
    for i in range(trials):
        pi = dropNeedles(numOfNeedles)
        estimates.append(pi)

    sd = stdDev(estimates)
    est = sum(estimates) / len(estimates)

    return (est, sd)


def simulate(precision, trials):  
    numOfNeedles = 1000
    sd = precision

    # 95% of the values lie within precision of the mean
    while sd &gt;= (precision / 2.0):
        est, sd = estimate(numOfNeedles, trials)
        print 'PI est =', est, "sd =", round(sd, 6), "needles =", numOfNeedles
        numOfNeedles *= 2

    return est


random.seed(0)  
simulate(0.005, 100)  
</code></pre>

<p>반지름이 1인 원 안에 바늘을 떨어트려, 해당 원 안에 있을 경우와 직사각형에 있을 경우의 비율에 직사각형의 넓이를 곱하면, 원의 넓이 즉 <code>PI</code> 값이 나온다.</p>

<p>실제 돌려보면</p>

<pre><code>PI est = 3.14844 sd = 0.047886 needles = 1000  
PI est = 3.13918 sd = 0.035495 needles = 2000  
PI est = 3.14108 sd = 0.02713 needles = 4000  
PI est = 3.141435 sd = 0.016805 needles = 8000  
PI est = 3.141355 sd = 0.0137 needles = 16000  
PI est = 3.14131375 sd = 0.008476 needles = 32000  
PI est = 3.141171875 sd = 0.007028 needles = 64000  
PI est = 3.1415896875 sd = 0.004035 needles = 128000  
PI est = 3.14174140625 sd = 0.003536 needles = 256000  
PI est = 3.14155671875 sd = 0.002101 needles = 512000  
</code></pre>

<p><code>32000</code> 개와 <code>64000</code> 개의 바늘을 떨어트린 샘플을 보면 실제 샘플도 후자가 많고, 표준편차도 후자가 작음에도 실제 추정값은 더 나쁘게 나왔다.</p>

<p>표준편차가 작으면 실제 값에 근접한 추정값이 나왔다는 뜻이 아닌가? </p>

<blockquote>
  <p>Having the small standard deviation doesn't mean we have a good estimate.</p>
</blockquote>

<p>그렇지 않다. 표준편차가 작다는 것이, 우리가 얻은 추정값이 실제 값과 같다는 뜻은 아니다.</p>

<blockquote>
  <p>All this means is that if we were to draw more samples from the same distribution, we can be reasonably confident that we would get a similar value.</p>
</blockquote>

<p>단지 같은 분포에서 더 많은 샘플을 이용하면 <em>현재 값과 비슷한 값 (!= 실제값)</em> 을 얻을 수 있다는 말이다.</p>

<p>우리가 구한 값이 실제 <code>PI</code> 와 근사하다고 믿기 전에 3가지를 먼저 확인해야한다.</p>

<p>(1) <strong>conceptual model</strong> (이 경우 <code>PI</code> 를 위한 계산) <br />
(2) <strong>implementation</strong> <br />
(3) <strong>enough samples</strong>  </p>

<p>만약에 <code>4 * (inCircle / float(num)</code> 대신에 <code>2 * (inCircle / float(num)</code> 를 사용해 잘못된 <em>conceptual model</em> 을 가진다면 (버그라 볼 수도 있겠다.)</p>

<pre><code>PI est = 1.57422 sd = 0.023943 needles = 1000  
PI est = 1.56959 sd = 0.017748 needles = 2000  
PI est = 1.57054 sd = 0.013565 needles = 4000  
PI est = 1.5707175 sd = 0.008402 needles = 8000  
PI est = 1.5706775 sd = 0.00685 needles = 16000  
PI est = 1.570656875 sd = 0.004238 needles = 32000  
PI est = 1.5705859375 sd = 0.003514 needles = 64000  
PI est = 1.57079484375 sd = 0.002017 needles = 128000  
</code></pre>

<p>보면 알겠지만, 표준편차는 충분히 작음에도 우리가 구한 추정값이 <code>PI</code> 와는 상당히 다르다.</p>

<blockquote>
  <p>Whenever possible, one should attempt to validate results against realilty</p>
</blockquote>

<h3 id="normaldistribution">Normal Distribution</h3>

<blockquote>
  <p>Instead of estimating an unknown parameter by a single value, a <strong>confidence interval</strong> provides a range that is likely to contain the unknown value and a confidence level that the unknown value lays within that range</p>
</blockquote>

<h3 id="commonpatterninscienceandengineering">Common Pattern in Science and Engineering</h3>

<p>보통 두 가지 작업이 있는데,</p>

<p>(1) develop a hypothesis <br />
(2) design an experiment, take measurements <br />
(3) use computation to <br />
- evaluate hypothesis, <br />
- determin values of unknowns, <br />
- predict consequences</p>

<p>두가지는 <code>1 -&gt; 2</code> 순서일 수 있고, 때때로 뒤 바뀔 수도 있다. 예를 한번 살펴보면</p>

<p>먼저 16세기에 <em>Hooke</em> 는 <em>"용수철에 가해진 힘은 그 길이에 비례한다는 가설"</em> 을 세웠다. 이를 증명하기 위해 실험을 고안했는데, 천장에 서로 다른 길이의 스프링을 연결하고 거기에 저울 추를 달았다.</p>

<p>늘어난 길이 <code>x</code> 에 대해 용수철 상수 <code>k</code> 를 <code>kx = mg</code> 를 이용해 계산하면, 얼추 맞는다. 그런데 몇몇 샘플에 대해서는 용수철 상수 <code>k</code> 가 상당히 다르게 나온다. <code>[11.41, 14.49 ...]</code> 왜 그럴까? 용수철 상수가 매번 변한다는걸까? </p>

<p>다음 데이터에 대해 그래프를 그려보면</p>

<pre><code>Distance (m) Mass (kg)  
0.0865 0.1  
0.1015 0.15  
0.1106 0.2  
0.1279 0.25  
0.1892 0.3  
0.2695 0.35  
0.2888 0.4  
0.2425 0.45  
0.3465 0.5  
0.3225 0.55  
0.3764 0.6  
0.4263 0.65  
0.4562 0.7  
0.4502 0.75  
0.4499 0.8  
0.4534 0.85  
0.4416 0.9  
0.4304 0.95  
0.437 1.0  
</code></pre>

<p><em>distance</em> 에 대한 예측 <code>ma / k</code> 와 실제 값이 일치하지 않는다. 이른바 <em>error (오류)</em> 가 있는 것인데, 이들 오류는 <em>small randomness</em> 에 대한 축적의 결과로 이루어 진 것이다.</p>

<p>오류에 대한 <em>probabilty density function</em> 로 <code>y = x - 1 (-1 &lt;= x &lt; 0)</code>, <code>y = -x + 1 (0 &lt; x &lt;= 1)</code> 을 가정했을때 시뮬레이션을 좀 해보자. <code>random.triangular</code> 를 이용하면 <em>triangle distribution</em> 을 얻을 수 있다.</p>

<pre><code class="python">def testErrors(ntrials=10000,npts=100):  
    results = [0] * ntrials
    for i in xrange(ntrials):
        s = 0   # sum of random points
        for j in xrange(npts):
            s += random.triangular(-1,1)
        results[i] =s
    # plot results in a histogram
    pylab.hist(results,bins=50)
    pylab.title('Sum of 100 random points -- Triangular PDF (10,000 trials)')
    pylab.xlabel('Sum')
    pylab.ylabel('Number of trials')

testErrors()  
pylab.show()  
</code></pre>

<p>실행해 보면 에러의 합의 분포가 정규 분포와 비슷하다. 우리가 어떤 에러 분포를 고르든지 간에 <em>finite mean, variance</em> 를 가지고 있다면 에러의 분포는 정규분포다. </p>

<p>실제 그런가 <code>random.triangular</code> 말고 <code>random.uniform</code> 을 이용해 보면 똑같이 정규분포를 얻는다. 이는 <em>central limit theorem (중심극한정리)</em> 를 의미하는데 위키에서 인용하면</p>

<blockquote>
  <p>동일한 확률분포를 가진 독립 확률 변수 n개의 평균값은 n이 적당히 크다면 정규분포에 가까워진다는 정리</p>
</blockquote>

<p>결국 우리가 이전에 스프링을 이용해 봤던 실험에서 발생한 에러는 <em>small random error</em> 의 <em>accumulation</em> 이므로, 우리는 이 에러의 분포를 정규분포라 말할 수 있다는 것이다.</p>

<p><strong>결국 오차 역시 평균 주변에 몰려있는 값이므로, 참값을 상당히 높은 확률로 추측해 낼 수 있다.</strong></p>

<blockquote>
  <p>정규분포는 19세기의 가장 위대한 수학자인 가우스(C. F. Gauss, 1777-1855)에 의해 새롭게 해석된다. 가우스는 관측에 따른 오차의 정도가 대체로 평균값 주변에서 발생한다는 점에 착안하여 정규분포에 따른 확률 밀도 함수와 똑 같은 식을 얻을 수 있었다. 이것은 <strong>관측 오차 역시 정규분포를 따른다는 것으로, 이후 실험으로 구한 관측값에서 참값을 추정해내는 근본적인 원리</strong>로 자리잡게 된다. 이런 점에서 위의 종모양 곡선을 오차곡선(error curve)라고도 부른다.</p>
</blockquote>

<p><em>normal distribution</em> 의 식은 </p>

<p><img src='http://latex.codecogs.com/gif.latex?f%28x%29%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20e%5E%7B-%28x%20-%20%5Cmu%29%5E2%20%5Cover%20%5Csigma%5E2%7D'  alt="" /></p>

<p><code>mu = 0, sigma = 1</code> 인 경우에 <em>standard normal</em> 혹은 <em>unit normal</em> 이라 부른다.</p>

<blockquote>
  <p>So when observation errors are due to the accumlation of many small random perturbations</p>
</blockquote>

<p><img src='http://latex.codecogs.com/gif.latex?f%28x%29%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20e%5E%7B-%28x%29%5E2%20%5Cover%20%5Csigma%5E2%7D'  alt="" /></p>

<p>다시 말해 작은 랜덤의 누적으로 발생한 관측 오차의 경우에는 <code>mu = 0</code> 이다. 그리고 식이 말해주는 바는, 큰 에러의 경우에는 확률이 <em>expnentially less likely</em> 하다는 것이다.</p>

<p>이제 각 에러가 일어날 확률 곱을 다음과 같이 구할 수 있다. </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cprod_%7Bi%20%3D%200%7D%5E%7Blen%28obj%29%20-%201%7D%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29'  alt="" /></p>

<p>이때 이 값을 최대화한다는 것은 각 에러가 나올 확률이 가장 높아야 한다. 다시 말해서 가장 평균적인 에러만 나와야 한다는 뜻이다. 이 값의 최대를 구하는 것은 뒤집은 식의 최소값을 찾는 것과 같으므로</p>

<p><img src='http://latex.codecogs.com/gif.latex?min%20%5C%20%7B1%20%5Cover%20%5Cprod_%7Bi%20%3D%200%7D%5E%7Blen%28obj%29%20-%201%7D%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29%7D'  alt="" /></p>

<p>여기에 자연 로그를 씌우면 확률 변수의 곱이 덧셈으로 변한다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?ln%20%28%7B1%20%5Cover%20%5Cprod%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29%7D%29%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20-%20%5Csum%20ln%20%28L_%7Berr%7D%28obs_i%20-%20pred_i%29%29'  alt="" /></p>

<p>이 값을 최소화 하면 된다. 여기서 <em>pdf</em> 식을 적용하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?min%20-%20%5Csum%20ln%20%28%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20e%5E%7B%28obs_i%20-%20pred_i%29%5E2%20%5Cover%20%5Csigma%5E2%7D%29'  alt="" /></p>

<p>로그를 씌우면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum%20%5Bln%20%7B%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20&plus;%20ln%20%7B%28obs_i%20-%20pred_i%29%5E2%20%5Cover%20%5Csigma%5E2%7D%5D'  alt="" /></p>

<p>이 때 다른 상수를 제외하고 실제 최소화 해야 할 부분만 고려하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?min%20%5Csum%20%28obs_i%20-%20pred_i%29%5E2'  alt="" /></p>

<p>따라서 이 값을 최소화 하면 <em>most likely observations</em> 가 된다. 이런 이유에서 오차 제곱의 합의 최소가 되는 파라미터가 바로 가장 신뢰할만한 파라미터가 된다.</p>

<p><br/> <br />
처음부터 정리하자면, 중심 극한 정리에 따라 에러의 분포가 어떠하든 간에 에러가 확률변수라면 이것의 평균은 정규분포다. 따라서 <em>pdf</em> 식을 적용할 수 있고 이때 <code>mean = 0</code> 이다.</p>

<p>에러가 나올 확률의 곱이 최대이면, 모든 에러에 대해 보편적인 에러를 얻었다는 뜻이므로 이에 대해 식을 정리하면,</p>

<p><em>sum of squared of erros (SSE, least square)</em> 를 최소화 하는 파라미터를 선택하면 가장 신뢰할 만한 관측 결과를 얻어낼 수 있다는 결론을 얻게된다.</p>

<p><br/> <br />
파이선에서는 <code>pylab.plotfit</code> 을 이용해 값을 최소화 하는 파라미터를 뽑아낼 수 있다. 예를 들어서 <code>y = ax + b</code> 의 합을 최소화 하는 <code>a, b</code> 를 찾으려면 </p>

<pre><code class="python">a, b = pylab.ployfir(xvals, yvals, 1)  
</code></pre>

<p><code>y = ax^2 + bx + c</code> 에 대해서는</p>

<pre><code class="python">a, b, c = pylab.polyfit(xvals, yvals, 2)  
</code></pre>

<h3 id="firingarrow">Firing Arrow</h3>

<p>이제 위에서 얻은 개념을 다른 예제에 적용해보면서 가설이 얼마나 <em>잘 맞는가</em> 를 어떻게 측정할건지를 좀 생각해 보자. (<em>Measuring "goodness" of fit</em>)</p>

<p>화살이 날라가는 거리에 따른 높이를 측정한 데이터다.</p>

<pre><code>Distance (yds) height (ins) height height height  
30  0 0 0 0  
29 2.25 3.25 4.5 6.5  
28 5.25 6.5 6.5 8.75  
27 7.5 7.75 8.25 9.25  
26 8.75 9.25 9.5 10.5  
25 12 12.25 12.5 14.75  
24 13.75 16 16 16.5  
23 14.75 15.25 15.5 17.5  
22 15.5 16 16.6 16.75  
21 17 17 17.5 19.25  
20 17.5 18.5 18.5 19  
15 19.5 20 20.25 20.5  
10 18.5 18.5 19 19  
5 13 13 13 13  
0 0 0 0 0  
</code></pre>

<pre><code class="python">def getTrajectoryData(fileName):  
    dataFile = open(fileName, 'r')
    distances = []
    heights1, heights2, heights3, heights4 = [],[],[],[]
    discardHeader = dataFile.readline()
    for line in dataFile:
        d, h1, h2, h3, h4 = line.split()
        distances.append(float(d))
        heights1.append(float(h1))
        heights2.append(float(h2))
        heights3.append(float(h3))
        heights4.append(float(h4))
    dataFile.close()
    return (distances, [heights1, heights2, heights3, heights4])

def tryFits(fName):  
    distances, heights = getTrajectoryData(fName)
    distances = pylab.array(distances)*36 # convert yard to
    totHeights = pylab.array([0]*len(distances))
    for h in heights:
        totHeights = totHeights + pylab.array(h)
    pylab.title('Trajectory of Projectile (Mean of 4 Trials)')
    pylab.xlabel('Inches from Launch Point')
    pylab.ylabel('Inches Above Launch Point')
    meanHeights = totHeights/float(len(heights))
    pylab.plot(distances, meanHeights, 'bo')
    a,b = pylab.polyfit(distances, meanHeights, 1)
    altitudes = a*distances + b
    pylab.plot(distances, altitudes, 'r',
               label = 'Linear Fit')
    a,b,c = pylab.polyfit(distances, meanHeights, 2)
    altitudes = a*(distances**2) + b*distances + c
    pylab.plot(distances, altitudes, 'g',
               label = 'Quadratic Fit')
    pylab.legend()
</code></pre>

<p>위 코드를 돌려보면 이차함수가 일차함수보다 더 <em>fit</em> 한 걸 볼 수 있다. 그럼 문제는 매번 그래프로 그릴수도 없고 어떻게 측정할거냐 하는건데, <em>variabilty</em> 를 이용하는 방법이 있다. 다시 말해 에러가 얼마나 많이 변하냐는 것이다.</p>

<p><em>variability of errors</em> 는 SEE, 즉 관측 데이터와 예측값 간 차이의 제곱의 합으로 구할 수 있다. 그리고 <em>variability of data</em> 는 관측값과 관측값의 평균의 차이의 제곱의 합으로 구할 수 있다. 그리고 이 두 변수간 비율로 모델이 얼마나 잘 맞는지를 판단할 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?1%20-%20%7B%5Csigma_%7Berr%7D%5E2%20%5Cover%20%5Csigma_%7Bdata%7D%5E2%7D'  alt="" /></p>

<p>이 값을 <code>R^2</code> 또는 <em>coefficient of determination</em> 이라 부른다. 이 값이 <code>1</code> 에 근접하면 모델이 데이터와 잘 맞고, <code>0</code> 에 가까우면 거의 안맞는다는 뜻이다.</p>

<p>그러나 주의해야 할 점이 하나 있다. <code>R^2</code> 값이 높은 모델이라고 해서 좋은 모델이라는 뜻은 아니다. 지금 현재 가진 데이터에 <em>fit</em> 된다는 거지, 실제 데이터에 적용하면 어떻게 될지 모른다. <em>overfitting</em> 할 수도 있다는 이야기다.</p>

<p>파이썬에서 <code>R^2</code> 를 구하는 함수를 만들면</p>

<pre><code class="python">def rSquare(measured, estimated):  
    """measured: one dimensional array of measured values
       estimate: one dimensional array of predicted values"""
    SEE = ((estimated - measured)**2).sum()
    mMean = measured.sum()/float(len(measured))
    MV = ((mMean - measured)**2).sum()
    return 1 - SEE/MV
</code></pre>

<h3 id="references">References</h3>

<p>(1) <em>MIT 6.00.2 2x</em> in <strong>edx</strong> <br />
(2) <a href='http://ko.wikipedia.org/wiki/%EC%A4%91%EC%8B%AC%EA%B7%B9%ED%95%9C%EC%A0%95%EB%A6%AC' >http://ko.wikipedia.org</a> <br />
(3) <a href='http://www.financedoctor.co.kr/finance/view.php?f_idx=14587&amp;b_code=8&amp;m_code=0&amp;s_code=0' >http://www.financedoctor.co.kr</a> <br />
(4) <a href='http://www.researchgate.net/post/What_is_the_difference_among_Deterministic_model_Stochastic_model_and_Hybrid_model' >www.researchgate.net/</a> <br />
(5) <a href='http://www4.stat.ncsu.edu/' ~gross/BIO560%20webpage/slides/Jan102013.pdf">www4.stat.ncsu.edu</a></p>]]></description><link>http://1ambda.github.io/edx-600-2x-2/</link><guid isPermaLink="false">32cb7752-47f2-4ad2-a5cf-176453e06a7c</guid><category><![CDATA[edx]]></category><category><![CDATA[python]]></category><category><![CDATA[simulation]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 21 Nov 2014 15:43:27 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 5]]></title><description><![CDATA[<p>키보드를 읽거나 화면에 무엇인가 쓰는 <em>intertactive program</em> 은 <em>side-effect</em> 를 만듭니다. 그런데, 하스켈은 <em>side-effect</em> 가 없지요. 그럼 입출력이 불가능한 것일까요? </p>

<p>당연히 그렇지 않습니다. <strong>IO 모나드</strong> 를 사용할겁니다.</p>

<p><em>pure expression</em> 부분과 <em>side-effect</em> 를 만들어내는 <em>impure action</em> 을 구분하여 하스켈에서 입출력을 할 수 있습니다.</p>

<blockquote>
  <p>Interactive program can be written in Haskell using types to distinguish pure expressions from impure actions that may involve side effects</p>
</blockquote>

<p>예를 들어 <code>IO a</code> 는 <code>a</code> 타입을 리턴하는 <em>action</em> 입니다.</p>

<p>몇 가지 예를 보면, <code>IO Char</code> 은 캐릭터를 리턴하는 액션입니다. <code>IO ()</code> 는 <em>unit</em> 을 돌려주는데 이건 절차형 언어에서의 <em>void</em> 와 같다고 보면 됩니다. 다시 말해서 <code>IO ()</code> 는 다른 것엔 아무것도 관심 없고 입출력에만 관심이 있다는 뜻이지요.</p>

<p>지난 시간에 언급 했듯이 <em>IO 모나드</em> 는 사실 <em>State 모나드</em> 입니다.</p>

<pre><code class="haskell">State -&gt; (a, State)  
</code></pre>

<p>스크린이나, 키보드 버퍼등 다양한 State 를 변화시켜 가면서 <code>a</code> 타입의 값을 리턴할 수 있죠. 위에서 본 <code>IO ()</code> 는 <em>purely side-effecting action</em> 입니다.</p>

<h3 id="basicactions">Basic Actions</h3>

<p><code>getChar</code> 는 키보드로부터 글자를 하나 읽어 캐릭터를 리턴합니다. 다른 언어에서는 <code>() -&gt; Char</code> 처럼 정의되었겠죠?</p>

<pre><code class="haskell">getChar :: IO Char  
</code></pre>

<p>다른 <em>action</em> 도 좀 살펴볼까요?</p>

<pre><code class="haskell">puChar :: Char -&gt; IO ()  
return :: a -&gt; IO a  
</code></pre>

<h3 id="sequencing">Sequencing</h3>

<p><em>action</em> 들을 <code>do</code> 로 조합할 수 있습니다.</p>

<pre><code class="haskell">a :: IO (Char, Char)  
a = do x &lt;- getChar  
    getChar
    y &lt;- getChar
    return (x, y)

getLine :: IO String  
getLine = do x &lt;- getChar  
             if x == '\n' then
               return []
             else
               do xs &lt;- getLine
                  return (x:xs)
</code></pre>

<p>몇 가지 더 볼까요?</p>

<pre><code class="haskell">putStr :: String -&gt; IO ()  
putStr [] = return ()  
putStr (x:xs) = do putChar x  
                   putStr xs

putStrLn :: String -&gt; IO ()  
putStrLn xs = do putStr xs  
                 putChar '\n'
</code></pre>

<p>모나드의 산을 넘고 넘어야 IO 의 간결함이 이해가 되니, 아이러니 하죠? 본래 입출력은 정말 기초적인 부분인데 말이지요.</p>

<p>참고로 <em>list comprehension</em> 을 이용하면 <code>putStr</code> 은 이렇게 정의할 수 있습니다.</p>

<pre><code class="haskell">seqn :: [IO a] -&gt; IO ()  
seqn [] = return ()  
seqn (x:xs) = do x  
                 seqn xs

putStr xs = seqn [putChar x | x &lt;- xs]  
</code></pre>

<p>조금 더 블럭을 쌓아봅시다. 문자열을 키보드로 부터 입력받아 화면에 그 길이를 띄워주는 함수를 작성해 봅시다.</p>

<pre><code class="haskell">strlen :: IO ()  
strlen = do putStr "Enter a string: "  
            xs &lt;- getLine
            putStr "The string has "
            putStr (show (length xs))
            putStrLn " characters"

&gt; strlen
-- Enter a string: Hello World!
-- the string has 12 characters
</code></pre>

<p><code>strlen</code> 은 <code>IO ()</code> 타입이니까, 아무것도 돌려주지 않습니다. 입출력에만 관심이 있지요.</p>

<h3 id="hangman">Hangman</h3>

<p>이제까지 배운것을 응용해서 자그마한 행맨 게임을 만들어 봅시다. <em>top down</em> 방식으로 접근할 겁니다.</p>

<pre><code class="haskell">hangman :: IO ()  
hangman = do putStrLn "Think of a word :"  
             word &lt;- sgetLine
             putStrLn "Try to guess it:"
             guess word
</code></pre>

<p>여기서 <code>sgetLine</code> 은 키보드로부터 문자를 입력받아 <code>-</code> 를 화면에 출력합니다.</p>

<pre><code class="haskell">sgetLine :: IO String  
sgetLine = do x &lt;- getCh  
              if x == '\n'
                then do putChar x
                        return []
                else do putChar '-'
                        xs &lt;- sgetLine
                        return (x:xs)
</code></pre>

<p><code>getCh</code> 는 문자열을 키보드로 부터 읽지만 화면에 출력하진 않지요.</p>

<pre><code class="haskell">import System.IO

getCh :: IO Char  
getCh = do hSetEcho stdin False  
           c &lt;- getChar
           hSetCho stdin True
           return c
</code></pre>

<p>여기서 잘 보면 <code>c &lt;- getChar</code> 이 할당(<code>=</code>)처럼 보일텐데, 사실은 그렇지 않습니다. 우린 어떠한 <em>mutable</em> 도 변수도 사용하고 있지 않습니다. 비록 우리가 작성한 코드가 절차형 언어처럼 보일지라도요!</p>

<p>이제 마지막 퍼즐인 <code>guess</code> 함수를 작성해 볼까요?</p>

<pre><code class="haskell">guess :: String -&gt; IO ()  
guess word = do putStr "&gt; "  
                xs &lt;- getLine
                if xs == word
                  then putStrLn "You got it!"
                  else do putStrLn (diff word xs)
                          guess word

diff :: String -&gt; String -&gt; String  
diff xs ys = [if elem x ys then x else '-' | x &lt;- xs]  
</code></pre>

<p><code>diff</code> 를 잠깐 실행해 보면</p>

<pre><code class="haskell">&gt; diff "haskell" "pascal"
-- "-as--ll"
</code></pre>

<h3 id="calculator">Calculator</h3>

<p>시작 전에 몇 가지 보조 함수를 정의하면,</p>

<pre><code class="haskell">getCh :: IO Char  
getCh =  do hSetEcho stdin False  
            c &lt;- getChar
            hSetEcho stdin True
            return c

beep :: IO ()  
beep = putStr "\BEL"

cls :: IO ()  
cls = putStr "\ESC[2J"

type Pos = (Int, Int)

goto :: Pos -&gt; IO ()  
goto (x, y) = putStr ("\ESC["  ++ show y ++ ";" ++ show x ++ "H")

writeAt :: Pos -&gt; String -&gt; IO ()  
writeAt p xs = do goto p  
                  putStr xs
</code></pre>

<p>콘솔 창에서 문자의 위치는 좌표 <code>(Int, Int)</code> 에 의해 결정됩니다. <code>goto</code> 는 그 위치로 커서를 옮기고 <code>writeAt</code> 는 해당 좌표에 입력받은 문자열을 출력합니다.</p>

<p>여기에 <a href='http://1ambda.github.io/haskell-intro4/' >지난번</a>에 만들었던 파서가 <code>-</code>, <code>/</code> 도 처리할 수 있게 조금 업그레이드 하면</p>

<pre><code class="haskell">int :: Parser Int  
int =  do char '-'  
          n &lt;- nat
          return (-n)
        +++ nat

natural :: Parser Int  
natural =  token nat

integer :: Parser Int  
integer =  token int

expr :: Parser Int  
expr = do t &lt;- term  
          do symbol "+"
             e &lt;- expr
             return (t + e)
           +++ do symbol "-"
                  e &lt;- expr
                  return (t - e)
           +++ return t

term :: Parser Int  
term = do f &lt;- factor  
          do symbol "*"
             t &lt;- term
             return (f * t)
           +++ do symbol "/"
                  t &lt;- term
                  return (f `div` t)
           +++ return f

factor :: Parser Int  
factor = do symbol "("  
            e &lt;- expr
            symbol ")"
            return e
          +++ natural
</code></pre>

<p>이제 간단한 계산기를 문자열로 나타내 보면</p>

<pre><code class="haskell">box :: [String]  
box =  ["+---------------+",  
       "|               |",
       "+---+---+---+---+",
       "| q | c | d | = |",
       "+---+---+---+---+",
       "| 1 | 2 | 3 | + |",
       "+---+---+---+---+",
       "| 4 | 5 | 6 | - |",
       "+---+---+---+---+",
       "| 7 | 8 | 9 | * |",
       "+---+---+---+---+",
       "| 0 | ( | ) | / |",
       "+---+---+---+---+"]
</code></pre>

<p><code>q, c, d, =</code> 는 <em>quit</em>, <em>clear</em>, <em>delete</em> <em>evaluation</em> 를 의미합니다. 나머지 버튼은 식을 입력하는데 사용하지요. 이제 박스를화면에 그려주는 <code>showbox</code> 함수를 작성합시다.</p>

<pre><code class="haskell">seqn :: [IO a] -&gt; IO ()  
seqn [] = return ()  
seqn (a:as) = do a  
                 seqn as

buttons :: [Char]  
buttons = standard ++ extra  
          where
            standard = "qcd=123+456-789*0()/"
            extra = "QCD \ESC\BS\DEL\n"

showbox :: IO ()  
showbox =  
  seqn [writeAt (1, y) line | (y, line) &lt;- zip [1..13] box]
</code></pre>

<p><code>buttons</code> 에서 <code>extra</code> 는 좀 더 유연한 버튼 인터페이스를 위해 사용합니다. 무슨 말인고 하니 <code>q</code> 뿐만 아니라 <code>Q</code> 를 눌러도 계산기가 종료되게끔요. </p>

<p>이제 수식을 표현하는 부분을 출력해줄 <code>display</code> 함수를 만듭시다. 입력받은 문자열을, 뒤에서부터 13개만 짤라서 <code>(3, 2)</code> 위치에 출력해줍니다.</p>

<pre><code class="haskell">display :: String -&gt; IO ()  
display xs = do writeAt (3, 2) "             "  
                writeAt (3, 2) (reverse (take 13 (reverse xs)))
</code></pre>

<p>이제 사용자로부터 문자를 입력받아 화면에 출력해주는 로직을 구현한 <code>calc</code> 함수를 보면</p>

<pre><code class="haskell">calc :: String -&gt; IO ()  
calc xs = do display xs  
             c &lt;- getCh
             if elem c buttons
               then process c xs
               else do beep
                       calc xs

process :: Char -&gt; String -&gt; IO ()  
process c xs  
  | elem c "qQ\ESC" = quit
  | elem c "dD\BS\DEL" = delete xs
  | elem c "=\n" = eval xs
  | elem c "cC" = clear
  | otherwise = press c xs
</code></pre>

<p><code>calc</code> 에서는 현재 수식창에 입력된 데이터 <code>xs</code> 와, 사용자로부터 받은 <code>c</code> 를 이용해 작업을 합니다. <code>c</code> 가 만약 <code>buttons</code> 내부에 없다면 다시 <code>calc xs</code> 를 호출해서 새로운 입력을 받습니다.</p>

<p>만약 <code>c</code> 가 <code>buttons</code> 내에 있는 문자들 중 하나라면 <code>process c xs</code> 를 호출하는데, 여기서는 버튼의 종류에 따라 다른 <code>IO ()</code> 를 돌려줍니다.</p>

<pre><code class="haskell">quit :: IO ()  
quit = goto (1, 14)

delete :: String -&gt; IO ()  
delete "" = calc ""  
delete xs = calc (init xs)

eval :: String -&gt; IO ()  
eval xs = case parse expr xs of  
           [(n, "")] -&gt; calc (show n)
           _ -&gt; do beep
                   calc xs

clear :: IO ()  
clear = calc ""

press :: Char -&gt; String -&gt; IO ()  
press c xs = calc (xs ++ [c])  
</code></pre>

<p>(1) <code>quit</code> 는 다시 <code>calc</code> 호출 없이 현재 커서를 14번째 라인으로 이동해 계산기를 종료합니다. <br />
(2) <code>delete</code> 는 현재 <code>xs</code> 에서 마지막 문자를 제거한 <code>init xs</code> 를 <code>calc</code> 에 넘겨줌으로써 수식 입력창에서 마지막 문자를 지웁니다. <br />
(3) <code>eval</code> 는 <code>parse expr xs</code> 의 결과로 올바른 계산 값을 얻으면 <code>calc</code> 에 그 숫자를 문자열로 변환한 결과를 넘겨주어 계산값을 표시합니다. (<code>show n</code>) 아니라면, 계산이 안되므로 비프음을 뿜고 다시 <code>calc xs</code> 를 호출해 새로운 입력을 기다립니다. <br />
(4) <code>clear</code> 는 수식 입력창에 있는 값을 <code>""</code> 를 돌려줌으로써 비웁니다. <br />
(5) <code>press</code> 는 현재 수식 입력창에 있는 데이터 <code>xs</code> 에 <code>c</code> 를 이어 붙입니다.  </p>

<p>잘 보시면 현재 가지고 있는 데이터는 <code>xs</code> 로 표시되고, 이외의 <code>IO ()</code> 를 조합해 가며 화면의 상태(<em>State</em>) 를 변화시킵니다. 이 과정에서 <strong>화면을 변화시키는 부분과, 데이터 <code>xs</code> 가 변하는 부분이 서로 분리</strong> 되어 있습니다.</p>

<p>마지막으로 계산기를 실행시키는 함수 <code>run</code> 을 만들겠습니다.</p>

<pre><code class="haskell">run :: IO ()  
run = do cls  
         showbox
         clear
</code></pre>

<h3 id="gameoflife">Game of Life</h3>

<p><del>인생게임은 아닙니다</del> 세포의 생존게임이라 생각하면 이해하기 쉽습니다. <code>n * m</code> 보드에서 각 칸마다 세포가 위치할 수 있습니다.</p>

<blockquote>
  <ol>
  <li><p>a living cell survives if it has precisely two or three neighbouring squares that contain living cells, and dies (becomes empty) otherwise.</p></li>
  <li><p>an empty square gives birth to a living cell if it has precisely neighbours that contain living cells, and remains empty otherwise.</p></li>
  </ol>
</blockquote>

<p>각 칸마다 균등한 기회를 주기 위해 모서리에 있는 칸 또한 8개의 이웃한 칸을 가졌다고 합시다. <em>torus (3차원의 도넛모양 )</em> 을 생각하심 됩니다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Simple_Torus.svg/310px-Simple_Torus.svg.png'  alt="" /></p>

<p align="center">(<a href='http://commons.wikimedia.org/wiki/File:Simple_Torus.svg' >http://commons.wikimedia.org/wiki/File:Simple_Torus.svg</a>)</p>

<p>초기값에 따라 턴을 반복하면서 다양한 종류의 결과물이 나옵니다. 그 중에서 초기값이 몇번의 턴을 지나면서 지속적으로 대각선으로 움직이는 패턴을 <em>glider</em> 라 부릅니다.</p>

<p><img src='https://camo.githubusercontent.com/f865db6a304d36aa7fef6c060729a2d635cd5c14/687474703a2f2f7777772d726f68616e2e736473752e6564752f7e72636172726574652f7465616368696e672f4d2d3539365f706174742f696d616765732f676c696465722e676966'  alt="" /></p>

<p align="center">(<a href='https://gist.github.com/boggle/10390842' >https://gist.github.com/boggle/10390842</a>)</p>

<p>이제 <em>row</em> 를 <code>x</code>, <em>column</em> 을 <code>y</code> 로 해서 1 부터 시작하는 <code>5 x 5</code> 의 <em>glider</em> 보드를 만들면</p>

<pre><code class="haskell">width :: Int  
width = 5

height :: Int  
height = 5

type Board = [Pos]

glider :: Board  
glider = [(4,2),(2,3),(4,3),(3,4),(4,4)]

showCells :: Board -&gt; IO ()  
showCells b = seqn [writeAt p "O" | p &lt;- b]

isAlive :: Board -&gt; Pos -&gt; Bool  
isAlive b p = elem p b

isEmpty :: Board -&gt; Pos -&gt; Bool  
isEmpty = not (isAlive b p)  
</code></pre>

<p>여기에 해당 칸의 세포가 살았는지 죽었는지 검사하는 <code>isAlive</code>, <code>isEmpty</code> 와 보드를 출력하는 <code>showCells</code> 함수도 만들었습니다.</p>

<p>이제 어떤 <code>(x, y)</code> 를 입력 받아 그 주변 8개의 이웃 세포 좌표를 돌려주는 함수를 만들면</p>

<pre><code class="haskell">neighbs :: Pos -&gt; [Pos]  
neighbs (x,y) =  map wrap [(x-1,y-1), (x,y-1),  
                           (x+1,y-1), (x-1,y),
                           (x+1,y)  , (x-1,y+1),
                           (x,y+1)  , (x+1,y+1)] 

wrap :: Pos -&gt; Pos  
wrap (x,y) =  (((x-1) `mod` width) + 1, ((y-1) `mod` height + 1))  
</code></pre>

<p><code>wrap</code> 은 <code>mod</code> 연산을 이용해서, 판의 범위를 벗어난 이웃 세포의 좌표를 판 내에 있는 이웃으로 만들어 돌려줍니다. 예를 들어 </p>

<pre><code class="haskell">&gt; wrap (0, 1)
-- (5,1)
</code></pre>

<p>이제 살아있는 이웃 세포의 개수를 돌려주는 <code>liveNeighbs</code> 와, 살아있는 세포들(인접한 살아있는 세포가 2, 3개인) 좌표를 돌려주는 <code>survivors</code> 함수를 만듭시다.</p>

<pre><code class="haskell">liveNeighbs :: Board -&gt; Pos -&gt; Int  
liveNeighbs b = length . filter (isAlive b) . neighbs

survivors :: Board -&gt; [Pos]  
survivors b = [p | p &lt;- b, elem (liveNeighbs b p) [2, 3]]  
</code></pre>

<p>그리고 죽은 세포에 대해 인접한 살아있는 세포가 3개일 때만 살아있는 세포로 변경하는 <code>births</code> 함수를 만들면</p>

<pre><code class="haskell">births :: Board  
births :: Board -&gt; [Pos]  
births b = [p | p &lt;- rmdups (concat (map neighbs b)),  
            isEmpty b p,
            liveNeighbs b p == 3]

rmdups :: Eq a =&gt; [a] -&gt; [a]  
rmdups [] = []  
rmdups (x:xs) = x : filter (/= x) xs  
</code></pre>

<p>중복을 제거하기 위해 <code>rmdups</code> 함수를 만들어서 사용했습니다.</p>

<p>이렇게 되면, 다음 턴에서의 <em>board</em> 는 <code>survivors</code> 와 <code>births</code> 의 원소들 이므로</p>

<pre><code class="haskell">nextGen :: Board -&gt; Board  
nextGen b = survivors b ++ births b  
</code></pre>

<p>이제 화면 출력을 위한 몇 가지 함수를 더 만들면</p>

<pre><code class="haskell">life :: Board -&gt; IO ()  
life b = do cls  
            showCells b
            wait 5000
            life (nextGen b)

wait :: Int -&gt; IO ()  
wait n = seqn [return () | _ &lt;- [1..n]]  
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <em>Programming in Haskell</em> <br />
(3) <a href='https://gist.github.com/boggle/10390842' >gist.github.com/boggle</a></p>]]></description><link>http://1ambda.github.io/haskell-intro5/</link><guid isPermaLink="false">2ec0d609-25c4-4cac-bfd7-196899ad001f</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[monad]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 21 Nov 2014 02:20:50 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 4]]></title><description><![CDATA[<p>이번시간엔 모나드를 배웁니다. <del>네. 올것이 왔습니다.</del> 간단한 파서를 구현하는 것 부터 시작해 보겠습니다.</p>

<h3 id="whatisaparser">What is a Parser</h3>

<p><strong>Parser (파서)</strong> 란 텍스트 조각을 분석하여 <em>syntaxtic structure</em> 를 만들어 내는 프로그램(코드)를 말합니다.</p>

<p>많은 프로그램들이 자신만의 파서를 가지고 있습니다. <em>GHC</em> 는 <em>haskell</em> , <em>UNIX</em> 는 <em>shell script</em>, <em>explorer</em> 는 <em>HTML</em> 분석합니다.</p>

<h3 id="theparsertype">The Parser Type</h3>

<pre><code class="haskell">type Parser = String -&gt; Tree  
</code></pre>

<p>하스켈 같은 함수형 언어에서 파서는 함수라 볼 수 있습니다. 문자열을 받아서 <em>Tree (트리)</em> 를 만들어 주는 함수처럼요.</p>

<p>때때로 입력된 문자열이 이상하다면 파서가 제대로 동작하지 않을수도 있습니다. 그럴때 분석되지 않은 문자열을 돌려주려면 이런 형태여야 합니다.</p>

<pre><code class="haskell">type Parser = String -&gt; (Tree, String)  
</code></pre>

<p>어떤 문자열들은 여러가지로 해석될 수도 있겠지요. 그럼 리스트를 돌려줘야겠네요.</p>

<pre><code class="haskell">type Parser = String -&gt; [(Tree, String)]  
</code></pre>

<p>꼭 파서가 트리를 만들 필요는 없지 않을까요? 문자열이 <code>1 + 2</code> 라면 이 값을 더한 <code>3</code> 을 돌려줄 수도 있을겁니다.</p>

<pre><code class="haskell">type Parser a = String -&gt; [(a, String)]  
</code></pre>

<p>이번 강의에서는 복잡한 파서를 구현하기 보다 파서가 무슨일을 하는지에 집중할 것이므로 파서의 타입을 심플하게 가져가겠습니다. 파서가 문자열을 분석하는데 실패하면 <code>[]</code>  성공하면 <em>singleton list</em> 를 돌려주겠습니다.</p>

<h3 id="basicparsers">Basic Parsers</h3>

<p>먼저 문자열에서 첫 번째 원소를 소비하고, 나머지를 돌려주는 간단한 <code>item</code> 파서를 만들어 봅시다. 이 파서는 빈 문자열에 대해서는 <code>[]</code> 를 돌려줍니다.</p>

<pre><code class="haskell">module Lecture7 where

type Parser a = String -&gt; [(a, String)]

item :: Parser Char  
item = \xs -&gt; case xs of  
               [] -&gt; []
               (x:xs) -&gt; [(x, xs)]
</code></pre>

<p>실행하면 이런 결과를 얻습니다.</p>

<pre><code class="haskell">&gt; item "hello world"
-- [('h',"ello world")]

&gt; item ""
-- []
</code></pre>

<p>항상 <code>[]</code> 만 돌려주는 <code>failure</code> 파서와 <code>a -&gt; Parser a</code> 타입의 <code>return</code> 도 만들어 봅시다. 하나는 항상 실패하고, 다른 하나는 항상 성공하는 파서입니다.</p>

<pre><code class="haskell">failure :: Parser a  
failure = \xs -&gt; []

return :: a -&gt; Parser a  
return v = \xs -&gt; [(v, xs)]

&gt; failure "hello world!"
-- []

&gt; (return "hello") " world"
-- [("hello"," world")]

&gt; (return "hello") ""
-- [("hello","")]
</code></pre>

<p>이제 두 개의 파서를 붙이는 함수 <code>(+++)</code> 를 만들어 봅시다. <code>p +++ q</code> 에 대해 파서 <code>p</code> 가 성공하면 <code>p</code> 의 리턴값을, <code>p</code> 가 실패하면 <code>q</code> 가 처리하게 합시다. 위에서 항상 성공하는 파서 <code>return v</code> 와 항상 실패하는 파서 <code>failure</code> 를 여기다 붙이며 어떻게 될지도 한번 생각해 보는것도 좋습니다.</p>

<pre><code class="haskell">(+++) :: Parser a -&gt; Parser a -&gt; Parser a
p +++ q = \xs -&gt; case p xs of  
                  [] -&gt; parse q xs
                  [(y, ys)] -&gt; [(y, ys)]

parse :: Parser a -&gt; String -&gt; [(a, String)]  
parse p xs = p xs  
</code></pre>

<p>여기서 <code>parse</code> 는 그냥 <em>readable</em> 한 코드를 만들기 위해 사용했다고 보면 됩니다. 파서와 텍스트를 받아서 그 적용한 결과를 돌려줍니다.</p>

<pre><code class="haskell">&gt; parse (return '1') "234"
-- [('1',"234")]

&gt; parse failure "abcd"
-- []

&gt; parse (failure +++ (return '1')) "abcd"
-- [('1',"abcd")]

&gt; parse (item +++ return 'd') "abc"
-- [('a', "bc")]
</code></pre>

<h3 id="monad">Monad</h3>

<p>여기서 잠깐 생각해 볼 거리가 있습니다. "<em>parser</em> 가 대체 무슨일을 하고 있는가?"</p>

<p>파서의 타입을 잘 보면 원본 타입 <code>String</code> 을 받아, 여기서 부가적인 작업을 해서 <code>a</code> 타입을 만들고, 다시 본래 타입인 <code>String</code> 더해 튜플로 만들어 돌려줍니다. 다시 말해 파서는 <em>한 타입을 받아 부가적인 정보를 만들어 본래 타입에 붙여주는 함수</em> 라 볼 수 있습니다.</p>

<p>파서의 연결을 도와주는 함수는 <code>(+++)</code> 무엇일까요? <em>부가적인 정보를 붙여주는 파서 를 <strong>합성</em></strong> 해 주는 역할을 합니다.</p>

<p>지금 <code>(+++)</code> 의 규칙은 <code>p</code> 가 실패하면 <code>q</code> 를 적용하지만, 파서 <code>t, u, v</code> 를 받아 모두 적용한 뒤 결과를 돌려주는 연산자도 만들 수 있습니다.</p>

<p><code>(+++)</code> 자체는 하나의 규칙을 의미하지만 자세히 보면 이외에도 다양한 규칙을 가진 합성 함수를 만들 수 있다는 것을 알 수 있습니다. </p>

<p>부가적인 정보를 만들어 내는 함수와(파서), 이 파서간의 합성이 아주 중요한 키 포인트입니다. 그리고 이 파서가 바로 <em>monad</em> 입니다. <del>두둥</del></p>

<blockquote>
  <p>The parser type is a <strong>monad</strong>, a mathematical structure that has proved useful for modeling many different kinds of computations</p>
</blockquote>

<h3 id="sequencing">Sequencing</h3>

<p>위에서는 두개의 파서를 엮어 하나로 만들긴 했지만 둘 중에 하나만 사용했죠. 둘 다 사용하진 않았습니다. 그럼 둘 이상의 파서를 엮어 하나의 파서를 만들려면 어떻게 해야할까요? 일단 생각해 볼 수 있는건 타입이 좀 다릅니다. </p>

<p>서로 다른 두개의 파서 <code>Parser a</code> 와 <code>Parser b</code> 를 고려해 봅시다. </p>

<pre><code class="haskell">type Parser a = String -&gt; [(a, String)]

Parser a  
-- String -&gt; [(a, String)]

Parser b  
-- String -&gt; [(b, String)]
</code></pre>

<p><code>Parser a</code> 의 출력은 <code>[(a, String)]</code>, 이기 때문에 다른 파서 <code>Parser b</code> 의 입력 <code>String</code> 이 될 수 없습니다. </p>

<p>그리고 여기서 한 가지 더 중요한 사실은, <code>Parser a</code> 가 <code>String</code> 을 이용해 만든 타입 <code>a</code> 의 부가정보를 <code>Parser b</code> 에 손실 없이 넘겨줘야 한다는 사실입니다. 그래야만 파서를 조합한 의미가 있지요.</p>

<p>정리하자면 <code>Parser a</code> 를 받아 <code>Parser b</code> 를 돌려주는 <em>파서 조합함수</em> 를 만들 것인데,  부가정보 <code>a</code> 의 보존을 위해 이 함수 내부에서 <code>a -&gt; Parser b</code> 타입의 중간 함수가 필요합니다. <strong>이 중간 함수가 어디에서 어떤 일을 할지가 구현해야 할 부분이자, 가장 중요한 부분</strong>입니다. 파서 종류에 따라 원본 데이터 (여기서는 <code>String</code>) 을 조작하는 방법이 다르기 때문입니다. 거꾸로 말하면 <em>다양한 종류의 파서가 있다는 말</em> 입니다.</p>

<p>함수의 이름은 <code>&gt;&gt;=</code> 라 짓겠습니다. <em>bind</em> 라 읽습니다. 타입은</p>

<pre><code class="haskell">type Parser a = String -&gt; [(a, String)]

parse :: Parser a -&gt; String -&gt; [(a, String)]  
parse p xs = p xs

(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b
</code></pre>

<p>구현은 </p>

<pre><code class="haskell">p &gt;&gt;= q = \xs -&gt; case p xs of  
                  [] -&gt; []
                  (y, ys) -&gt; parse (q y) ys
</code></pre>

<p>즉 <code>&gt;&gt;=</code> 는 <code>Parser a</code> 의 처리 결과가 <code>[]</code> 이면 <code>[]</code> 을 돌려줍니다. 올바르게 처리되었을 경우에는 <code>Parser a</code> 의 결과로 얻어진 부가정보 <code>a</code> 타입에 대해 <code>a -&gt; Parser b</code> 타입의 함수인 <code>y</code> 에게 넘겨 <code>Parser b</code> 를 받고 결과적으로는 <code>\xs -&gt; parse k ys</code> 를 돌려줍니다. (<code>k :: parser b</code>) 그런데, 여기서 <code>parse k ys</code> 의 결과가 <code>[(b, String)]</code> 이기 때문에 <code>\xs -&gt; parse k ys</code> 는 <code>Parser b</code> 라 볼 수 있습니다. </p>

<p>최종적으로는 <code>Parser a</code> 를 이용해 <code>Parser b</code> 를 만들어 냈습니다.</p>

<p>예제를 한번 보시죠. <code>Parser Char</code> 을 이용해 <code>Parser (Char, Char)</code> 을 만들어 볼 수 있습니다.</p>

<pre><code class="haskell">return :: a -&gt; Parser a  
return v = \xs -&gt; [(v, xs)]

(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b
p &gt;&gt;= q = \xs -&gt; case p xs of  
                   [] -&gt; []
                   (y, ys) -&gt; parse (q, y) ys

-- consume only one Char
parseTwice :: Parser (Char, Char)  
parseTwice = item &gt;&gt;= \x -&gt; return (x, x)  
</code></pre>

<pre><code class="haskell">parseTwice "5BEAF"  
-- [((5, 5), "BEAF")] 
</code></pre>

<p><code>item</code> 과 <code>return (x, x)</code> 두개의 파서를 조합해서 <code>parseTwice</code> 라는 새로운 파서를 만들었습니다. 조금 더 붙여볼까요?</p>

<pre><code class="haskell">ignore2 :: Parser (Char, Char)  
ignore2 = item &gt;&gt;= \x -&gt; item &gt;&gt;= \y -&gt; item &gt;&gt;= \z -&gt; return (x, z)

&gt; ignore2 "2A371"
-- [(('2','3'),"71")]
</code></pre>

<h3 id="do">Do</h3>

<p>위에서 보았듯이 같은 원본 타입 <code>String</code> 을 가지는 같은 종류의 파서(모나드)는 계속 연결할 수 있습니다. <code>p1, ..., pn</code> 을 파서라 하고 <code>v1, ..., vn</code> 을 파서가 만드는 부가정보라 할 때 다음과 같이 일반화 할 수 있습니다.</p>

<pre><code class="haskell">p1 &gt;&gt;= \v1 -&gt;  
p2 &gt;&gt;= \v2 -&gt;  
p3 &gt;&gt;= \v3 -&gt;  
...
pn &gt;&gt;= \vn -&gt;  
return (f v1 v2 ... vn)  
</code></pre>

<p>하스켈에선 조금 더 편한 문법을 지원하는데요 바로 <code>do</code> 구문입니다.</p>

<pre><code class="haskell">do v1 &lt;- p1  
   v2 &lt;- p2
   ...
   vn &lt;- pn
   return (f v1 v2 ... vn)
</code></pre>

<h3 id="monadicaxioms">Monadic Axioms</h3>

<p>이 때 <code>do</code> 구문을 활용하는 파서(모나드) <code>pn</code> 에 대해서는 미리 <code>&gt;&gt;=</code> 과 <code>return</code> 이 구현되어 있어야 합니다. 우리도 위에서 두 가지 함수를 사용했습니다. </p>

<p>하스켈에서는 모나드 클래스가 따로 있습니다. 그리고 모든 모나드 클래스의 인스턴스는 최소한 <code>&gt;&gt;=</code> 와 <code>return</code> 을 구현해야 합니다. 우리가 위에서 구현했던 파서를 잠깐 보면</p>

<pre><code class="haskell">type Parser a = String -&gt; [(a, String)]

return :: a -&gt; Parser a  
return v = \xs -&gt; [(v, xs)]

(&gt;&gt;=) :: Parser a -&gt; (a -&gt; Parser b) -&gt; Parser b
p &gt;&gt;= q = \xs -&gt; case parse p xs of  
                  [] -&gt; []
                  [(y, ys)] -&gt; parse (q y) ys
</code></pre>

<p><code>return</code> 은 <code>a</code> 를 받아 파서를 돌려줍니다. <code>&gt;&gt;=</code> 는 파서(모나드)를 결합하지요.</p>

<p>아까 다양한 파서(모나드)가 있을 수 있다고 말했던 것 기억 나시죠? 많은 종류의 모나드에 대해  최소한 <code>return</code> 과 <code>&gt;&gt;=</code> 를 구현해야 하는데, 이때 지켜져야 할 <em>axioms (공리)</em> 가 있습니다.</p>

<p>(1) <code>m &gt;&gt;= return</code> == <code>m</code> (<em>right unit</em>) <br />
(2) <code>return x &gt;&gt;= f</code> == <code>f x</code> (<em>left unit</em>) <br />
(3) <code>(m &gt;&gt;= f) &gt;&gt;= g</code> == <code>m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g)</code> (<em>associativity</em>)  </p>

<h3 id="sowhymonad">So, Why Monad?</h3>

<p>근데, 이런 복잡한 모나드가 왜 중요한걸까요? 바로 <em>부가정보</em> 를 만들면서 본래의 타입을 유지하기 때문입니다. </p>

<p>본래 순수 함수형 프로그래밍에선 콘솔 출력 같은 <em>side-effect</em> 를 만들 수 없습니다. 그러나 모나드를 이용하면 <strong>부가정보 (= <em>side-effect</em>)</strong> 와 <strong>연산 부분 (<em>purely functional</em>)</strong> 를 분리할 수 있습니다.</p>

<p>실제 하스켈에서도 <em>IO Monad</em> 를 통해 입출력을 할 수 있죠.</p>

<h3 id="monadagain">Monad, Again</h3>

<p>그러면 실제로 하스켈에서 제공하는 모나드를 클래스를 사용해 봅시다. 코드를 조금 변경해야합니다.</p>

<pre><code class="haskell">module Lecture7 where

import Control.Monad

-- ref: http://www.cs.nott.ac.uk/~gmh/Parsing.lhs
newtype Parser a = P (String -&gt; [(a, String)])

instance Monad Parser where  
  return v = P $ \inp -&gt; [(v, inp)]
  p &gt;&gt;= f = P $ \inp -&gt; case parse p inp of
                         [] -&gt; []
                         [(v, out)] -&gt; parse (f v) out

item :: Parser Char  
item = P $ \inp -&gt; case inp of  
                    [] -&gt; []
                    (x:xs) -&gt; [(x, xs)]

parse                         :: Parser a -&gt; String -&gt; [(a,String)]  
parse (P p) inp               =  p inp

ignore2 :: Parser (Char, Char)  
ignore2 = do x &lt;- item  
             item
             z &lt;- item
             return (x, z)
</code></pre>

<p>실제 돌려보면,</p>

<pre><code class="haskell">&gt; parse ignore2 "7A3BCEF"
-- [(('7','3'),"BCEF")]
</code></pre>

<h3 id="monadplus">MonadPlus</h3>

<p>아까 작성했었던 파서 <code>failure</code>, <code>(+++)</code> 기억 나시나요? <code>failure</code> 는 항상 실패하는 파서를, <code>(+++)</code> 는 첫번째 파서와 두번째 파서를 붙여 둘 중 성공하는 하나의 파서만 선택하는 합성 파서입니다.</p>

<p>하스켈에선 이런 두 가지 특징을 구현한 모나드를 <code>MonadPlus</code> 라 부릅니다. 다시 말해 <code>MonadPlus</code> 에는 기본적인 <code>return</code> 이나 <code>&gt;&gt;=</code> 이외에도 위 두 가지가 더 구현되어 있다는 말이죠. </p>

<p><code>MonadPlus</code> 에서는 <code>failure</code> 대신 <code>mzero</code> 를 <code>(+++)</code> 대신 <code>mplus</code> 란 이름을 사용합니다.</p>

<pre><code class="haskell">instance MonadPlus Parser where  
  mzero = P $ \_ -&gt; []
  p `mplus` q = P $ \inp -&gt; case parse p inp of
                             [] -&gt; parse q inp
                             [(v, out)] -&gt; [(v, out)]

failure :: Parser Char  
failure = mzero

(+++) :: Parser a -&gt; Parser a -&gt; Parser a
p +++ q = p `mplus` q  
</code></pre>

<pre><code class="haskell">&gt; parse (item +++ return 'd') "abc"
-- [('a',"bc")]

&gt; parse (item +++ return 'd') ""
-- [('d',"")]
</code></pre>

<h3 id="derivedprimitives">Derived Primitives</h3>

<p>이제 파서를 엮어서 다양한 파서를 만들어 봅시다.</p>

<pre><code class="haskell">import Data.Char

sat :: (Char -&gt; Bool) -&gt; Parser Char  
sat p = do x &lt;- item  
           if p x then return x else failure

digit :: Parser Char  
digit = sat isDigit

lower :: Parser Char  
lower = sat isLower

upper :: Parser Char  
upper = sat isUpper 

letter :: Parser Char  
letter = sat isAlpha

alphanum :: Parser Char  
alphanum = sat isAlphaNum

char :: Char -&gt; Parser Char  
char x = sat (== x)  
</code></pre>

<p>여기서 <code>char</code> 을 이용하면 지정된 문자열이 있는지 검사하는 파서 <code>string</code> 을 만들 수 있습니다.</p>

<pre><code class="haskell">string :: String -&gt; Parser String  
string [] = return []  
string (x:xs) = do char x  
                   string xs
                   return (x:xs)
</code></pre>

<p><code>string</code> 은 재귀를 이용해 작성했는데, 입력된 문자열이 모두 존재할 경우에만 <code>return</code> 하고 아니면 <code>[]</code> 를 돌려줍니다. (<code>do</code> 매크로는 중간에 <code>[]</code> 가 나오면 <code>[]</code> 를 바로 리턴합니다.)</p>

<pre><code class="haskell">&gt; parse (string "google") "naver google yahoo"
-- []

&gt; parse (string "google") "google yahoo"
-- [("google"," yahoo")]

&gt; parse (string "google") "goo yahoo"
-- []
</code></pre>

<p>그러면, <code>digit</code> 나 <code>letter</code> 같은 파서에 대해 동일한 파서를 여러번 사용하려면 어떻게 해야 할까요? <code>string</code> 처럼 재귀를 이용해 매번 파서를 만들어야 할까요?</p>

<p>그렇지 않습니다. <em>mutual recursion</em> 을 이용해서 파서를 받아 여러번 적용해 주는 <code>many</code> 란 파서를 만들어 봅시다.</p>

<pre><code class="haskell">many :: Parser a -&gt; Parser [a]  
many p = many1 +++ return []

many1 :: parser a -&gt; Parser [a]  
many1 p = do x &lt;- p  
             xs &lt;- many p
             return (x:xs)
</code></pre>

<p><code>many</code> 는 <code>p</code> 을 0번 이상, <code>many1</code> 은 적어도 1번 이상 <code>p</code> 를 적용합니다. </p>

<p><code>many</code> 를 활용하면 변수의 이름도 파싱할 수 있습니다. 변수의 이름은 첫 글자가 소문자로, 나머지는 알파벳 혹은 숫자로 구성되어 있다고 하면 이를 위한 파서 <code>ident</code> 는</p>

<pre><code class="haskell">ident :: Parser String  
ident = do x &lt;- lower  
           xs &lt;- many alphanum
           return (x:xs)

&gt; parse ident "left = 3"
-- [("left"," = 3")]
</code></pre>

<p>이제 뭔가 파서가 좀 쓸만해 보이죠? 자연수를 파싱하는 <code>nat</code> 와 스페이스를 파싱하는 <code>space</code> 를 만들어 보겠습니다.</p>

<pre><code class="haskell">nat :: Parser Int  
nat = do xs &lt;- many1 digit  
         return (read xs)

space :: Parser ()  
space = do many (sat isSpace)  
           return ()

&gt; parse nat "123 abc"
-- [(123," abc")]

&gt; parse space "   abc"
-- [((),"abc")]        
</code></pre>

<p>코드를 분석하는 파서를 만들때 스페이스를 주의해야 합니다. 예를 들어 <code>1+2</code> 와 <code>1 + 2</code> 는 같은 코드입니다. </p>

<p>파서를 받아 앞 뒤로 붙은 스페이스를 제거하는 기능을 덧붙인 파서를 돌려주는 <code>token</code> 이란 함수를 만들어 봅시다. 그리고 나면 <code>token</code> 을 활용해 <code>identifier</code>, <code>natural</code>, <code>symbol</code> 을 만들겁니다.</p>

<pre><code class="haskell">token :: Parser a -&gt; Parser a  
token p = do space  
             v &lt;- p
             space
             return v

identifier :: Parser String  
identifier = token ident

natural :: Parser Int  
natural = token nat

symbol :: String -&gt; Parser String  
symbol xs = token (string xs)  
</code></pre>

<p>이제 이걸 엮어서 숫자 리스트를 분석하는 파서를 만들어 봅시다.</p>

<pre><code class="haskell">nlist :: Parser [Int]  
nlist = do symbol "["  
           n &lt;- natural
           ns &lt;- many (do symbol ","
                          natural)
           symbol "]"
           return (n:ns)


&gt; parse nlist "[1, 2, 3]"
-- [([1,2,3],"")]

&gt; parse nlist "[1, 2]"
-- [([1,2],"")]

&gt; parse nlist "[1, 2"
-- []

&gt; parse nlist "[1 2"
-- []

&gt; parse nlist "[1,"
-- []
</code></pre>

<p><del>모나드의 세계란 참으로 놀랍죠?</del></p>

<h3 id="arithmeticexpressions">Arithmetic Expressions</h3>

<p>이제 단순한 텍스트가 아니라, 코드를 분석해 보죠. 우선 작은 수식을 분석하는 파서를 작성해 봅시다. 우리가 작성할 파서는 정수에 대한 <code>*</code> 과 <code>+</code> 만 처리할 수 있습니다. 간단히 문법을 만들어 보면</p>

<pre><code class="haskell">expr   ::= expr + expr | term  
term   ::= term * term | factor  
factor ::= (expr) | nat  
nat    ::= 0 | 1 | 2 | ...  
</code></pre>

<p>처음보면 난해할 수 있습니다. 이 그림과 비교해가며 보세요. 완벽히 일치하진 않지만 대략적인 설명을 해줍니다.</p>

<p><img src='http://www.csee.umbc.edu/courses/331/fall11/hw/hw2/parsetree.gif'  alt="" /></p>

<p align="center">(<a href='http://www.csee.umbc.edu/' >http://www.csee.umbc.edu</a>)</p>

<p>그런데, 실제로 <code>2 + 3 + 4</code> 에 적용해보면, <code>(2 + 3) + 4</code> 과 <code>2 + (3 + 4)</code> 두 가지 방법으로 해석될 수 있습니다. 따라서 모호함을 제거하기 위해</p>

<pre><code class="haskell">expr   ::= term + expr | term  
term   ::= factor * term | factor  
factor ::= (expr) | nat  
nat    ::= 0 | 1 | 2 | ...  
</code></pre>

<p>이제 <code>2 + 3 + 4</code> 는 확실히 <code>2 + (3 + 4)</code> 입니다. 괴상한 문법을 하스켈로 옮기기 위해 조금  더 다듬어 보도록 하지요.</p>

<p><code>term + expr | term</code> 은 사실 <code>term + (expr | e)</code> 과 동일합니다. (<code>e</code> 는 <strong>비었음</strong> 을 의미) <code>factor * term | factor</code> 도 <code>factor + (term | e)</code> 구요. 따라서</p>

<pre><code class="haskell">expr   ::= term + (expr | e)  
term   ::= factor + (term | e)  
factor ::= (expr) | nat  
nat    ::= 0 | 1 | 2 | ...  
</code></pre>

<p>이제 하스켈 코드로 옮길겁니다. 우리는 트리를 만드는 대신 바로바로 계산할 겁니다. </p>

<pre><code class="haskell">expr :: Parser Int  
expr = do t &lt;- term  
          do symbol "+"
             e &lt;- expr
             return (t + e)
           +++ return t

term :: Parser Int  
term = do f &lt;- factor  
          do symbol "*"
             t &lt;- term
             return (t * f)
           +++ return f

factor :: Parser Int  
factor = do symbol "("  
            e &lt;- expr
            symbol ")"
            return e
          +++ natural          
</code></pre>

<p><code>return t</code> 도 하나의 파서고, <code>+++</code> 로 둘 중 올바르게 작동하는 파서만 택함으로써 문법에서의 <code>|</code> 를 구현했습니다.</p>

<p>이제 파싱된 결과를 해석하는 <code>eval</code> 함수를 만들어 봅시다.</p>

<pre><code class="haskell">eval :: String -&gt; Int  
eval xs = case parse expr xs of  
           [(n, [])] -&gt; n
           [(_, out)] -&gt; error ("ununsed input: " ++ out)
           [] -&gt; error ("invalid input: " ++ xs)


&gt; eval "2 * 3 + 4"
-- 10

&gt; eval "2 * (3 + 4)"
-- 14

&gt; eval "2 * 3 +"
-- *** Exception: ununsed input: +

&gt; eval "2 * 3 - 4"
-- *** Exception: ununsed input: - 4

&gt; eval "-4"
-- *** Exception: invalid input: -4
</code></pre>

<h3 id="programmingwitheffects">Programming With Effects</h3>

<p><a href='http://www.cs.nott.ac.uk/' ~gmh/monads">Programming With Effects</a> 는 <em>Programming in Haskell</em> 의 저자인 <strong>Graham Hutton</strong> 이 작성한 글입니다. 모나드에 대해 이보다 쉽고, 간결하게 설명한 글은 찾기 힘들죠. </p>

<p><em>Programming with Effects</em> 를 참고하여 몇 가지 예제를 더 작성해 보면서 모나드에 더 익숙해져 봅시다.</p>

<pre><code class="haskell">data Expr = Val Int | Div Expr Expr  
</code></pre>

<p>위와 같은 <code>Expr</code> 이 있다고 합시다. 평가하기 위해서 <code>eval</code> 함수를 만들고 실행해 봅시다.</p>

<pre><code class="haskell">eval :: Expr -&gt; Int  
eval (Val n) = n  
eval (Div x y) = eval x `div` eval y

&gt; eval (Val 3)
-- 3

&gt; eval (Div (Val 3) (Val 4))
-- 0

&gt; eval (Div (Val 8) (Val 4))
-- 2

&gt; eval (Div (Val 8) (Val 0))
-- *** Exception: divide by zero
</code></pre>

<p><code>0</code> 으로 나누니 에러가 발생합니다. <code>expr</code> 이 <code>Val 0</code> 인지 아닌지를 판별할 필요가 있습니다. </p>

<p>조금 더 고쳐보면</p>

<pre><code class="haskell">import Prelude hiding (Maybe, Just, Nothing)

data Expr = Val Int | Div Expr Expr  
data Maybe a = Nothing | Just a

safediv :: Int -&gt; Int -&gt; Maybe Int  
safediv n m = if m == 0 then Nothing else Just (n `div` m)

eval :: Expr -&gt; Maybe Int  
eval (Val n) = Just n  
eval (Div x y) = case eval x of  
                  Nothing -&gt; Nothing
                  Just n -&gt; case eval y of
                             Nothing -&gt; Nothing
                             Just m -&gt; safediv n m
</code></pre>

<p>너무 복잡합니다. <code>eval</code> 에서 <code>safediv</code> 에 인자를 넘기는 부분을 추상화하면</p>

<pre><code class="haskell">seqn :: Maybe a -&gt; Maybe b -&gt; Maybe (a, b)  
seqn _ Nothing = Nothing  
seqn Nothing _ = Nothing  
seqn (Just x) (Just y) = Just (x, y)

apply :: (a -&gt; Maybe b) -&gt; Maybe a -&gt; Maybe b  
apply f Nothing = Nothing  
apply f (Just x) = f x

eval :: Expr -&gt; Maybe Int  
eval (Val n) = Just n  
eval (Div x y) = apply f (eval x `seqn` eval y)  
                 where f (n, m) = safediv n m
</code></pre>

<p>조금 더 간편해졌습니다. 그런데 만약 인자가 3개인 연산자에 대해 평가 방법을 정의한다면</p>

<pre><code class="haskell">eval (Op x y z) =  
  apply f (eval x `seqn` (eval y `seqn` eval z))
  where f (a, (b, c)) =                 
</code></pre>

<p>괄호가 점점 중첩됩니다. 모든 것을 나중에 <code>seqn</code> 로 모든 결과를 모아 <code>f</code> 에서 처리하기 보다는 <code>Maybe a</code> 를 받아 <code>a -&gt; Maybe b</code> 를 바로 적용해 <code>Maybe b</code> 를 돌려주고, 이런식으로 순차적으로 처리하는 방식으로 바꿔봅시다.</p>

<pre><code class="haskell">(&gt;&gt;=) :: Maybe a -&gt; (a -&gt; Maybe b) -&gt; Maybe b
m &gt;&gt;= f = case m of  
           Nothing -&gt; Nothing
           Just x -&gt; f x

eval :: Expr -&gt; Maybe Int  
eval (Val x) = Just x  
eval (Div x y) = eval x &gt;&gt;= \n -&gt;  
                 eval y &gt;&gt;= \m -&gt; 
                 safediv n m 
</code></pre>

<p>어디서 많이 보다싶은 식이죠? 바로 하스켈의 <code>do</code> 와 비슷합니다.</p>

<p>하스켈에서 <code>Eq</code> 의 클래스의 정의는 이렇게 되어있습니다.</p>

<pre><code class="haskell">class Eq a where  
  (==) :: a -&gt; a -&gt; Bool
  (/=) :: a -&gt; a -&gt; Bool

  x /= y = not (x == y)
</code></pre>

<p>이 말은 <code>Eq</code> 클래스의 인스턴스가 되는 <code>a</code> 타입은 무조건 <code>==</code> 를 구현해야 한다는 뜻입니다. (<code>/=</code> 는 이미 구현되어 있는거 보이시죠?)</p>

<p>마찬가지로 타입 <code>m</code> 으로 <em>parameterized</em> 된 <code>Monad</code> 클래스의 인스턴스 또한 다음의 두 함수를 구현해야 합니다.</p>

<pre><code class="haskell">class Monad m where  
  return :: a -&gt; m a
  (&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b
</code></pre>

<p>예를 들어 <code>Maybe</code> 같은 경우</p>

<pre><code class="haskell">instance Monad Maybe where  
  return x = Just x

  Nothing &gt;&gt;= _ = Nothing
  (Just x) &gt;&gt;= f = f x
</code></pre>

<h3 id="listmonad">List Monad</h3>

<p><code>Maybe</code> 모나드를 잘 보면 <code>Nothing</code> 은 실패를, <code>Just x</code> 는 성공을 나타내는 연산으로 볼 수 있습니다. </p>

<p>리스트 모나드는 이런 개념을 좀 더 일반화한 것입니다. 복수번의 성공이 있을 수 있죠.</p>

<pre><code class="haskell">instance Monad [] where  
  return x = [x]
  xs &gt;&gt;= f = concat (map f xs)
</code></pre>

<p>이를 이용하면 <code>pairs</code> 와 같은 함수를 만들수 있습니다.</p>

<pre><code class="haskell">pairs :: [a] -&gt; [b] -&gt; [(a, b])  
pairs xs ys = do x &lt;- xs  
                 y &lt;- ys
                 return (x, y)

&gt; pairs [1, 2, 3] [4, 5, 6]
-- [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)]                 
</code></pre>

<p><em>list comprehension</em> 구문과 비슷합니다. 실제로 <code>do</code> 와 <em>list comprehension</em> 모두 리스트의 <code>&gt;&gt;=</code> 를 이용합니다.</p>

<h3 id="statemonad">State Monad</h3>

<p>한 상태(State) 에서 다른 상태로 변환시켜주는 <em>state transformer</em> 의 타입은 이렇게 정의할 수 있을 겁니다.</p>

<pre><code class="haskell">type ST = State -&gt; State  
</code></pre>

<p>그리고 상태가 변하면서 어떤 정보를 남겼을때의 타입을 이렇게 만들어 볼 수 있겠죠.</p>

<pre><code class="haskell">type ST a = State -&gt; (a, State)  
</code></pre>

<p>어디서 많이 본것 같죠? 맞습니다. 위에서 본 <code>Parser</code> 입니다. <code>String -&gt; (a, String)</code> 이였으니까, <code>State</code> 가 <code>String</code> 이었던 거죠.</p>

<pre><code class="haskell">instance Monad ST where  
  return x = \s -&gt; (x, s)

  st &gt;&gt;= f = \s -&gt; let (x, s') = st s
                   in f x s'
</code></pre>

<p>누차 언급했듯이 <code>&gt;&gt;=</code> 는 모나드(연산)간 연결입니다. <code>st</code> 에 <code>s</code> 를 넣은 결과를 <code>(x, s')</code> 라 하면 다시 <code>f x</code> 에 <code>s</code> 를 넣어 연결할 수 있다는 뜻이지요.</p>

<p>위에서는 <code>type</code> 을 사용했지만 실제로 이 키워드를 사용하면 클래스의 인스턴스가 될 수 없습니다. <code>ST</code> 를 <em>monadic type</em> 클래스의 인스턴스로 만들려면 <code>data</code> 나 <code>newtype</code> 을 이용할 수 있습니다. <code>data</code> 의 경우엔 <em>dummy constructor</em> 가 필요합니다. 여기선 <code>S</code> 가 되겠습니다. <em>dummy constructor</em> 의 런타임 오버헤드를 피하려면 <em>newtype</em> 을 이용하면 됩니다.</p>

<p>그리고 이 예제에서는 <em>dummy constructor</em> 를 제거하기 위해 <code>apply</code> 함수를 만들어서 이용하겠습니다. </p>

<p><code>State</code> 는 정수로 표시할겁니다. </p>

<pre><code class="haskell">type State = Int  
data ST a = S (State -&gt; (a, State))

apply :: ST a -&gt; State -&gt; (a, State)  
apply (S f) x = f x

instance Monad ST where  
  return x = S (\s -&gt; (x, s))
  st &gt;&gt;= f = S (\s -&gt; let (x, s') = apply st s in apply (f x) s')
</code></pre>

<p>이제 예제에서 활용할 간단한 이진트리를 정의해 봅시다. 이진트리의 <em>leaf</em> 는 <code>a</code> 타입의 값을 가지고 있습니다.</p>

<pre><code class="haskell">data Tree = Leaf a | Node (Tree a) (Tree b)

-- example
tree :: Tree Char  
tree = Node (Node (Leaf 'a') (Leaf 'b')) (Leaf 'c')  
</code></pre>

<p>이제 <em>State</em> 를 받아 <code>+1</code> 을 더한 다음 <em>State</em> 를 돌려주는 <code>fresh</code> 를 만들어 봅시다.</p>

<pre><code class="haskell">-- data ST a = S (State -&gt; (a, State))

fresh :: ST Int  
fresh = S (\n -&gt; (n, n + 1))  
</code></pre>

<p>즉 <code>fresh</code> 는 <em>State</em> 를 <code>1</code> 만큼 증가시키고 부가정보로 <em>current state</em> <code>n</code> 을 남깁니다. <code>fresh</code> 를 이용하면 위에서 만든 이진트리를 순회하면서 번호를 붙일 수 있습니다. 부가정보로 남는 <code>n</code> 을 <code>Leaf</code> 에다가 붙이는 것이죠. </p>

<p>다음 <code>fresh</code> 의 입력은 이전 <code>fresh</code> 의 아웃풋인 <code>n + 1</code> 이기 때문에 서로 다른 두 노드가 같은 숫자를 가질 일은 없습니다.</p>

<pre><code class="haskell">mlabel :: Tree a -&gt; ST (Tree (a, Int))  
mlabel (Leaf x) = do n &lt;- fresh  
                     return (Leaf (x, n))
mlabel (Node l r) = do l' &lt;- mlabel l  
                       r' &lt;- mlabel r
                       return (Node l' r')

label  :: Tree a -&gt; Tree (a,Int)  
label t = fst (apply (mlabel t) 0)

&gt; label tree
-- Node (Node (Leaf ('a',0)) (Leaf ('b',1))) (Leaf ('c',2))
</code></pre>

<h3 id="iomonad">IO Monad</h3>

<p>하스켈에서 입출력은 IO 모나드를 이용합니다. 무슨말인고 하니, 다음과 같은 <em>axioms</em> 를 구현한 <strong>IO 모나드</strong> 에 대해</p>

<pre><code class="haskell">return  :: a -&gt; IO a  
(&gt;&gt;=)   :: IO a -&gt; (a -&gt; IO b) -&gt; IO b
getChar :: IO Char  
putChar :: Char -&gt; IO ()  
</code></pre>

<p>다음처럼 <code>do</code> 구문을 이용해서 프로그램을 작성할 수 있다는 뜻입니다.</p>

<pre><code class="haskell">getLine :: IO String  
getLine = do x &lt;- getChar  
             if x == '\n' then
               return []
             else
               do xs &lt;- getLine
                  return (x:xs)
</code></pre>

<p>IO 모나드는 <em>State 모나드</em> 라 볼 수 있습니다. <code>IO a</code> 는 타입 <code>a</code> 의 부가정보를 만들면서 <em>State</em> 를 변화시키는 것으로요</p>

<pre><code class="haskell">type World = ...  
type IO a = World -&gt; (a, World)  
</code></pre>

<p>여기서 입/출력이 수행되는 것은 <em>action</em> 에 의해 <code>World</code> 가 변경되는 것이라 볼 수 있습니다.</p>

<h3 id="derivedprimitives">Derived Primitives</h3>

<p>다양한 종류의 모나드에 대해 적용할 수 있는 함수를 만들 수 있습니다. </p>

<p><code>liftM</code> 는 모나드에 대한 <code>map</code> 을 <code>join</code> 은 <code>concat</code> 을, <code>&gt;&gt;</code> 는 첫 번째 결과값을 다 버리고 두번째만 취하는 함수입니다. 마지막으로 <code>sequence</code> 는 모나드 익스프레션 리스트를  하나의 모나드 익스프레션으로 바꾸고, 그 결과를 리스트로 돌려줍니다. 타입을 보시면 이해가 빠를겁니다.</p>

<pre><code class="haskell">liftM :: Monad m =&gt; (a -&gt; b) -&gt; m a -&gt; m b  
liftM f mx = do x &lt;- mx  
             return (f x)

join :: Monad m =&gt; m (m a) -&gt; m a  
join mmx = do mx &lt;- mmx  
              x &lt;- mx
              return x

(&gt;&gt;) :: Monad m =&gt; m a -&gt; m b -&gt; m b
mx &gt;&gt; my = do _ &lt;- mx  
              y &lt;- my
              return y

sequence :: Monad m =&gt; [m a] -&gt; m [a]  
sequence (mx:mxs) = do x &lt;- mx  
                       xs &lt;- sequence mxs
                       return (x:xs)
</code></pre>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> <br />
(2) <a href='http://stackoverflow.com/questions/2607498/programming-in-haskell-error-in-sat-function' >error in sat function in "Programming in Haskell"</a> <br />
(3) <a href='http://wiki.reeseo.net/Haskell/%EA%B3%B5%EC%8B%9D%20%EC%9E%85%EB%AC%B8%EC%84%9C%20%EB%B2%88%EC%97%AD%EB%AC%B8/9.%20%EB%AA%A8%EB%82%98%EB%93%9C%20' (Monads)">http://wiki.reeseo.net/Haskell</a> <br />
(4) <a href='http://en.wikibooks.org/wiki/Haskell/Understanding_monads' >Understanding Monads</a> <br />
(5) <a href='http://www.csee.umbc.edu/courses/331/fall11/hw/hw2/' >http://www.csee.umbc.edu</a> <br />
(6) <a href='http://www.cs.nott.ac.uk/' ~gmh/monads">Programming With Effects</a> by <em>Graham Hutton</em>  </p>]]></description><link>http://1ambda.github.io/haskell-intro4/</link><guid isPermaLink="false">1b0aad8b-73c3-4f02-9556-e14d8933cae4</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[functional parser]]></category><category><![CDATA[monad]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 19 Nov 2014 04:39:46 GMT</pubDate></item><item><title><![CDATA[Process Mining, Week1]]></title><description><![CDATA[<p>매 10분마다 새롭게 생성되는 데이터의 양은 2003년까지의 모든 데이터를 합한 것보다 더 많다고 한다. 이 데이터 속에는 무궁무진한 가치가 있다고 하여 어떤 사람들은 데이터를 기름이라 비유하기도 한다.</p>

<p><img src='https://farm9.staticflickr.com/8037/8008798697_d36feb328d_h_d.jpg'  alt="" /></p>

<h3 id="datascienceandbigdata">Data Science and Big Data</h3>

<p>우리가 들고 다니는 핸드폰에는 14개 이상의 센서가 달려있는데, 이렇게 다양한 이벤트로부터 데이터가 무수히 많이 발생하는걸 볼 수 있다. <em>Internet of Events</em> 시대다.</p>

<p><em>Internet of Events</em> 에는 크게 4개의 <em>source</em> 가 있는데</p>

<p>(1) <em>Internet of Content</em> (e.g Google, Wiki) <br />
(2) <em>Internet of People</em> (e.g Twitter, Facebook) <br />
(3) <em>Internet of Things</em> (e.g home appliances) <br />
(4) <em>Internet of Places</em> (e.g Smart phones)</p>

<p>왜 이렇게 데이터가 많이 증가할까? 데이터를 만드는 도구들이 널리 퍼졌기도 하지만 기본적으로 디바이스들이 어마어마하게 좋아졌기 때문이다. (가격도 물론). </p>

<p>매 2년마다 같은 범위에 집약할 수 있는 트랜지스터가 2배씩 늘어난다는 무어의 법칙을 일상생활에 적용하면 어떻게 될까? 40년전에는 비행기로 7시간 걸리던 거리가, 매 2년마다 1/2씩 줄어든다면 24 milliseconds 가 된다. 이건 정말 어마어마하게 줄어든 것이다. </p>

<p>이렇게 디바이스들의 처리, 저장 능력이 급속도로 늘었기 때문에 사람들은 이제 <em>Big Data</em> 를 이야기 하게 되었다. 그리고 문제는 여전히</p>

<blockquote>
  <p>How to extract real value from big data?</p>
</blockquote>

<p>기존의 데이터에 비해서 <em>Big data</em> 가 다른점은 무엇일까? 사람들은 빅데이터에 대해 이야기 할때 <em>4V</em> 를 말하곤 하는데</p>

<p>(1) <strong>Variety:</strong> Different froms of data sources <br />
(2) <strong>Veracity:</strong> Uncertainty of data <br />
(3) <strong>Volumn:</strong> Data size <br />
(4) <strong>Velocity:</strong> Speed of change</p>

<p><em>Veracity</em> 가 묻고자 하는것은 이런 것들이다. <em>"다량의 면도기 사용 데이터를 수집했는데, 이 면도기를 사용한 사람이, 실제로 그 면도기를 구매한 사람인가?"</em></p>

<p>이런 성격을 가진 빅데이터를 포함해서 일반적인 데이터를 분석할때 데이터 사이언티스트가 하는 4가지 질문이 있다.</p>

<ol>
<li>What happened?  </li>
<li>Why did it happen?  </li>
<li>What will happen?  </li>
<li>What is the best that can happen?</li>
</ol>

<p>예를 들어 병원에서는 <em>"왜 이 환자가 이렇게 오래 기다렸나?</em>", <em>"의사가 가이드라인을 따랐나?"</em>, <em>"그럼 대기 시간을 예측할 수 있을까?"</em>, <em>"내일은 얼마나 많은 스태프가 더 필요할까?"</em>, <em>"비용을 얼마나 줄일 수 있을까?"</em> 와 같은 질문을 할 수 있다.</p>

<p>이런 질문에 답하기 위해 다양한 스킬을 이용할 수 있다.</p>

<p><img src='http://blog.zhaw.ch/datascience/files/2014/06/SkillSet-1024x751.png'  alt="" /></p>

<p align="center">(<a href='http://blog.zhaw.ch/datascience' >http://blog.zhaw.ch/datascience</a>)</p>

<p>지금까지 빅데이터에 대해 했지만 이 강의에서는 특별히 <em>process</em> 에 집중한다. 이유는</p>

<blockquote>
  <p>In the end, It is the process that matters (and no the data or the software)    </p>
  
  <p>Not just patterns and decisions, but end-to-end processes</p>
</blockquote>

<p>간단히 말하면 프로세스 마이닝은 <em>process-centric view on data science</em> 라 할 수 있다.</p>

<p>즉 프로세스 마이닝은 <em>event data</em> 와 <em>processes</em>, <em>process models</em> 간의 관계를 파악하는 것이다. 어떤 사람들은 <em>Business process intelligence</em> 라 부르기도 한다.</p>

<p>프로세스 마이닝의 <em>use cases</em> 는</p>

<blockquote>
  <ol>
  <li>What is the process that people really follow?</li>
  <li>Where are the bottlenecks in my process?  </li>
  <li>Where do people (or machines) deiate from the expected or idealized processes?</li>
  </ol>
</blockquote>

<p>결국 프로세스 마이닝은 <em>Data science in Action</em> 이다.</p>

<blockquote>
  <p>Not just data processes matter</p>
</blockquote>

<h3 id="differencetypesofprocessmining">Difference Types of Process Mining</h3>

<p>프로세스 마이닝의 포지션은 <em>process model analysis</em> 와 <em>data-oriented analysis</em> 의 중간이다. </p>

<p><img src='http://fluxicon.com/blog/wp-content/uploads/2014/02/Overview-ProcessMining.jpg'  alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog' >http://fluxicon.com/blog</a>)</p>

<p>기존의 데이터마이닝은 데이터만을 보고 프로세스에 집중하지 않았다면, 프로세스 마이닝은 <em>end-to-end</em> 를 포함한 프로세스 자체에 집중한다. </p>

<p>왜 이런 프로세스에 집중할까? 그 이유는 <em>performance-oriented questions</em>, <em>comliance-oriented questions</em> 에 답하기 위해서다.</p>

<p>프로세스 마이닝의 시작은 <em>event data</em> 를 분석하는 것 부터다. <em>event log</em> 는 3가지 컬럼을 기본적으로 가지고 있는데 <em>case id</em>, <em>activity name</em>, <em>time stamp</em> 다.</p>

<p><img src='http://fluxicon.com/blog/wp-content/uploads/2012/02/PM-Example_small.png'  alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog' >http://fluxicon.com/blog</a>)</p>

<p><em>model</em> 과 <em>event data</em> 사이에는 3가지 관계가 있다.</p>

<p>(1) <strong>Play-Out:</strong> 단순히 <em>model</em> 을 <em>simulation</em> 하면 다양한 시나리오 (<em>event logs</em>) 를 만들 수 있다. <br />
(2) <strong>Play-In:</strong> 다양한 <em>event logs</em> 로 부터 <em>model</em> 을 추론하는 것이다. (<em>No modeling is needed</em>) <br />
(3) <strong>Replay:</strong> <em>event data</em> 를 <em>model</em> 에서 재현함으로써 어떤 요소가 부족한지, 혹은 병목 지점등을 파악할 수 있다. (<em>conformance checking</em>)  </p>

<p><img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-20-728.jpg?cb=1305062721'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-21-728.jpg?cb=1305062721'  alt="" /></p>

<p><img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-22-728.jpg?cb=1305062721'  alt="" /></p>

<p><br/> <br />
<em>play-in</em> 은 좀 신선하다. 단순히 <em>event logs</em> 만으로 실제로 사람들이 따르는 프로세스를 추론할 수 있다는 이야기다.</p>

<p>그리고 이런 모델에 대해 <em>real data</em> 를 <em>repaly</em> 함으로써 병목 지점을 발견하여 개선함으로써 <em>performance</em> 를 늘릴 수 있다는 것이다.</p>

<p><br/> <br />
<img src='http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-17-728.jpg?cb=1305062721'  alt="" /></p>

<p>요약하자면 <em>event logs</em> 로 부터 <em>play-in</em> 을 통해 <em>model</em> 을 이끌어 내고 여기에 대해 <em>replay</em> 를 통해 <em>conformance checking</em> 을 할 수 있다. 그리고 <em>enchanced model</em> 을 실제 적용하는 과정이 <em>play-out</em> 이라 볼 수 있다.</p>

<h3 id="howprocessminingrelatestodatamining">How process Mining Relates to Data Mining</h3>

<p><br/> <br />
<img src='http://fluxicon.com/blog/wp-content/uploads/2011/08/Version2.png'  alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog' >http://fluxicon.com/blog</a>)</p>

<p>기존의 <em>BI</em> 는 실제 <em>reality</em> 를 단순히 <em>KPI</em> 를 요약하는데 그쳤었다. 그러나 <em>anscombe's quartet</em> 를 보면 알 수 있듯이 똑같은 통계치를 가졌더라도 시각화 하면 전혀 다른 양상일 수 있다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/638px-Anscombe%27s_quartet_3.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Anscombe' s_quartet'>http://en.wikipedia.org/wiki/Anscombe's_quartet</a>)</p>

<p>따라서 <em>event data</em> 를 단순히 값으로 요약하는건 <em>reality</em> 를 반영하지 못할 수도 있다. 값도 중요하지만 <em>process</em> 를 봐야한다.</p>

<p>더 깊이 들어가기전에 데이터마이닝에 대해서 좀 알고 가자.</p>

<h4 id="variables">Variables</h4>

<p>두 타입의 <em>variable</em> 이 있는데 </p>

<p>(1) <strong>categorical variables:</strong> <em>ordinal</em>, <em>nominal</em> <br />
(2) <strong>numerical varaibles:</strong> ordered, cannot be enumerated easily  </p>

<p><em>yes / no</em> 같은건 <em>nominal</em> 이다.</p>

<h4 id="supervisedlearning">Supervised Learning</h4>

<p><em>supervised learning</em> 의 목표는 <em>labeled data</em> 를 이용하여</p>

<blockquote>
  <p>Explain <strong>response variable (dependent variable)</strong> in terms of <strong>predictor variable (independent variables)</strong></p>
</blockquote>

<p>여기에는 크게 나누면 두 가지 테크닉이 쓰인다. 하나는 <em>categorial response variable</em> 에 대해 사용하는 <em>classification</em> 이고 다른 하나는 <em>numerical response variable</em> 에 대해 쓸 수 있는 <em>regression</em> 이다.</p>

<h4 id="unsupervisedlearning">Unsupervised Learning</h4>

<p><em>unsupervised learning</em> 은 <em>unlabeled data</em> 를 가지고 <em>clustering</em> 이나 <em>pattern discovert</em> 등을 하는 것이다.</p>

<p><em>k-means</em>, <em>agglomerative hierarchical</em>, <em>association rules</em> 등 다양한 알고리즘을 이용한다.</p>

<h4 id="processminingvsdatamining">Process Mining vs Data Mining</h4>

<ul>
<li>둘 다 데이터로부터 시작한다.  </li>
<li>데이터마이닝은 <em>process-centric</em> 이 아니다.  </li>
<li><em>process discovery</em>, <em>conformance checking</em>, <em>bottleneck analysis</em> 는 전통적인 데이터마이닝으로 풀기 어렵다.  </li>
<li>프로세스 마이닝은 <em>end-to-end process models</em>, <em>concurrency</em> 중심이다.  </li>
<li>프로세스 마이닝의 <em>event log</em> 는 <em>timestamp</em> 와 <em>case</em> 컬럼이 있다.  </li>
<li>프로세스 마이닝과 데이터마이닝은 복잡한 문제를 풀기 위해 같이 사용될 수 있다.  </li>
</ul>

<h3 id="learningdecisiontree">Learning Decision Tree</h3>

<p><em>decision tree</em> 는 <em>supervised learning</em> 에서 사용되는 기법이다. <em>decision tree</em> 에 놓여있는 아이디어는 처음의 <em>*high entropy (uncertain)</em> 상태에서 <em>attribute</em> 에 따라 <em>subset</em> 으로 쪼개면서 복잡도를 낮춤으로써 <em>low entropy</em> 를 만들 수 있다.</p>

<p><em>entropy</em> 는 <em>degree of uncertainty</em>, <em>inverse of compressibility</em> 다. 만약 데이터에서 <em>entropy</em> 가 매우 적다면 데이터를 압축할 수 있다. 그러나 대부분의 경우 <em>high entropy</em> 이기 때문에</p>

<blockquote>
  <p><strong>Goal:</strong> reduce entropy in leaves of tree to improve predictability  </p>
</blockquote>

<p>엔트로피를 계산하기 위해 로그를 이용하면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?E%20%3D%20-%20%5Csum_%7Bi%20%3D%201%7D%5Ek%20P_i%20%5C%20log_2%28P_i%29'  alt="" /></p>

<p><em>intuition</em> 은 초록공과 빨간공이 1:1 로 섞여있을땐 <code>E = 1</code> 이고, 빨간공이나 초록공만 있을때는 <code>E = 0</code> 이다. 따라서 <em>decision tree</em> 가 깊어지면 깊어질수록 전체 <code>E</code> 가 낮아진다. </p>

<p><img src='http://cfile26.uf.tistory.com/image/2023334B5153F4EE27D112'  alt="http://frontjang.tistory.com/" /></p>

<p align="center">(<a href='http://frontjang.tistory.com/' >http://frontjang.tistory.com</a>)</p>

<p>그리고 이렇게 얻어진 <em>overall entropy</em> 의 차이를 <em>information gain</em> 이라 부른다. <em>classification</em> 에는 변화가 없어도 <em>information gain</em> 이 있을 수 있다. 반대로 한단계 더 분리 되었어도 <em>information gain</em> 이 <code>0</code> 일 수 있다.</p>

<p>따라서 선택 가능한 모든 <em>attribute</em> 에 대해 <em>information gain</em> 을 비교하여 가장 큰 <em>attribute</em> 를 선택하고 더 이상의 커다란 변화가 없을때 까지 반복하면 <em>decision tree</em> 를 만들 수 있다.</p>

<p><em>minimal gain</em>, <em>maximum depth</em> 등을 세팅할 수도 있고, <em>overfitting</em> (모든 경우를 다 분리하는것) 을 막기 위해 최소 노드 사이즈를 정할 수 있다. <em>post pruning</em> 등 다양한 기술이 있다.</p>

<p>프로세스 마이닝에 적용해 보면 모델에서 분기 될 때 <em>"What is driving these decisions?"</em>, 등을 파악할 수 있고 <em>"most likely path"</em> 같은 문제도 해결할 수 있다.</p>

<h3 id="associationrule">Association Rule</h3>

<p><em>unsupervised learning</em> 도구인 <em>association rule</em> 을 이용해 패턴을 찾아보자.</p>

<p><em>association rule</em> 은 <code>X =&gt; Y</code> 형태다. 시작 전에 몇가지 개념을 보고 넘어가자.</p>

<h4 id="support">Support</h4>

<p><em>support</em> 는 <code>0 ~ 1</code> 사이의 값을 가지는데, <code>1</code> 이면 <em>good</em>, <code>0</code> 로 갈수록 <em>bad</em> 를 의미한다. </p>

<p><img src='http://latex.codecogs.com/gif.latex?support%28X%5CRightarrow%20Y%29%20%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%20%5Cover%20N%20%7D'  alt="" /></p>

<p>즉 전체 데이터 중 <code>X</code>, <code>Y</code> 가 같이 있는 <em>instance</em> 의 비율을 의미한다.</p>

<h4 id="confidence">Confidence</h4>

<p><em>support</em> 와 마찬가지로 <code>0 ~ 1</code> 값을 가지며 높은 값일수록 더 연관성 있음을 의미한다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?confidence%28X%5CRightarrow%20Y%29%20%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%20%5Cover%20N_X%20%7D'  alt="" /></p>

<p>전체 <code>X</code> 인스턴스 중 <code>X</code>, <code>Y</code> 가 같이 있는 <em>instance</em> 의 비율을 의미한다.</p>

<h4 id="lift">Lift</h4>

<p><img src='http://latex.codecogs.com/gif.latex?lift%28X%5CRightarrow%20Y%29%20%5C%5C%20%5C%5C%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%5C%20/%5C%20N%20%5Cover%20%7B%28N_X%20/%20N%29%20%28N_Y%20/%20N%29%7D%20%7D%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%5C%20N%20%5Cover%20%7BN_X%20%5C%20N_Y%7D%20%7D'  alt="" /></p>

<p><em>lift</em> 는 <em>실제 같이 나타나는 비율 / 기대했던 비율</em> 이다. 식을 보면 알겠지만 각 아이템이 나타나는 비율을 독립이라 가정한 것을 분모로 실제 나타나는 비율을 나눈 것이다. 따라서 <code>lift &gt; 1</code> 이면 <code>X</code> 는 <code>Y</code> 가 나타나는데 긍정적인 영향을 미치거나 혹은 <code>Y</code> 가 <code>X</code> 에 대해 긍정적인 영향을 미친것이다. 반면 <code>lift &lt; 1</code> 이면 반대고, <code>lift = 1</code> 이면 서로 관계가 없다 볼 수 있다.</p>

<p><a href='http://analyticstrainings.com/?p=151' >여기</a>를 인용하면</p>

<blockquote>
  <p><strong>A lift value greater than 1</strong> indicates that X and Y appear more often together than expected; this means that the occurrence of X has a positive effect on the occurrence of Y or that X is positively correlated with Y.</p>
  
  <p><strong>A lift smaller than 1</strong> indicates that X and Y appear less often together than expected, this means that the occurrence of X has a negative effect on the occurrence of Y or that X is negatively correlated with Y</p>
  
  <p><strong>A lift value near 1</strong> indicates that X and Y appear almost as often together as expected; this means that the occurrence of X has almost no effect on the occurrence of Y or that X and Y have Zero Correlation.</p>
</blockquote>

<p><em>class</em> 가 많으면 <em>rule</em> 또한 엄청나게 많아지기 때문에 <em>support</em>, <em>confidence</em>, <em>lift</em> 를 이용해서 룰을 필터링하거나 정렬할 수 있다.</p>

<p>일반적으로 이 3가지에 대해</p>

<p>(1) <em>support</em> 는 높을수록 좋다. <br />
(2) <em>confidence</em> 는 1에 가까워야 한다. <br />
(3) <em>lift</em> 는 1보다 커야한다.  </p>

<p>다음의 조건이 있을때 각 룰에 대해 <em>support</em>, <em>confidence</em>, <em>lift</em> 를 계산해 보자.</p>

<blockquote>
  <p>100 customers buy diapers and / or beer: <br />
  - 9 customers buy just Hoegaarden <br />
  - 40 customers buy just Pampers <br />
  - 50 customers buy just Pampers and Dommelsch <br />
  - 1 customer buys just Pampers, Hoegaarden and Dommelsch  </p>
</blockquote>

<p>먼저 <code>{Pampers} =&gt; {Dommelsch}</code> 는</p>

<p><code>s = 51 / 100 = 0.51</code>, <code>c = 51 / 91 = 0.56</code>, <code>l = 51 * 100 / (91 * 51) = 1.1</code> </p>

<p>다음으로 <code>{Dommelsch} =&gt; {Pampers}</code> 는</p>

<p><code>s = 0.51, c = 1, l = 1.1</code> 이다.</p>

<p>값을 보면 이 두 가지 룰은 상당히 신빙성이 있다고 볼 수 있다. 그리고 나머지 룰들을 살펴봐도 <code>supoort, confidence, lift</code> 값 이 상당히 낮다.</p>

<p>계산 방법은 간단한데, <em>class</em> 가 많으면 계산해야 할 <em>rule</em> 자체가 어마어마하게 많아진다. 이 문제를 해결하기 위해 몇 가지 방법이 있다.</p>

<h4 id="apriorialgorithm">Apriori Algorithm</h4>

<p><img src='http://latex.codecogs.com/gif.latex?Y%20%5Csubset%20X%5C%20%3D%3E%5C%20%28N_Y%20/%20N%29%20%5Cgeq%20%28N_X%20/%20N%29'  alt="" /></p>

<p><code>X</code> 의 부분집합인 <code>Y</code> 에 대해서, <code>X</code> 의 <em>support</em> 가 높으면 <code>X</code> 의 부분집합도 충분히 빈번해야 한다. 그래서 <code>X</code> 의 부분집합인 <code>Y</code> 의 <em>support</em> 가 낮으면 <code>Y</code> 의 부분집합을 살펴볼 필요가 없어 연산 수를 줄일 수 있다.</p>

<h4 id="patternmining">Pattern Mining</h4>

<p>여기서 본 연관 분석은 <em>process</em> 를 고려하지 않지만, 이 기법을 잘 활용하면 <em>sequence mining</em> 이나 <em>episode mining</em> 등등에 활용 될 수 있다.</p>

<h3 id="clusteranalysis">Cluster Analysis</h3>

<p><em>unsupervised learning</em> 기법인 <em>clustering</em> 도 간단히 살펴보자.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/SLINK-Gaussian-data.svg/186px-SLINK-Gaussian-data.svg.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Cluster_analysis' >http://en.wikipedia.org/wiki/Cluster_analysis</a>)</p>

<h4 id="kmeansclustering">k-means clustering</h4>

<p>여기서 <code>k</code> 는 몇개의 집단으로 나눌건지를 의미하는 숫자다. 알고리즘 자체는 굉장히 직관적이다.</p>

<p>(1) 먼저 <em>centroid</em> 라 부르는 점들을 <em>attribute</em> 에 랜덤하게 혹은 레귤러 하게 <code>k</code> 개 배치한다. <br />
(2) 각 점에서 <em>centroid</em> 까지 거리가 가장 짧은 <em>centroid</em> 를 선택하고, 이 집단 내부에서 가운데 점을 계산해 <em>centroid</em> 로 다시 정한다. <br />
(3) <em>centroid</em> 에 변화가 없을 때 까지 계속 반복한다.  </p>

<p><img src='http://datavisualization.blog.com/files/2011/08/kmeansclustering.jpg'  alt="" /></p>

<p align="center">(<a href='http://datavisualization.blog.com/' >http://datavisualization.blog.com</a>)</p>

<pre><code>// ref: http://datavisualization.blog.com/visible-data/cluster-analysis/

Select K points as the initial Centroids  
REPEAT  
   Form K clusters by assigning all points to the closest Centroid
   recompute the Centroid for each cluster
UNTIL Centroids don’t change // or less than thresahold”  
</code></pre>

<p>초기에 <em>centroid</em> 가 랜덤하게 선택되기 때문에 <em>non-deterministic</em> 이어서 여러번 계산 후에 가장 좋은 <em>clustering</em> 을 골라야 한다. </p>

<p>그리고 <code>k</code> 값에 따라 클러스터가 달라질 수 있으므로 변화시켜가면서 좋은 <code>k</code> 값을 찾아야 한다.</p>

<p><img src='http://datavisualization.blog.com/files/2011/08/howmanyclusters.jpg'  alt="" /></p>

<p align="center">(<a href='http://datavisualization.blog.com/' >http://datavisualization.blog.com</a>)</p>

<h4 id="agglomerativehierarchicalclustring">Agglomerative hierarchical clustring</h4>

<p><em>k-means</em> 이외에도 다양한 클러스터링 알고리즘이 있다.</p>

<p><img src='http://www.cs.umd.edu/hcil/hce/hce3-manual/dendrogram.png'  alt="" /></p>

<p align="center">(<a href='http://www.cs.umd.edu/' >http://www.cs.umd.edu</a>)</p>

<h4 id="applyingprocessmining">Applying Process Mining</h4>

<p>클러스터링은 <em>event-log</em> 를 분할하는데 쓸 수 있다. 그러면 특징이 다른 <em>event-log</em> 를 뽑아낼 수 있고 각각의 클러스터에 대해 모델을 만드는데 유용하다.</p>

<h3 id="evaluatingminingresult">Evaluating Mining Result</h3>

<p>마이닝으로 모델을 만들거나, 결과를 얻었다고 하자. 어떻게 평가할까?</p>

<h4 id="confusionmatrix">Confusion Matrix</h4>

<p><em>confusion matrix</em> 는 <em>predict class</em> 와 <em>actual class</em> 를 기반으로 테이블을 만든 것이다.</p>

<p><img src='http://lh3.ggpht.com/_qIDcOEX659I/SzjW6wGbmyI/AAAAAAAAAtY/Nls9tSN6DgU/contingency_thumb%5B3%5D.png?imgmax=800'  alt="" /></p>

<p align="center">(<a href='http://crsouza.blogspot.kr/' >http://crsouza.blogspot.kr</a>)</p>

<p><br/> <br />
여기에 대해 <em>error</em>, <em>accuracy</em>, <em>precision</em>, <em>recall</em>, <em>F1-score</em> 등을 계산할 수 있다.</p>

<p><img src='http://image.slidesharecdn.com/08classbasic-140913212207-phpapp02/95/data-miningconcepts-and-techniques-chapter-8-classification-basic-concepts-51-638.jpg?cb=1410662460'  alt="" /></p>

<p align="center">(<a href='http://www.slideshare.net/salahecom/08-classbasic' >http://www.slideshare.net/salahecom/08-classbasic</a>)</p>

<h4 id="crossvalidation">Cross Validation</h4>

<p>가지고 있는 데이터로 모델을 만들면, 모델에는 잘 맞지만 실제 데이터에는 안맞을 수 있다.</p>

<blockquote>
  <p><strong>Overfitting :</strong> the model is too specific for the data set used to learn the model and performs poorly on new instances</p>
  
  <p><strong>Underfitting :</strong> the model is too general and does not exploit the data</p>
</blockquote>

<p>그래서 데이터셋을 <em>training set</em> 과 <em>test set</em> 으로 분리해서 각각 훈련, 퍼포먼스 테스트를 위해 사용한다.</p>

<h3 id="summary">Summary</h3>

<p>이번 주차엔 데이터마이닝에 대해서 논했는데, 다음 시간부터는 <em>process discovery</em>, <em>conformance checking</em> 등에 대해 이야기 한다. <del>어째 오토마타의 향연이 될 것 같기도</del></p>

<h3 id="references">References</h3>

<p>(1) <strong>Process Mining: Data science in Action</strong> by Wil van der Aalst <br />
(2) <a href='http://1ambda.github.io/www.processmining.org' >www.processmining.org</a> <br />
(3) <a href='http://blog.zhaw.ch/datascience/the-data-science-skill-set/' >http://blog.zhaw.ch/datascience/the-data-science-skill-set/</a> <br />
(4) <a href='http://fluxicon.com/blog/2014/02/how-is-process-mining-different-from/' >http://fluxicon.com/blog</a> <br />
(5) <a href='http://www.slideshare.net/wvdaalst/process-mining-chapter01introduction?related=1' >Process Mining Chapter 1</a> <br />
(6) <a href='http://en.wikipedia.org/wiki/Anscombe' s_quartet">Anscombe's quartet</a> <br />
(7) <a href='http://frontjang.tistory.com/category/Computer/MachineLearning' >http://frontjang.tistory.com</a> <br />
(8) <a href='http://analyticstrainings.com/?p=151' >http://analyticstrainings.com/?p=151</a> <br />
(9) <a href='http://datavisualization.blog.com/visible-data/cluster-analysis/' >http://datavisualization.blog.com</a> <br />
(10) <a href='http://www.cs.umd.edu/hcil/hce/hce3-manual/hce3_manual.html' >http://www.cs.umd.edu</a> <br />
(11) <a href='http://crsouza.blogspot.kr/2009/12/performing-discriminant-power-analysis.html' >http://crsouza.blogspot.kr</a> <br />
(12) <a href='http://www.slideshare.net/salahecom/08-classbasic' >http://www.slideshare.net/salahecom/08-classbasic</a></p>]]></description><link>http://1ambda.github.io/process-mining-week1/</link><guid isPermaLink="false">6b0990d6-e516-4154-9e40-4b7b7244bdbf</guid><category><![CDATA[coursera]]></category><category><![CDATA[process mining]]></category><category><![CDATA[decision tree]]></category><category><![CDATA[association rule]]></category><category><![CDATA[k-means clustering]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Tue, 18 Nov 2014 03:51:30 GMT</pubDate></item><item><title><![CDATA[Graph Search and Connectivity￼]]></title><description><![CDATA[<p>기본적인 그래프 탐색 방법 <em>DFS</em>, <em>BFS</em> 에 대해 배우고 약간씩 응용하여 <em>shortest path</em>, <em>conncected components</em>, <em>topological order</em>, <em>strongly connected components</em> 등을 찾는 방법을 배운다. </p>

<p>마지막 부분에선 웹이 어떻게 생겼을까 잠깐 고민해 본다.</p>

<h3 id="graphsearch">Graph Search</h3>

<p>그래프 탐색은 다양하게 활용할 수 있다.</p>

<p>(1) check if a network is connected <br />
(2) driving directoin (shortest path) <br />
(3) formulate a plan (e.g how to fill in a sudoku puzzle) <br />
(4) compute the <em>"pieces"</em> of a graph (e.g clustering)</p>

<p>그래프를 탐색하는데는 <em>"재 방문하지 않는다"</em> 등 여러 조건이 붙으면서 다양한 방법이 있을 수 있겠지만 여기서는 단순히 모든 <em>vertex</em> 를 방문하는 일반적인 그래프 탐색 알고리즘 (<em>generic algorithm</em>) 에 대해 먼저 이야기 해 보자.</p>

<p>이렇게 먼저 일반적인 알고리즘을 정의해 보는 이유는, <em>BFS</em> 와 <em>DFS</em> 를 증명할때 먼저 정의한 일반적인 알고리즘의 특수한 경우임을 파악하여 이미 증명된 결과를 활용할 수 있기 때문이다.</p>

<blockquote>
  <p>Goals: <strong>find everything findable from a given start vertex</strong>, <code>O(m + n)</code></p>
</blockquote>

<p>여기서 <em>findable</em> 이란 말은 두 점 <code>(s, e)</code> 사이에 <em>path (경로)</em> 가 있냐는 질문과 동일하다. 경로가 없으면 <em>findable</em> 이 아니다.</p>

<p>목표로 하는 복잡도가 <code>O(m + n)</code> 인데, 이것은 정점의 수 <code>n</code> 이나 엣지수 <code>m</code> 중 더 큰 수를 따라간다고 이해하면 된다. 알고리즘은 이렇다.</p>

<pre><code>initially `s` explored, all other vertices are unexplored  
while possible:  
  choose an edge `(u, v)` with `u` explored and `v` unexplored  
  mark `v` explored  
</code></pre>

<p><em>generic graph search algorithm</em> 이 끝났을때 <code>v</code> 가 <em>explored</em> 라면 그래프 <code>G</code> 가 <code>s -&gt; v</code> 인 <em>path</em> 가 존재한다. 이를 귀납법으로 증명해 보자.</p>

<p>귀납법이므로 먼저 증명하려는 바를 부정하여 알고리즘이 종료 되었을 때 <code>G</code> 에서 <code>(s -&gt; v)</code> 로 가는 경로가 없다고 하자. </p>

<p>알고리즘 초기 단계에서 <code>s</code> 만 <em>explored</em> 고 나머지는 <em>unexplored</em> 다. 매 탐색마다 <code>(u, w)</code> 를 찾아내며 <em>unexplored</em> <code>w</code> 를 <em>explored</em> 로 마킹한다. </p>

<p><code>(s, v)</code> 사이 경로가 없다면, 어떤 <code>w</code> 가 <em>unexplored</em> 인 <code>(u, w)</code> 가 알고리즘이 끝났을때 존재해야 한다. <code>w</code> 가 <code>v</code> 일수도, <code>u</code> 가 <code>s</code> 일수도 있다.</p>

<p>그러나 이 경우 <em>unexplored</em> <code>w</code> 가 존재하면 알고리즘이 절대 종료될 수 없다. 결국 모순이므로 <code>s -&gt; v</code> <em>path</em> 가 없다는 것이 잘못되었다.</p>

<h3 id="bfsvsdfs">BFS vs DFS</h3>

<p>사실 그래프 탐색 문제는 <em>crossing edge</em> 문제와 같다. 한쪽을 <em>explored</em>, 다른쪽을 <em>unexplored</em> 라 놓고 각 <em>vertex</em> 들을 잇는 <em>crossing edge</em> 를 고르는 문제다.</p>

<p><em>BFS</em> 는 기본적으로 <em>queue</em> 를 사용하면 <code>O(m + n)</code> 이다. 그리고</p>

<p>(1) explore nodes in <em>"layers"</em> <br />
(2) can compute <em>"shortest path"</em> <br />
(3) can compute connected components of an undirected graph  </p>

<p><em>DFS</em> 는 <em>stack</em> 을 이용하면 <code>O(m + n)</code> 이다. 그리고</p>

<p>(1) explore aggressively like a maze, backtrack only when necessary <br />
(2) compute topological ordering of directed acyclic graph <br />
(3) compute connected components in directed graphs</p>

<h3 id="breadthfirstsearch">Breadth-First Search</h3>

<p><em>BFS</em> 는 <em>shortest path</em> 를 계산할 수 있고 <em>undirected graph</em> 의 <em>connected components</em> 를 구할 수 있다. 그리고 복잡도는 <code>O(m + n)</code> 이다.</p>

<p>함수를 <code>BFS(graph G, start-vertex s)</code> 라 하면 시작단계에서는 모든 그래프 노드가 <em>unexplored</em> 다.</p>

<p>(1) mark <code>s</code> as explored <br />
(2) Let <code>Q</code> - queue data structure <strong>(FIFO)</strong>, initialied with <code>s</code> <br />
(3) while <code>Q</code> is not empty: <br />
- remove the first node of <code>Q</code>, call it <code>v</code> <br />
- for each edge <code>(v, w)</code>, if <code>w</code> unexplored mark <code>w</code> as explored and add <code>w</code> to Q</p>

<p>시작 점 <code>s</code> 를 <em>layer 0</em> 이라 부르면 <em>layer 1</em> 은 <em>layer 0</em> 에서 갈 수 있는 지점이다. 모두 저장하고, 큐에서 하나 꺼내 <em>layer 2</em> 를 계산해서 다시 집어넣고, 이 과정을 반복한다. 알고리즘 중에 이미 방문했는지를 검사하기 때문에 같은 노드를 두번 이상 방문하지 않는다.</p>

<p>알고리즘이 종료되었을때 <code>v</code> 가 <em>explored</em> 라면 <code>s -&gt; v</code> 인 <em>path</em> 가 존재한다. 증명은 간단한데 <em>BFS</em> 가 <em>generic search algorithm</em> 의 <em>spcial case</em> 이기 때문이다. </p>

<p><em>BFS</em> 알고리즘을 잘 보면 <em>generic algorithm</em> 처럼 <code>(u, w)</code>, <code>w</code> 는 <em>unexplored</em> 인 <em>edge</em> 를 찾는데, 이 때 <em>BFS</em> 는 한 레이어에서 다음 레이어로 갈 수 있는 <em>edge</em> 만 찾는다는 점이 다르다.</p>

<p><em>running time</em> 은 <code>O(n_s + m_s)</code> 다. 여기서 <code>n_s</code> 는 <code>s</code> 에서 갈 수 있는 <em>node</em> 의 숫자고 <code>m_s</code> 는 <code>s</code> 에서 갈 수 있는 <em>edge</em> 수다.</p>

<p><code>while</code> 루프 알고리즘을 다시 보면</p>

<pre><code>while `Q` is not empty:  
  remove the first node of `Q`, call it `v`  
  for each edge `(v, w)`:
    if `w` is unexplored:
      mark `w` as explored
      add `w` to Q
</code></pre>

<p>한 <em>vertex</em> 는 아무리 많아봐야 큐에 한번 들어가고,  이 때마다 이 <em>vertex</em> 에서 갈 수 있는 <em>edge</em> 를 검사하지만, 결국 아무리 많아봐야 한 <em>edge</em> 당 두번씩만 검사되고, 검사하는 <code>for</code> 구문은 <code>O(1)</code> 이기 때문에 <code>O(m + n)</code> 이다.</p>

<h3 id="shortestpath">Shortest Path</h3>

<p>생각해보면 굉장히 쉽다. <code>s</code> 부터 시작해서 <code>v</code> 까지의 거리를 찾는 경우 <code>s = v</code> 면 각 노드의 <code>dist</code> 값을 <code>0</code> 으로, 아니면 무한히 큰 값으로 한다. </p>

<p><em>BFS</em> 에서 레이어마다 하나씩 넘어갈때 마다 <code>dist</code> 값을 1씩 증가시키는데, 이때 이미 <code>dist</code> 값이 있는 경우 그 값보다 적으면 새로운 <code>dist</code> 값을 기록하고, 아니면 기록하지 않는다.</p>

<p>따라서 알고리즘이 종료되었을때 <code>dist(v) = i</code> 라면 <code>v</code> 는 <code>i</code> 번째 레이어에 있다. 바꿔말하면 <em>shortest path <code>(s, v)</code></em> 는 <code>i</code> 개의 <em>edge</em> 를 가지고 있다는 뜻이다.</p>

<h3 id="undirectedconnectivity">Undirected Connectivity</h3>

<p><em>undirected connectivity</em> 는 그래프에서 서로 연결된 부분 집합을 찾는 문제다. 용어부터 정의하고 가자면</p>

<blockquote>
  <p>equivalence classes of the relation <code>u ~ v</code> &lt;=> <code>E(u, v)</code> path in <code>G</code></p>
</blockquote>

<p><em>equivalence class</em> 는 처음봤는데 위키에 보니 다음의 3 가지 속성을 만족한다고 한다.</p>

<blockquote>
  <p>For every element <code>a</code> in X, <code>a ~ a</code> <strong>(reflexivity)</strong> <br />
  For every two elements <code>a</code> and <code>b</code> in X, if <code>a ~ b</code>, then <code>b ~ a</code> <strong>(symmetry)</strong> <br />
  For every three elements <code>a</code>, <code>b</code>, and <code>c</code> in X, if <code>a ~ b</code> and <code>b ~ c</code>, then <code>a ~ c</code> <strong>(transitivity)</strong></p>
</blockquote>

<p><em>connected component</em> 를 어디다 쓸 수 있을까? </p>

<p>네트워크에 대해 적용해 보면, 네트워크가 끊어졌는지를 <em>connected component</em> 를 구해서 두개 이상이 나오는지로 판단할 수 있다.</p>

<p><em>clustering</em> 에도 쓸 수 있다. 만약 두 유전자나, 웹페이지가 비슷한지를 비교해서 <em>connected component</em> 로 만들면 구별되는 특징을 가진 집단을 만들 수 있다.</p>

<p><em>clustering</em> 하는 다른 알고리즘이 많음에도 <em>BFS</em> 는 <em>linear time</em> 이기 때문에 <em>clustering</em> 에 충분히 쓸만하다.</p>

<p><em>undirected</em> 그래프에서 <em>BFS</em> 를 이용하면 <em>conncected component</em> 를 구하는 알고리즘은 이렇다.</p>

<pre><code>all node unexplored // assume labelled 1 to n

for i = 1 to n  
  if i not yet explored
    BFS(G, i)
</code></pre>

<p>따라서 <code>BFS</code> 를 수행할 때 마다 <em>connected component</em> 가 하나씩 나온다고 말할 수 있다. </p>

<p>성능은 마찬가지로 <code>O(m + n)</code> 이다. 왜냐하면 부의 <code>if</code> 나 <code>for</code> 그리고 모든 노드를 <em>unexplored</em> 로 초기화 하는 부분도 <code>O(n)</code> 이고, 각 노드 하나씩에 대해서 방문하지 않았을 때만 <em>BFS</em> 를 수행하는데 <em>BFS</em> 는 <em>edge</em> 에 대해서는 <code>O(1)</code> 이고, 모든 <em>edge</em> 를 검사하므로 <em>BFS</em> 의 전체 성능은 <code>O(m)</code> 이다. 따라서 <code>O(m + n)</code></p>

<h3 id="depthfirstsearch">Depth-First Search</h3>

<blockquote>
  <p>explore aggressively, and backtrack when necessary</p>
</blockquote>

<p><em>BFS</em> 로도 <code>O(m +n)</code> 시간 내에 탐색하고 <em>shortest path</em>, <em>connected component</em> 를 찾는데 왜 <em>DFS</em> 가 필요할까?</p>

<p>(1) can computes a topological ordering of a directed acyclic graph <br />
(2) strongly conncected components of directed graphs</p>

<p><em>BFS</em> 는 못하는 이 두 가지 문제를 <code>O(m + n)</code> 으로 해결할 수 있다.</p>

<p>코드는 비슷한데 <em>queue</em> 대신 <em>stack</em> 을 쓰도록 하고, 재귀버전으로 작성해 보자.</p>

<pre><code>DFS(graph G, start-vertex s)

mark s as explored

for every edge (s, v):  
  if v is unexplored
    DFS(G, v)
</code></pre>

<p><em>DFS</em> 가 종료 됐을때 <code>v</code> 가 <em>explored</em> 라면 <code>s -&gt; v</code> 인 <em>path</em> 가 있다. 이는 <em>DFS</em> 가 위에서 본 <em>generic search algorithm</em> 의 특별한 케이스임을 생각하면 쉽게 알 수 있다.     </p>

<p>성능은 <em>BFS</em> 와 같이 <code>O(n_s  m_s)</code> 인데, 각 <em>vertex</em> 는 아무리 많아봐야 한번, <em>edge</em> 는 아무리 많아봐야 두번씩 체크하고 <em>edge</em> 내부에서의 연산은 <code>O(1)</code> 이기 때문이다.</p>

<h3 id="topologicalsort">Topological Sort</h3>

<p>정의부터 보면</p>

<blockquote>
  <p>A <strong>toplogical ordering</strong> of a <em>directed graph</em> <code>G</code> is a labelling <code>f</code> of <code>G</code>'s nodes such that <br />
  1. the <code>f(v)</code>'s are the set <code>{1, 2, 3, ..., n}</code> <br />
  2. <code>(u, v)</code> in <code>G</code> => <code>f(u)</code> &lt; <code>f(v)</code></p>
</blockquote>

<p>이미지로 보면 더 이해하기 쉽다.</p>

<p><img src='http://www.stoimen.com/blog/wp-content/uploads/2012/12/3.-Topological-Sort-Order.png'  alt="" /></p>

<p align="center">(<a href='http://www.stoimen.com/' >http://www.stoimen.com</a>)</p>

<p>왜 <em>topological sort</em> 가 필요할까? <em>precedence constraints</em> 가 있는 <em>sequence</em> 에서 나올 수 있는 모든 경우의 수를 파악하기에 좋다. 예를 들어 선수과목이 있을때 이수 가능한 스케쥴이라던가, 일정이라던가.</p>

<blockquote>
  <p>Sequence taks while respecting all precedence constraints</p>
</blockquote>

<p>단, <em>topological sort</em> 를 하기 위한 조건이 하나 있는데 <em>directed cycle</em> 이 없어야 한다. 다시 말해 <em>acyclic</em> 이어야 한다.</p>

<blockquote>
  <p>If <code>G</code> has directed cycle, then no topological ordering</p>
</blockquote>

<p><em>directed graph</em> 에서 <em>outgoing edge</em> 가 없는 것을 <em>sink vertex</em> 라 하자. 그러면 <em>directed acyclic graph, DAG</em> 는 최소한 하나의 <em>sink vertex</em> 를 가지고 있다.</p>

<p>증명은 <em>contradiction</em> 을 이용하자. <em>sink vertex</em> 가 없다고 하면, 쭈욱 방문하다 보면 하나의 <em>vertex</em> 를 두번 이상 방문하게 되고, 그건 <em>cyclic</em> 이므로 <em>acyclic</em> 이란 조건에 위배되므로 모순이다. 따라서 <em>DAG</em> 에서는 최소한 하나의 <em>sink vertex</em> 가 있다.</p>

<p><em>topological sort</em> 의 알고리즘은 </p>

<pre><code>let v be a sink vertex of G  
set f(v) = n  
recurse on G - {v}  
</code></pre>

<p><code>G - {v}</code> 도 <em>DAG</em> 이다. 왜냐하면 <em>DAG</em> 에서 <em>sink vertex</em> 를 제거해도 <em>DAG</em> 이기 때문에 매 재귀마다 <code>G</code> 는 <em>DAG</em> 가 된다. 이 때 제거하는 <em>sink vertex</em> 에 전체 노드 수 <code>n</code> 을 매기기 때문에 최종적으로는 <code>1, .., n</code> 을 가진 <em>toplogical order</em> 을 계산할 수 있다.</p>

<p>이제 <em>DFS</em> 를 이용해 <em>toplogical sort (위상 정렬)</em> 을 해보자.</p>

<pre><code>DFS(graph G, start-vertex s)  
- mark s explored  
- for every edge (s, v):
    if v not yet explored:
      DFS(G, v)
- set f(s) = current_label // sink vertex
- current_label--

DFS-Loop(graph G)  
- mark all nodes unexplored
- current_label = n // to keep track of ordering
- for each vertex v in G:
    if v not yet explored:
      DFS(G, v)
</code></pre>

<p><em>running time</em> 은 <code>O(m + n)</code> 이다. <em>node</em> 마다 <code>O(1)</code>, <em>edge</em> 마다 <code>O(1)</code> 이고 <em>node</em> 나 <em>edge</em> 는 두번 방문하지 않기 때문에 (<em>directed graph</em>) <code>O(m + n)</code></p>

<p>위상정렬을 하는지는 <code>(u, v)</code> 가 <em>edge</em> 라면 <code>f(u) &lt; f(v)</code> 임을 보이면 된다.</p>

<p><code>u</code> 먼저 방문되었을 경우에는 <code>v</code> 가 먼저 끝나 <code>n</code> 이 할당되기 때문에 <code>f(u) &lt; f(v)</code> 다.</p>

<p>만약에 <code>v</code> 가 <code>u</code> 보다 먼저 방문되면 <code>u</code> 가 방문되기도 전에 <code>v</code> 에 대한 방문이 끝나므로 <code>f(u) &lt; f(v)</code> 다.</p>

<h3 id="stronglyconnectedcomponents">Strongly Connected Components</h3>

<p>먼저 정의부터 보면 </p>

<blockquote>
  <p><strong>Strongly conncected components (SCCs)</strong> of a directed graph <code>G</code> are the equivalence classes of the relation. <code>u ~ v</code> means path <code>u -&gt; v</code> and <code>v -&gt; u</code> in G</p>
</blockquote>

<p><em>directed graph</em> 는 방향성이 있기 때문에 단순히 <em>component</em> 를 구한다고 해서 <em>equivalence classes</em> 가 되지 않는다. 서로 순환이 될 수 있는, cyclic  인 <em>component</em> 를 찾아야 한다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/5/5c/Scc.png'  alt="" /></p>

<p align="center">(<a href='http://commons.wikimedia.org/' >http://commons.wikimedia.org</a>)</p>

<p><em>SCC</em> 는 <em>cycle</em> 이기 때문에 <em>DFS</em> 만 돌려도 나올 <strong>수</strong> 있다. 그런데, 만약 전체로 갈 수 있는 노드에서 <em>DFS</em> 를 돌려버리면 모든 <em>SCC</em> 가 합쳐진 형태가 나온다. 다시 말해서 단순 DFS 를 모든 노드에 대해 돌리는 것으로는 <em>SCC</em> 를 얻을 수도, 못 얻을 수도 있다는 소리다. <em>Kosaraju's Two-Pass Algorithm</em> 으로 해결할 수 있다.</p>

<h3 id="kosarajus2passalgorithm">Kosaraju's 2-pass algorithm</h3>

<p><code>O(m + n)</code> 으로 <em>SCC</em> 를 구하는 것을 보장한다. 어떻게 그럴까? <em>SCC</em> 를 찾을 때 <em>DFS</em> 를 돌릴려면 <strong>특정 노드의 순서</strong>로 <em>DFS</em> 를 돌려야 한다. 그렇지 않으면 <em>SCC</em> 가 나오지 않는다. <em>Kosaraju algorithm</em> 은 이 순서를 찾아준다. </p>

<pre><code>Let G_rev = G with all arcs reversed  
run DFS-Loop on G_rev // compute "magical ordering"  
run DFS-Loop on G // discover SCCs  
</code></pre>

<p>좀 더 자세히 보면 <code>f(v)</code> 를 각 <em>vertex</em> 에 대해 <em>finishing time</em> 이라 보면, 두번째 <code>DFS-Loop</code> 에서 <code>f(v)</code> 의 <em>decreasing order</em> 로 <code>DFS</code> 를 여러번 돌리면 <em>SCC</em> 를 찾아준다. 각 함수의 구현을 보면</p>

<pre><code>DFS-Loop(graph G)

global variable t = 0 // # of nodes processed so far  
global variable s = NULL // current source vertex

// assume nodes labelled 1 to n
for i = n to 1 by -1:  
  if i not yet explored:
    s := i
    DFS(G, i)
</code></pre>

<pre><code>DFS(graph G, node i)

mark i as explored  
set leader(i) := node s

for each arc (i, j) in G:  
  if j not yet explored:
    DFS(G, j)

t++  
set f(i) := t  
</code></pre>

<p>첫번째 <code>DFS-Loop</code> 에서는 <em>edge</em> 가 뒤집어져 있다. 함수가 끝나면 각 노드마다 <code>f(t)</code> 를 계산 해 주는데, 이게 사실 <em>SCC</em> 기준으로 보면 같은 <em>SCC</em> 내에서는 외부와의 연결고리가 없는 내부 노드가 가장 낮은 <code>f(t)</code> 를 가지게 된다. </p>

<p>이제 두번째 <code>DFS-Loop</code> 를 돌리기 위해 <em>edge</em> 를 다시 뒤집어서 보면 가장 높은 <code>f(t)</code> 값을 가지는 노드가 가장 먼저 <em>DFS</em> 를 돌려야 할 노드가 된다. 그리고 <em>leader</em> 는 각 <em>SCC</em> 를 얻기 위해 <em>DFS</em> 를 시작해야 할 지점이 된다.</p>

<p><em>running time</em> 은 <code>2 x DFS</code> 기 때문에 <code>O(m + n)</code> 이다. 첫 번째 노드에서 얻은 <em>finisihing time</em> <code>f(t)</code> 를 정렬하면 <code>O(n logn)</code> 이기 때문에 정렬 없이 <em>decreasing</em> 순서로 <em>DFS</em> 를 돌게 해줘야 한다.</p>

<h3 id="analysis">Analysis</h3>

<p>분석에 앞서서 간단한 성질을 먼저 이끌어 내자. 그래프를 변형해 <em>node</em> 각각을 <em>SCC</em> 로 만든 <em>meta-graph</em> 를 생각 해 보자. 이 <em>meta graph</em> 는 <em>DAG</em> 다. 왜냐하면 모든 <em>cycle</em> 있는 그래프는 <em>SCC</em> 로 포함되었기 때문이다.</p>

<p>따라서 <code>G</code> 나, 여기서 <em>edge, arc</em> 를 뒤집은 <code>G_rev</code> 나 같은 <em>SCC</em> 를 가지고 있다.</p>

<p>이 때 <code>G</code> 에서 서로 인접한 <em>SCC</em> <code>C1 -&gt; C2</code> 에 대해서 <em>edge</em> <code>(i, j)</code> 가 있다고 해 보자. (<code>i -&gt; j</code>)</p>

<p>그러면 <code>G_rev</code> 로 계산한 <code>max f(C1) &lt; max f(C2)</code> 임을 알 수 있다. 다시 말해 <code>C2</code> 가 먼저 <em>DFS</em> 를 돌려야 하는 <em>SCC</em> 인데, 먼저 돌려야 할 수록 더 높은 <em>finishing time</em> <code>f(t)</code> 를 가진다. </p>

<p>이건 쉽게 보일 수 있는데, <code>G_rev</code> 에서는 <em>arc</em> 가 반대 방향이 되므로 더 큰 <em>SCC</em> <code>C1</code> 이, 다시 말해 더 나중에 계산해야 할 <em>SCC</em> 가 더 작은 <em>SCC</em> 가 되므로 먼저 계산이 끝나 더 작은 <code>max f(t)</code> 를 가지게 된다. </p>

<p>증명은 <code>C1 union C2</code> 의 첫번째 노드가 <code>C1</code> 에 있을 때 <code>C2</code> 에 있을때로 각각 나눠서 참임을 보이면 쉽다.</p>

<p>알고리즘을 다시 보면</p>

<pre><code>DFS-Loop(graph G)

global variable t = 0 // # of nodes processed so far  
global variable s = NULL // current source vertex

// assume nodes labelled 1 to n
for i = n to 1 by -1:  
  if i not yet explored:
    s := i
    DFS(G, i)
</code></pre>

<pre><code>DFS(graph G, node i)

mark i as explored  
set leader(i) := node s

for each arc (i, j) in G:  
  if j not yet explored:
    DFS(G, j)

t++  
set f(i) := t  
</code></pre>

<p><code>DFS</code> 를 한번 돌릴 때 마다 <em>SCC</em> 가 하나씩 발견된다. 우선 <em>sink SCC</em> 가 가장 높은 <code>f(t)</code> 값을 가지게 되므로 가장 먼저 <em>DFS</em> 를 돌게 된다. 그리고 <em>SCC</em> 는 <em>cyclic</em> 이므로 하나의 <em>SCC</em> 만 찾고 끝남을 보장한다. 다음으로 높은 <code>f(t)</code> 값을 가지는 <em>SCC</em> 를 찾고, 더이상 <em>SCC</em> 를 찾지 못할 때 까지 반복하고 알고리즘이 끝나는걸 확인할 수 있다.</p>

<p>처음엔 잘 몰랐는데 <em>leader</em> 가 해당 <em>SCC</em> 에서 가장 높은 <code>f(t)</code> 값을 가지는 <em>node</em> 다.</p>

<h3 id="structureoftheweb">Structure of the Web</h3>

<p><em>vertices</em> 를 웹페이지라 보고 <em>edges</em> 를 하이퍼링크라 보면 웹을 <em>directed graph</em> 이해할 수 있다.</p>

<p>그럼 웹은 어떻게 생겼을까? 사람들이 첫번째로 웹이 어떻게 생겼는지 확인하기 위해 시도한 방법은 <em>crawling</em>, 즉 링크를 따라가며 모든 웹페이지를 긁는 방식이었다.</p>

<p>그래서 실제로 해보니 2000 년도에는 <em>200 milions</em> 의 <em>node</em>, <em>1 bilion</em> 의 <em>edge</em> 가 있었다고 한다.</p>

<p>그럼 이게 어떻게 생겼을까? <em>one big scc</em> 일거라 보는 관점이 있다. 한쪽에선 오래된 웹페이지들이 있고, 더 뻗어나가지 않는다. 이쪽을 <em>out</em> 이라 보면 반대편에서는 새로운 웹페이지들이 생겨 기존의 웹페이지에 <em>edge</em> 를 붙여 나가는 <em>in</em> 부분이 있다고 할 수 있다. 몇몇 부분에는 전혀 연결이 되지 않은 부분이 있을 수 있다.</p>

<p><img src='http://bparsia.files.wordpress.com/2009/11/bowtieweb.png?w=600&amp;h=364'  alt="" /></p>

<p align="center">(<a href='http://bparsia.wordpress.com/' >http://bparsia.wordpress.com</a>)</p>

<p>웹의 <em>core</em> 부분은 <em>well connected</em> 되어 있는데 <em>small world property</em> 를 가지고 있다. 무슨말이냐면 모든 노드가 각각 서로 연결되어 있진 않지만 연결을 많이 가지고 있는 특정 몇몇 노드에 의해 모든 노드가 연결된다는 뜻이다. 결국 서로 연결되는데 몇 <em>hop</em> 안걸린다 볼 수 있다.</p>

<p><img src='http://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Small-world-network-example.png/330px-Small-world-network-example.png'  alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Small-world_network' >http://en.wikipedia.org/wiki/Small-world_network</a>)</p>  

<p><img src='http://web.mit.edu/9.29/www/neville_jen/connectivity/MEA2_files/image002.jpg'  alt="" /></p>

<p align="center">(<a href='http://web.mit.edu/' >http://web.mit.edu</a>  
)</p>

<p>요즘의 연구들은 웹 그래프가 어떤식으로 진화하는지, 정보들이 어떤식으로 전파되는지 등을 중점으로 하고 있다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong> <br />
(2) <a href='http://en.wikipedia.org/wiki/Equivalence_class' >Equivalence class</a> <br />
(3) <a href='http://www.stoimen.com/blog/2012/12/10/computer-algorithms-topological-sort-revisited/' >http://www.stoimen.com</a> <br />
(4) <a href='http://commons.wikimedia.org/wiki/File:Scc.png' >http://commons.wikimedia.org/wiki/File:Scc.png</a> <br />
(5) <a href='http://bparsia.wordpress.com/2009/11/24/does-rest-explain-the-bowtie-gross-structure-of-the-web/' >http://bparsia.wordpress.com</a> <br />
(6) <a href='http://web.mit.edu/9.29/www/neville_jen/connectivity/MEA2.htm' >http://web.mit.edu</a> <br />
(7) <a href='http://en.wikipedia.org/wiki/Small-world_network' >http://en.wikipedia.org/wiki/Small-world_network</a></p>]]></description><link>http://1ambda.github.io/graph-search-and-connectivity/</link><guid isPermaLink="false">dcb3c85a-c903-4dab-bb88-b408099fb092</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[graph]]></category><category><![CDATA[BFS]]></category><category><![CDATA[DFS]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 15 Nov 2014 04:29:52 GMT</pubDate></item><item><title><![CDATA[Machine Learning, Week 6]]></title><description><![CDATA[<p>지난시간엔 <em>back propagation</em> 구현해 보고 여기에 적용할 수 있는 소소한 것들 <em>random initialization</em> 과 <em>gradient checking</em> 등도 알아 보았다.</p>

<p>머신러닝을 단순히 아는것과, 실전에서 사용할 수 있다는 건 큰 차이가 있다. 이번 시간에는 실전에서 필요한 여러가지 팁들에 대해 설명한다. 후반부에서는 스팸 분류기를 통해 간단한 머신러닝 시스템을 설계해 본다.</p>

<h3 id="diagnostics">Diagnostics</h3>

<p><img src='http://chart.apis.google.com/chart?cht=tx&amp;chl=J' (%5Ctheta)%20%3D%20%7B1%20%5Cover%202m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20(h_%5Ctheta(x%5E%7B(i)%7D%20-%20y%5E%7B(i)%7D)%5E2%20%2B%20%5Clambda%5Csum_%7Bj%3D1%7D%5Em%20%5C%20%5Ctheta_j%5E2%5D" alt="" /></p>

<p>집 가격에 대한 <em>linear regression</em> 가설을 세웠는데 <em>error</em> 가 좀 큰 것을 발견했다. 어떻게 해야할까?</p>

<p>(1) Get more training examples <br />
(2) Try smaller sets of features <br />
(3) Try getting additional features <br />
(4) Try adding polynomial features <br />
(5) Try decreasing <em>lambda</em> <br />
(5) Try increasing <em>lambda</em>  </p>

<p>이중에서 더 많은 트레이닝 셋을 추가하는 것은 별로 도움이 안 될 수도 있다. (이유는 뒷 부분에서 논의한다.)</p>

<p>알고리즘의 정상 동작여부를 파악할 수 있는 몇 가지 판별법을 알아보자. <em>gradient checking</em> 이 그랬던 것처럼, 구현하는데는 좀 시간이 걸려도 디버깅에 드는 시간을 많이 줄여준다.</p>

<blockquote>
  <p>A diagnostic can sometimes rule out certain courses of action (changes to your learning algorithm) as being unlikely to improve its performance significantly</p>
</blockquote>

<h3 id="evaluatingahypothesis">Evaluating a hypothesis</h3>

<p><em>low training error</em> 를 갖는 <em>hypothesis (가설)</em> 이 항상 좋은 건 아니다. <em>overfitting</em> 이 발생할 수 있기 때문이다.</p>

<p>그리고 <em>feature</em> 가 많을 수록 <em>plotting</em> 하기 힘들기 가설을 평가할 다른 방법을 찾아야 한다. 단순히 그리는 것 만으로 모든 가설을 평가하긴 어렵다.</p>

<p>한가지 평가 방법으로 전체 <em>training set</em> 을 <code>70% / 30%</code> 로 분리해 <code>70%</code> 은 <em>training set</em> 으로 나머지 <code>30%</code> 는 <em>test set</em> 으로 활용할 수 있다. (<em>참고로 테스트셋과 트레이닝셋은 랜덤하게 분리하는 편이 좋다.</em>)</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360378105_8286.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>linear regressoin</em> 에 트레이닝 셋과 테스트셋을 분리하는 과정을 알아 보면</p>

<p>(1) <code>0(theta)</code> 를 트레이닝 셋에 대해 학습시켜 트레이닝 에러를 최소화 하는 <code>J(0)</code> 를 찾는다. <br />
(2) 학습된 <code>0(theta)</code> 에 대해 테스트 셋을 돌려 <em>test error</em> 를 찾는다.</p>

<p>그럼 <em>linear regression</em> 말고 <em>classification</em> 에는 어떻게 적용할까?</p>

<p>마찬가지로 <code>0(theta)</code> 에 대해 <code>J(0)</code> 를 찾고, 여기에 <code>J_test(0)</code> 를 돌려 테스트 에러를 찾는다.</p>

<p>아니면 아래 그림에서 볼 수 있듯이 <em>misclassification error</em> 를 이용해도 된다. 보면 알겠지만 같은 정의다. <code>y = 0</code> 일때 <code>h(x) &lt; 0.5</code> 이어야 하고, <code>y = 1</code> 일때 <code>h(x) =&gt; 0.5</code> 이어야 하기 때문에 엇갈리게 나온 경우 <code>err</code> 함수에서 <code>1</code> 을 리턴해, 이 값을 모두 합한 뒤 전체 테스트 셋의 숫자로 나누면 테스트 에러값을 구할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360378588_2059.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h3 id="modelselection">Model Selection</h3>

<p>당연한 이야기지만 <em>training set</em> 에 가설이 <em>well fit</em> 되어있기 때문에 트레이닝셋에 포함되지 않은 새로운 경향의 데이터를 만나면 에러가 많이 생길 수 있다.</p>

<blockquote>
  <p>Once parameters were fir to some set of data (training set), the error of the parameters as measured on that data (the training error <code>J(0)</code>) is likely to be lower than the actual generalization error.</p>
</blockquote>

<p><code>d</code> 를 <em>degree of polynomial (가설의 다항식 차수)</em> 이라 하자. 그럼 <code>d = 1, 2, .. , 10</code> 중에 어떤 걸 택하는 게 좋을까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/09/1360380082_1392.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>각각에서 나오는 파라미터 벡터를 <code>0^(1), 0^(2), ...</code> 이라 하자. 그리고 여기서 나오는 테스트 셋의 에러를 <code>J_test(0^(1))</code>, <code>J_test(0^(2))</code> 등이라 하면 이 값을 모두 조사해 최소로 나오는 <code>d</code> 를 가진 모델을 택한다. </p>

<p>그러나 문제는 이렇게 선택한 모델이 <em>optimistic estimate of generalization error</em> 라는 점이다. 테스트 셋에 대해서 가장 적은 에러를 모델이 보여준다 해도 실제 데이터에 대해 똑같이 적은 에러를 보여주리라고 확신할 수 없다.</p>

<h3 id="trainvalidationtestsets">Train / Validation / Test Sets</h3>

<p>이 문제를 해결하기 위해 <em>training set</em> 을 <em>60%/20%/20%</em> 로 나누어 각각을 <em>training set</em>, <em>cross validation set (CV)</em>, <em>test set</em> 이라 하자. 그리하여 각각의 에러를 구할 수 있다. </p>

<p>여기서 <em>CV</em> 에 대한 <em>error</em> 가 최저인 모델을 택하면 이 모델은 <em>test set</em> 에 대해서는 <em>fit</em> 되어 있지 않기 때문에 <em>test error</em> 가 <em>estimate generalization error</em> 라 볼 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360459807_7333.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>다시 정리해 보면 먼저 <code>0</code> 를 <em>training set</em> 에 대해 학습 시켜 <code>0</code> 값을 얻은 뒤, <em>cross validation (CV)</em> 에 대해 <em>error</em> 를 구해 가장 작은 값을 갖는 모델을 고른다.</p>

<p>이제 이 모델에 대해서 <em>test error</em> 를 구하면 이 모델은 테스트 셋에 대해서 <em>fit</em> 되지도, 가장 적은 에러를 가지는지 검사되지도 않은 데이터이므로 일반적인 에러값에 대한 추정치라 볼 수 있다.</p>

<p>일반적으로 <em>CV error</em> 는 <em>test error</em> 보다 더 작은 값을 가지는데, 이는 선택한 모델의 <code>0</code> 가 <em>CV set</em> 에 대해 최저치를 갖도록 <em>fit</em> 되어있기 때문이다.</p>

<h3 id="diagnosingbiasvsvariance">Diagnosing Bias vs Variance</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360461366_4352.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>그림에서 볼 수 있듯이 <code>d=1</code> 인 경우엔 <em>underfit</em>, <code>d=4</code> 인 경우엔 <em>overfit</em> 이 발생한다. 다른말로 각각 <em>high bias</em>, <em>high variance</em> 라 부른다.</p>

<p>아래와 같이 가로 축을 <code>d</code>, 세로 축을 <code>error</code> 라 하면 <code>d</code> 가 증가할 수록 <em>training error</em> 는 0 에 가까워진다. 반면 <em>CV set</em> 에 대해서는 하나의 <code>d</code> 만 최저치를 가지고 나머지는 그 보다 높기 때문에 아래와 같은 그래프를 그릴 수 있다.</p>

<p><img src='http://my.csdn.net/uploads/201207/28/1343484056_3257.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>이 그래프가 시사하는 바는, </p>

<p>(1) <em>underfit</em> 할 경우 <code>d</code> 가 작으므로 <code>J_train(0)</code> 는 매우 크고, <code>J_cv(0)</code> 는 그의 거의 비슷한 값을 가지게 된다. (<em>bias problem</em>) <br />
(2) <em>overfit</em> 할 경우 <code>d</code> 가 크므로 <code>J_train(0)</code> 는 매우 작고, <code>J_cv(0)</code> 는 그보다는 훨씬 크다. (<em>variance problem</em>)  </p>

<p>따라서 <code>J_train(0)</code> 값이 <code>J_cv(0)</code> 과 얼마나 비슷한지 비교함으로써 <em>overfit</em> 혹은 <em>underfit</em> 되는지 판단할 수 있다.</p>

<p><img src='http://my.csdn.net/uploads/201207/28/1343484595_6134.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><a href='http://www.4four.us/article/2010/11/bias-variance-tradeoff' >여기</a> 서 <em>bias vs varance</em> 의 이해를 위해 인용을 좀 하자면,</p>

<blockquote>
  <p>Bias, 즉 선입관이 크면, (좋게 말해서) 줏대가 있고 (나쁘게 말해서) 고집이 세기 때문에 새로운 경험을 해도 거기에 크게 휘둘리지 않는다. 평소 믿음과 다른 결과가 관찰되더라도 한두 번 갖고는 콧방귀도 안 뀌며 생각의 일관성을 중시한다. (High Bias, Low Variance) 반대로 선입관이 작으면, (좋게 말하면) 사고가 유연하고 (나쁘게 말하면) 귀가 얇기 때문에 개별 경험이나 관찰 결과에 크게 의존한다. 새로운 사실이 발견되면 최대한 그걸 받아들이려고 하는 것이다. 그래서 어떤 경험을 했느냐에 따라서 최종 형태가 왔다갔다한다. (High Variance, Low Bias)</p>
</blockquote>

<h3 id="regularizationandbiasvariance">Regularization and Bias / Variance</h3>

<p><em>regularization</em> 이 끼어들면 <code>lambda</code> 를 <em>bias vs variance</em> 문제에서 고려해야 한다. 아래 그림을 보자.</p>

<p><img src='http://my.csdn.net/uploads/201207/28/1343485336_9809.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p><em>lambda</em> 가 크면 당연히 <em>high bias</em>, 매우 작으면 <em>high variance</em> 다. 그러면 중간 값을 찾아야 한다는건 알겠는데, 어느정도가 적당한 값일까?</p>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360461577_6101.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>이 전과 비교했을때 <code>J(0)</code> 에 <em>regularization term</em> 이 추가되었지만 <code>J_train(0)</code> 이나 <code>J_cv(0)</code>, <code>J_test(0)</code> 에는 <em>regularization term</em> 이 없다는 점에 유의하자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360461899_5163.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>모델을 선택했다면 <em>lambda</em> 를 천천히 증가시켜가면서 각각에 대해 <code>0(theta)</code> 를 구한다. 그리고 이 값을 이용해 구한 <code>J_cv(0)</code> 가 가장 적은 에러 값을 가지는 <em>lambda</em> 를 구하면 된다. <em>model selection</em> 과 비슷하다.</p>

<p><em>lambda</em> 과 <em>CV error</em>, <em>training error</em> 간 관계를 알아보자면 아래와 같다. 위에서 언급 했듯이 <em>lambda</em> 가 크면 <em>bias</em>, 0 에 가까우면 <em>variance</em> 임을 확인할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/10/1360462458_2256.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>bias</em> 와 <em>variance</em>, 그리고 <em>lambda</em> 의 관계는 아래 그래프에서도 확인할 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201210/12/1350026192_9384.jpg'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<h3 id="learningcurves">Learning Curves</h3>

<p>전체 트레이닝 셋의 사이즈 <code>m</code> 이 커질때 에러는 어떻게 되는가 그래프로 한번 보자.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552101_5795.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>간단히 생각해 보면 <code>m</code> 의 사이즈가 클수록 <em>training set</em> 의 에러는 점점 늘어나고, <code>m</code> 이 커지면 커질수록 <em>generalize</em> 가 가능하므로 <em>CV error</em> 는 점점 줄어든다.</p>

<p><em>high bias</em> 인 경우 처음엔 <em>training error</em> 이 매우 크다가, <code>m</code> 이 클수록 <em>training error</em> 의 증가율이 작아지므로</p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552417_8655.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>이 그림이 시사하는 바는 </p>

<blockquote>
  <p><em>high bias</em> 알고리즘이라면 <code>m</code> 이 을 많이 수집한다 해도 <code>J_cv(0)</code> 의 감소율이 적기 때문에 별 도움이 되지 못한다. 다시 말해 <code>m</code> 을 많이 투입해도 얻어지는 <em>training error</em> 와 <em>CV error</em> 의 차이는 미미하다.</p>
</blockquote>

<p>반면 <em>high variance</em> 의 경우에는 <code>m</code> 이 크면 클수록 <em>training error</em> 의 증가율이 점점 줄어들고, <em>overfit</em> 이기 때문에 <em>CV error</em> 는 <em>training set</em> 과 차이가 많이 난다. 그래프는</p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552431_2697.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>결국</p>

<blockquote>
  <p><em>high variance</em> 일 경우 <code>m</code> 을 많이 투입하면 할수록 낮은 <em>CV error</em> 를 얻는데 도움이 된다.</p>
</blockquote>

<p>다시 말해 이 두가지 경우는 <em>training error</em> 와 <em>CV error</em> 의 차이가 꽤 클때는 <code>m</code> 을 높이면 낮은 <em>CV error</em> 를 적은 비용으로 얻을 수 있다는 뜻이다.</p>

<h3 id="applyingtoneuralnetwork">Applying to Neural Network</h3>

<p>이제 처음에 나왔던 6가지 경우를 고려해 보자.</p>

<p>(1) Get more training examples -> <em>fixing high variance</em> <br />
(2) Try smaller sets of features -> <em>fixing high variance</em> <br />
(3) Try getting additional features -> <em>fixing high bias</em> <br />
(4) Try adding polynomial features -> <em>fixing high bias</em> <br />
(5) Try decreasing <em>lambda</em> -> <em>fixing high bias</em> <br />
(5) Try increasing <em>lambda</em> -> <em>fixing high variance</em>  </p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552523_3279.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>bias vs variance</em> 문제를 <em>neural network</em> 에 적용시켜보자. </p>

<p>(1) 작은 사이즈의 신경망이라면 계산 비용은 저렴한 대신 <em>underfit</em> 할 수 있다. <br />
(2) 큰 사이즈의 신경망이라면 계산 비용은 비싸고 <em>overfit</em> 할 수 있다. 따라서 <em>regurarization</em> 을 이용해 <em>overfit</em> 되는 정도를 줄일 수 있다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/11/1360552606_9371.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h3 id="machinelearningsystemdesign">Machine Learning System Design</h3>

<p>간단한 스팸 분류기를 작성한다고 하자. <em>supervised learning</em> 을 위해서</p>

<p>(1) <code>x</code> = features of email (<em>choose 100 words indicative of spam or not</em>) <br />
(2) <code>y</code> = spam <code>1</code> or not spam <code>0</code>  </p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360804751_1943.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>각 단어가 이메일 본문에 등장했는지 아닌지를 각 <em>feature</em> 의 값으로 사용한다. (<code>1</code> or <code>0</code>)</p>

<p>일반적으로는 100개를 수동으로 고르는게 아니라, 스팸에서 많이 사용된 단어를 <code>n</code> 개 골라 사용한다.</p>

<p>그럼 <em>low error</em> 를 얻기 위해서는 무엇을 해야할까?</p>

<p>(1) Collect lots of data : 항상 도움이 되진 않는다. <br />
(2) Develop sophisticated features based on email routing information <br />
(3) Develop sophisticated features for message body. e.g should "discount" and "discounts" be treated as the same word? <br />
(4) Develop sophisticated algorithm to detect misspelings e.g m0rtgage  </p>

<p>등등 의 다양한 방법을 고안할 수 있다. 이 중 무엇을 선택해야 할까? 좀 더 체계적인 방법은 없을까? 여기 몇 가지 가이드라인이 있다.</p>

<blockquote>
  <ol>
  <li>Start with a simple algorithm that can implement quickly. Implement it and test it on your corss-validation data.</li>
  <li>Plot learning curves to decide if more data, more features, etc. are likely to help.</li>
  <li>Error analysis: manually examine the examples (in corss validation set) that your algorithm made errors on. See if you spot any systematic trend in what type of examples it is making errors on.</li>
  </ol>
</blockquote>

<h3 id="erroranalysis">Error Analysis</h3>

<p><em>error analysis</em> 하는 방법은 <em>CV error</em> 를 발견했을 때, 각각의 에러를 수동으로 검사하면서 분류하는 것이다.</p>

<p>이메일의 타입이 무엇인지, 혹은 어떤 <em>feature</em> 가 알고리즘에서 이 이메일을 분류하는데 도움이 될만한지 생각해 본다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360804909_5716.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p><em>error analysis</em> 가 에러가 나타난 이유에 대한 어떤 경향을 제공할 수 있기 때문에 간단히 먼저 구현해 보고 분석 해 보는것도 나쁘지 않다.</p>

<p><em>error analysis</em> 는 실제로 분석 결과를 새로운 알고리즘에 적용했을때 <em>performace</em> 가 더 좋을지 알려주지 않는다. 따라서 해보고 <em>numerical evaluation</em> 을 비교해 본다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360804976_1060.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<h3 id="skewedclasses">Skewed Classes</h3>

<p>암을 진단한다고 하자. <em>logistic regression</em> 을 구현했고, 놀랍게도 <em>test error</em> 가 <code>1%</code> 라고 하자.</p>

<p>근데, 만약에 환자중에 <code>0.5%</code> 만 암환자라면, 차라리 모두 암이 아니라고 진단하는 다음의 함수가 더 에러가 낮다.</p>

<pre><code class="matlab">function y = predictCancer(x)  
  y = 0; 
return  
</code></pre>

<p>이렇게 확률이 희박한 <em>class</em> 를 <strong>skewed class</strong> 라 부른다. 또 한가지 사실을 알 수 있는데, <em>error</em> 가 낮다고 해서 항상 좋은 알고리즘이 아니라는 사실이다. <code>y = 0</code> 은 <code>99.5</code> 의 정확도를 보여주지만 알고리즘이 아니다. 에러값 말고 다른 평가방법이 필요하다!</p>

<h3 id="precisionrecall">Precision / Recall</h3>

<p>그림을 먼저 보자. 예측 여부와 실제 값에 따라서 <code>2 x 2</code> 매트릭스를 붙일 수 있다. </p>

<p><img src='http://my.csdn.net/uploads/201208/06/1344228190_4576.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a>)</p>

<p>여기서 <em>precision</em> 과 <em>recall</em> 이란 개념을 끌어낼 수 있는데</p>

<blockquote>
  <p><em>*Precision: *</em> Of All patients where we predicted y = 1, what fraction actually has cancer?</p>
  
  <p><em>*Recall: *</em> Of all patients that actually have cancer, what fraction did we correctly detect as having cancer?</p>
</blockquote>

<p>다시 말해 <em>precision</em> 은 우리가 암이 있다고 진단한 환자중 실제 암이 있는 환자의 비율이고, <em>recall</em> 은 실제 암이 있는 환자 중 우리가 암이 있다고 진단한 환자의 비율이다.</p>

<p>위의 함수처럼 <code>y = 0</code> 으로 진단하는 경우 <em>true positive</em> = <code>0</code> 이므로 <em>recall</em> = <code>0</code> 이다.</p>

<p>단순히 <em>error</em> 만으로 판단하는 것은 위의 예처럼 잘못된 판단일 수 있다. 따라서 <em>skewed class</em> 가 있더라도 <em>precision</em> 과 <em>recall</em> 을 보면 알고리즘에 속임수가 있는지, 없는지를 파악할 수 있다.</p>

<h3 id="tradingoffprecisionandrecall">Trading off Precision and Recall</h3>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360805261_5122.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>일반적으로 <code>h(x) &gt;= 0.5</code> 일경우에 <code>1</code> 을, <code>h(x) &lt; 0.5</code> 일 경우에 <code>0</code> 을 예측하는데, 이 수치를 좀 더 올려 <code>0.7</code> 이상 또는 미만으로 예측한다 해 보자.</p>

<p>이 경우 좀 더 확실한 환자만 암이라 진단하므로 <em>precision</em> 은 올라가는 반면 <em>recall</em> 은 내려간다. </p>

<p>거꾸로 수치를 <code>0.3</code> 으로 낮추면 덜 확실해도 그냥 암이라 우기므로 <em>recall</em> 은 높아지겠지만 예측한 것중 실제 환자를 의미하는 <em>precision</em> 값은 떨어진다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360805315_5777.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>위 그림을 보면 <em>threshold</em> 에 따라서 <em>recall</em> 과 <em>precision</em> 값이 얼추 반비례하는 걸 볼 수 있다. 디테일에 따라서 구체적인 그래프의 모양은 다를 수 있다.</p>

<p>그럼 이제 문제는, <em>threshold</em> 를 고를 수 있느냐, 다시 말해 어느 <em>(precision, recall)</em> 쌍이 더 좋은가 하는 문제다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360805419_2578.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>단순히 평균을 쓰면 <code>y = 1</code> 로 예측하는 것과 같은 알고리즘들이 높은 값을 얻을 수 있다. 예를 들어 위 그림에서 <em>algorithm 3</em> 가 그렇듯이.</p>

<p>따라서 단순히 평균을 하기 보다는 <em>F1 score</em> 를 많이 쓴다.</p>

<p><img src='http://my.csdn.net/uploads/201208/06/1344234475_3823.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>따라서 <em>CV set</em> 에 대해 높은 <em>F1 score</em> 를 가지는 <em>threshold</em> 를 택함으로써 좋은 알고리즘을 고를 수 있다.</p>

<h3 id="dataformachinelearning">Data for Machine Learning</h3>

<p>지금까지는 <em>evaluation</em> 에 대한 논의었고, <em>data</em> 에 대한 이야기를 좀 더 해 보자. 앞에서는 단순히 데이터가 많다고 해서 좋다는 뉘앙스로 이야기를 했지만 실제 특정 상황에서, 특정 알고리즘은 다량의 데이터를 이용하면 좋은 성능을 내기도 한다. 실제 그런가 보자. 4개의 서로 다른 알고리즘을 트레이닝 셋 사이즈를 늘려가며 정확도를 비교한 결과다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360806606_8278.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<blockquote>
  <p><em>"It's not who has the best algorithm that wins, It's who has the most data."</em></p>
</blockquote>

<p>항상 그렇지는 않다. 집 값을 예측 할 때 <em>feature</em> 로 사이즈 하나만 준다면 정확하게 예측하기란 불가능하다. 양이 문제가 아니고 집 값을 예측하기에 충분한 정보가 필요하다.</p>

<p><img src='http://img.my.csdn.net/uploads/201302/14/1360807112_1041.png'  alt="" /></p>

<p align="center">(<a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a>)</p>

<p>많은 수의 <em>parameter</em> 가 있다. 하자. <em>low bias</em> 기 때문에 <code>J_train(0)</code> 는 작을 것이다. (<em>not underfit</em>)</p>

<p>그리고 여기에 <em>parameter</em> 보다 훨씬 많은 <em>training set</em> 을 사용한다면, <em>overfit</em> 하지 않는다 볼 수 있다. 따라서 <em>underfit</em> 도 아니고 <em>overfit</em> 도 아니므로</p>

<p><code>J_test(0)</code> 는 <code>J_train(0)</code> 에 근사한 값을 가진다 볼 수 있다. 결국 작은 <code>J_test(0)</code> 을 얻을 수 있다.</p>

<p>정리하자면, 충분한 양의 정보를 가지고 있고 (<em>large parameters</em>), 큰 사이즈의 데이터를 대상으로 알고리즘을 훈련 시킨다면 상당히 좋은 성능을 뽑아낼 수 있다는 훈훈한 이야기. (거꾸로 말하면, 반복하지만, 데이터만 많다고, 혹은 파라미터만 많다고 좋은 결과를 얻을 수 없다는 이야기)</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong> <br />
(2) <a href='http://blog.csdn.net/linuxcumt' >http://blog.csdn.net/linuxcumt</a> <br />
(3) <a href='http://blog.csdn.net/abcjennifer' >http://blog.csdn.net/abcjennifer</a> <br />
(4) <a href='http://www.4four.us/article/2010/11/bias-variance-tradeoff' >http://www.4four.us</a></p>]]></description><link>http://1ambda.github.io/machine-learning-week-6/</link><guid isPermaLink="false">58386046-1a88-4f88-b8dc-b5c6c76aa5cb</guid><category><![CDATA[coursera]]></category><category><![CDATA[machine lerning]]></category><category><![CDATA[precision]]></category><category><![CDATA[bias]]></category><category><![CDATA[learning curves]]></category><category><![CDATA[recall]]></category><category><![CDATA[variance]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 14 Nov 2014 05:00:50 GMT</pubDate></item><item><title><![CDATA[하스켈로 배우는 함수형 언어 3]]></title><description><![CDATA[<p>하스켈에서 <em>repetition (반복)</em> 은 <em>recursion</em> 을 통해 표현됩니다. 간단한 재귀부터 시작해서 <em>mutual recursion</em> 까지 알아보고, <em>Higher order function</em> (특히 <code>fold</code>) 에 대해 배운 뒤 적용을 위해 <em>church numerals</em> 를 구현해보고, 마지막으로 간단한 문자열 전송기를 모델링 해 보겠습니다.</p>

<h3 id="tailcall">Tail call?</h3>

<p><em>recursion</em> 을 주로 사용한다면 <em>stack</em> 이 많이 쌓일 수 있습니다. 이런 문제를 해결해 주는 것이 <em>tail call elimination</em> 입니다.</p>

<p>간단한 재귀 함수를 만들어서 스택이 어떻게 변하나 한번 보죠.</p>

<pre><code class="haskell">factorial 0 = 1  
factorial n = n * factorial(n - 1)  
</code></pre>

<p>이 때 <code>factorial 3</code> 을 평가한다면</p>

<pre><code class="haskell">factorial 3  
3 * factorial 2  
3 * (2 * factorial 1)  
3 * (2 * (1 * factorial 0))  
3 * (2 * (1 * 1))  
3 * (2 * 1)  
3 * 2  
6  
</code></pre>

<p>이렇게 각 단계가 확장되면서 <code>n</code> 이 매우 클 경우 마지막 단계에서 연산의 길이가 엄청나게 길어집니다. 함수 한번 호출당 스택이 하나씩 생긴다고 보면 어마어마한 스택이 생기는 것이죠. </p>

<p>다행히도 하스켈은 <em>tail recursion optimization (꼬리 재귀 최적화)</em> 를 가지고 있습니다. 꼬리 재귀에 대한 이야기는 나중에 더 이야기 하도록 하지요.</p>

<h3 id="recursiononlists">Recursion on Lists</h3>

<p>리스트는 같은 타입을 여러개 저장할 수 있기 때문에 <em>recursion</em> 을 사용하기 적합하죠.</p>

<p>리스트 내의 모든 원소의 곱을 구하는 <code>product</code> 함수를 만들어 볼까요? 하스켈에 원래 있지만, 재미삼아 만들어 봅시다. 이름은 충돌이 안나게 <code>productC</code> 라 부릅시다.</p>

<pre><code class="haskell">productC :: [Int] -&gt; Int  
productC [] = 1  
productC (n : ns) = n * productC ns  
</code></pre>

<p><code>length</code> 와 <code>reverse</code> 도 만들어 봅시다.</p>

<pre><code class="haskell">lengthC :: [a] -&gt; Int  
lengthC [] = 0  
lengthC (x : xs) = 1 + length xs

reverseC :: [a] -&gt; [a]  
reverseC [] = []  
reverseC (x : xs) = reverse(xs) ++ [x]  
</code></pre>

<p>조금 더 복잡한 <code>zip</code>, <code>drop</code> 함수나 <code>++</code> 연산자도 어렵지 않습니다. </p>

<pre><code class="haskell">zipC :: [a] -&gt; [b] -&gt; [(a, b)]  
zipC [] _ = []  
zipC _ [] = []  
zipC (x:xs) (y:ys) = (x, y) : zip xs ys

dropC :: Int -&gt; [a] -&gt; [a]  
dropC 0 xs = xs  
dropC _ [] = []  
dropC n (x:xs) = drop (n-1) xs

(++) :: [a] -&gt; [a] -&gt; [a]
[] ++ ys = ys
(x:xs) ++ ys = x : (xs ++ ys)
</code></pre>

<h3 id="quicksort">Quick sort</h3>

<p>퀵소트 알고리즘은 간단합니다. 매 함수 호출에서, <em>pivot</em> 이라 불리는 리스트 내 원소를 고른 후 <em>pivot</em> 좌측에는 그 보다 작은 수를, 우측에는 <em>pivot</em> 보다 큰 수를 배치합니다. 그리고 <em>pivot</em> 을 제외한 좌측 과 우측에 대해 재귀 호출을 하지요.</p>

<p><img src='https://sadakurapati.files.wordpress.com/2013/10/qsort_2.png?w=902&amp;h=617'  alt="" /></p>

<p align="center">(<a href='https://sadakurapati.wordpress.com/' >https://sadakurapati.wordpress.com</a>)</p>

<p>지난 강의에서 배운 <em>list comprehension</em> 을 이용하면 매우 간단하게 <em>quick sort</em> 를 만들 수 있습니다.</p>

<pre><code class="haskell">qsort :: [Int] -&gt; [Int]  
qsort [] = []  
qsort (x:xs) = qsort smaller ++ [x] ++ qsort larger  
               where
                 smaller = [a | a &lt;- xs, a &lt;= x]
                 larger = [b | b &lt;- xs, b &gt; x]
</code></pre>

<p>위 코드에서는 매 재귀마다 인자로 받는 리스트의 첫번째 원소 <code>x</code> 를  <em>pivot</em> 으로 사용했습니다.</p>

<p><img src='http://media-cache-ec0.pinimg.com/736x/11/09/78/11097867a0e6c772c36285d97d94623b.jpg'  alt="" /></p>

<h3 id="recursion">Recursion</h3>

<p>위의 예에서 보았듯이 자기 자신을 호출하는 함수 패턴을 <em>recursion (재귀)</em> 라 부릅니다. 언제 유용할까요? 재귀를 이용하면 <em>induction (귀납법)</em> 을 이용해 함수의 성질을 증명할 수 있습니다. 제대로 동작하는지, 의도 했던대로 동작하는지 등을요.</p>

<blockquote>
  <p>Properties of functions defined using recursion can be proved using the simple but powerful mathematical technique of <strong>induction</strong></p>
</blockquote>

<h3 id="mutialrecursion">Mutial recursion</h3>

<p><em>mutual recursion</em> 은 서로 다른 두개의 함수가 상호간 재귀를 이용해 정의되는 방식입니다. </p>

<p><code>odd</code> 와 <code>even</code> 함수를 <em>mutual recursion</em> 을 이용해 정의할 수 있습니다. 일반적으로는 효율성을 위해  2로 나눈 나머지를 이용해 정의하지만, 양수에 대해서는 아래와 같이 <em>mutual recursion</em> 으로 만들 수 있죠.</p>

<pre><code class="haskell">even :: Int -&gt; Bool  
even 0 = True  
even n = oddC (n-1)

odd :: Int -&gt; Bool  
odd 0 = False  
odd n = evenC (n-1)  
</code></pre>

<p>비슷하게 리스트에서 짝수번째, 혹은 홀수번째 원소들만 돌려주는 <code>evens</code> 와 <code>odds</code> 함수도 <em>mutual recursion</em> 을 이용해 정의할 수 있습니다. <code>evens</code> 는 0번째 부터 돌려줍니다. <code>odds</code> 는 턴을 넘기는데 쓰고 실제 작업은 <code>evens</code> 에서 한다고 생각하면 금방 이해할 수 있습니다.</p>

<pre><code class="haskell">evens :: [a] -&gt; [a]  
evens [] = []  
evens (x:xs) = x : odds xs

odds :: [a] -&gt; [a]  
odds [] = []  
odds (_:xs) = evens xs  
</code></pre>

<h3 id="adviceonrecursion">Advice on recursion</h3>

<p>재귀는 자전거 타기와 비슷합니다. 처음엔 불가능해 보이는데 한번 시도해보면 정말 쉽게 탈 수 있죠. 여기 재귀를 만드는데 도움이 될만한 5가지 스텝이 있습니다. <code>init</code> 함수를 예로 들어 설명하겠습니다.</p>

<p>(1) define the type  </p>

<pre><code class="haskell">init :: [a] -&gt; [a]  
</code></pre>

<p>(2) enumerate the cases  </p>

<pre><code class="haskell">init (x:xs) =  
</code></pre>

<p>(3) define the simple case  </p>

<pre><code class="haskell">init (x:xs) | null xs = []  
            | otherwise = 
</code></pre>

<p>(4) define the other cases  </p>

<pre><code class="haskell">init (x:xs) | null xs = []  
            | otherwise = x : init xs
</code></pre>

<p>(5) generalise and simplify</p>

<pre><code class="haskell">init :: [a] -&gt; [a]  
init [_] = []  
init (x:xs) = x : init xs  
</code></pre>

<h3 id="examples">Examples</h3>

<p>예제 몇 가지를 좀 더 살펴봅시다. 먼저 곱셈 연산입니다.</p>

<pre><code class="haskell">(*) :: Int -&gt; Int -&gt; Int
m * 0 = 0  
m * n = m + (m * (n - 1))  
</code></pre>

<p>정렬된 리스트에 원소를 삽입하는 <code>insert</code> 함수입니다. 바로 다음에 만들 <code>isort</code> (<em>insertion sort</em>) 를 구현한 함수에서 사용합니다.</p>

<pre><code class="haskell">insert :: Ord a =&gt; a -&gt; [a] -&gt; [a]  
insert x [] = [x]  
insert x (y:ys) | x &lt;= y = x : y : ys  
                | otherwise = y : insert x ys

isort :: Ord a =&gt; [a] -&gt; [a]  
isort [] = []  
isort (x:xs) = insert x (isort xs)  
</code></pre>

<p>이번엔 <em>merge sort</em> 입니다.</p>

<pre><code class="haskell">merge :: Ord a =&gt; [a] -&gt; [a] -&gt; [a]  
merge [] ys = ys  
merge xs [] = xs  
merge (x:xs) (y:ys) =  
  if x &lt;= y then x : merge xs (y: ys) else y : merge (x:xs) ys

halve :: [a] -&gt; ([a], [a])  
halve xs = splitAt (length xs `div` 2) xs

msort :: Ord a =&gt; [a] -&gt; [a]  
msort [] = []  
msort [x] = [x]  
msort xs = merge (msort ys) (msort zs)  
           where (ys, zs) = halve xs
</code></pre>

<h3 id="higherorderfunction">Higher-order function</h3>

<p><em>higher-order function</em> 은 함수를 인자로 받아 다시 함수를 돌려주는 함수를 말합니다. <del>응?</del></p>

<blockquote>
  <p>A function is called <em>higher-order</em> if it takes a function as an argument or returns a function as a result</p>
</blockquote>

<pre><code class="haskell">twice :: (a -&gt; a) -&gt; a -&gt; a  
twice f x = f (f x)  
</code></pre>

<p><code>twice</code> 는 인자 <code>x</code> 에 <code>f</code> 를 두번 적용한 뒤 값을 돌려줍니다. 더 정확히는 <em>curried function</em> 이므로 <code>twice f</code> 는 앞으로 뭘 인자로 받을지 모르지만 <code>f</code> 를 두번 적용하는 함수를 돌려줍니다.</p>

<p>이런 <em>higher-order function (고차함수)</em> 가 언제 유용할까요?</p>

<blockquote>
  <ol>
  <li><p><strong>Common programming idioms</strong> can be encoded as functions within the language itself.</p></li>
  <li><p><strong>Domain specific languages</strong> can be defined as collections of higher-order functions.</p></li>
  <li><p><strong>Algebraic properties</strong> of higher-order functions can be used to reason about programs.</p></li>
  </ol>
</blockquote>

<h3 id="map">map</h3>

<p>먼저 <code>map</code> 함수를 살펴봅시다.</p>

<pre><code class="haskell">map :: (a -&gt; b) -&gt; [a] -&gt; [b]

map (+1) [1, 3, 5, 7]  
-- [2, 4, 6, 8]
</code></pre>

<p>이 <code>map</code> 함수는 우리가 이전에 배웠던 <em>list comprehension</em> 으로 똑같이 작성할 수 있습니다.</p>

<pre><code class="haskell">map f xs = [f x | x &lt;- xs]  
</code></pre>

<p>아니면 <em>recursive function</em> 으로 작성할 수도 있습니다.</p>

<pre><code class="haskell">map f [] = []  
map f (x:xs) = f x : map f xs  
</code></pre>

<h3 id="filter">filter</h3>

<p><code>filter</code> 도 고차함수입니다. <code>filter</code> 는 <em>predicate</em> 즉, <code>(a -&gt; Bool)</code> 을 받아 <code>True</code> 인 원소만 모아 돌려줍니다.</p>

<pre><code class="haskell">filter :: (a -&gt; Bool) -&gt; [a] -&gt; [a]

filter even [1..10]  
-- [2, 4, 6, 8, 10]
</code></pre>

<p><code>filter</code> 도 마찬가지로 <em>list comprehension</em> 과 <em>recursive function</em> 두 가지 버전으로 작성될 수 있습니다.</p>

<pre><code class="haskell">filter p xs = [x | x &lt;- xs, p x]

filter p [] = []  
filter p (x:xs)  
  | p x = x : filter p xs
  | otherwise = filter p xs
</code></pre>

<p>단순히 <em>list comprehension</em> 으로 작성하는 것 보다, <em>recursive function</em> 으로 작성하면 위에서 볼 수 있듯이 공통점을 파악할 수 있습니다. 그러면 한단계 더 추상화 할 수 있지요. <code>filter</code> 와 <code>map</code> 의 공통점이 보이시나요?</p>

<h3 id="foldr">foldr</h3>

<p>위의 두 가지 예에서 <code>filter</code>, <code>map</code> 모두 빈 리스트와 그렇지 않은 리스트를 구분했습니다. 그리고 각각의 원소에 대해서 연산을 수행했지요. </p>

<pre><code class="haskell">f [] = v  
f (x:xs) = x pred f xs  
</code></pre>

<p>빈 원소라면 특정 값 <code>v</code> 를 돌려주고 아니라면 원소 <code>x</code> 에 <code>pred</code>를 적용하고, 나머지 <em>tail</em> <code>xs</code> 에 <code>f</code> 를 적용합니다. 비슷한 예제를 살펴볼까요?</p>

<pre><code class="haskell">-- v = 0, pred = +
sum [] = 0  
sum (x:xs) = x + sum xs

-- v = 1, pred = *
product [] = 1  
product (x:xs) = x * product xs

-- v = True, pred = &amp;&amp;
and [] = True  
and (x:xs) = x &amp;&amp; and xs  
</code></pre>

<p>따라서 다음과 같이 <code>foldr</code> (<em>fold right</em>) 을 이용해 정의할 수 있습니다.</p>

<pre><code class="haskell">sum = foldr (+) 0

product = foldr (*) 1

or = foldr (||) False

and = foldr (&amp;&amp;) True  
</code></pre>

<p>위에서 대략적인 정의를 봤지만, 더 엄밀하게 <code>foldr</code> 은 이렇게 정의할 수 있습니다.</p>

<pre><code class="haskell">foldr :: (a -&gt; b-&gt; b) -&gt; b -&gt; [a] -&gt; b  
foldr f v [] = []  
foldr f v (x:xs) = f x (foldr f v xs)  
</code></pre>

<p>보면 알겠지만, 리스트의 <em>the right-most (가장 우측)</em> 부터 연산합니다. 그래서 <em>fold right</em> 라는 이름이 붙었지요. 그림으로 보자면</p>

<p><img src='http://www.pling.org.uk/cs/funimg/foldr.png'  alt="" /></p>

<p align="center">(<a href='http://www.pling.org.uk/cs/fun.html' >http://www.pling.org.uk/cs/fun.html</a>)</p>

<pre><code class="haskell">sum [1, 2, 3]  
foldr (+) 0 [1, 2, 3]  
foldr (+) 0 (1:(2:(3:[])))  
1 + (2 + (3 + 0))  
</code></pre>

<p>콘싱 <code>:</code> 하고 비슷합니다. 이 부분에 연산자를 집어넣고, <code>[]</code> 에 초기값 <code>v</code> 를 넣는다고 생각하면 이해하기 쉽습니다.</p>

<p><code>length</code> 도 비슷한 패턴을 가지고 있기 때문에 <code>foldr</code> 로 바꿀 수 있습니다.</p>

<pre><code class="haskell">length :: [a] -&gt; Int  
length [] = 0  
length (x:xs) = 1 + length xs

length = foldr (\_ n -&gt; 1 + n) 0  
</code></pre>

<p>이렇게 바꿀 수 있는 이유는</p>

<pre><code class="haskell">length [1, 2, 3]  
length (1: (2: (3:[])))  
1 + (1 + (1 + 0)))  
</code></pre>

<p>여기서 각 <code>:</code> 을 <code>\_ n -&gt; 1 + n</code> 으로 바꾸면 되기 때문입니다.</p>

<pre><code class="haskell">reverse [] = []  
reverse (x:xs) reverse xs ++ [x]  
</code></pre>

<p>이제 위 <code>reverse</code> 함수도 <code>foldr</code> 을 이용할 수 있습니다.</p>

<pre><code class="haskell">reverse = foldr (\x xs -&gt; xs ++ [x]) []  
</code></pre>

<p>처음의 <code>filter</code>, <code>map</code> 도 이렇게 정의할 수 있습니다.</p>

<pre><code class="haskell">foldr :: (a -&gt; b -&gt; b) -&gt; b -&gt; [a] -&gt; b  
foldr f v [] = v  
foldr f v (x:xs) = f x (foldr f v xs)

filter :: (a -&gt; Bool) -&gt; [a] -&gt; [a]  
filter p xs = foldr (\x acc -&gt; if p x then x : acc else acc) [] xs

map :: (a -&gt; b) -&gt; [a] -&gt; [b]  
map p xs = foldr (\x acc -&gt; p x : acc) [] xs  
</code></pre>

<p><code>foldr</code> 을 이용하면 몇 가지 장점이 있습니다.</p>

<blockquote>
  <ol>
  <li><p>Some recursive functions on lists, such as sum, are <strong>simpler</strong> to define using foldr.</p></li>
  <li><p>Properties of functions defined using foldr can ben proved using algebraic properties of foldr, such as <strong>fusion</strong> and the <strong>banana split</strong> rule.</p></li>
  <li><p>Advanced program <strong>optimizations</strong> can be simpler if foldr is used in place of explicit recursion.</p></li>
  </ol>
</blockquote>

<p>여기서 <em>fusion</em> 은, 하나의 <code>foldr</code> 은 리스트를 순회하면서 새로운 리스트를 리턴하고, 다른 <code>foldr</code> 을 그 결과에 사용할 때 <em>intermediate list</em> 를 생성하는 것 없이 계산을 해 낸다는 뜻입니다.</p>

<blockquote>
  <p>In particular <strong>fusion</strong> means that I have two functions. One that uses <code>foldr</code> to traverse one list and return another list. And if I do another <code>foldr</code> on the result of that I can fuse these two together, such that the <strong>intermediate list is never constructed</strong>. So program can be optimized.</p>
</blockquote>

<p>다른 고차함수들을 좀 살펴봅시다.</p>

<h3 id="composition">composition</h3>

<p><code>(.)</code> 은 함수를 <em>composition (합성)</em> 해 줍니다. </p>

<pre><code class="haskell">(.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; (a -&gt; c)
f . g = \x -&gt; f(g x)  
</code></pre>

<p>예를 들어</p>

<pre><code class="haskell">odd :: Int -&gt; Bool  
odd = not . even  
</code></pre>

<p><em>compoisition</em> 을 사용할때는 괄호와 나머지 인자를 제거하여 함수의 정의를 간단히 할 수 있습니다.</p>

<pre><code class="haskell">twice f x = f (f x)

-- same as
twice f = f f  
</code></pre>

<h3 id="allany">all, any</h3>

<p>모든 원소에 대해 <code>p</code> 를 적용한 결과가 참인지를 돌려주는 <code>all</code> 은 다음처럼 정의할 수 있습니다.</p>

<pre><code class="haskell">all :: (a -&gt; Bool) -&gt; [a] -&gt; Bool  
all p xs = and [p x | x &lt;- xs]  
</code></pre>

<p>이번엔 <em>list comprehension</em> 을 사용했습니다. <code>foldr</code> 과의 차이는, <code>foldr</code> 은 모든 순회 가능한 데이터 타입에 적용 가능한 반면 <em>list comprehension</em> 은 리스트에만 사용할 수 있습니다. 위 예제를 <code>foldr</code> 로 바꾸면</p>

<pre><code class="haskell">all :: (a -&gt; Bool) -&gt; [a] -&gt; Bool  
all p xs = foldr (\x acc -&gt; p x &amp;&amp; acc) True xs  
</code></pre>

<p><code>any</code> 도 만들 수 있습니다.</p>

<pre><code class="haskell">import Data.Char

any :: (a -&gt; Bool) -&gt; [a] -&gt; Bool  
any p xs = or [p x | x &lt;- xs]

-- same as
any p xs = or (map p xs)  
</code></pre>

<h3 id="takewhiledropwhile">takeWhile, dropWhile</h3>

<p><code>takeWhile</code> 은 <em>predicate</em> 가 참인 원소까지만 돌려줍니다. 예를 들어</p>

<pre><code class="haskell">takeWhile :: (a -&gt; Bool) -&gt; [a] -&gt; [a]  
takeWhile p [] = []  
takeWhile p (x:xs) | p x = x : takeWhile p xs  
                    | otherwise = [] 

takeWhile isAlpha "abc def"  
-- "abc"
</code></pre>

<p>반면 <code>dropWhile</code> 은 <em>predicate</em> 를 적용한 결과가 참인 원소를 모두 버리고 나머지만 돌려줍니다. 예를 들어</p>

<pre><code class="haskell">dropWhile :: (a -&gt; Bool) -&gt; [a] -&gt; [a]  
dropWhile p [] = []  
dropWhile p (x:xs) | p x = dropWhile p xs  
                    | otherwise = x:xs

dropWhile isAlpha "fp 101"  
-- " 101" 
</code></pre>

<h3 id="churchnumerals">Church Numerals</h3>

<blockquote>
  <p><strong>Church Numerals</strong> give us a way to <em>abstract</em> over the concrete representation of a number by means of <strong>functions</strong> and <strong>unction application</strong>.</p>
</blockquote>

<p>숫자 <code>n</code> 은 <em>zero</em> 에 <code>n</code> 번의 <code>s</code> <em>function application</em> 을 통해 정의합니다. </p>

<pre><code class="haskell">zero = \s z -&gt; z  
one = \s z -&gt; s z  
two = \s z -&gt; s (s z)

-- same as
two = \s z -&gt; (s . s) z

-- we can remove z
two = \s -&gt; s . s  
</code></pre>

<p>여기서 데이터 <code>z</code> 자체는 아무것도 정해진 것이 없습니다. 다시 말해 어떤 타입이든 가져다 쓸 수 있다는 뜻이지요.</p>

<p>우리가 숫자 3을 표현하기 위해 <code>1</code>을 세번 더해 <code>3</code> 을 표시하든, 아니면 <code>*</code> 를 세번 컨싱하든 상관 없다는 뜻 입니다.</p>

<pre><code class="haskell">zero = \s z -&gt; z  
one = \s z -&gt; s z  
two = \s -&gt; s . s

-- church to int
c2i x = x (+1) 0

c2i zero  
-- 0

c2i one  
-- 1

c2i two  
-- 2
</code></pre>

<p><em>* (에스터리스크)</em> 의 개수로 숫자를 정의해 봅시다.</p>

<pre><code class="haskell">-- church to int
c2s x = x ('*' :) ""

c2s zero  
-- ""

c2s one  
-- "*"

c2s two  
-- "**"
</code></pre>

<p>이제 연산자를 만들어 봅시다. 덧셈부터 시작해 보죠! <code>c2i</code> 에 <code>x</code> 를 넣어 만들어낸 <em>수 (Number)</em> 를 <code>x'</code> 라 하고 <code>y</code> 를 넣어 만든 수를 <code>y'</code> 라 합시다. </p>

<pre><code class="haskell">x' = c2i x  
y' = c2i y  
</code></pre>

<p>그러면 덧셈은 이렇게 정의할 수 있습니다.</p>

<pre><code class="haskell">x' + y' = c2i (add x y)  
</code></pre>

<p>증명해 봅시다.</p>

<pre><code class="haskell">x' + y'  
= c2i x + c2i y
= x (+1) 0 + c2i y -- 0 is substituted
= x (+1) (c2i y)
= x (+1) (y (+1) 0)
= (\s z -&gt; x s (y s z)) (+1) 0 -- by beta expension
</code></pre>

<p>보면 알겠지만 <code>c2i y</code> 나 <code>0 + c2i y</code> 나 같습니다. 따라서 <code>0</code>을 지우고 <code>x c2i</code> 의 베이스 값으로 <code>(c2i y)</code> 를 사용할 수 있죠.</p>

<p>그리고 마지막 치환은 <code>s</code> 와 <code>z</code> 를 <code>(+1)</code> 과 <code>0</code> 으로 취하는 <em>lambda</em> 를 구할 수 있습니다. <code>\s z -&gt; x s (y s z)</code> 를 <code>add</code> 라 부르면</p>

<pre><code class="haskell">x' + y' = (add x y) (+1) 0  
= c2i (add x y)
</code></pre>

<p>결국 <em>addtion</em> 은</p>

<pre><code class="haskell">add x y = \s z -&gt; x s (y s z)

c2i (add one two)  
-- 3
</code></pre>

<p><em>multiplication (곱셈)</em>은 어떻게 만들까요? 간단한 예제부터 시작해 <em>intuition</em> 을 얻어보도록 합시다.</p>

<pre><code class="haskell">two = \s -&gt; s . s  
three = \s -&gt; s . s . s  
</code></pre>

<p>결국 <code>n</code> 번째 수란건 <code>s</code> <em>successor function</em> 을 <code>n</code> 번 만큼 수행한거지요. 그럼 <code>a * b</code> 의 곱셈은 <code>b</code> 번 적용한 <em>successor</em> 를 <code>a</code> 번 적용하면 되므로</p>

<pre><code class="haskell">mul = \s z -&gt; x (y s) z

c2i (mul two five)  
-- 10
</code></pre>

<h3 id="examples">Examples</h3>

<pre><code class="haskell">id :: a -&gt; a  
id = \x -&gt; x

compose :: [a -&gt; a] -&gt; (a -&gt; a)  
compose = foldr (.) id  
</code></pre>

<p><code>id</code> 함수는 받은걸 그대로 돌려주기 때문에 <code>id . f</code>, <code>f . id</code> 는 <code>f</code> 입니다. 따라서 함수 리스트를 위한 <code>foldr</code> 의 초기값으로 <code>id</code> 를 사용할 수 있습니다.</p>

<h3 id="stringtransmitter">String Transmitter</h3>

<p>간단한 문자열 전송을 모델링한 코드를 작성해 봅시다.</p>

<pre><code class="haskell">import Data.Char

type Bit = Int

bin2int :: [Bit] -&gt; Int  
bin2int bits = sum [w * b | (w, b) &lt;- zip weights bits]  
  where weights = iterate (*2) 1

-- or
-- bin2int bitis = foldr (\x acc -&gt; x + acc * 2) 0

int2bin :: Int -&gt; [Bit]  
int2bin 0 = []  
int2bin n = n `mod` 2 : int2bin(n `div` 2)

make8 :: [Bit] -&gt; [Bit]  
make8 bits = take 8 (bits ++ repeat 0)

encode :: String -&gt; [Bit]  
encode = concat . map (make8 . int2bin . ord)

chop8 :: [Bit] -&gt; [[Bit]]  
chop8 [] = []  
chop8 bits = take 8 bits : chop8 (drop 8 bits)

decode :: [Bit] -&gt; String  
decode = map (chr . bin2int) . chop8

channel :: [Bit] -&gt; [Bit]  
channel = id

transmit :: String -&gt; String  
transmit = decode . channel . encode  
</code></pre>

<p>재밌는 부분은 마지막 <code>channel</code> 부분인데요, <code>id</code> 함수를 써서 인코딩된 문자열이 바로 디코딩을 위해 전송된다는 것을 표현했습니다.</p>

<p>위 코드 중에서 <code>int2bin</code> 과 <code>chop8</code> 은 헤드에 특정 연산을 수행하고, <code>tail</code> 에 나머지 연산을 수행 한 결과를 다시 재귀적으로 호출하는 패턴을 가지고 있는데요, <code>unfold</code> 함수로 추상화 할 수 있습니다. </p>

<p>쉽게 말해서 <code>fold</code> 가 리스트를 <em>접어 (folding)</em> 원소 하나로 만든다면, <code>unfold</code> 는 리스트를 더 한단계 펼친다고 볼 수 있습니다.</p>

<pre><code class="haskell">unfold p h t x  
  | p x = []
  | otherwise = h x : unfold p h t (t x)
</code></pre>

<p>그리하면 구현을</p>

<pre><code class="haskell">type Bit = Int  
int2bin :: Int -&gt; [Bit]  
int2bin = unfold (== 0) (`mod` 2) (`div` 2)

chop8 :: [Bit] -&gt; [[Bit]]  
chop8 = unfold null (take 8) (drop 8)  
</code></pre>

<p><code>map</code> 과 <code>iterate</code> 도 구현할 수 있습니다.</p>

<pre><code class="haskell">map2 f = unfold null (f . head) tail

iterate' f = unfold (const False) id f -- const False is pred. always return False  
</code></pre>

<p>여기서 <code>const False</code> 는 항상 <code>False</code> 만 돌려주는 <em>predicate</em> 라 보시면 됩니다.</p>

<h3 id="references">References</h3>

<p>(1) <strong>DelftX FP 101x</strong> in <em>edx</em> <br />
(2) <a href='https://sadakurapati.wordpress.com/' >https://sadakurapati.wordpress.com</a> <br />
(3) <em>Programming in Haskell, Chapter 6, 7</em> <br />
(4) <a href='http://www.pling.org.uk/cs/fun.html' >http://www.pling.org.uk/cs/fun.html</a>  </p>]]></description><link>http://1ambda.github.io/haskell-intro3/</link><guid isPermaLink="false">6ae03a58-8478-4f0d-a716-75f09c81a985</guid><category><![CDATA[edx]]></category><category><![CDATA[haskell]]></category><category><![CDATA[recursion]]></category><category><![CDATA[church numerals]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 12 Nov 2014 02:10:13 GMT</pubDate></item><item><title><![CDATA[Foundations of Data Analysis, Week1]]></title><description><![CDATA[<p><em>edx</em> 수업. R 을 이용해 실제 데이터에 학습한 통계 이론들을 적용하는 수업이다. <em>edx</em> 에서 제공하는 <em>discussion board</em> 대신에 <em>piazza board?</em> 이런것도 쓰고, <em>lab</em> 전에 비슷한 질문을 하는 <em>pre-lab</em> 도 있고.. 구성이 친절하다. 여러모로 신경을 많이 쓴듯 </p>

<h3 id="classifyingvariables">Classifying Variables</h3>

<p><em>population (모집단)</em> 의 각각을 <em>unit</em>, <em>subject</em> 라 부른다. <em>Galapagos Tortoises</em> 
예제에서 <em>unit</em> 은 각각의 거북이들이다.</p>

<p>연구자들이 갈라파고스 거북이들로부터 몇 가지 특징들을 뽑아내 도표로 만들었는데, 이런 특징들을 <em>varaible</em> 이라 부른다.</p>

<p><em>variable</em> 은 종류에 따라서 <em>categorical</em>, <em>numerical</em> 로 구분한다. 다른말로는 <em>qualitative (= categorical)</em>, <em>quantitative (= numerical)</em> 이라 부르기도 한다.</p>

<p>날씨나 등 껍질 종류 같은 경우는 <em>qualitative variable</em> 이고 <em>number of individuals repatriated</em> 는 <em>quantitative variable</em> 이다. 저 속성이 뭔 소린가 했는데, 갈라파고스 거북이들은 섬의 중앙에서 보호를 받고 자라다가 나중에 야생으로 돌아간다고.. 그 숫자를 의미하는것이 <em>number of indiviaudls repatriated</em> 다.</p>

<p><em>complete counting</em> 혹은 <em>census (인구조사)</em> 같은 경우는 대부분의 경우 힘들기 때문에 <em>population</em> 에서 일부를 떼어낸 <em>sample</em> 을 이용하게 된다.</p>

<blockquote>
  <p>It is common to use a smaller, representative group from the population, called a <em>sample</em></p>
</blockquote>

<h3 id="errors">Errors</h3>

<p><em>sample</em> 이 <em>population</em> 을 대표하지 못할 수도 있기 때문에, 완벽히 <em>parameter (모수)</em> 를 추정하는 것은 어렵다. 그래서 통계학자들은 <em>point estimate</em> 나 <em>interval estimiate</em> 를 사용한다. 예를 들면</p>

<blockquote>
  <p><em>"I am 95% confident that the true number of tortoises is actually between 561 and 1075."</em></p>
</blockquote>

<p><em>true paramter</em> 와 샘플로부터 얻어진 <em>statistic</em> 간 차이는 <em>sampling error</em> 라 부른다.</p>

<p>갈라파고스 거북이를 조사 할 때 밀집 지역에서만 거북이를 골라낸다고 하자. 그리고 그 샘플을 전체 지역에 대한 통계값을 얻을 때 사용하면 너무 높은 값이 나올 수 있다. 이런 종류의 오류를 <em>bias</em> 라 부른다. 다행히도 통계학자들이 <em>bias</em> 를 피할 수 있는 다양한 도구들을 준비 해 놓았으니 배우기만 하면 된다.</p>

<h3 id="levelsofmeasurement">Levels of Measurement</h3>

<p>아까는 <em>variable</em> 을 간단히 두 종류로 나누어 봤지만 더 자세하게 나눌 수 있다. </p>

<blockquote>
  <p>A <strong>nominal measurement</strong> is one in which the values of the variable are names. The names of the different species of Galapagos tortoises are an example of a nominal measurement</p>
  
  <p>An <strong>ordinal measurement</strong> involves collecting information of which the order is somehow significant. The name of this level is derived from the use of ordinal numbers for ranking. If we measured the different species of tortoise from the largest population to the smallest, this would be an example of ordinal measurement.</p>
  
  <p>With <strong>interval measurement</strong>, the distance between any two values has a specific meaning. An example commonly cited for interval measurement is temperature. A change of 1 degree is the same if the temperature goes from <code>0C</code> to <code>1C</code> as it is when the temperature goes from <code>40C</code> to <code>41C</code>. In addition, there is meaning to the values between the ordinal numbers. That is, a half of a degree has meaning.</p>
  
  <p>A <strong>Ratio measurement</strong> is the estimation of the ratio between a magnitude of a continuous quantity and a unit magnitude of the same kind. A variable measured at this level not only includes the concepts of order and interval, but also adds the idea of <code>nothingness</code>, or absolute zero. With the temperature scale of the previous example, <code>0C</code> is really an arbitrarily chosen number and does not represent the absence of tempertature. As a result, the ratio between temperature is relative, and <code>40C</code>, for example, is not twice as hot as <code>20C</code>.</p>
</blockquote>

<p>간단히 정리하자면 <em>nominal measurement</em> 는 이름으로 분류를 할 수 있는 경우다. </p>

<p><em>ordinal measurement</em> 는 각 <em>unit</em> 간 순위, 순서를 매긴 것이다. 이 경우 값 자체가 1, 2, 3 같은 순서기 때문에 <em>unit</em> 간 차이는 아무런 의미도 없다.</p>

<p><em>interval measurement</em> 는 두 값간 <em>distance (차이)</em> 가 의미를 가지는 경우다. 온도를 잘 보면 40도와 39도의 차이 1은, 1도와 0도의 차이 와 같다. 그리고 <em>interval measurement</em> 에서는 각 <em>unit</em> 사이의 값들도 의미가 있다. (ex. 0.5도)</p>

<p>마지막으로 <em>ratio measurement</em> 는 <em>nothingness</em> 혹은 <em>absolute zero</em> 가 존재하는 값이다. 켈빈 온도의 경우 20K 는 40K 의 1/2 이다. 반면 섭씨 온도의 경우 20C 가 40C 보다 1/2 덥다고 말할 수가 없다. </p>

<p>이렇게 <em>nominal, ordinal, interval, ratio</em> 로 구분하는 방법을 <em>Stevens' Theory</em> 라 부른다. 단순히 <em>numerical, categorical</em> 로 구분하는 것 보다 좀 더 자세히 분류할 수 있다.</p>

<p>몇 가지 예제를 좀 더 살펴보자면</p>

<p>(1) 학생들의 <em>gender, race, political opinions</em> 등은 모두 <em>nominal measurement</em> 다. <br />
(2) 학생들의 학년(7, 8, 9) 를 수집한다면 <em>ordinal measurement</em> 다. <br />
(3) SAT 수학 점수를 모은다면, 그건 <em>interval measurement</em> 다. (아마 상대평가인가 봄) <br />
(4) 나이, 키, 몸무게, 점수(0-100) 등을 수집한다면 <em>ratio measurement</em> 다.</p>

<p><em>nominal</em> 에서 <em>ratio</em> 로 갈수록 값들이 점점 복잡해진다. </p>

<p><img src='https://dr282zn36sxxg.cloudfront.net/datastreams/f-d%3A92ba1471fd7e4ab92e330423cc7653fc15f9e1808cbbd03f8cdad61a%2BIMAGE%2BIMAGE.1'  alt="" /></p>

<p align="center">(<a href='http://www.ck12.org/statistics' >http://www.ck12.org/statistics</a></p>

<p>이렇게 데이터를 구분하는 이유는, 각각 에 쓸 수 있는 <em>Tool</em> 이 다르기 때문이다. 어떤 툴은 <em>categorical variable</em> 에 유용할 수도 있고, 그렇지 않은 툴도 있기 마련이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>UT.7.01x Foundations of Data Analysis</em> <br />
(2) <a href='http://www.ck12.org/statistics/Levels-of-Measurement/lesson/Levels-of-Measurement/' >http://www.ck12.org/statistics</a></p>]]></description><link>http://1ambda.github.io/foundations-of-data-analysis-week1/</link><guid isPermaLink="false">7a56ea31-f2e1-4117-a5db-5140868a8668</guid><category><![CDATA[edx]]></category><category><![CDATA[statistics]]></category><category><![CDATA[R]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Wed, 12 Nov 2014 01:51:36 GMT</pubDate></item><item><title><![CDATA[Graphs, The Contraction Algorithm]]></title><description><![CDATA[<p>이번엔 지난시간에 배운 <em>randomized algorithm</em> 을 새로운 <em>domain</em> 인 그래프에 적용해 보고, <em>contraction algorithm</em> 이 무엇인지 알아본다.</p>

<h3 id="graphs">Graphs</h3>

<p>용어 정리부터 시작하자. <em>edge</em> <code>(E)</code> 는 <em>pair of vertices</em> 와 같은 말이다. <code>(E)</code> 는 <em>directed or undirected</em> 일 수 있으므로 <em>unordered pair</em> 또는 <em>ordered pair</em> 일 수 있다. <em>directed edges</em> 는 다른말로 <em>arcs</em> 라 부르기도 한다.</p>

<p><em>cut</em> 은 그래프를 비어있지 않은 두개의 그룹으로 분리하는 것을 말한다.</p>

<blockquote>
  <p>A cut of a graph <code>(V, E)</code> is a partition of <code>V</code> into two non-empty sets <code>A</code> and <code>B</code></p>
</blockquote>

<p>따라서 <em>vertice</em> 가 <code>n</code> 개라면 <code>2^n - 2</code> 개의 <em>cut</em> 을 만들 수 있다.</p>

<h3 id="minimumcutproblem">Minimum Cut Problem</h3>

<p><em>crossing edge</em> 를 최소로 하는 <em>cut</em> 을 찾는 문제다. 이걸 어디다 쓸 수 있을까?</p>

<p>(1) identify network bottlenecks / weaknesses <br />
(2) community detection in social network  </p>

<p>두 사람 혹은 집단간 강하게 결합되고 나머지와는 약하게 결합된 부분(<em>mimimum cut</em>) 을 찾으면 두 개체간 관련성이 있다고 볼 수 있다.    </p>

<p>(3) image segmentation  </p>

<p>이미지를 <em>2D grid</em> 라 <em>grid edge</em> 를 만들어 <em>same object</em> 에서 왔을 가능성을 나타내는 가중치를 부여해 <em>min cut</em> 을 하면 쓸모 없는 부분이 잘려나간다.</p>

<h3 id="graphrepresentation">Graph representation</h3>

<p>그래프가 <em>sparse graphs</em>, <em>dense graphs</em> 냐에 따라 알고리즘이 성능이 잘 나올수도 있고 아닐수도 있기 때문에 이 두 가지를 구분해 보자.</p>

<p><code>n</code> 을 <em>the number of vetices</em>, <code>m</code> 을 <em>the number of edges</em> 라 하자. 대부분의 경우에 <code>m</code> 은 <code>Omega(n)</code>, <code>O(n^2)</code> 이다.</p>

<p><em>sparse graph</em> 는 <code>m</code> 이 <code>O(n)</code> 에 가깝고 <em>dense graphs</em> 는 <code>m</code> 이 <code>O(n^2)</code> 에 가깝다.</p>

<h3 id="adjacencymatrix">Adjacency Matrix</h3>

<p>그래프를 자료구조로 표현하는 몇 가지 방법이 있는데 <em>Adjacency matrix (인접행렬)</em> 의 경우에는 노드 수, <code>n</code> 에 대해 <code>n x n</code> 의 행렬 <code>A</code> 를 만들어서 <code>A_ij</code> 를 <code>i</code> 노드와 <code>j</code> 노드가 연결되었다면 값을 <code>1</code> 채운다</p>

<p>몇 가지 변형이 있을 수 있는데 <em>parallel edges</em> 가 허용된다면 <code>A_ij</code> 는 연결된 엣지 수 일 수 있고, <code>A_ij</code> 에 가중치를 담는 경우도 있다. <em>directed graph</em> 면 <code>i -&gt; j</code> 냐 <code>j -&gt; i</code> 냐에 따라 <code>-1 or +1</code> 을 값으로 사용할 수 있다.</p>

<p>어떤 경우든 <em>adjacency matrix</em> 방식 자체는 <em>edge</em> 수와는 관계 없이 <em>vertice</em> 수의 제곱에 비례하는 공간이 필요하다. 따라서 <em>sparse graphs</em> 에서는 사용하지 않는 편이 낫다.</p>

<h3 id="adjacencylist">Adjacency List</h3>

<p><em>Adjacency list (인접 리스트)</em> 로 그래프를 표현할 경우엔 </p>

<p>(1) array (or list) of vertices (<code>theta(n)</code>) <br />
(2) array (or list) of edges (<code>theta(m)</code>) <br />
(3) each edge points to its endpoint (<code>theta(m)</code>) <br />
(4) each vertex points edges (<code>theta(m)</code>)</p>

<p>(4) 의 경우 <em>undirected graph</em> 라면 명확한데, <em>directed graph</em> 의 경우에는 <em>tail</em> 만 저장 한다던지 몇가지 방법을 쓸 수 있다. </p>

<p>그럼 <em>adjacency list</em> 는 얼마의 공간을 차지할까? (3) 의 경우는 위에 표시했듯이 (<code>theta(m)</code>) 인데, 각각의 <em>edge</em> 는 2 개의 <em>vertex</em> 를 저장하지만 <code>2</code> 는 상수 취급한다.</p>

<p>(4) 가 노드마다 간선 수가 달라 계산이 어려울 수 있는데, (3) 과 1:1 대응이라 보면 된다. 노드가 가리키는 간선이나, 간선이 가리키는 노드나 수는 같다. 따라서 (<code>theta(m)</code>) 이므로 전체 메모리 사용은 (<code>theta(m + n)</code>) 이다. </p>

<p>그러면 인접 행렬과 인접 행렬중 어떤게 더 나을까? 둘 다 장단이 있지만 <em>graph search</em> 는 단연 인접 행렬이 더 낫고, 요즘엔 <em>node</em> 는 정말 많은 반면 <em>edge</em> 는 좀 적기 때문에 인접 리스트가 더 낫다.</p>

<p>간단히 웹만 생각해봐도 노드 자체는 엄청나게 많은 반면 간선은 적다. 만약 인접 행렬로 그래프를 표현하면 노드 수의 제곱에 비례하는 메모리가 필요한데, 이건 리소스 문제를 겪을 수 있다.</p>

<h3 id="randomcontractionalgorithm">Random Contraction Algorithm</h3>

<p><em>min cut</em> 을 해결하기 위해 <em>quick sort</em>, <em>randomized selection</em> 에서 보았던 랜덤 샘플링을 이용할건데, 이 문제는 랜덤 샘플링이 그래프 문제에도 얼마나 효과적인지 보여준다. 알고리즘은 이렇다.</p>

<p>(1) while there are more than 2 vertices <br />
(2) pick a remaining edge <code>(u, v)</code> uniformly at random <br />
(3) merge (or "contract") <code>u</code> and <code>v</code> into a single vertex <br />
(4) remove self-loops <br />
(5) return cut represented by final 2 vertices  </p>

<p>해보면 알겠지만 이 알고리즘은 <em>min cut</em> 을 답으로 제공할 수도, 아닐 수도 있다. 따라서 문제는, <em>What is prob of success?</em> 를 계산하는 것으로 바뀐다.</p>

<h3 id="analysiscontractionalgorithm">Analysis: Contraction Algorithm</h3>

<p>분석 전에 몇 가지 용어를 정의하고 가자. <em>graph</em> <code>G = (V, E)</code> 에 대해 <code>n</code> 개의 <em>vertices</em>, <code>m</code> 개의 <em>edges</em> 가 있다. 그리고 <em>minimum cut</em> <code>(A, B)</code> 는 <code>G</code> 를 두개의 비어있지 않은 그룹 <code>A</code>, <code>B</code> 로 나눈다. 그리고 <code>k</code> 를 <code>(A, B)</code> 의 <em>crossing edges</em> 숫자라 하자. 그리고 이들 <em>crossing edges</em> 를 <code>F</code> 라 부르자.</p>

<p>만약에 <code>F</code> 중 하나의 <em>edge</em> 가 <em>contraction</em> 알고리즘 중에 선택 된다면 <code>(A, B)</code> 는 섞여버린다. </p>

<p>따라서 이터레이션 동안 <code>A</code> 내부에 있는 <em>vertex</em> 끼리만, 그리고 <code>B</code> 내부에 있는 <em>vertex</em> 끼리만 <em>contraction</em> 이 일어나야 한다. 그래야만 <em>minimum cut</em> 을 찾을 수 있다.</p>

<p>따라서 올바른 <code>(A, B)</code> 를 아웃풋으로 얻을 확률은 <code>F</code> 중 어느 <em>edge</em>도 선택되지 않을 확률과 같다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5Boutput%20%5C%20is%20%5C%20%28A%2C%20B%29%5D%20%3D%20P_r%5Bnever%5C%20contracts%5C%20an%5C%20edge%5C%20of%20F%5D'  alt="" /></p>

<p><del>Tex 에 맛들려서 이미지를 추가한건 아니요!</del></p>

<p><code>S_i</code> 를 <code>F</code> 에 있는 <em>edge</em> 가 이터레이션 <code>i</code> 에서 <em>contracted</em> 되는 <em>event (사건)</em> 이라 하자. 그럼 우리의 목표는 다음의 확률을 계산하는 것이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_1%20%5Ccap%20%5Cneg%20S_2%20%5Ccap%20%5Ccdots%20%5Ccap%20%5Cneg%20S_%7Bn-2%7D%5D'  alt="" /></p>

<p>증명에 사용할 재미난 그래프의 특징이 하나 있다. 모든 <em>vertex</em> 의 <em>incident edges, degree</em> 의 값은 <code>k</code> 보다 크거나 같다. 왜냐하면 모든 <em>vertex</em> 는 그 자신과 나머지를 분리하는 <em>cut</em> 을 가지는데, 이게 <code>k</code> 라면 <em>min cut</em> 이고 아니라면 <code>k</code> 보다 크기 때문이다.    </p>

<blockquote>
  <p>degree of each vertex is at least <code>k</code></p>
</blockquote>

<p>그리고 모든 <em>vertex</em> 의 <em>degree</em> 는 <code>2m</code>, 즉 모든 <em>edge</em> 수의 2배이기 때문에 아래 식은 참이고, </p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Csum_%7Bv%7Ddegree%28v%29%20%3D%202m'  alt="" /></p>

<p>위 식과 각 <em>degree</em> 합은 <code>kn</code> 보다 크거나 같으므로 <code>2m</code> 도 <code>kn</code> 보다 크거나 같다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?2m%20%5Cgeq%20kn'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?m%20%5Cgeq%20%28kn/2%29'  alt="" /></p>

<p>여기서 처음 이터레이션에서 <code>F</code> 내에 있는 <em>edge</em> 가 선택될 확률인 <code>P(S_1) = k / m</code> 이기 때문에 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B2%20%5Cover%20n%7D%20%5Cgeq%20%7Bk%20%5Cover%20m%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5BS_1%5D%20%5Cleq%20%7B2%20%5Cover%20n%7D'  alt="" /></p>

<p>이제 <code>P(S_1)</code> 을 구했으니, 두번째 이터레이션에서 <code>F</code> 내에 있는 <em>edge</em> 가 선택되지 않을 확률을 구해보자. 조건부 확률 공식을 이용하면, </p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_1%20%5Ccap%20%5Cneg%20S_2%5D%20%3D%20P_r%5B%5Cneg%20S_2%20%7C%20%5Cneg%20S_1%5D%20' *%20P_r%5B%5Cneg%20S_1%5D" alt="" /></p>

<p>이때 <code>P(~S_1)</code> 이 <code>n/2</code> 보다 작거나 같으므로</p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_1%5D%20%5Cgeq%20%281%20-%20%7B2%20%5Cover%20n%7D%29'  alt="" /></p>

<p>나머지 <code>P(~S_2 | ~S_1)</code> 을 구하려다 보니 남아있는 <em>edge</em> 가 얼만지 알 수가 없다. </p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_2%20%7C%20%5Cneg%20S_1%5D%20%3D%201%20-%7Bk%20%5Cover%20number%20%5C%20of%5C%20remaining%20%5C%20edges%7D'  alt="" /></p>

<p>그런데, 본래의 그래프가 모든 <em>vertex</em> 에 대해 <em>at least</em> <code>k</code> 개의 <em>edge</em> 를 가졌으면 <em>contracted</em> 된 그래프도 모든 <em>vertex</em> 에 대해 <em>at least</em> <code>k</code> 개의 <em>edge</em> 를 가져야 한다. (우리는 <code>F</code> 내의 <em>edge</em> 를 선택하지 않았기 때문)</p>

<p>따라서 <em>remaining edge</em> 는 <code>1/2 * k * (n-1)</code> 보다 크다. (1/2 은 <code>n</code> 으로 <em>edge</em> 수를 세면 두번씩 카운팅하기 때문에 필요)</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7Bnumber%20%5C%20of%5C%20remaining%20%5C%20edges%7D%20%5Cgeq%201/2%20' *%20k%20*%20%28n-1%29" alt="" /></p>

<p><em>denominator</em> 의 <em>lower bound</em> 를 구했기 때문에 <em>fraction</em> 의 <em>upper bound</em> 를 구한셈이 된다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_2%20%7C%20%5Cneg%20S_1%5D%20%5Cgeq%201%20-%7B2%20%5Cover%20n%20-%201%7D'  alt="" /></p>

<p>이제 규칙성이 보인다. 우리가 구하려는 값은 </p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20S_1%20%5Ccap%20%5Cneg%20S_2%20%5Ccap%20%5Ccdots%20%5Ccap%20%5Cneg%20S_%7Bn-2%7D%5D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%3D%20P_r%5B%5Cneg%20S_1%5D%20' *%20P_r%5B%5Cneg%20S_2%20%7C%20S_1%5D%20*%20P_r%5B%5Cneg%20S_3%20%7C%20%5Cneg%20S_2%20%5Ccap%20%5Cneg%20S_1%5D%20*%20%5Ccdots%20*%20P_r%5B%5Cneg%20S_%7Bn-2%7D%20%7C%20%5Cneg%20S_1%20%5Ccap%20%5Ccdots%20%5Ccap%20%5Cneg%20S_%7Bn-3%7D%5D" alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cgeq%20%281%20-%20%7B2%20%5Cover%20n%7D%29' *%281%20-%20%7B2%20%5Cover%20%28n%20-%201%29%7D%29*%281%20-%20%7B2%20%5Cover%20%28n%20-%202%29%7D%29*%5Ccdots*%20%281%20-%20%7B2%20%5Cover%20%28n%20-%20%28n-4%29%29%7D%29%20*%20%281%20-%20%7B2%20%5Cover%20%28n%20-%20%28n-3%29%29%7D%29" alt="" /></p>

<p>정리하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%3D%20%7B2%20%5Cover%20n%20%5C%20%28n-1%29%7D%20%5Cgeq%20%7B1%20%5Cover%20n%5E2%7D'  alt="" /></p>

<p>따라서 <em>contraction</em> 알고리즘이 성공할 확률은 <code>n</code> 이 크면 굉장히 낮다. 근데 이게 <em>brute-force</em> 에 비하면 놀랍게도 굉장히 높은 성공률이다. </p>

<p>본래 <code>n</code> 개의 <em>vertex</em> 가 있으면 모든 <em>cut</em> 을 다 해 보려면 <code>2^n</code> 의 시도가 필요하다. 따라서 <em>contraction</em> 알고리즘은 꽤 높은 확률을 보장하는 알고리즘이다. </p>

<p><code>T_i</code> 를 <code>i</code> 번째 <em>trial</em> 에서 <em>min cut</em> 을 찾아낼 확률이라 하자. <code>N</code> 번의 <em>trial</em> 동안 <em>min cut</em> 을 찾지 못할 확률은, 매 <em>trial</em> 이 독립적이기 때문에 </p>

<p><img src='http://latex.codecogs.com/gif.latex?P_r%5B%5Cneg%20T_1%20%5Ccap%20%5Cneg%20T_2%20%5Ccap%20%5Ccdots%20%5Ccap%20%5Cneg%20T_N%20%5Ccap%20%5D%20%3D%20%5Cprod_%7Bi%20%3D%201%7D%5EN%20P_r%5B%5Cneg%20T_i%5D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%5Cprod_%7Bi%20%3D%201%7D%5EN%20P_r%5B%5Cneg%20T_i%5D%20%5Cleq%20%281%20-%20%7B1%20%5Cover%20n%5E2%20%7D%29%5EN'  alt="" /></p>

<p>이 때 <code>1 + x &lt;= e^x</code> 란 사실을 이용하면 좀 더 간단한 <em>upper bound</em> 를 찾으 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?%281%20-%20%7B1%20%5Cover%20n%5E2%20%7D%29%5EN%20%5Cleq%20%28e%5E%7B-1%20%5Cover%20n%5E2%7D%29%5EN'  alt="" /></p>

<p>이때 <code>N = n^2</code> 이라면 <code>N</code> 번째까지 실패할 확률은 <code>1/e</code> 보다 작거나 같다. 만약에 <code>N = n^2 lnn</code> 이면 <code>1/n</code> 까지 내려간다.</p>

<p>따라서 단순히 계산을 반복하는 것만으로도 성공 확률을 <code>1/n^2</code> 에서 <code>1 - 1/n</code> 까지 올릴 수 있다.</p>

<p><em>running time</em> 은 <code>Omega(n^2 * m)</code> 쯤 된다. <code>n^2</code> 정도의 <em>trial</em> 이 필요하고 매 <em>trial</em> 마다 <code>m</code> 의 <em>edge</em> 를 살펴봐야 한다.</p>

<p>여전히 느리다. 이후에는 단순히 <em>trial</em> 을 늘리는 것 뿐만 아니라 다양한 옵티마이제이션 기법을 활용하는법을 배워보자. 거의 <code>O(n^2)</code> 까지 줄일 수 있다.</p>

<h3 id="countingminimumcuts">Counting Minimum Cuts</h3>

<p>그래프를 그려보면 알겠지만 <em>min cut</em> 은 한개가 아니라 여러개 일 수 있다. 그러면 <code>n</code> 개의 <em>vertice</em> 를 가진 그래프에서 최대로 가질 수 있는 <em>min cut</em> 은 몇개 일까? </p>

<p>그래프에서 각 노드마다 <em>edge</em> 가 하나밖에 없을땐 <code>n-1</code> 이고, 아무리 <em>cut</em> 이 많아봐야 <code>2^n - 2</code> 보다 적으니까 이 사이에 있는건 분명하다.</p>

<p>답은 <em>n choose 2</em>, <code>(n * (n - 1)) / 2</code> 다.</p>

<p>먼저 <em>lower bound</em> 부터 보자. <em>n-cycle</em> 그래프를 보면 2개를 끊으면 되므로 <code>nC2</code> 다. </p>

<p>따라서 <code>n</code> 개의 <em>vectice</em> 를 가진 모든 그래프 중에서 가장 많은 <em>min-cut</em> 을 가진 그래프들은 적어도 이것보다는 많은 <em>min-cut</em> 을 가져야 한다.</p>

<p><em>upper bound</em> 를 보자. <code>(A1, B1), (A2, B2), ..., (At, Bt)</code> 만큼의 <em>min cut</em> 이 있다 하자. 이 때 특정 <em>min cut</em> 인 <code>(Ai, Bi)</code> 가 나올 확률은 위의 증명을 다시 보면 <code>1/n^2</code> 보다 큰 <code>2/(n(n-1))</code> 이다. 이건 <code>nC2</code> 를 뒤집은 수다.</p>

<p>다시 말해서 <em>min cut</em> 을 뽑아낼 확률이</p>

<p><img src='http://latex.codecogs.com/gif.latex?P%5Boutput%5C%20%3D%5C%20%28A_i%2C%20B_i%29%5D%20%5Cgeq%20%7B2%20%5Cover%20n%28n-1%29%7D%20%3D%20%7B1%20%5Cover%20%5Cbinom%7Bn%7D%7B2%7D%7D'  alt="" /></p>

<p>이 때 <code>S_i</code> 를 <code>(A_i, B_i)</code> 가 나오는 사건이라 하면 <code>S_i</code> 각각은 <em>disjoint</em> 다.</p>

<p>중요하니까 다시 한번 반복하면, <code>S_i</code> 는 <em>disjoin</em> 고 이로인해 모든 <code>S_i</code> 를 합하면 <code>1</code> 이다. 따라서 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%7Bt%20%5Cover%20%5Cbinom%7Bn%7D%7B2%7D%7D%20%5Cleq%201'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?%7Bt%7D%20%5Cleq%20%5Cbinom%7Bn%7D%7B2%7D'  alt="" /></p>

<p>이건 <em>upper bound</em> 다. <em>lower bound</em> 와 같으므로 모든 <code>n</code> 개의 <em>vertice</em> 를 가진 그래프는 최대 <code>nC2</code> 의 <em>min cut</em> 을 가진다.</p>

<h3 id="conditionalprob">Conditional Prob</h3>

<p>중간에 잠깐 조건 부 확률과 독립성, 그리고 기대값에 대해 나오는데 반-직관적인 예제를 교수님이 소개해 주셔서 적어볼까 한다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?X_1%2C%20X_2%20%5Cin%20%5C%7B%200%2C%201%20%5C%7D%20%5C%20and%20%5C%20X_3%20%3D%20X_1%20%5Coplus%20X_3'  alt="" /></p>

<p>일때 <code>X_1</code> 과 <code>X_3</code> 는 독립이고, <code>X_1, X_3</code> 와 <code>X_2</code> 는 독립이 아니다. 기대값을 이용하면 쉽게 증명이 가능하다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?E%5BX_1%2C%20X_2%2C%20X_3%5D%20%5Cneq%20E%5BX_1%2C%20X_2%5D%20' *%20E%5BX_3%5D" alt="" /></p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong>  </p>]]></description><link>http://1ambda.github.io/graphs-the-contraction-algorithm/</link><guid isPermaLink="false">29f4c654-dc5f-4724-b30c-760a534e17c2</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[randomization]]></category><category><![CDATA[graph]]></category><category><![CDATA[contraction]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Sat, 08 Nov 2014 05:00:35 GMT</pubDate></item><item><title><![CDATA[Randomized Selection]]></title><description><![CDATA[<h3 id="intuition">Intuition</h3>

<p>중복이 없는 <code>n</code> 개의 원소를 가진 배열에서 <code>i</code> 번째로 큰 원소를 얻고 싶다고 하자. 간단한 방법은 먼저 정렬을 한 뒤 거기서 <code>i</code> 번째 원소를 고르면 된다. 이 방법을 <em>reduction</em> 이라 부르는데 <em>selection</em> 문제를 <em>sorting</em> 문제로 바꾸어 푼 것이다. 이 경우 정렬에 머지소트를 사용한다면 <code>O(n logn)</code> 만큼의 시간이 걸릴 것이다.</p>

<p><em>selection</em> 문제는 <code>O(n)</code> 시간 안에 <em>deterministic</em> 하게 해결할 수 있다. 지난시간에 잠깐 논의했던 <em>randomization</em> 을 이용하면 된다. 어떻게 그럴 수 있을까? 저기서 정렬을 더 개선할 수 없다는건 모두가 알고 있는 사실인데</p>

<p><em>quick sort</em> 를 수정해서 <em>pivot</em> 을 <em>median of medians</em> 로 고르면 된다. <del>아니 의사양반 이게 무슨 개소리요!</del></p>

<p>더 정확히 말해서 이 문제는 <strong>정렬 문제가 아니기 때문에</strong> 더 개선할 여지가 있다. <em>pivot</em> <code>P</code> 를 기준으로 좌측이나 우측 한쪽만 선택하면 되는 <em>selection</em> 문제다.</p>

<p><em>worst case</em> 는 당연히 매 재귀호출마다 문제 수가 1씩 줄어드는 경우이므로 <code>O(n^2)</code> 일테다. 만약에, <em>bast case</em> 로 문제가 절반씩 줄어든다면? <em>master method</em> 를 이용하면 <code>a = 1, b = 2, d = 1</code> 에서 <code>T(n) = O(n^1)</code> 이다.</p>

<p><img src='https://acrocontext.files.wordpress.com/2014/01/master-method.png?w=300&amp;h=160'  alt="" /></p>

<p>그럼 이제 문제는 어떻게 사이즈를 <code>1/2</code> 로, 더 정확히는 <em>median</em> 을 <em>pivot</em> 으로 삼느냐다.</p>

<h3 id="analysis">Analysis</h3>

<p><em>randomized selection</em> 문제를 풀기 위해 구현한 함수를 <code>rSelect</code> 라 하자. 매 재귀마다 문제 사이즈가 <code>n</code> 이라고 하면, 각 재귀에서의 <code>rSelect</code> 의 연산은 <code>c * n</code> 보다 작거나 같다. (<code>c</code> 는 상수)</p>

<p>이제 본격적인 분석전에  잠깐 <em>notation</em> 을 하나 만들고 가면 <code>phase j</code> 는 문제의 사이즈가 <code>(3/4)^j+1 * n</code> 과 <code>(3/4)^j * n</code> 사이에 있는 <code>rSelect</code> 다. 따라서 문제의 사이즈가 <code>n</code> 부터 <code>3/4</code> 가 되기 전까지의 모든 <code>rSelect</code> 는 <code>phase 0</code> 에 있다.</p>

<p>그리고 <code>Xj</code> 를 <code>phase j</code> 에 있는 <code>rSelect</code> 호출의 수라 정의하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20%5Csum_%7Bphase%20j%7D%20X_j%20' *%20c%20*%20%28%7B3%20%5Cover%204%7D%29%5Ej%20*%20n" alt="" /></p>

<p>이렇게 정의해 놓으면 재밌는 조건을 하나 쓸 수 있다. 바로 <em>pivot</em> 이 <code>25%-75%</code> 사이로 분할만 해주면, 다시 말해서 반으로 갈린 문제 중 작은 한쪽이 적어도 <code>25%</code> 가 넘으면 현재 <em>phase</em> 가 끝난다. 그럼 이제 전체 알고리즘의 기대값을 구하기 위해 <em>linearity of expectation</em> 을 이용해서 <code>E(Xj)</code> 를 구하면 된다. </p>

<p><code>25-75%</code> 로 피벗이 걸릴 확률 <code>P(25-75%) = 1/2</code> 이고 그럴때의 <code>Xj = 1</code> 이다. 반면 두번째에 피벗이 제대로 걸릴 확률은 <code>1/4</code> 이고, 세번째에 피벗이 제대로 걸릴 확률은 <code>1/2^3</code> 이다.</p>

<p>기대값은 이 모든 각각 확률변수값과 그 확률의 곱이므로 계산하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?%7B1%20%5Cover%202%7D%20&plus;%20%7B1%20%5Cover%202%5E2%7D%20&plus;%20%7B1%20%5Cover%202%5E3%7D%20&plus;%20%5Ccdots%20%5Cleq%202'  alt="" /></p>

<p>이것 말고 더 재밌는 계산법도 있다. 자세한 건 강의 내용을 참조 </p>

<p><img src='http://latex.codecogs.com/gif.latex?E%28X_j%29%20%3D%201%20&plus;%20%7B1%20%5Cover%202%7D%20' *%20E%28X_j%29" alt="" /></p>

<p>이제 <em>average running</em> 타임을 구하기 위해 <code>T(n)</code> 의 평균을 구하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20E%5Bc%20' *%20n%20*%20%5Csum_%7Bphase%20j%7D%20%28%7B3%20%5Cover%204%7D%29%5Ej%20*%20X_j%5D" alt="" /></p>

<p>여기서 <em>linearity of expectation (기대값의 선형성)</em> 을 이용하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20c%20' *%20n%20*%20%5Csum_%7Bphase%20j%7D%20%28%7B3%20%5Cover%204%7D%29%5Ej%20*%20E%28X_j%29" alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20c%20' *%20n%20*%20%5Csum_%7Bphase%20j%7D%202%20*%20%28%7B3%20%5Cover%204%7D%29%5Ej" alt="" /></p>

<p>무한급수 공식을 적용하면,</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20c%20' *%20n%20*%204" alt="" /></p>

<p><del>얼마나 멋진가?</del></p>

<h3 id="deterministicselection">Deterministic Selection</h3>

<p>만약에 <em>randomization</em> 을 이용할 수 없다면? 그럼 이제 문제는 <em>good pivot</em>, 즉 <code>50/50</code> 에 최대한 가깝게 잘라내는 <em>pivot</em> 을 찾아야 한다. <em>median of medians</em> 를 이용하면 해낼 수 있다.</p>

<p><em>deterministic selection</em> 알고리즘을 구현한 함수를 <code>dSelect</code> 라 부르면</p>

<pre><code>dSelect(array A, length n, order statistic i)  
</code></pre>

<p>(1) Break <code>A</code> into groups of 5, sort each group <br />
(2) C = the <code>n/5</code> "middle elements" <br />
(3) p = <code>dSelect(C, n/5, n/10)</code>, recursivly computes median of C <br />
(4) Partition <code>A</code> around <code>p</code> <br />
(5) if <code>j = i</code> return <code>p</code> <br />
(6) if <code>j &lt; i</code> return <code>dSelect(1st part of A, j-1, i)</code> <br />
(7) if <code>j &gt; i</code> return <code>dSelect(2nd part of A, j-j, i-j)</code>  </p>

<p><code>4-7</code> 스텝은 <em>randomized selection</em> 과 똑같다. 더 복잡해진 부분은 앞의 <code>1-3</code> 스텝에서 피벗을 고르는 일이다.</p>

<p>퍼포먼스를 다시 이야기 해 보자 <em>randomized selection</em> 은 <em>pivot</em> 이 정말 나쁘게 선택되면 <code>O(n^2)</code> 이 될 수 있다. </p>

<p>반면 <em>deterministic selection</em> 은 모든 경우에 <code>O(n)</code> 을 보장한다. 그러나 실제로는 <em>randomized</em> 보다 성능이 나쁜데, 이유는 알고리즘에서 볼 수 있듯이 새로운 배열 <code>C</code> 가 필요하고 (<em>not in-place</em>), 표기법에는 상수가 생략되는데 <em>deterministic selection</em> 은 이 상수가 꽤나 커질 수 있다.</p>

<h3 id="analysis">Analysis</h3>

<p>이제 좀 더 자세히 살펴보자.</p>

<p>(1) Break <code>A</code> into groups of 5, sort each group  </p>

<p>이건 얼마의 시간이 걸릴까? 주어진 배열을 5개씩 짜르고, 각각의 그룹을 정렬하는데 걸리는 시간은? <code>O(n)</code> 이다.</p>

<p>먼저 <code>n = 120</code> 이라 하자. 정렬에 <em>merge sort</em> 를 사용하면 <em>merge sort</em> 연산 수 공식은</p>

<p><img src='http://latex.codecogs.com/gif.latex?6n%20' *%20log_2%28n&plus;1%29" alt="" /></p>

<p>따라서 잘려진 5개짜리를 정렬하는데 걸리는 시간은 <code>30 * log_2(6)</code> 에서, 이 값은 적어도 120 보다는 작음을 알 수 있다. 따라서 전체 그룹의개수 <code>n/5</code> 를 곱하면, <code>24n</code> 으로 <code>O(n)</code> 임을 알 수 있다. 비록 상수가 좀 크긴 하지만</p>

<p>(2) C = the <code>n/5</code> "middle elements" <br />
(3) p = <code>dSelect(C, n/5, n/10)</code>, recursivly computes median of C <br />
(4) Partition <code>A</code> around <code>p</code> <br />
(5) if <code>j = i</code> return <code>p</code> <br />
(6) if <code>j &lt; i</code> return <code>dSelect(1st part of A, j-1, i)</code> <br />
(7) if <code>j &gt; i</code> return <code>dSelect(2nd part of A, j-j, i-j)</code>  </p>

<p>(2), (4) 는 <code>O(n)</code> 임을 알 수 있고, (3) 은 <code>T(n/5)</code> 다. 문제는 (6), (7) 이다. 둘 중에 하나만 호출되긴 하지만 선택되는 <em>pivot</em> <code>p</code> 에 따라서 문제의 사이즈가 달라진다. 모르니까 <code>T(?)</code> 라 두자 그러면 <em>determinitic selection</em> 의 <em>running time</em> 은</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20T%28n/5%29%20&plus;%20T%28%3F%29'  alt="" /></p>

<p>간단한 가설을 세워보자. </p>

<blockquote>
  <p><strong>두번째 <code>dSelect</code> 호출의 input size 는 <code>7/10 * n</code> 보다 작거나 같다</strong></p>
</blockquote>

<p>그러면 수식을 이렇게 바꿀 수 있다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20T%28n/5%29%20&plus;%20T%287n/10%29'  alt="" /></p>

<p>(2) 에서 <em>medians</em> 를 찾고, 이걸 (3)에서 재귀에 한번 더 넘기면 <em>median of medians</em> 을 찾게된다. 이게 어떤 효과가 있냐면, 모든 원소를 5개씩 짤라 아래에서 위로 정렬, <em>medians</em> 는 좌에서 우로 정렬하면 다음과 같은 행렬이 나오는데</p>

<p><img src='http://i.imgur.com/gaOxb1A.jpg?1'  alt="" title="" /><p align="center">(<a href='http://functionspace.org/articles/19' >http://functionspace.org/articles/19</a>)</p></p>

<p>모든 원소 중 좌측 하단에 있는 <code>30%</code> 는 <em>median of medians</em> 보다 분명히 작다. 그리고 우측 상단 <code>30%</code> 는 <em>medians of medians</em> 보다 분명히 크다. 따라서 나머지 40% 값이 어쨌던건 간에 적어도 <code>30-70%</code> 분할은 해주므로 문제의 사이즈가 (6) 스텝에서 <code>7n/10</code> 보다 작거나 같다는 것을 분명히 보장해준다. 따라서 아래 식은 참이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20T%28n/5%29%20&plus;%20T%287n/10%29'  alt="" /></p>

<p>쉽게 <em>master method</em> 를 이용하고 싶은데 문제가 서로 다른 사이즈로 분할되니까 사용할 수 없다. <em>induction</em> 을 이용하자. 아래가 참임을 보이면 된다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20an'  alt="" /></p>

<p>우선 <em>base case</em> 는 <code>T(1) = 1</code> 이므로 <code>T(1) &lt;= a (where a &gt;= 1)</code> 에서 참이다.</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20T%28n/5%29%20&plus;%20T%287n/10%29'  alt="" /></p>

<p>이제 위 식에서 <em>induction hypothesis</em> 를 이용하고, 정리하면</p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20cn%20&plus;%20a%28n/5%29%20&plus;%20a%287n/10%29'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20n%20' *%20%289a/10%29" alt="" /></p>

<p>이 때 <code>c</code> 는 상수이므로 <code>c = a / 10</code> 이라 하면 </p>

<p><img src='http://latex.codecogs.com/gif.latex?T%28n%29%20%5Cleq%20an'  alt="" /></p>

<p>따라서 <em>deterministic selection</em> 의 성능은 <code>O(n)</code> 이다.</p>

<h3 id="lowerboundforsorting">lower bound for sorting</h3>

<p><em>comparison-based sorting</em> 의 <em>lower bound</em> 는 </p>

<p><img src='http://latex.codecogs.com/gif.latex?%0A%5COmega%20' (n*log%20n)" alt="" /></p>

<p>여기 해당되는 정렬들은 <em>merge sort, quick sort, heap sort</em> 등이 있다. 이런 정렬들은 데이터가 어떠할 것이라는 가정 없이 정렬을 해낸다. </p>

<p>반면 데이터의 분포를 안다면 <em>bucket sort</em> 같은 경우 <em>linear time</em> 으로 해결할 수 있다. <em>counting sort</em> 나 <em>radix sort</em> 같은 정렬도 데이터에 대한 정보(정수)라는 것을 이미 알고 있는 경우이므로 <code>O(n)</code> 으로 정렬 가능하다.</p>

<p>데이터에 대한 정보를 모른다고 해 보자. <code>1, 2, ..., n</code> 까지의 데이터를 가지고 있다면 이 데이터들이 배열 안에 담겨있을 수 있는 경우의 수는 <code>n!</code> 이다.</p>

<p><code>n!</code> 개의 모든 종류의 인풋에 대해서 <code>k</code> 번만큼, 혹은 그보다 더 적게 비교가 일어난다고 하자. 그럼 모든 <code>n!</code> 종류의 인풋에 대해서 <code>2^k</code> 개의 서로 다른 <em>execution</em> 이 생긴다.</p>

<blockquote>
  <p>Suppose algorithm always makes &lt;= k comparisons to correctly sort these <code>n!</code> inputs. Across all <code>n!</code> possile inputs algorithms exhibits &lt;= <code>2^k</code> distinct executions</p>
</blockquote>

<p>쉽게 생각해서 <code>k-bit</code> 문자열이 있을때 이걸로 얻을 수 있는 문자열은 <code>2^k</code> 개수다. 즉 어떤 문자는 없을수도 있다.</p>

<p>비둘기 집 원리를 생각해 보자. 우리는 <code>n!</code> 비둘기가 있고, <code>2^k</code> 개의 비둘기 집이 있다. 만약에 <code>k</code> 가 작아 <code>2^k &lt; n!</code> 이면 서로 다른 두개의 인풋에 대해서 같은 종류의 <em>execution</em> 을 공유 한다는 뜻이다. 따라서 둘 중 하나는 제대로 정렬되고, 나머지 하나는 제대로 정렬되지 않는다. </p>

<p>따라서 <code>2^k &gt;= n!</code> 이다. 이때 </p>

<p><img src='http://latex.codecogs.com/gif.latex?n%21%20%5Cgeq%20n%20' *%20%28n-1%29%20*%20%28n-2%29%20%5Ccdots%20%28n/2%29%20%5Cgeq%20%28n/2%29%5E%7B%28n/2%29%7D" alt="" /></p>

<p>이므로 </p>

<p><img src='http://latex.codecogs.com/gif.latex?2%5Ek%20%5Cgeq%20%28n/2%29%5E%7Bn/2%7D'  alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?k%20%5Cgeq%20%28n/2%29' *%20log_2%28n/2%29" alt="" /></p>

<p><img src='http://latex.codecogs.com/gif.latex?k%20%5Cgeq%20%5COmega%28n' *logn%29" alt="" /></p>

<p><code>k</code> 가 연산 수 이므로 <em>comparison-based sorting</em> 의 <em>lower bound</em> 는 <code>Omega(n logn)</code> 이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Algorithms: Design and Analysis, Part 1</em> by <strong>Tim Roughgarden</strong> <br />
(2) <a href='http://functionspace.org/articles/19' >http://functionspace.org/articles/19</a></p>]]></description><link>http://1ambda.github.io/randomized-selection/</link><guid isPermaLink="false">fa03e2ba-fcfe-46a0-987a-4a8137bba43f</guid><category><![CDATA[Algorithm]]></category><category><![CDATA[quick sort]]></category><category><![CDATA[selection]]></category><category><![CDATA[randomization]]></category><dc:creator><![CDATA[1ambda]]></dc:creator><pubDate>Fri, 07 Nov 2014 08:17:47 GMT</pubDate></item></channel></rss>