<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/Blog">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

  <title>Process Mining, Week1</title>
  <meta name="description" content="" />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Process Mining, Week1">
  <meta name="twitter:description" content="매 10분마다 새롭게 생성되는 데이터의 양은 2003년까지의 모든 데이터를 합한 것보다 더 많다고 한다. 이 데이터 속에는 무궁무진한 가치가 있다고 하여 어떤 사람들은 데이터를 기름이라 비유하기도 한다. Data Science and Big Data 우리가 들고 다니는 핸드폰에는 14개 이상의 센서가 달려있는데, 이렇게 다양한 이벤트로부터 데이터가 무수히 많이 발생하는걸 볼 수 있다">
  <meta name="twitter:creator" content="@yourTwitterUsername">
  <meta name="twitter:image" content="">
  <meta name="twitter:url" content="http://1ambda.github.io/process-mining-week1/">
  <meta name="twitter:domain" content="http://1ambda.github.io">

  

  <link rel="author" href="https://plus.google.com/101105410053351451441?rel=author" />

  <link rel="shortcut icon" href="../favicon.ico">

  <link rel="stylesheet" type="text/css" href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" />
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Droid+Serif" />
  <link rel='stylesheet' type='text/css' href="http://fonts.googleapis.com/css?family=Open+Sans:600,300" />
  <link rel="stylesheet" type="text/css" href="../assets/stylesheets/xpressio.css" />
  <link rel="stylesheet" type="text/css" href="../assets/1ambda/1ambda.css" />
  <script type="text/javascript" src="../assets/1ambda/modernizr.js">
  </script>
  <script type="text/javascript" src="../assets/1ambda/detectizr.min.js">
  </script>

  <!--load css if windows -->
  <script type="text/javascript">
    if (Modernizr.windows) {
      file = location.pathname.split( "/" ).pop();
      link = document.createElement( "link" );
      link.href = "/assets/1ambda/1ambda_windows.css";
      link.type = "text/css";
      link.rel = "stylesheet";
      link.media = "screen,print";
      document.getElementsByTagName("head")[0].appendChild( link );
    }
  </script>


  
  <link rel="stylesheet" href="../assets/highlight/styles/github.css">
<script src="../assets/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


  <meta name="generator" content="Ghost 0.5" />
<link rel="alternate" type="application/rss+xml" title="Old Lisper" href="../rss">
<link rel="canonical" href="http://1ambda.github.io/process-mining-week1/" />

  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52181619-1', '1ambda.github.io');
  ga('send', 'pageview');
</script>

  
</head>
<body>

  
  <script src="../public/jquery.js?v=7a66dda120"></script>

  

<header class="site_width text center padding_top_big margin_bottom_big">
  
  <h1 class="blog_title margin_bottom_small"><a href="http://1ambda.github.io">Old Lisper</a></h1>
  <h4 class="text book">Functional Programming</h4>
  
  <div class="social border solid top_small bottom_small padding_medium">
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="/about-me"><i class="fa fa-user"></i> <span class="margin_left_small desktop">About me</span></a></h6>
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="http://kr.linkedin.com/in/1ambda" target="_blank"><i class="fa fa-linkedin-square"></i> <span class="margin_left_small desktop">Linkedin</span></a></h6>
  <h6 class="text book color c_black_medium without_margin"><a href="http://github.com/1ambda" target="_blank"><i class="fa fa-github"></i> <span class="margin_left_small desktop">GitHub</span></a></h6>
</div>

</header>

<main class="site_width" role="main">
  <article class="post tag-coursera tag-process-mining tag-decision-tree tag-association-rule tag-k-means-clustering">

    

    <header class="text center margin_bottom_medium">
      <h5 class="text book small uppercase color c_black_light margin_bottom_small">Posted in <a href="../tag/coursera">coursera</a>, <a href="../tag/process-mining">process mining</a>, <a href="../tag/decision-tree">decision tree</a>, <a href="../tag/association-rule">association rule</a>, <a href="../tag/k-means-clustering">k-means clustering</a></h5>
      <h1 class="margin_bottom_medium">Process Mining, Week1</h1>
      <h5 class="text book small uppercase color c_black_light margin_bottom_small"><time datetime="2014-11-18">Tuesday, November 18, 2014</time>
      <br/><br/>
       <a href="http://1ambda.github.io/process-mining-week1/#disqus_thread">Comment</a>
      </h5>
    </header>

    <section>
      <p>매 10분마다 새롭게 생성되는 데이터의 양은 2003년까지의 모든 데이터를 합한 것보다 더 많다고 한다. 이 데이터 속에는 무궁무진한 가치가 있다고 하여 어떤 사람들은 데이터를 기름이라 비유하기도 한다.</p>

<p><img src="https://farm9.staticflickr.com/8037/8008798697_d36feb328d_h_d.jpg" alt="" /></p>

<h3 id="datascienceandbigdata">Data Science and Big Data</h3>

<p>우리가 들고 다니는 핸드폰에는 14개 이상의 센서가 달려있는데, 이렇게 다양한 이벤트로부터 데이터가 무수히 많이 발생하는걸 볼 수 있다. <em>Internet of Events</em> 시대다.</p>

<p><em>Internet of Events</em> 에는 크게 4개의 <em>source</em> 가 있는데</p>

<p>(1) <em>Internet of Content</em> (e.g Google, Wiki) <br />
(2) <em>Internet of People</em> (e.g Twitter, Facebook) <br />
(3) <em>Internet of Things</em> (e.g home appliances) <br />
(4) <em>Internet of Places</em> (e.g Smart phones)</p>

<p>왜 이렇게 데이터가 많이 증가할까? 데이터를 만드는 도구들이 널리 퍼졌기도 하지만 기본적으로 디바이스들이 어마어마하게 좋아졌기 때문이다. (가격도 물론). </p>

<p>매 2년마다 같은 범위에 집약할 수 있는 트랜지스터가 2배씩 늘어난다는 무어의 법칙을 일상생활에 적용하면 어떻게 될까? 40년전에는 비행기로 7시간 걸리던 거리가, 매 2년마다 1/2씩 줄어든다면 24 milliseconds 가 된다. 이건 정말 어마어마하게 줄어든 것이다. </p>

<p>이렇게 디바이스들의 처리, 저장 능력이 급속도로 늘었기 때문에 사람들은 이제 <em>Big Data</em> 를 이야기 하게 되었다. 그리고 문제는 여전히</p>

<blockquote>
  <p>How to extract real value from big data?</p>
</blockquote>

<p>기존의 데이터에 비해서 <em>Big data</em> 가 다른점은 무엇일까? 사람들은 빅데이터에 대해 이야기 할때 <em>4V</em> 를 말하곤 하는데</p>

<p>(1) <strong>Variety:</strong> Different froms of data sources <br />
(2) <strong>Veracity:</strong> Uncertainty of data <br />
(3) <strong>Volumn:</strong> Data size <br />
(4) <strong>Velocity:</strong> Speed of change</p>

<p><em>Veracity</em> 가 묻고자 하는것은 이런 것들이다. <em>"다량의 면도기 사용 데이터를 수집했는데, 이 면도기를 사용한 사람이, 실제로 그 면도기를 구매한 사람인가?"</em></p>

<p>이런 성격을 가진 빅데이터를 포함해서 일반적인 데이터를 분석할때 데이터 사이언티스트가 하는 4가지 질문이 있다.</p>

<ol>
<li>What happened?  </li>
<li>Why did it happen?  </li>
<li>What will happen?  </li>
<li>What is the best that can happen?</li>
</ol>

<p>예를 들어 병원에서는 <em>"왜 이 환자가 이렇게 오래 기다렸나?</em>", <em>"의사가 가이드라인을 따랐나?"</em>, <em>"그럼 대기 시간을 예측할 수 있을까?"</em>, <em>"내일은 얼마나 많은 스태프가 더 필요할까?"</em>, <em>"비용을 얼마나 줄일 수 있을까?"</em> 와 같은 질문을 할 수 있다.</p>

<p>이런 질문에 답하기 위해 다양한 스킬을 이용할 수 있다.</p>

<p><img src="http://blog.zhaw.ch/datascience/files/2014/06/SkillSet-1024x751.png" alt="" /></p>

<p align="center">(<a href='http://blog.zhaw.ch/datascience'>http://blog.zhaw.ch/datascience</a>)</p>

<p>지금까지 빅데이터에 대해 했지만 이 강의에서는 특별히 <em>process</em> 에 집중한다. 이유는</p>

<blockquote>
  <p>In the end, It is the process that matters (and no the data or the software)    </p>
  
  <p>Not just patterns and decisions, but end-to-end processes</p>
</blockquote>

<p>간단히 말하면 프로세스 마이닝은 <em>process-centric view on data science</em> 라 할 수 있다.</p>

<p>즉 프로세스 마이닝은 <em>event data</em> 와 <em>processes</em>, <em>process models</em> 간의 관계를 파악하는 것이다. 어떤 사람들은 <em>Business process intelligence</em> 라 부르기도 한다.</p>

<p>프로세스 마이닝의 <em>use cases</em> 는</p>

<blockquote>
  <ol>
  <li>What is the process that people really follow?</li>
  <li>Where are the bottlenecks in my process?  </li>
  <li>Where do people (or machines) deiate from the expected or idealized processes?</li>
  </ol>
</blockquote>

<p>결국 프로세스 마이닝은 <em>Data science in Action</em> 이다.</p>

<blockquote>
  <p>Not just data processes matter</p>
</blockquote>

<h3 id="differencetypesofprocessmining">Difference Types of Process Mining</h3>

<p>프로세스 마이닝의 포지션은 <em>process model analysis</em> 와 <em>data-oriented analysis</em> 의 중간이다. </p>

<p><img src="http://fluxicon.com/blog/wp-content/uploads/2014/02/Overview-ProcessMining.jpg" alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog'>http://fluxicon.com/blog</a>)</p>

<p>기존의 데이터마이닝은 데이터만을 보고 프로세스에 집중하지 않았다면, 프로세스 마이닝은 <em>end-to-end</em> 를 포함한 프로세스 자체에 집중한다. </p>

<p>왜 이런 프로세스에 집중할까? 그 이유는 <em>performance-oriented questions</em>, <em>comliance-oriented questions</em> 에 답하기 위해서다.</p>

<p>프로세스 마이닝의 시작은 <em>event data</em> 를 분석하는 것 부터다. <em>event log</em> 는 3가지 컬럼을 기본적으로 가지고 있는데 <em>case id</em>, <em>activity name</em>, <em>time stamp</em> 다.</p>

<p><img src="http://fluxicon.com/blog/wp-content/uploads/2012/02/PM-Example_small.png" alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog'>http://fluxicon.com/blog</a>)</p>

<p><em>model</em> 과 <em>event data</em> 사이에는 3가지 관계가 있다.</p>

<p>(1) <strong>Play-Out:</strong> 단순히 <em>model</em> 을 <em>simulation</em> 하면 다양한 시나리오 (<em>event logs</em>) 를 만들 수 있다. <br />
(2) <strong>Play-In:</strong> 다양한 <em>event logs</em> 로 부터 <em>model</em> 을 추론하는 것이다. (<em>No modeling is needed</em>) <br />
(3) <strong>Replay:</strong> <em>event data</em> 를 <em>model</em> 에서 재현함으로써 어떤 요소가 부족한지, 혹은 병목 지점등을 파악할 수 있다. (<em>conformance checking</em>)  </p>

<p><img src="http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-20-728.jpg?cb=1305062721" alt="" /></p>

<p><img src="http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-21-728.jpg?cb=1305062721" alt="" /></p>

<p><img src="http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-22-728.jpg?cb=1305062721" alt="" /></p>

<p><br/> <br />
<em>play-in</em> 은 좀 신선하다. 단순히 <em>event logs</em> 만으로 실제로 사람들이 따르는 프로세스를 추론할 수 있다는 이야기다.</p>

<p>그리고 이런 모델에 대해 <em>real data</em> 를 <em>repaly</em> 함으로써 병목 지점을 발견하여 개선함으로써 <em>performance</em> 를 늘릴 수 있다는 것이다.</p>

<p><br/> <br />
<img src="http://image.slidesharecdn.com/processminingchapter01introduction-110510153155-phpapp01/95/process-mining-chapter-1-introduction-17-728.jpg?cb=1305062721" alt="" /></p>

<p>요약하자면 <em>event logs</em> 로 부터 <em>play-in</em> 을 통해 <em>model</em> 을 이끌어 내고 여기에 대해 <em>replay</em> 를 통해 <em>conformance checking</em> 을 할 수 있다. 그리고 <em>enchanced model</em> 을 실제 적용하는 과정이 <em>play-out</em> 이라 볼 수 있다.</p>

<h3 id="howprocessminingrelatestodatamining">How process Mining Relates to Data Mining</h3>

<p><br/> <br />
<img src="http://fluxicon.com/blog/wp-content/uploads/2011/08/Version2.png" alt="" /></p>

<p align="center">(<a href='http://fluxicon.com/blog'>http://fluxicon.com/blog</a>)</p>

<p>기존의 <em>BI</em> 는 실제 <em>reality</em> 를 단순히 <em>KPI</em> 를 요약하는데 그쳤었다. 그러나 <em>anscombe's quartet</em> 를 보면 알 수 있듯이 똑같은 통계치를 가졌더라도 시각화 하면 전혀 다른 양상일 수 있다.</p>

<p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/638px-Anscombe%27s_quartet_3.svg.png" alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Anscombe's_quartet'>http://en.wikipedia.org/wiki/Anscombe's_quartet</a>)</p>

<p>따라서 <em>event data</em> 를 단순히 값으로 요약하는건 <em>reality</em> 를 반영하지 못할 수도 있다. 값도 중요하지만 <em>process</em> 를 봐야한다.</p>

<p>더 깊이 들어가기전에 데이터마이닝에 대해서 좀 알고 가자.</p>

<h4 id="variables">Variables</h4>

<p>두 타입의 <em>variable</em> 이 있는데 </p>

<p>(1) <strong>categorical variables:</strong> <em>ordinal</em>, <em>nominal</em> <br />
(2) <strong>numerical varaibles:</strong> ordered, cannot be enumerated easily  </p>

<p><em>yes / no</em> 같은건 <em>nominal</em> 이다.</p>

<h4 id="supervisedlearning">Supervised Learning</h4>

<p><em>supervised learning</em> 의 목표는 <em>labeled data</em> 를 이용하여</p>

<blockquote>
  <p>Explain <strong>response variable (dependent variable)</strong> in terms of <strong>predictor variable (independent variables)</strong></p>
</blockquote>

<p>여기에는 크게 나누면 두 가지 테크닉이 쓰인다. 하나는 <em>categorial response variable</em> 에 대해 사용하는 <em>classification</em> 이고 다른 하나는 <em>numerical response variable</em> 에 대해 쓸 수 있는 <em>regression</em> 이다.</p>

<h4 id="unsupervisedlearning">Unsupervised Learning</h4>

<p><em>unsupervised learning</em> 은 <em>unlabeled data</em> 를 가지고 <em>clustering</em> 이나 <em>pattern discovert</em> 등을 하는 것이다.</p>

<p><em>k-means</em>, <em>agglomerative hierarchical</em>, <em>association rules</em> 등 다양한 알고리즘을 이용한다.</p>

<h4 id="processminingvsdatamining">Process Mining vs Data Mining</h4>

<ul>
<li>둘 다 데이터로부터 시작한다.  </li>
<li>데이터마이닝은 <em>process-centric</em> 이 아니다.  </li>
<li><em>process discovery</em>, <em>conformance checking</em>, <em>bottleneck analysis</em> 는 전통적인 데이터마이닝으로 풀기 어렵다.  </li>
<li>프로세스 마이닝은 <em>end-to-end process models</em>, <em>concurrency</em> 중심이다.  </li>
<li>프로세스 마이닝의 <em>event log</em> 는 <em>timestamp</em> 와 <em>case</em> 컬럼이 있다.  </li>
<li>프로세스 마이닝과 데이터마이닝은 복잡한 문제를 풀기 위해 같이 사용될 수 있다.  </li>
</ul>

<h3 id="learningdecisiontree">Learning Decision Tree</h3>

<p><em>decision tree</em> 는 <em>supervised learning</em> 에서 사용되는 기법이다. <em>decision tree</em> 에 놓여있는 아이디어는 처음의 <em>*high entropy (uncertain)</em> 상태에서 <em>attribute</em> 에 따라 <em>subset</em> 으로 쪼개면서 복잡도를 낮춤으로써 <em>low entropy</em> 를 만들 수 있다.</p>

<p><em>entropy</em> 는 <em>degree of uncertainty</em>, <em>inverse of compressibility</em> 다. 만약 데이터에서 <em>entropy</em> 가 매우 적다면 데이터를 압축할 수 있다. 그러나 대부분의 경우 <em>high entropy</em> 이기 때문에</p>

<blockquote>
  <p><strong>Goal:</strong> reduce entropy in leaves of tree to improve predictability  </p>
</blockquote>

<p>엔트로피를 계산하기 위해 로그를 이용하면 </p>

<p><img src="http://latex.codecogs.com/gif.latex?E%20%3D%20-%20%5Csum_%7Bi%20%3D%201%7D%5Ek%20P_i%20%5C%20log_2%28P_i%29" alt="" /></p>

<p><em>intuition</em> 은 초록공과 빨간공이 1:1 로 섞여있을땐 <code>E = 1</code> 이고, 빨간공이나 초록공만 있을때는 <code>E = 0</code> 이다. 따라서 <em>decision tree</em> 가 깊어지면 깊어질수록 전체 <code>E</code> 가 낮아진다. </p>

<p><img src="http://cfile26.uf.tistory.com/image/2023334B5153F4EE27D112" alt="http://frontjang.tistory.com/" /></p>

<p align="center">(<a href='http://frontjang.tistory.com'>http://frontjang.tistory.com</a>)</p>

<p>그리고 이렇게 얻어진 <em>overall entropy</em> 의 차이를 <em>information gain</em> 이라 부른다. <em>classification</em> 에는 변화가 없어도 <em>information gain</em> 이 있을 수 있다. 반대로 한단계 더 분리 되었어도 <em>information gain</em> 이 <code>0</code> 일 수 있다.</p>

<p>따라서 선택 가능한 모든 <em>attribute</em> 에 대해 <em>information gain</em> 을 비교하여 가장 큰 <em>attribute</em> 를 선택하고 더 이상의 커다란 변화가 없을때 까지 반복하면 <em>decision tree</em> 를 만들 수 있다.</p>

<p><em>minimal gain</em>, <em>maximum depth</em> 등을 세팅할 수도 있고, <em>overfitting</em> (모든 경우를 다 분리하는것) 을 막기 위해 최소 노드 사이즈를 정할 수 있다. <em>post pruning</em> 등 다양한 기술이 있다.</p>

<p>프로세스 마이닝에 적용해 보면 모델에서 분기 될 때 <em>"What is driving these decisions?"</em>, 등을 파악할 수 있고 <em>"most likely path"</em> 같은 문제도 해결할 수 있다.</p>

<h3 id="associationrule">Association Rule</h3>

<p><em>unsupervised learning</em> 도구인 <em>association rule</em> 을 이용해 패턴을 찾아보자.</p>

<p><em>association rule</em> 은 <code>X =&gt; Y</code> 형태다. 시작 전에 몇가지 개념을 보고 넘어가자.</p>

<h4 id="support">Support</h4>

<p><em>support</em> 는 <code>0 ~ 1</code> 사이의 값을 가지는데, <code>1</code> 이면 <em>good</em>, <code>0</code> 로 갈수록 <em>bad</em> 를 의미한다. </p>

<p><img src="http://latex.codecogs.com/gif.latex?support%28X%5CRightarrow%20Y%29%20%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%20%5Cover%20N%20%7D" alt="" /></p>

<p>즉 전체 데이터 중 <code>X</code>, <code>Y</code> 가 같이 있는 <em>instance</em> 의 비율을 의미한다.</p>

<h4 id="confidence">Confidence</h4>

<p><em>support</em> 와 마찬가지로 <code>0 ~ 1</code> 값을 가지며 높은 값일수록 더 연관성 있음을 의미한다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?confidence%28X%5CRightarrow%20Y%29%20%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%20%5Cover%20N_X%20%7D" alt="" /></p>

<p>전체 <code>X</code> 인스턴스 중 <code>X</code>, <code>Y</code> 가 같이 있는 <em>instance</em> 의 비율을 의미한다.</p>

<h4 id="lift">Lift</h4>

<p><img src="http://latex.codecogs.com/gif.latex?lift%28X%5CRightarrow%20Y%29%20%5C%5C%20%5C%5C%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%5C%20/%5C%20N%20%5Cover%20%7B%28N_X%20/%20N%29%20%28N_Y%20/%20N%29%7D%20%7D%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20%7BN_%7BX%20%5Ccup%20Y%7D%5C%20N%20%5Cover%20%7BN_X%20%5C%20N_Y%7D%20%7D" alt="" /></p>

<p><em>lift</em> 는 <em>실제 같이 나타나는 비율 / 기대했던 비율</em> 이다. 식을 보면 알겠지만 각 아이템이 나타나는 비율을 독립이라 가정한 것을 분모로 실제 나타나는 비율을 나눈 것이다. 따라서 <code>lift &gt; 1</code> 이면 <code>X</code> 는 <code>Y</code> 가 나타나는데 긍정적인 영향을 미치거나 혹은 <code>Y</code> 가 <code>X</code> 에 대해 긍정적인 영향을 미친것이다. 반면 <code>lift &lt; 1</code> 이면 반대고, <code>lift = 1</code> 이면 서로 관계가 없다 볼 수 있다.</p>

<p><a href="http://analyticstrainings.com/?p=151">여기</a>를 인용하면</p>

<blockquote>
  <p><strong>A lift value greater than 1</strong> indicates that X and Y appear more often together than expected; this means that the occurrence of X has a positive effect on the occurrence of Y or that X is positively correlated with Y.</p>
  
  <p><strong>A lift smaller than 1</strong> indicates that X and Y appear less often together than expected, this means that the occurrence of X has a negative effect on the occurrence of Y or that X is negatively correlated with Y</p>
  
  <p><strong>A lift value near 1</strong> indicates that X and Y appear almost as often together as expected; this means that the occurrence of X has almost no effect on the occurrence of Y or that X and Y have Zero Correlation.</p>
</blockquote>

<p><em>class</em> 가 많으면 <em>rule</em> 또한 엄청나게 많아지기 때문에 <em>support</em>, <em>confidence</em>, <em>lift</em> 를 이용해서 룰을 필터링하거나 정렬할 수 있다.</p>

<p>일반적으로 이 3가지에 대해</p>

<p>(1) <em>support</em> 는 높을수록 좋다. <br />
(2) <em>confidence</em> 는 1에 가까워야 한다. <br />
(3) <em>lift</em> 는 1보다 커야한다.  </p>

<p>다음의 조건이 있을때 각 룰에 대해 <em>support</em>, <em>confidence</em>, <em>lift</em> 를 계산해 보자.</p>

<blockquote>
  <p>100 customers buy diapers and / or beer: <br />
  - 9 customers buy just Hoegaarden <br />
  - 40 customers buy just Pampers <br />
  - 50 customers buy just Pampers and Dommelsch <br />
  - 1 customer buys just Pampers, Hoegaarden and Dommelsch  </p>
</blockquote>

<p>먼저 <code>{Pampers} =&gt; {Dommelsch}</code> 는</p>

<p><code>s = 51 / 100 = 0.51</code>, <code>c = 51 / 91 = 0.56</code>, <code>l = 51 * 100 / (91 * 51) = 1.1</code> </p>

<p>다음으로 <code>{Dommelsch} =&gt; {Pampers}</code> 는</p>

<p><code>s = 0.51, c = 1, l = 1.1</code> 이다.</p>

<p>값을 보면 이 두 가지 룰은 상당히 신빙성이 있다고 볼 수 있다. 그리고 나머지 룰들을 살펴봐도 <code>supoort, confidence, lift</code> 값 이 상당히 낮다.</p>

<p>계산 방법은 간단한데, <em>class</em> 가 많으면 계산해야 할 <em>rule</em> 자체가 어마어마하게 많아진다. 이 문제를 해결하기 위해 몇 가지 방법이 있다.</p>

<h4 id="apriorialgorithm">Apriori Algorithm</h4>

<p><img src="http://latex.codecogs.com/gif.latex?Y%20%5Csubset%20X%5C%20%3D%3E%5C%20%28N_Y%20/%20N%29%20%5Cgeq%20%28N_X%20/%20N%29" alt="" /></p>

<p><code>X</code> 의 부분집합인 <code>Y</code> 에 대해서, <code>X</code> 의 <em>support</em> 가 높으면 <code>X</code> 의 부분집합도 충분히 빈번해야 한다. 그래서 <code>X</code> 의 부분집합인 <code>Y</code> 의 <em>support</em> 가 낮으면 <code>Y</code> 의 부분집합을 살펴볼 필요가 없어 연산 수를 줄일 수 있다.</p>

<h4 id="patternmining">Pattern Mining</h4>

<p>여기서 본 연관 분석은 <em>process</em> 를 고려하지 않지만, 이 기법을 잘 활용하면 <em>sequence mining</em> 이나 <em>episode mining</em> 등등에 활용 될 수 있다.</p>

<h3 id="clusteranalysis">Cluster Analysis</h3>

<p><em>unsupervised learning</em> 기법인 <em>clustering</em> 도 간단히 살펴보자.</p>

<p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/SLINK-Gaussian-data.svg/186px-SLINK-Gaussian-data.svg.png" alt="" /></p>

<p align="center">(<a href='http://en.wikipedia.org/wiki/Cluster_analysis'>http://en.wikipedia.org/wiki/Cluster_analysis</a>)</p>

<h4 id="kmeansclustering">k-means clustering</h4>

<p>여기서 <code>k</code> 는 몇개의 집단으로 나눌건지를 의미하는 숫자다. 알고리즘 자체는 굉장히 직관적이다.</p>

<p>(1) 먼저 <em>centroid</em> 라 부르는 점들을 <em>attribute</em> 에 랜덤하게 혹은 레귤러 하게 <code>k</code> 개 배치한다. <br />
(2) 각 점에서 <em>centroid</em> 까지 거리가 가장 짧은 <em>centroid</em> 를 선택하고, 이 집단 내부에서 가운데 점을 계산해 <em>centroid</em> 로 다시 정한다. <br />
(3) <em>centroid</em> 에 변화가 없을 때 까지 계속 반복한다.  </p>

<p><img src="http://datavisualization.blog.com/files/2011/08/kmeansclustering.jpg" alt="" /></p>

<p align="center">(<a href='http://datavisualization.blog.com'>http://datavisualization.blog.com</a>)</p>

<pre><code>// ref: http://datavisualization.blog.com/visible-data/cluster-analysis/

Select K points as the initial Centroids  
REPEAT  
   Form K clusters by assigning all points to the closest Centroid
   recompute the Centroid for each cluster
UNTIL Centroids don’t change // or less than thresahold”  
</code></pre>

<p>초기에 <em>centroid</em> 가 랜덤하게 선택되기 때문에 <em>non-deterministic</em> 이어서 여러번 계산 후에 가장 좋은 <em>clustering</em> 을 골라야 한다. </p>

<p>그리고 <code>k</code> 값에 따라 클러스터가 달라질 수 있으므로 변화시켜가면서 좋은 <code>k</code> 값을 찾아야 한다.</p>

<p><img src="http://datavisualization.blog.com/files/2011/08/howmanyclusters.jpg" alt="" /></p>

<p align="center">(<a href='http://datavisualization.blog.com'>http://datavisualization.blog.com</a>)</p>

<h4 id="agglomerativehierarchicalclustring">Agglomerative hierarchical clustring</h4>

<p><em>k-means</em> 이외에도 다양한 클러스터링 알고리즘이 있다.</p>

<p><img src="http://www.cs.umd.edu/hcil/hce/hce3-manual/dendrogram.png" alt="" /></p>

<p align="center">(<a href='http://www.cs.umd.edu'>http://www.cs.umd.edu</a>)</p>

<h4 id="applyingprocessmining">Applying Process Mining</h4>

<p>클러스터링은 <em>event-log</em> 를 분할하는데 쓸 수 있다. 그러면 특징이 다른 <em>event-log</em> 를 뽑아낼 수 있고 각각의 클러스터에 대해 모델을 만드는데 유용하다.</p>

<h3 id="evaluatingminingresult">Evaluating Mining Result</h3>

<p>마이닝으로 모델을 만들거나, 결과를 얻었다고 하자. 어떻게 평가할까?</p>

<h4 id="confusionmatrix">Confusion Matrix</h4>

<p><em>confusion matrix</em> 는 <em>predict class</em> 와 <em>actual class</em> 를 기반으로 테이블을 만든 것이다.</p>

<p><img src="http://lh3.ggpht.com/_qIDcOEX659I/SzjW6wGbmyI/AAAAAAAAAtY/Nls9tSN6DgU/contingency_thumb%5B3%5D.png?imgmax=800" alt="" /></p>

<p align="center">(<a href='http://crsouza.blogspot.kr'>http://crsouza.blogspot.kr</a>)</p>

<p><br/> <br />
여기에 대해 <em>error</em>, <em>accuracy</em>, <em>precision</em>, <em>recall</em>, <em>F1-score</em> 등을 계산할 수 있다.</p>

<p><img src="http://image.slidesharecdn.com/08classbasic-140913212207-phpapp02/95/data-miningconcepts-and-techniques-chapter-8-classification-basic-concepts-51-638.jpg?cb=1410662460" alt="" /></p>

<p align="center">(<a href='http://www.slideshare.net/salahecom/08-classbasic'>http://www.slideshare.net/salahecom/08-classbasic</a>)</p>

<h4 id="crossvalidation">Cross Validation</h4>

<p>가지고 있는 데이터로 모델을 만들면, 모델에는 잘 맞지만 실제 데이터에는 안맞을 수 있다.</p>

<blockquote>
  <p><strong>Overfitting :</strong> the model is too specific for the data set used to learn the model and performs poorly on new instances</p>
  
  <p><strong>Underfitting :</strong> the model is too general and does not exploit the data</p>
</blockquote>

<p>그래서 데이터셋을 <em>training set</em> 과 <em>test set</em> 으로 분리해서 각각 훈련, 퍼포먼스 테스트를 위해 사용한다.</p>

<h3 id="summary">Summary</h3>

<p>이번 주차엔 데이터마이닝에 대해서 논했는데, 다음 시간부터는 <em>process discovery</em>, <em>conformance checking</em> 등에 대해 이야기 한다. <del>어째 오토마타의 향연이 될 것 같기도</del></p>

<h3 id="references">References</h3>

<p>(1) <strong>Process Mining: Data science in Action</strong> by Wil van der Aalst <br />
(2) <a href="/process-mining-week1/www.processmining.org">www.processmining.org</a> <br />
(3) <a href="http://blog.zhaw.ch/datascience/the-data-science-skill-set/">http://blog.zhaw.ch/datascience/the-data-science-skill-set/</a> <br />
(4) <a href="http://fluxicon.com/blog/2014/02/how-is-process-mining-different-from/">http://fluxicon.com/blog</a> <br />
(5) <a href="http://www.slideshare.net/wvdaalst/process-mining-chapter01introduction?related=1">Process Mining Chapter 1</a> <br />
(6) <a href="http://en.wikipedia.org/wiki/Anscombe's_quartet">Anscombe's quartet</a> <br />
(7) <a href="http://frontjang.tistory.com/category/Computer/MachineLearning">http://frontjang.tistory.com</a> <br />
(8) <a href="http://analyticstrainings.com/?p=151">http://analyticstrainings.com/?p=151</a> <br />
(9) <a href="http://datavisualization.blog.com/visible-data/cluster-analysis/">http://datavisualization.blog.com</a> <br />
(10) <a href="http://www.cs.umd.edu/hcil/hce/hce3-manual/hce3_manual.html">http://www.cs.umd.edu</a> <br />
(11) <a href="http://crsouza.blogspot.kr/2009/12/performing-discriminant-power-analysis.html">http://crsouza.blogspot.kr</a> <br />
(12) <a href="http://www.slideshare.net/salahecom/08-classbasic">http://www.slideshare.net/salahecom/08-classbasic</a></p>
    </section>

    <footer>
      
      <section class="author_info margin_top_big">
        <div class="alignleft border rad_circle" style="height: 87px; width: 87px; background-image: url(http://www.gravatar.com/avatar/aa2032ba2302419e3c2ede54f1fbf687?d=404&amp;s=250); background-size: cover;"></div>
        <p class="margin_left_medium text small">Author</p>
        <p class="margin_left_medium text bold"><a href="http://language.is">1ambda</a></p>
        <p class="margin_left_medium text small">Lisp, Emacs, FP</p>
      </section>
      
    </footer>

    

    
    <div id="disqus_thread" class="margin_top_big"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = '1ambda'; // required: replace example with your forum shortname
  var disqus_identifier = '61';
  var disqus_url = 'http://1ambda.github.io/process-mining-week1/';

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

    </article>
</main>


  
  <script src="../assets/fitvids/jquery.fitvids.js"></script>
<script>
$(document).ready(function(){
  // Target your .container, .wrapper, .post, etc.
  $("section").fitVids();
});
</script>


  <footer class="blog_info margin_top_big padding_medium text center">
    <h5 class="text book small">&copy; 2014 <a href="..">Old Lisper</a>. All rights reserved.</h5>
    <h5 class="text book small"><a href="https://github.com/dreyacosta/velox" target="_blank" class="text bold">Velox theme</a> by <a href="http://dreyacosta.com/">David Rey</a></h5>
    <h5 class="text book small">Proudly published with <a href="http://ghost.org"><span>Ghost</span></a></h5>

  </footer>

  
  <script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = '1ambda'; // required: replace example with your forum shortname

/* * * DON'T EDIT BELOW THIS LINE * * */
(function () {
 var s = document.createElement('script'); s.async = true;
 s.type = 'text/javascript';
 s.src = '//' + disqus_shortname + '.disqus.com/count.js';
 (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
 }());
</script>



  </body>
  </html>
