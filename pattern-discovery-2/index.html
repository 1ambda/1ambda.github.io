
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <title>Pattern Discovery 2</title>
  <meta name="description" content="">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Pattern Discovery 2">
  <meta name="twitter:description" content="패턴 마이닝을 통해 만들어지는 수많은 pattern, rule 이 모두 유용한 것은 아닙니다. 따라서 interestingness measure 을 위해 객관적이거나, 주관적인 평가방법을 이용할 수 있습니다. (1) Objective interestingness measures support, confidence, correlation (2) Subjective interestingness measures Query-based: relevant to a user's particular request Against one's knowledge-base: unexpected, freshness, timeliness Visualization tools: Multi-dimensional,">
  <meta name="twitter:creator" content="@yourTwitterUsername">
  <meta name="twitter:image" content="">
  <meta name="twitter:url" content="http://1ambda.github.io/pattern-discovery-2/">
  <meta name="twitter:domain" content="http://1ambda.github.io">


  <link rel="author" href="https://plus.google.com/101105410053351451441?rel=author">

  <link rel="shortcut icon" href="../favicon.ico">

  <link rel="stylesheet" type="text/css" href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Droid+Serif">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Open+Sans:600,300">
  <link rel="stylesheet" type="text/css" href="../assets/stylesheets/xpressio.css">
  <link rel="stylesheet" type="text/css" href="../assets/1ambda/1ambda.css">
  <script type="text/javascript" src="../assets/1ambda/modernizr.js">
  </script>
  <script type="text/javascript" src="../assets/1ambda/detectizr.min.js">
  </script>

  <!--load css if windows -->
  <script type="text/javascript">
    if (Modernizr.windows) {
      file = location.pathname.split( "/" ).pop();
      link = document.createElement( "link" );
      link.href = "/assets/1ambda/1ambda_windows.css";
      link.type = "text/css";
      link.rel = "stylesheet";
      link.media = "screen,print";
      document.getElementsByTagName("head")[0].appendChild( link );
    }
  </script>


  <link rel="stylesheet" href="../assets/highlight/styles/github.css">
<script src="../assets/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

  <link rel="canonical" href="http://1ambda.github.io/pattern-discovery-2/">
    <meta name="referrer" content="origin">
    
    <meta property="og:site_name" content="Old Lisper">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Pattern Discovery 2">
    <meta property="og:description" content="패턴 마이닝을 통해 만들어지는 수많은 pattern, rule 이 모두 유용한 것은 아닙니다. 따라서 interestingness measure 을 위해 객관적이거나, 주관적인 평가방법을 이용할 수 있습니다. (1) Objective interestingness measures support, confidence, correlation (2) Subjective interestingness measures Query-based: relevant to a user's particular...">
    <meta property="og:url" content="http://1ambda.github.io/pattern-discovery-2/">
    <meta property="article:published_time" content="2015-02-20T02:49:15.956Z">
    <meta property="article:modified_time" content="2015-02-20T07:51:22.899Z">
    <meta property="article:tag" content="coursera">
    <meta property="article:tag" content="pattern discovery">
    <meta property="article:tag" content="data mining">
    <meta property="article:tag" content="lift">
    <meta property="article:tag" content="pattern-fusion">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Pattern Discovery 2">
    <meta name="twitter:description" content="패턴 마이닝을 통해 만들어지는 수많은 pattern, rule 이 모두 유용한 것은 아닙니다. 따라서 interestingness measure 을 위해 객관적이거나, 주관적인 평가방법을 이용할 수 있습니다. (1) Objective interestingness measures support, confidence, correlation (2) Subjective interestingness measures Query-based: relevant to a user's particular...">
    <meta name="twitter:url" content="http://1ambda.github.io/pattern-discovery-2/">
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "Old Lisper",
    "author": {
        "@type": "Person",
        "name": "1ambda",
        "image": "//www.gravatar.com/avatar/aa2032ba2302419e3c2ede54f1fbf687?d=404&s=250",
        "url": "http://1ambda.github.io/author/1ambda",
        "sameAs": "http://1ambda.github.io",
        "description": "Functional, Scala, Akka, Rx and Haskell"
    },
    "headline": "Pattern Discovery 2",
    "url": "http://1ambda.github.io/pattern-discovery-2/",
    "datePublished": "2015-02-20T02:49:15.956Z",
    "dateModified": "2015-02-20T07:51:22.899Z",
    "keywords": "coursera, pattern discovery, data mining, lift, pattern-fusion",
    "description": "패턴 마이닝을 통해 만들어지는 수많은 pattern, rule 이 모두 유용한 것은 아닙니다. 따라서 interestingness measure 을 위해 객관적이거나, 주관적인 평가방법을 이용할 수 있습니다. (1) Objective interestingness measures support, confidence, correlation (2) Subjective interestingness measures Query-based: relevant to a user&#x27;s particular..."
}
    </script>

    <meta name="generator" content="Ghost 0.6">
    <link rel="alternate" type="application/rss+xml" title="Old Lisper" href="http://1ambda.github.io/rss/">

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52181619-1', '1ambda.github.io');
  ga('send', 'pageview');
</script>
  
</head>
<body>

  <script src="../public/jquery.js?v=5798977227"></script>

  
<header class="site_width text center padding_top_big margin_bottom_big">
  
  <h1 class="blog_title margin_bottom_small"><a href="http://1ambda.github.io">Old Lisper</a></h1>
  <h4 class="text book">Functional Programming World</h4>
  <div class="social border solid top_small bottom_small padding_medium">
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="http://1ambda.github.io/articles/"><i class="fa fa-columns"></i> <span class="margin_lefarticlest_small desktop">Article</span></a></h6>
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="http://kr.linkedin.com/in/1ambda" target="_blank"><i class="fa fa-linkedin-square"></i> <span class="margin_left_small desktop">Linkedin</span></a></h6>
  <h6 class="text book color c_black_medium without_margin"><a href="http://github.com/1ambda" target="_blank"><i class="fa fa-github"></i> <span class="margin_left_small desktop">GitHub</span></a></h6>
</div>
</header>

<main class="site_width" role="main">
  <article class="post tag-coursera tag-pattern-discovery tag-data-mining tag-lift tag-pattern-fusion">


    <header class="text center margin_bottom_medium">
      <h5 class="text book small uppercase color c_black_light margin_bottom_small">Posted in <a href="../tag/coursera/">coursera</a>, <a href="../tag/pattern-discovery/">pattern discovery</a>, <a href="../tag/data-mining/">data mining</a>, <a href="../tag/lift/">lift</a>, <a href="../tag/pattern-fusion/">pattern-fusion</a></h5>
      <h1 class="margin_bottom_medium">Pattern Discovery 2</h1>
      <h5 class="text book small uppercase color c_black_light margin_bottom_small"><time datetime="2015-02-20">Friday, February 20, 2015</time>
      <br><br>
       <a href="http://1ambda.github.io/pattern-discovery-2/#disqus_thread">Comment</a>
      </h5>
    </header>

    <section>
      <p><img src="https://m1.behance.net/rendition/modules/7116731/disp/d18c13cd5b49bf40b41e6ef0610b26d3.png" alt=""></p>

<p>패턴 마이닝을 통해 만들어지는 수많은 <em>pattern</em>, <em>rule</em> 이 모두 유용한 것은 아닙니다. 따라서 <em>interestingness measure</em> 을 위해 객관적이거나, 주관적인 평가방법을 이용할 수 있습니다.</p>

<p>(1) <strong>Objective interestingness measures</strong></p>

<ul>
<li>support, confidence, correlation</li>
</ul>

<p>(2) <strong>Subjective interestingness measures</strong></p>

<ul>
<li><em>Query-based:</em> relevant to a user's particular request</li>
<li><em>Against one's knowledge-base:</em> unexpected, freshness, timeliness</li>
<li><em>Visualization tools:</em> Multi-dimensional, interactive examination</li>
</ul>

<p>이 방법중, 먼저 객관적인 방법에 대해 좀 더 알아보겠습니다.</p>

<p><br></p>

<h3 id="liftchisquared">Lift, χ²(Chi-squared)</h3>

<p><em>confidence</em> 는 두 변수가 관련있는지 말해주지만, <em>positive</em> 혹은 <em>negative</em> 관계인지 말해주지 않습니다. 이를 판별하기 위해 <em>lift</em> 를 이용할 수 있죠</p>

<p><img src="http://latex.codecogs.com/gif.latex?lift%28B%2C%20C%29%20%5C%5C%20%5C%5C%20%3D%20%7Bc%28B%20-%3E%20C%29%20%5Cover%20s%28C%29%7D%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20%7Bs%28B%20%5Ccup%20C%29%20%5Cover%20%7Bs%28B%29%20%5Ctimes%20s%28C%29%7D%7D" alt=""></p>

<p><code>Lift(B, C)</code> 는 <code>B</code> 와 <code>C</code> 가 얼마나 관련있는지를 말해줍니다. 수식을 보면 알겠지만</p>

<ul>
<li><code>Lift(B, C) = 1</code> 이면 <code>B</code> 와 <code>C</code> 는 <em>independent</em></li>
<li><code>&gt; 1</code> 이면 <em>positive correlated</em></li>
<li><code>&lt; 1</code> 이면 <em>negative correlated</em></li>
</ul>

<p><br></p>

<p><em>correlated events</em> 를 판별하는 다른 방법은 <code>χ²</code> 를 이용하는 것입니다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Cchi%5E2%20%3D%20%5Csum%20%7B%28observed%20-%20expected%29%5E2%20%5Cover%20expected%7D" alt=""></p>

<ul>
<li><code>χ² = 0</code> 이면 <em>independent</em></li>
<li><code>χ² &gt; 1</code> 이면 <em>correlated</em> 이며 <em>positive</em> 인지 <em>negative</em> 인지는 <em>expected</em> 값과 비교하면 알 수 있습니다.</li>
</ul>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/null_transaction.jpg" alt=""></p>

<p>그러나 <em>lift</em> 와 <em>chi-squared</em> 가 항상 좋은 평가지표는 아닙니다. 위 테이블을 보면 <code>Lift(B, C) = 8.44</code> 입니다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?lift%28B%2C%20C%29%20%5C%5C%20%5C%5C%20%3D%20%7B%28100/102100%29%20%5Cover%20%7B%281100/102100%29%20*%20%281100/102100%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%208.4380" alt=""></p>

<p>이는 <code>~B and ~C</code> 부분의 숫자가 <code>B, C</code> 보다 월등히 높아서 그런데, 이런 영역을 <em>null transaction</em> 이라 부릅니다. </p>

<p><code>B, C</code> 는 같이 일어날 확률이 상당히 낮지만, <em>null transaction</em> 때문에 높은것처럼 보입니다.</p>

<p><br></p>

<h3 id="nullinvariantmeasures">Null Invariant Measures</h3>

<p><em>lift</em> 와 <em>chi-squared</em> 는 많은 수의 <em>null transaction</em> 이 있을 때 좋은 평가 지표가 될 수 없습니다. </p>

<p>이를 해결하기 위해 <em>null transaction</em> 에 영향을 받지 않는 <em>null-invaraint measures</em> 를 사람들이 만들어 두었습니다.</p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/null_invariant_measures.jpg" alt=""></p>

<p><em>null invariance</em> 는 <em>massive transaction data</em> 를 마이닝할때 아주 중요합니다. <em>null transaction</em> 이 아주 많을 수 있기 때문이죠. </p>

<p>그러면 이 많은 <em>measures</em> 중 어떤것이 가장 나을까요? 예제 데이터로 한번 비교해 봅시다. <code>m</code> 은 <em>milk</em>, <code>c</code> 는 <em>coffee</em> 입니다.</p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/comparison_of_measures.jpg" alt=""></p>

<blockquote>
  <p>Kulc holds firm and is in balance of both directional implications</p>
</blockquote>

<p>여기에 <em>imbalance ratio</em> 라는 개념을 도입할 수 있습니다.</p>

<ul>
<li><strong>imbalance ratio:</strong> measure the imbalance of two itemsets <code>A</code> and <code>B</code> in rule implications</li>
</ul>

<p><img src="http://latex.codecogs.com/gif.latex?IR%28A%2C%20B%29%20%5C%5C%20%5C%5C%20%3D%20%7B%7B%7Cs%28A%29%20-%20s%28B%29%7D%20%5Cover%20s%28A%29%20&amp;plus;%20s%28B%29%20-%20s%28A%5Ccup%20B%29%7D" alt=""></p>

<p><em>Kulc</em> 와 <em>IR</em> 을 이용하면 조금 더 데이터를 자세히 살펴볼 수 있죠.</p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/IR.jpg" alt=""></p>

<ul>
<li>D4 is <em>neutral</em>, <em>balanced</em></li>
<li>D5 is <em>neutral</em>, but <em>imbalanced</em></li>
<li>D6 is <em>neutral</em>, but very <em>imbalanced</em></li>
</ul>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/DBLP_example.jpg" alt=""></p>

<p><code>ID 5</code> 를 보면, <em>Kulc</em> 는 아이템 <code>A, B</code> 가 상당한 연관성이 있지만, <em>imbalance</em> 하므로 <code>0.562</code> 의 값을 돌려주는 것을 볼 수 있습니다.</p>

<p><br></p>

<h2 id="5miningdiversepatterns">5. Mining Diverse Patterns</h2>

<p>이번 시간에 배울 주제들은 다음과 같습니다.</p>

<ul>
<li>Mining Multiple-Level Associations</li>
<li>Mining Multi-Dimensional Associations</li>
<li>Mining Quantitative Associations</li>
<li>Mining Negative Correlations</li>
<li>Mining Compressed and Redundancy-Aware Patterns</li>
<li>Mining Long/Colossal Patterns</li>
</ul>

<p><br></p>

<h3 id="multilevelassociations">Multi-Level Associations</h3>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/multi_level_items.jpg" alt=""></p>

<p><em>item</em> 은 하위 계층으로 다시 분류될 수 있습니다. 이럴때는 단순히 <em>uniform min support</em> 를 이용하는 것보다, 아래 계층으로 내려갈수록 <em>reduced min support</em> 를 이용하는 편이 더 낫습니다.</p>

<p>그리고 한번의 여러 단계(<em>multi-level</em>) 을 마이닝하기 위해 <em>shared multi-level mining</em> 이란 기법을 이용할 수 있습니다.  이건 뒷부분에서 더 살펴보겠습니다.</p>

<p><em>multi-level association</em> 마이닝의 문제점은 <em>redundant rules</em> 을 만들 수 있다는 점입니다. 따라서 필터링 기법이 필요합니다. <code>level 1</code> 에서 발견된 룰을, <code>level 2</code> 에서 다시 검사하지 않는것 처럼요</p>

<ul>
<li><code>milk -&gt; wheat bread [s=8%, c=70%]</code></li>
<li><code>2% milk -&gt; wheat breadk [s=2%, c=72%]</code></li>
</ul>

<p>아이템에 따라서 <em>customized min support</em> 가 필요한 경우도 있습니다. 우유나 빵은 그렇지 않아도 상관 없지만, <em>diamond</em>, <em>watch</em> 등은 커스터마이징이 꼭 필요합니다. 고가의 아이템이니까요. 이 경우 <em>group-based individualized min-support</em> 를 이용하면 됩니다.</p>

<ul>
<li><code>{diamon, watch}: 0.05%; {bread, milk}: 5%;, ...</code></li>
</ul>

<p><br></p>

<h3 id="multidimensionalassociations">Multi-Dimensional Associations</h3>

<p><em>multi-dimensional</em> 의 예는</p>

<p>(1) <strong>inter-dimension association rules</strong> (no repeated pred)</p>

<p><code>age(X, "18-25") ∩ occupation(X, "student") =&gt; buys(X, "coke")</code></p>

<p>(2) <strong>hybrid-dimension association rules</strong> (repeated pred)</p>

<p><code>age(X, "18-25") ∩ buys(X, "popcorn") =&gt; buys(X, "coke")</code></p>

<p><em>attribute</em> 는 <em>categorical</em> 이거나 <em>quantitative</em> 일 수 있습니다. </p>

<p><br></p>

<h3 id="quantitativeassociations">Quantitative Associations</h3>

<p><em>numerical attribute</em> (e.g <em>age, salary</em>) 를 마이닝 하기 위해 다양한 <em>method</em> 를 사용할 수 있습니다.</p>

<p>(1) static discretization based on prefefined concept hierarchies. data cube-based aggregation</p>

<p>(2) dynamic discretization based on data distribution</p>

<p>(3) clustering: distance-based association. first one-dimensional clustering, then association</p>

<p>(4) deviation analysis</p>

<p><br></p>

<h3 id="negativecorrelations">Negative Correlations</h3>

<p><em>rare pattern</em> 과 <em>negative pattern</em> 은 다릅니다.</p>

<p>(1) <strong>Rare patterns</strong></p>

<ul>
<li>아주 낮은 <em>support</em> 지만, 롤렉스 시계를 사는 행위처럼 중요할 수 있습니다</li>
<li><em>individualized</em>, <em>group-based min support</em> 를 다양한 아이템 그룹에 설정해서 마이닝합니다.</li>
</ul>

<p>(2) <strong>Negative patterns</strong></p>

<ul>
<li>자동차를 동시에 2개 사는것처럼, 같이 일어나는 경우가 드뭅니다 (<em>unlikely to happen together</em>)</li>
</ul>

<p><br></p>

<p><em>negative pattern</em> 은 어떻게 마이닝할까요? 한가지 방법은 <em>lift</em> 에서 사용했던 <em>support-based definition</em> 을 이용하는 것입니다.</p>

<ul>
<li><code>s(A ∪ B) &lt;&lt; s(A) X s(B)</code></li>
</ul>

<p>이 정의는 작은 <em>transaction dataset</em> 에서는 통하지만, 데이터 크기가 커지면 적용되지 않습니다.</p>

<p>(1) 전체 200개의 트랜잭션에 대해</p>

<ul>
<li><code>s(A∪B) = 0.005, s(A) x s(B) = 0.25, s(A∪B) &lt;&lt; s(A) X s(B)</code></li>
</ul>

<p>(2) 전체 10^5 개의 트랜잭션에 대해</p>

<ul>
<li><code>s(A∪B) = 1/10^5, s(A) x s(B) = 1/10^3 X 1/10^3, s(A∪B) &gt;&gt; s(A) X s(B)</code></li>
</ul>

<p>이전에 봤었던 <em>null transaction</em> 때문입니다. <em>support-based definition</em> 은 <em>not null-invariant</em> 입니다.</p>

<p>이를 해결하기 위해 <em>Kulczynski measure-based definition</em> 을 이용하면</p>

<p><img src="http://latex.codecogs.com/gif.latex?%28P%28A%7CB%29%20&amp;plus;%20P%28B%7CA%29%29%20/%202%20%3C%20%5Cepsilon" alt=""></p>

<p>여기서 <code>ɛ</code> 는 <em>negative pattern threshold</em> 를 의미합니다. 만약 위 수식이 <code>ɛ</code> 보다 작으면 <em>negatively correlated</em> 란 뜻이지요. </p>

<p><br></p>

<h3 id="compressedpatterns">Compressed Patterns</h3>

<p>때로는 너무 많아 의미가 없는 <em>scattered pattern</em> 때문에 <em>compressed pattern</em> 을 마이닝 할 필요가 있습니다. </p>

<p><em>compressed pattern</em> 인 <em>closed pattern</em> 과 <em>max pattern</em> 의 정의를 복습해보면</p>

<ul>
<li><strong>closed pattern:</strong> A pattern <code>x</code> is <strong>closed</strong> if <code>x</code> is frequent, and there exists no super pattern <code>Y ⊃ X</code> with the same support as <code>X</code></li>
<li><strong>max pattern:</strong> A pattern <code>X</code> is a <strong>max pattern</strong>. if <code>X</code> is frequent and there exists no frequent super-pattern <code>Y ⊃ X</code></li>
</ul>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/compressed_pattern.jpg" alt=""></p>

<p>예를 들어 위 그림에서 <code>P1, 2, 3, 4, 5</code>는 모두 <em>closed</em> 고, <code>P3</code> 는 <em>max pattern</em> 입니다. <em>P3</em> 만 남기자니 <em>information loss</em> 가 너무 많고, 다 남기자니 엣지가 없습니다. <code>P2, P3, P4</code> 정도면 적당할 것 같습니다.</p>

<p>이 적당한 정도를 결정하기 위해 <em>pattern distance measure</em> 을 사용할 수 있습니다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?Dist%28P_1%2C%20P_2%29%20%3D%201%20-%20%7B%7CT%28P_1%29%20%5Ccap%20T%28P_2%29%7C%20%5Cover%20%7CT%28P_1%29%20%5Ccup%20T%28P_2%29%7C%7D" alt=""></p>

<p>그리고 이 <em>distance</em> 값을 이용해 <em>δ-cluserting</em> 을 합니다. </p>

<ul>
<li><strong>δ-clustering:</strong> For each pattern <code>P</code>, find all patterns which can be expressed by <code>P</code> and whose distance to within <code>δ</code> (<em>δ-cover</em>)</li>
</ul>

<p><br></p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/redundancy_aware_top_k.jpg" alt=""></p>

<p><em>Redundancy-Aware Top-k pattern</em> 이란 기법도 있습니다.</p>

<p><code>(a)</code> 가 본래 패턴이고, <em>traditional top-k</em> 기법으로는 가장 컴팩트한(진한) 3개의 패턴만 남깁니다. 따라서 우측 클러스터는 버려지죠.</p>

<p>이를 막기 위해 클러스터별로 하나씩 남기는 <code>(d)</code> <em>summarization</em> 을 이용할 수도 있으나, 이건 중요한 것만을 돌려주지 않습니다. </p>

<p>따라서 두 방법을 조합한 <code>(b)</code>, 중복을 허용하는 <em>redundancy-aware top-k</em> 를 이용하면 적절한 패턴을 남기고, 나머지는 버릴 수 있습니다.</p>

<p>이를 위해 <em>MMS (Maximal Marginal Significance)</em> 메소드를 사용할 수 있습니다.</p>

<p><br></p>

<h3 id="colossalpatterns">Colossal Patterns</h3>

<p><em>long pattern mining</em> 은 소셜 네트워크 분석이나, 바이오인포메틱스, 소프트웨어 엔지니어링등 다양한 분야에서 필요로 합니다. 그러나, 지금까지 우리가 본건 길이가 10 보다 적은 패턴을 마이닝하는 기법들이었습니다.</p>

<p><em>long pattern</em> 을 분석하기 어려운 이유는 지난시간에 봤듯이 <em>downward closure property</em> 때문입니다. <em>frequent pattern</em> 의 <em>sub-pattern</em> 은 적어도 그만큼은 빈번하기 때문에, 패턴의 길이가 길고 <em>frequent</em> 하다면, 그 수많은 서브패턴을 분석해야 하는 것이지요.</p>

<p><em>BFS (e.g Apriori)</em>, <em>DFS (e.g FPgrowth)</em> 등 무엇을 이용하든 수 많은 패턴을 검색해야 하고, <em>combinatorial explosion</em> 과 마주할 수 밖에 없습니다.</p>

<p><code>40C20</code> 컴비네이션의 경우 기존에 존재하는 가장 빠른 마이닝 알고리즘들(e.g FP-Close, LCM)도 계산을 완료하지 못하는 경우가 많습니다. 그러나 놀랍게도 <em>pattern-fusion</em> 알고리즘은 1초만에 결과를 돌려줍니다.</p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/pattern_fusion1.jpg" alt=""></p>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/pattern_fusion2.jpg" alt=""></p>

<p>즉, 작은 <em>core pattern</em> 을 모아 <em>colossal pattern</em> 을 만들어 낸다는 것이지요.</p>

<ul>
<li><strong>core patterns</strong> of a colossal pattern <code>α</code>: A set of subpatterns of <code>α</code> that cluster around <code>α</code> by sharing a similar support</li>
</ul>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/robustness_of_colossal_pattern.jpg" alt=""></p>

<p><em>core pattern</em> 에 대한 더 엄밀한 정의는 위와 같습니다.</p>

<p><em>frequent pattern</em> <code>α</code> 에 대해, <em>sub-pattern</em> 인 <code>β</code> 는  다음을 만족하면 <em>τ-core pattern</em> 입니다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?%7B%7CD_%5Calpha%7C%20%5Cover%20%7CD_%5Cbeta%7C%7D%20%5Cgeq%20%5Ctau%5C%20%28where%5C%20%5Ctau%5C%20is%5C%20core%5C%20ratio%29" alt=""></p>

<p>그리고 패턴 <code>α</code> 에서 <code>d</code> 만큼의 아이템을 제거해도, 여전히 <em>τ-core pattern of α</em> 이면 <code>α</code> 를 <em>(d, τ)-robust</em> 라 부릅니다. 따라서 <code>d</code> 만큼의 아이템이 있거나 없어도, 코어패턴이므로 전체 숫자는 <code>2^d</code> 만큼의 코어패턴을 만들 수 있습니다.</p>

<p>그러므로 <em>colossal pattern</em> 이라면, 정말 많은 수의 <em>core pattern</em> 을 만들 수 있습니다. 그리고 이런 <em>core pattern</em> 은  <em>distance</em> 가 충분히 작으므로 <em>dense ball</em> 형태로 뭉칩니다. 결과적으로 <em>random pattern space</em> 에서 패턴을 뽑으면, <em>dense ball</em> 내의 패턴일 확률이 굉장히 높습니다.</p>

<p>이를 기반으로한 <em>Pattern-Fusion Algorithm</em> 은</p>

<ol>
<li><p><strong>Initialize (creating initial pool)</strong>: </p></li>
<li><p>Use an existing algorithm to min all frequent patterns up to a small size (e.g 3)</p></li>
<li><p><strong>Iteration (iterative pattern fusion):</strong> </p></li>
<li><p>At each iteration, <code>K</code> seed patterns are randomly picked from the current pattern pool</p></li>
<li>For each seed pattern thus picked, we find all the patterns within a bounding ball centered at the seed pattern</li>
<li>All these patterns found are fused tohether to generate a set of super-patterns</li>
<li><p>All the super-patterns thus generated form a new pool for the next iteration</p></li>
<li><p><strong>Termination:</strong></p></li>
<li><p>when the current poll contains no more than <code>K</code> patterns at the beginning of an iteration</p></li>
</ol>

<p><br></p>

<h2 id="6constraintbasedmining">6. Constraint-Based Mining</h2>

<p>이번시간에 배울 내용은 다음과 같습니다.</p>

<ul>
<li>Different Pruning Strategies</li>
<li>Constrainted Mining with Pattern Anti-Monotonicity</li>
<li>Constrainted Mining with Pattern Monotonicity</li>
<li>Constrainted Mining with Data Anti-Monotonicity</li>
<li>Constrainted Mining with Succinct Constraints</li>
<li>Constrainted Mining with Convertible Constraints</li>
<li>Hanlding Multiple Constraints</li>
</ul>

<p>왜 <em>Constraint-Based Mining</em> 이 필요할까요? 데이터셋에 있는 <strong>all</strong> 패턴을 <strong>autonomously</strong> 하게 찾는것은 불가능합니다. 이는 <em>compressed pattern mining</em> 에서 언급했듯이, 너무 많은 패턴이 있기 때문이지요. 특히 데이터셋이 커지면 사용자가 관심 없는 데이터가 기하급수적으로 늘어납니다.</p>

<p>따라서 패턴 마이닝은 사용자가 무엇을 원하는지 <em>data mining query language</em> 나 <em>GUI</em> 를 통해서 직접 명령을 내리는 <em>interactive</em> 한 과정이 되야 합니다.</p>

<p><em>constraints</em> 를 이용하면 다음과 같은 장점이 있습니다.</p>

<ul>
<li><strong>user flexibility:</strong> provides <strong>constraints</strong> on what to be mined</li>
<li><strong>optimization:</strong> explores such constraints for efficient mining</li>
</ul>

<p><br></p>

<h3 id="differentpruning">Different Pruning</h3>

<p><em>constraints</em> 에 따라 <em>pruning strategy</em> 달라집니다.</p>

<p>(1) <strong>pattern space pruning constraints</strong></p>

<ul>
<li><em>anti-monotonic:</em> if constraint <code>c</code> is violated, its further mining can be terminated</li>
<li><em>monotonic:</em> if <code>c</code> is satisfied, no need to check <code>c</code> agina</li>
<li><em>succinct:</em> <code>c</code> can be enforced by directly manipulating the data</li>
<li><em>convertible:</em> <code>c</code> can be converted to monotonic or anti-monotonic if items can be propery ordered in processing</li>
</ul>

<p>(2) <strong>data space pruning constraints</strong></p>

<ul>
<li><em>data succinct:</em> data space can be pruned at the initial pattern mining process</li>
<li><em>data anti-monotonic:</em> if a transaction <code>t</code> doesn't satisfy <code>c</code>, then <code>t</code> can be pruned to reduce data processing effort</li>
</ul>

<p><br></p>

<h3 id="antimonotonicity">Anti-Monotonicity</h3>

<p><em>constaint</em> <code>C</code> 는 다음의 경우에 <em>anti-monotone</em> 이라고 말합니다.</p>

<ul>
<li>If an itemset <code>S</code> <strong>violates</strong> constraint <code>C</code>, so does any of its superset</li>
<li>That is, mining on itemset <code>S</code> can be terminated</li>
</ul>

<p>예를 들어서 다음의 제약조건은 <em>anti-monotone</em> 입니다</p>

<ul>
<li><code>sum(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &lt;= 15</code> </li>
<li><code>support(S) &gt;= k</code></li>
</ul>

<p>따라서 <em>Apriori pruning</em> 은 본질적으론 <em>anti-monotonic constaint</em> 에 기반합니다.</p>

<p>반대로 <code>sum(S.price) &gt;= v</code> 는 <em>not anti-monotone</em> 입니다.</p>

<p><br></p>

<h3 id="monotonicity">Monotonicity</h3>

<p><em>itemset</em> <code>S</code> 가 <em>constaint</em> <code>c</code> 를 만족할때, <code>S</code> 의 <em>superset</em> 도 그러하다면 <code>c</code> 는 <em>monotone</em> 이라 부릅니다. 다음은 모두 <em>monotone</em> 입니다.</p>

<ul>
<li><code>sum(S.price) &gt;= v</code></li>
<li><code>min(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &gt;= 15</code></li>
</ul>

<p><br></p>

<h3 id="dataantimonotonicity">Data Anti-Monotonicity</h3>

<p><em>data anti-monotone</em> 는 <em>transaction</em> 기반으로 <em>pruning</em> 을 진행해 나아갑니다. 정의는 이렇습니다.</p>

<ul>
<li>In the mining process, if a data entry <code>t</code> cannot satisfy a pattern <code>p</code> under <code>c</code>, <code>t</code> cannot satisfy <code>p</code>'s superset either</li>
</ul>

<p>다음은 모두 <em>data anti-monotone</em> 입니다.</p>

<ul>
<li><code>sum(S.price) &gt;= v</code> </li>
<li><code>min(S.price) &lt;= v</code></li>
<li><code>range(S.profit) &gt;= 25</code></li>
</ul>

<p><img src="https://raw.githubusercontent.com/1ambda/1ambda.github.io/master/assets/images/pattern-discovery/week2/data_anti_monotone.jpg" alt=""></p>

<p><br></p>

<h3 id="succinctconstaints">Succinct Constaints</h3>

<p><em>succintness</em> 는 <em>data space</em> 와 <em>pattern space</em> 를 모두 <em>pruning</em> 합니다.</p>

<blockquote>
  <p>if the constaint <code>c</code> can be enforced by directly manipulating the data</p>
</blockquote>

<p>(1) To find those patterns without item <code>i</code></p>

<p><em>pattern space pruning</em> 처럼 <code>i</code> 을 DB 에서 제거합니다.</p>

<p>(2) To find those patterns containing item <code>i</code></p>

<p><em>data space pruning</em> 처럼 <em>i-projected</em> DB 만 마이닝 합니다.</p>

<p>(3) <code>min(S.price) &lt;= v</code> is succinct</p>

<p><code>price &lt;= v</code> 에서 시작해서, <em>high-price item</em> 을 제거해 나가기 때문에 <em>pattern + data space pruning</em> 입니다.</p>

<p>(4) <code>sum(S.price) &gt;= v</code> is not succinct</p>

<p><em>itemset</em> <code>S</code> 의 <em>sum</em> 이 점점 크기때문에, 미리 제거할 수 없습니다.</p>

<p><br></p>

<h3 id="convertibleconstaints">Convertible Constaints</h3>

<blockquote>
  <p>Convert tough constaints into (anti-) monotone by proper ordering of items in transactions</p>
</blockquote>

<p><code>avg(S.profit) &gt; 20</code> 같은 경우는 <em>anti-monotone</em> 도 <em>monotone</em> 도 아닙니다. </p>

<ul>
<li>만약 현재 만족한다고 했을때, 아주 작은 <code>profit*</code> 을 가지는 아이템을 추가하면 <em>violation</em> 이고,</li>
<li>만약 현재 위반한다고 했을때, 아주 큰 값을 추가하면 <em>satisfaction</em> 이기 때문입니다.</li>
</ul>

<p>이런 <em>constaint</em> 에 대해서도 <em>pruning advantage</em> 를 얻고자 하는것이 바로 <em>convertible constaints</em> 의 목적입니다. 가능하면 <em>anti-monotone</em> 이 더 선호되는데, 이는 <em>monotone</em> 일 경우 검사만 하지 않고, <em>anti-monotone</em> 일 경우 <em>super-pattern</em> 을 날려버릴 수 있기 때문입니다.</p>

<ul>
<li>만약 <code>c: avg(S.profit &gt; 20)</code> 에 대해서 </li>
<li><em>itemset</em> 을 내림차순으로 <code>S: {a, g, f, b, h, d, c, e}</code> 정렬하고 </li>
<li><code>avg(ab) = 20</code>, <code>g = 20</code> 이면</li>
</ul>

<p><em>constaint</em> <code>C</code> 는 <em>anti-monotone</em> 이라 할 수 있습니다. 왜냐하면 패턴 내부가 <code>profit</code> 을 기준으로 내림차순으로 되어서, 어떤 <em>item entry</em> 를 뽑아도 <code>c</code> 를 만족할 수 없기 때문입니다.</p>

<p>아쉽게도 이 방법은 <em>level-wise candidate generation</em> 을 하는 <em>Apriori</em> 알고리즘엔 적용되지 않습니다.</p>

<p><br></p>

<h3 id="hanldingmultipleconstaints">Hanlding Multiple Constaints</h3>

<p>다수개의 <em>constaints</em> 를 사용하는것은 좋으나, <em>item ordering</em> 에서 충돌이 생길 수 있습니다. 이럴땐 먼저 하나의 <em>constaint</em> 기준으로 정렬하고, 나머지는 <em>projected databases</em> 를 마이닝할때 하면 좋습니다.</p>

<p>예를 들어 다음 두개의 <em>constaints</em> 가 있을때</p>

<ul>
<li><code>c1: avg(S.profit) &gt; 20</code></li>
<li><code>c2: avg(S.price) &lt; 50</code></li>
</ul>

<p><code>c1</code> 이 더 강력한 <em>pruning power</em> 가 있다고 생각하고, <code>c1</code> 먼저  <em>anti-monotone</em> 으로 변경 한 후, 각 <em>projected-DB</em> 에서 트랜잭션을 오름차순으로 정렬해 <code>c2</code> 를 마이닝에 이용합니다.    </p>

<p><br></p>

<h3 id="refs">Refs</h3>

<p>(1) <a href="https://www.behance.net/gallery/625042/Icon-and-pattern-with-a-marketing-theme">Title image</a> <br>
(2) <strong>Pattern Discovery</strong> by <em>Jiawei Han</em> </p>
    </section>

    <footer>
      <section class="author_info margin_top_big">
        <div class="alignleft border rad_circle" style="height: 87px; width: 87px; background-image: url(http://www.gravatar.com/avatar/aa2032ba2302419e3c2ede54f1fbf687?d=404&amp;s=250); background-size: cover;"></div>
        <p class="margin_left_medium text small">Author</p>
        <p class="margin_left_medium text bold"><a href="http://1ambda.github.io">1ambda</a></p>
        <p class="margin_left_medium text small">Functional, Scala, Akka, Rx and Haskell</p>
      </section>
    </footer>


    <div id="disqus_thread" class="margin_top_big"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = '1ambda'; // required: replace example with your forum shortname
  var disqus_identifier = '105';
  var disqus_url = 'http://1ambda.github.io/pattern-discovery-2/';

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
    </article>
</main>


  <script src="../assets/fitvids/jquery.fitvids.js"></script>
<script>
$(document).ready(function(){
  // Target your .container, .wrapper, .post, etc.
  $("section").fitVids();
});
</script>

  <footer class="blog_info margin_top_big padding_medium text center">
    <h5 class="text book small">© 2015 <a href="../">Old Lisper</a>. All rights reserved.</h5>
    <h5 class="text book small"><a href="https://github.com/dreyacosta/velox" target="_blank" class="text bold">Velox theme</a> by <a href="http://dreyacosta.com/">David Rey</a></h5>
    <h5 class="text book small">Proudly published with <a href="http://ghost.org"><span>Ghost</span></a></h5>

  </footer>

  <script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = '1ambda'; // required: replace example with your forum shortname

/* * * DON'T EDIT BELOW THIS LINE * * */
(function () {
 var s = document.createElement('script'); s.async = true;
 s.type = 'text/javascript';
 s.src = '//' + disqus_shortname + '.disqus.com/count.js';
 (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
 }());
</script>


  </body>
  