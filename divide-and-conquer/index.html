<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/Blog">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />

  <title>Divide and Conquer</title>
  <meta name="description" content="" />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Divide and Conquer">
  <meta name="twitter:description" content="Divide and Conquer (분할 정복) 을 배운다. merge, quick sort 를 배우고 이 과정에서 왜 combine 단계가 O(n) 이 되어야 하는지 알아본다. 뒷부분에서는 Big O 뿐만 아니라 master method, decomposition approach 를 이용해 성능을 분석한다. Divide and Conquer 각 level 의 문제 갯수는 2^j (j = 0, 1, 2">
  <meta name="twitter:creator" content="@yourTwitterUsername">
  <meta name="twitter:image" content="">
  <meta name="twitter:url" content="http://1ambda.github.io/divide-and-conquer/">
  <meta name="twitter:domain" content="http://1ambda.github.io">

  

  <link rel="author" href="https://plus.google.com/101105410053351451441?rel=author" />

  <link rel="shortcut icon" href="../favicon.ico">

  <link rel="stylesheet" type="text/css" href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" />
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Droid+Serif" />
  <link rel='stylesheet' type='text/css' href="http://fonts.googleapis.com/css?family=Open+Sans:600,300" />
  <link rel="stylesheet" type="text/css" href="../assets/stylesheets/xpressio.css" />
  <link rel="stylesheet" type="text/css" href="../assets/1ambda/1ambda.css" />
  <script type="text/javascript" src="../assets/1ambda/modernizr.js">
  </script>
  <script type="text/javascript" src="../assets/1ambda/detectizr.min.js">
  </script>

  <!--load css if windows -->
  <script type="text/javascript">
    if (Modernizr.windows) {
      file = location.pathname.split( "/" ).pop();
      link = document.createElement( "link" );
      link.href = "/assets/1ambda/1ambda_windows.css";
      link.type = "text/css";
      link.rel = "stylesheet";
      link.media = "screen,print";
      document.getElementsByTagName("head")[0].appendChild( link );
    }
  </script>


  
  <link rel="stylesheet" href="../assets/highlight/styles/github.css">
<script src="../assets/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


  <meta name="generator" content="Ghost 0.5" />
<link rel="alternate" type="application/rss+xml" title="Old Lisper" href="../rss">
<link rel="canonical" href="http://1ambda.github.io/divide-and-conquer/" />

  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-52181619-1', '1ambda.github.io');
  ga('send', 'pageview');
</script>

  
</head>
<body>

  
  <script src="../public/jquery.js?v=6f23f02e25"></script>

  

<header class="site_width text center padding_top_big margin_bottom_big">
  
  <h1 class="blog_title margin_bottom_small"><a href="http://1ambda.github.io">Old Lisper</a></h1>
  <h4 class="text book">Lisp, Emacs, Scala</h4>
  
  <div class="social border solid top_small bottom_small padding_medium">
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="/about-me"><i class="fa fa-user"></i> <span class="margin_left_small desktop">About me</span></a></h6>
  <h6 class="text book color c_black_medium without_margin padding_right_big"><a href="http://kr.linkedin.com/in/1ambda" target="_blank"><i class="fa fa-linkedin-square"></i> <span class="margin_left_small desktop">Linkedin</span></a></h6>
  <h6 class="text book color c_black_medium without_margin"><a href="http://github.com/1ambda" target="_blank"><i class="fa fa-github"></i> <span class="margin_left_small desktop">GitHub</span></a></h6>
</div>

</header>

<main class="site_width" role="main">
  <article class="post tag-algorithm tag-divide-and-conquer tag-master-method tag-merge-sort tag-quick-sort tag-decomposition-principle">

    

    <header class="text center margin_bottom_medium">
      <h5 class="text book small uppercase color c_black_light margin_bottom_small">Posted in <a href="../tag/algorithm">Algorithm</a>, <a href="/tag/divide-and-conquer/">divide and conquer</a>, <a href="/tag/master-method/">master method</a>, <a href="/tag/merge-sort/">merge sort</a>, <a href="/tag/quick-sort/">quick sort</a>, <a href="/tag/decomposition-principle/">decomposition principle</a></h5>
      <h1 class="margin_bottom_medium">Divide and Conquer</h1>
      <h5 class="text book small uppercase color c_black_light margin_bottom_small"><time datetime="2014-10-29">Wednesday, October 29, 2014</time>
      <br/><br/>
       <a href="http://1ambda.github.io/divide-and-conquer/#disqus_thread">Comment</a>
      </h5>
    </header>

    <section>
      <p><em>Divide and Conquer (분할 정복)</em> 을 배운다. <em>merge, quick sort</em> 를 배우고 이 과정에서 왜 <em>combine</em> 단계가 <code>O(n)</code> 이 되어야 하는지 알아본다. 뒷부분에서는 <em>Big O</em> 뿐만 아니라 <em>master method</em>, <em>decomposition approach</em> 를 이용해 성능을 분석한다.</p>

<h3 id="divideandconquer">Divide and Conquer</h3>

<p>각 level 의 문제 갯수는 <code>2^j (j = 0, 1, 2, ... , log2n)</code> 이고 문제의 사이즈는 <code>n / 2^j</code> 이므로 연산수를 <code>k</code> 라 하면, 각 레벨에서 연산 수는 <code>k * n</code>, 레벨의 <em>depth</em> 가 <code>log2n + 1</code> 이므로, </p>

<p><em>merge sort</em> 같은 경우는 연산수 <code>k = 6</code> 에서 <code>6n (log2n + 1)</code></p>

<p>Big O 는 <code>O(f(n))</code> 이라 했을때 <em>at most</em>, <code>f(n)</code> 에 proportional 하므로 upper 바운드. <br />
반면 Omega 는 <code>omega(f(n))</code> 이라 했을 때 <em>at least</em> <code>f(n)</code> 에 proportional 하므로 lower 바운드.</p>

<p>분할 정복의 핵심은 각 sub-problem 에서 연산 수를 o(n) 으로 맞출 수 있느냐 없느냐, 맞춘다면 nlogn 알고리즘이 되는 것이다. </p>

<p>알고리즘은 3단계로 구성된다.</p>

<p>(1) Divide <br />
(2) Conquer sub problems <br />
(3) combine (merge)  </p>

<p>여기서 중요한건, combine 단계인데 이게 O(n) 이기만 하면 전체 알고리즘의 성능을 O(nlogn) 으로 보장할 수 있음.</p>

<h3 id="mastermethodmotivation">Master Method: Motivation</h3>

<p>T(n) 을 O(n) 으로 upper bound 를 구하긴 했지만 O(n) 연산 수 구하는게 좀 힘들다. 재귀 호출의 갯수나, 문제의 분할 사이즈로 O(n) 을 쉽게 구해보자.</p>

<p>가우스 곱셈? 의 경우에 T(n) &lt;= 4 * T(n/2) + O(n)</p>

<p>그러나 더 작아질 수 있음. (a+b)(c+d) 에서 ad+bc = (a+b)(c+d) - ad - bd 로 구할 수 있음</p>

<p>즉 3개의 부분식만 구해도 됌.</p>

<p>T(n) &lt;= 3 * T(n/2) + O(n)</p>

<p>머지소트는 2 * T(n/2) + O(n) 쯤 되니까 가우스보다 더 낫긴 함. 그럼 가우스의 그것은 얼마일까?</p>

<h4 id="mastermethod">Master Method</h4>

<p><em>Master method</em> 는 재귀 문제의 러닝타임을 구하는데 <em>black box</em> 같은 역할을 한다. 대강의 코드만으로도 러닝타임을 추측할 수 있다.</p>

<p>그러나 <em>master method</em> 는 가정을 하나 하는데, 바로 모든 문제가 같은 사이즈로 분할 된다는 것.</p>

<blockquote>
  <p>All sub priblems have equal size</p>
</blockquote>

<p><code>n</code> 이 충분히 작다면, <code>T(n)</code> 은 상수라 볼 수 있고 만약 <code>n</code> 이 충분히 크다면 <em>master method</em> 는 다음의 포맷을 가진다.</p>

<p><img src="https://acrocontext.files.wordpress.com/2014/01/master-method.png?w=300&amp;h=160" align="center" />  </p>

<p align="center">(<a href='https://acrocontext.wordpress.com'>https://acrocontext.wordpress.com</a>)</p>

<p>여기서 <code>a</code> 는 재귀 함수 호출의 수고, <code>b</code> 는 분할된 문제의 사이즈다. <code>d</code> 는 <em>combine</em> 스텝에서 사용하는 함수의 러닝타임의 지수다. (<em>merge-sort</em> 에서 머징하는 함수라 보면 된다.)</p>

<ul>
<li><code>a</code>: number of recursive calls (<code>&gt;= 1</code>)  </li>
<li><code>b</code>: input size shrinkage factor (<code>&gt; 1</code>)  </li>
<li><code>d</code>: exponent in running time of <em>combine step</em> (<code>&gt;= 0</code>)</li>
</ul>

<p>이제 몇 가지 예제를 좀 살펴보자.</p>

<p><em>merge sort</em> 의 경우는 <code>a = 2, b = 2, d = 1</code> 이므로 <code>2 = 2^1</code> 이어서 <code>O(n^1 * logn)</code> 즉 <code>O(nlogn)</code> 의 러닝타임을 가진다.</p>

<p><em>binary search</em> 는 문제 수가 절반으로 줄긴 하나 반쪽만 사용하고, 매 재귀호출 마다 한번의 비교만 하므로 <code>a = 1, b = 2, d = 0</code> 이므로 <code>a = b^d</code> 는 <code>1 = 1^1</code> 이 되어 <code>O(nlogn)</code> 이 된다. </p>

<p>가우스 곱셈은 <code>a = 3, b = 2, d = 1</code> 이므로 <code>O(n^log2_3)</code> 이 된다. 더 정확히는 <code>O(n^1.59)</code> <em>merge-sort</em> 보다 빠르진 않지만 <em>quadratic</em> 보단 빠르다.</p>

<p><em>strassen</em> 행렬 곱셈은 어떨까? <code>a = 7, b = 2, d = 2</code> 에서 마찬가지로 <em>case 3</em> 이므로 <code>O(n^log2_7)</code> 이다. <code>O(n^2.81)</code> 쯤 되므로 <code>O(n^3)</code> 보다는 훨씬 낫다.</p>

<p><em>merge-sort</em> 에서 <code>d = 2</code> 라면 <code>O(n^2)</code> 이 나온다. 사실 일반적으로 생각하기에는 <code>O(n^2 * logn)</code> 이 나올거 같은데, 사실 이건 <em>upper bound</em> 이므로 <code>O(n^2)</code> 이 좀 더 나은 <em>upper bound</em> 임을 알 수 있다. 이 사실은  <em>master method</em> 를 이용하면 수학적으로 더 근사한 값을 찾아낼 수 있다는걸 알려준다.</p>

<h4 id="proofmastermethod">Proof: Master Method</h4>

<p>재귀의 각 단계를 <code>j = 0, 1, 2, ... , logb_n (base b)</code> 라 하면 각 단계에서는 <code>a^j</code> 사이즈의 <em>sub-problem</em> 수와 <code>n / b^j</code> 사이즈의 문제가 있다. </p>

<p>단계 <code>j</code> 에서의 연산은 <code>a^j * c * (n / b^j)^d</code> 즉 <em>문제의 수 x 각 문제의 사이즈와 일어나는 거기서 일어나는 연산 수</em> 로 정의할 수 있다. 수식을 <code>j</code> 로 다시 정리하면</p>

<p>각 단계의 <em>sub problem</em> 에서 일어나는 연산은 <code>c * n ^d * (a / b^d)^j</code> 다. 따라서 전체 단계를 구하려면 여기에 시그마를 씌우면 된다.</p>

<p>식을 좀 더 자세히 보면</p>

<ul>
<li><em><code>a</code>:</em> rate of sub problem proliferation <em>(RSP)</em> </li>
<li><em><code>b^d</code>:</em> rate of work shirinkage <em>(RWS)</em></li>
</ul>

<p><code>d</code> 가 <code>n^d</code> 에도 섞여있어 좀 복잡하긴 한데 느낌만 알아보자면 <code>b = 2, d = 1</code> 일때는 <em>sub-problem</em> 당 문제가 1/2 씩 줄어든다. 하지만 <code>b = 2, d  = 2</code> 라면 문제의 수가 2배가 될때 문제 사이즈는 4배가 되고, <code>b^d = 4</code> 가 되어 1/4 만큼의 연산만 줄어든다. 따라서 <code>d</code> 가 커지는 건 생각보다 영향이 큰 걸 알 수 있다.</p>

<p>위 식으로부터 다음의 관계를 이끌어 낼 수 있다.</p>

<p>(1) if <em>RSP &lt; RWS</em>, then the amount of work is decreasing with the recursion level <code>j</code> <br />
(2) if <em>RSP > RWS</em>, then the amount of work is increasing with the recursion level <code>j</code> <br />
(3) if <em>RSP = RWS</em>, then the amount of work is same at every recursion level <code>j</code>  </p>

<p>따라서 <code>(3)</code> 의 경우 각 단계에서의 연산이 <code>c* n^d * 1^j</code> 이므로 깊이 <code>logb_n (base b)</code> 을 곱하면 <code>O(n^d * logn)</code> 이다. <em>(<code>a</code>, <code>b</code> 는 문제의 사이즈와 관계가 없다 그리고 더 정확히는 시그마를 더하면 <code>O(n^d * (1 + logb_n)</code> 이다)</em> </p>

<p><code>(2)</code> 의 경우 깊이가 깊어질 수록 각 단계에서의 연산이 급격하게 줄어들고, 루트에서의 (<code>j = 0</code>) 연산이 가장 크므로 루트에서의 연산을 <em>upper bound</em> 로 보면 <code>O(n^d)</code> 라 볼 수 있다. </p>

<p>마지막으로 <code>(1)</code> 의 경우 깊이가 깊어질수록 연산이 늘어나고, 대충 생각하면 마지막 노드의 개수에 비례하는 <em>Big O</em> 를 가지리라는 생각을 해볼 수 있다. </p>

<p>좀 더 수식에 대한 이해를 얻기 위해 수학적으로 접근해 보자.</p>

<p><code>1 + r + r^2 + ... + r^k</code> 를 귀납법으로 풀면 <code>r^(k+1) - 1 / r - 1</code> 이란 값이 나온다. <code>(r != 1)</code> 이 때 </p>

<p><code>r &lt; 1</code> 이고 <code>k</code> 가 충분히 크다면 이 식은 <code>1 / (1 - r)</code> 이라 보아도 된다. 다시 말해서 <code>k</code> 와는 관련 없는 상수라 보아도 된다는 뜻이다. 그리고 첫번 째 항이 다른 것들의 합보다 크다고 볼 수 있다.</p>

<p><code>r &gt; 1</code> 이라 했을때, 우측 식 <code>r^(k+1) - 1 / r - 1</code> 은 <code>r^k * (1 + 1 / r - 1)</code> 보다 항상 작거나 같다는 사실을 알 수 있다 <em>(upper bound)</em> 다시 말해서 마지막 항 <code>r^k</code> 의 2배보다 작거나 같다는 사실을 알 수 있다. 이것도 <code>r = 2</code> 일때나 맥시멈 두배다. </p>

<p>1 부터 256까지 더해봐도 512 보다 작거나 같다는 사실을 알 수 있다. 다시 말해서 마지막 항이 그 전 모든 항을 합한 것 보다 크다.</p>

<p>이제 다시 <em>master method</em> 로 다시 돌아오자.</p>

<p><code>c* n^d * sigma(j) (a / b^d)^j</code> (<code>j = 0 to logb_n</code>) 에서 <code>a / b^d</code> 를 <code>r</code> 이라 두자.</p>

<p><em>RSP &lt; RWS (case 2)</em> 이면 <code>r &lt; 1</code> 이므로 시그마를 합해봐야 특정 상수다. <code>O(n^d)</code></p>

<p>반대로 <em>RSP > RSW (case 3)</em> 이면 <code>r &gt; 1</code> 이므로 시그마를 합해봐야 <code>r^k * 상수</code> 보다 작거나 같으므로 가장 큰 항 <code>r^k</code> 는 <code>(a / b^d)^logb_n</code> 이다. 여기서 <code>b^(-dlogb_n)</code> 이 <code>n^-d</code> 라는 사실을 이용하면 <code>O(a^logb_n)</code>만 남는다.</p>

<p>그런데, 재미있는 사실은 <code>logb_n</code> 이 마지막 단계이고, <code>a</code> 는 각 단계에서 분할되는 노드의 갯수이므로 <code>a^(logb_n)</code> 은 <em>recursion tree</em> 에서 <em>leave</em> 의 갯수다. </p>

<p>다시 말해서 마지막 단계에서의 노드의 갯수에 연산이 비례한다. 근데 처음에 우리가 봤던건 <code>n^(logb_n)</code> 아니었던가? 사실 로그를 배우면 위 두 식은 같다는걸 알 수 있다.</p>

<h3 id="quicksort">Quick Sort</h3>

<p>퀵소트는 평균적으로 <code>O(n logn)</code> 성능을 보여주며 <em>in-place</em> 로 작동하는 인기있는 정렬 알고리즘이다.</p>

<p><em>key idea</em> 는 <em>pivot</em> 을 중심으로 문제를 좌우로 분할하는 것이다.   <em>less than pivot</em> 들은 왼쪽에, <em>greater than pivot</em> 들은 우측에 놓음으로써 최소한 한번의 분할당 하나의 원소 <em>(pivot)</em> 은 자리를 잡는 다는 것을 보장한다.</p>

<p>퀵소트의 매 호출당 일어나는 <em>partition (분할)</em> 은 다음의 두 특징을 가진다.</p>

<p>(1) linear time, <code>O(n)</code> <br />
(2) no extra memory</p>

<p>대강의 로직은 이렇다. <code>Quicksort(array A, length n)</code> 에 대해서</p>

<p>(1) if <code>n = 1</code> return <code>A</code> <br />
(2) <code>p</code> = choose <code>Pivot(A, n)</code> <br />
(3) partition <code>A</code> round <code>p</code> => <code>L, R</code> <br />
(4) recursively solve <code>L</code>, <code>R</code></p>

<p>보면 알겠지만 <em>combine</em> 혹은 <em>merge</em> 스텝이 전혀 없다. </p>

<h4 id="partitioninplace">Partition: In-place</h4>

<p><code>O(n)</code> 의 추가 메모리를 사용하면 연산시간 <code>O(n)</code> 을 구현하기 쉽다. 추가 메모리 없이 어떻게 <code>O(n)</code> 으로 <em>partitioning</em> 을 구현할 수 있을까?</p>

<p>(1) 첫 번째 원소를 <em>pivot</em> 이라 놓고 <br />
(2) <em>pivot</em> 다음의 원소를 <code>i</code>, <code>j</code> 가 가리키게 한다. <br />
(3) <code>j</code> 보다 작은 원소들은 <em>partitioned</em> , 큰 원소는 <em>unpartitioned</em> 라 보고 <br />
(4) <code>i</code> 보다 작은 원소들은 <em>pivot</em> 보다 작은 값, 큰 원소들은 <em>pivot</em> 보다 큰 값이다. <br />
(5) <code>i &lt;= j</code> 이며, <code>i == j</code> 일때는 <code>j</code> 값을 증가시켜 원소를 비교 한뒤 <code>j</code> 에 있는 원소가 <code>i</code> 가 가리키는 원소보다 크면 <em>swap</em> 하고 <code>i += 1, j +=1</code> 아니면 <code>j += 1</code> 한다.</p>

<p>이해가 쉽게 그림을 첨부하면</p>

<p><img src="http://sadakurapati.files.wordpress.com/2013/10/qsort_1.png" align="center" /> <br />
<img src="http://sadakurapati.files.wordpress.com/2013/10/qsort_2.png" align="center" />  </p>

<p align="center">(<a href='http://sadakurapati.wordpress.com'>http://sadakurapati.wordpress.com</a>)</p>

<p>이런 로직으로 <code>n</code> 개의 원소를 순회하면, <code>n-1</code> 번 만큼 <code>j</code> 순회를 하고 최악의 경우 <code>n-1</code> 번의 <em>swap</em> 과 <em>i += 1</em> 연산이 일어난다.  다시 말해 각 원소마다 <code>O(1)</code> 연산이므로, <em>partition</em> 연산은 <code>O(n)</code> 이라 보장할 수 있다.</p>

<p><em>quick-sort</em> 는 귀납법으로 증명하기도 쉬운데, <code>P(n)</code> 이 1부터 <code>n</code> 까지의 정렬된 원소를 가지고 있는 배열이라고 하면, </p>

<p><code>P(1)</code> 임은 자명하고, 문제의 수 <code>k</code> 에 대해 퀵소트가 <code>P(k)</code> 일때  <code>P(k+1)</code> 임을 보이면 <code>P(n)</code> 에 대해서도 참임을 알 수 있다.</p>

<p>그런데, <code>P(k+1)</code> 에서 <em>pivot</em> 을 제외한 좌측과 우측의 사이즈를 <code>k1</code>, <code>k2</code> 라 하면 <code>k1, k2 &lt; k</code> 이다. 좌측 또는 우측이 없을 때라야 <code>k1 or k2 = k</code> 다. 이때 <code>P(k)</code> 가 참이므로 이보다 작거나 같은 <code>k1, k2</code> 의 문제 사이즈에 대해서도 참이다. 따라서 <code>P(k+1)</code> 도 참이다.</p>

<h4 id="choosingagoodpivot">Choosing a good pivot</h4>

<p>그럼 <em>pivot</em> 은 무엇을 기준으로 잡는게 좋을까? 어차피 비교에서 <code>i != p and j != p</code> 라면 구현에는 어느 위치에 잡던 문제가 없을것 같은데..</p>

<p>만약에 <em>pivot</em> 이 첫 번째 원소이고, 입력이 이미 정렬이 된 배열이라면 성능이 어떻게 될까? 바로 <code>O(n^2)</code> 이다. 왜냐하면 이미 정렬이 되어있으므로 문제가 1/2 로 분할되지 않기 때문이다. 배열 사이즈만 1씩 줄어들면서 재귀호출이 반복된다.</p>

<p>그럼 만약에, <em>pivot</em> 을 원소들의 <em>median (중앙값)</em> 으로 고른다면? 매 재귀마다 문제가 좌우로 분할되므로 <code>O(nlogn)</code> 이라 볼 수 있다.</p>

<p>근데 생각해 볼 거리가 있다. <em>pivot</em> 을 구하는 함수의 비용은 어떻게 되는걸까? 이것 또한 <code>O(n)</code> 이므로 전체 <em>partition</em> 의 비용은 <code>O(n)</code> 이라 보아도 된다.</p>

<h4 id="randomizedpivots">Randomized pivots</h4>

<p>그럼 만약에 <em>pivot</em> 을 무작위로 고르면 어떻게 될까 생각해 보자. <em>pivot</em> 을 무작위로 선택했을 때 한쪽이 <code>25-75%</code> 로 분할될 확률은 1/2 이다. </p>

<p>그리고 무작위로 <em>pivot</em> 을 선택했을때 첫번째 다음 재귀 호출에 넘겨질 배열의 길이의 기대값을 구하면, 다시 말해 <code>X</code> 를 <em>subproblem size</em> 라 했을때 <code>E(X)</code> 를 구하면</p>

<p><code>1/n * (0 + 1 + ... + (n - 1)) = (n - 1) / 2</code> 다.</p>

<p>여기서 잠깐 중요한 속성인 <em>linearity of expection</em> 을 설명하면 </p>

<blockquote>
  <p>모든 <em>random variable</em> <code>X</code> 의 합의 기대값은, 각 <code>X</code>의 기대값의 합과 같다.</p>
</blockquote>

<p><img src="http://www.opendatastructures.org/ods-java/img333.png" align="center" />  </p>

<p align="center">(<a href='http://www.opendatastructures.org'>http://www.opendatastructures.org</a>)</p>

<p><code>Xj(i)P(i)</code> 를 컬럼의 개수가 <code>j</code>, 행의 개수가 <code>i</code> 인 행렬의 원소로 보면 이 <em>linearity of expectation</em> 은 쉽게 이해할 수 있다. 이 속성은 꽤나 유용하다.</p>

<p>예를 들어 두개의 주사위를 독립적으로 굴린다고 할 때 나오는 값인 <em>random variable</em> <code>X1, X2</code> 에 대한 기대값을 직접 구하려면 36개의 <em>sample space</em> 를 살펴봐야 하는데, 그러지 말고 하나를 굴렸을때의 값을 구해 이걸 2배 하면 된다. 하나를 굴렸을때는 6개의 <em>sample space</em> 만 살피면 되니 금방 구한다.</p>

<p>로드 밸런싱문제에 <em>linearity of expectation</em> 을 적용해보자. <code>n</code>개의 서버가 있고 여기에 <code>n</code> 개의 프로세스를 랜덤하게 할당할때 한개의 서버에 할당될 프로세스의 기대값은 얼마일까? 다시 말해 평균적으로 몇개의 프로세스가 서버에 할당될까?</p>

<p><em>sample space</em> 는 <code>n</code> 개의 항끼리의 곱에서 항의 개수를 구하는 문제와 같으므로 <code>n^n</code> 이다.</p>

<p>이때 <code>Y</code> 를 첫 번째 서버에 할당된 프로세스 수의 합이라 하면 이때 <code>Y</code> 는 <code>sigma Xj (j = 1 to n, Xj = 1 or 0)</code>이다.</p>

<p><code>E[Y]</code> 를 구하는 것이 본래의 문제인데 가능한 <code>Y</code> 값을 모두 구한 뒤에 각각의 확률을 곱해서 더하느니, <code>Y</code> 를 분해해 각각의 기대값을 구한 후 더하는게 훨씬 빠르다. (주사위 굴리기 문제처럼)</p>

<p>다시 말해서, <code>Y</code> 가 여러개의 항으로 구성될때는 각각의 기대값을 구하는게 더 계산이 빠르다는것이 <em>lineariry of expectation</em> 의 본질이다.</p>

<p>따라서 기대값을 시그마 뒤쪽으로 빼서 계산하면 <code>1</code> 이 나온다. 다시 말해 서버 하나당 평균적으로 1개의 프로세스를 가진다는 이야기.</p>

<p>다시 이 확률 테크닉을 <em>randomized pivot</em> 을 선택하는 <em>merge sort</em> 에 적용하러 가 보자.</p>

<h3 id="decompositionprinciple">Decomposition Principle</h3>

<p>일단 랜덤 피벗을 가지는 퀵소트를 <em>master method</em> 로는 <em>Big O</em> 를 찾을 수가 없다는 사실을 알아 두자. 이는 입력한 배열이 일정하게 분할되지 않고 피벗때문에 랜덤하게 분할되지 때문이다.</p>

<p>이제, 퀵 소트의 각 재귀에서 일어나는 연산 중 <em>comparison (비교)</em> 가 다른 연산보다 <em>dominant</em> 하다고 하면, 다시 말해서 비교하는 숫자에 의해 연산 수가 결정된다고 하자. 이건 생각해보면 사실인데, <em>partition</em> 과정에서 일어나는 비교가 각 <em>sub-problem</em> 에서의 연산 수를 결정한다.</p>

<p>이렇게 하면 연산수의 기대값, 다시 말해서 <em>비교가 일어나는 회수의 평균으로</em>, 퀵소트의 평균 성능을 찾아낼 수 있다.</p>

<p>그런데 입력 배열에 대한 전체 비교 수를 <code>C</code> 라 두면 <code>E(C)</code> 는 사실 구하기가 굉장히 어렵다. 그런데, <code>E(C)</code> 를 시그마 두번으로 분해할 수 있고, 심지어 가장 내부의 항은 <code>1</code> 또는 <code>0</code> 을 가지는 원소이다. 따라서 <em>linearity of expectation</em> 을 이용할 수 있다 <del>할렐루야</del> </p>

<p>참고로 가장 내부의 항에 대해서 설명하자면, 전체 입력에서 두개의 원소를 골랐을 때 이 두개의 원소가 비교 되는 수다. 이 두개의 원소는 <code>i</code>, <code>j</code> 를 기준으로 구할 수 있으므로 <code>X_ij</code> 라 두면 <code>i, j</code> 에 각각에 대해 시그마를 씌울 수 있다. 이것이 <code>C</code> 이므로 <code>E(C)</code> 를 구하기는 상당히 복잡함을 알 수 있다. 그런데 <code>X_ij</code> 자체는 <code>0</code> 또는 <code>1</code> 만 가지는 값이니 이것에 대해 <code>E(X_ij)</code> 를 구하면 심플해진다. (수식을 적기 힘드니 자세한 내용은 강의 <em>Analysis I: A Decomposition Principle</em> 을 참조)</p>

<p>따라서 <code>E(C)</code> 는 <code>sigma i &lt;- 1 to n-1, sigma j &lt;- i+1 to n P(X_ij = 1)</code> 이다. </p>

<p>여기서 잠깐 이제 까지 나온 <em>decompositio principle</em> 을 설명하자면</p>

<p>(1) 구하고자 하는 랜덤 변수 <code>Y</code> 를 정의하고 <br />
(2) <code>Y</code> 를 더 간단한 랜덤 변수 <code>X</code> 의 합으로 정의하자. <code>X</code> 가 0 또는 1만 가지는 값이면 더 좋다. 
(3) <em>linearity of expectation</em> 을 적용  </p>

<p>다시 말해 알고리즘의 성능을 결정하는 <em>dominant operation</em> 을 확률변수로 표현할 수 있고, 더 간단한 확률 변수의 합으로 표현할 수 있다면 해해 여기에 <em>기대값의 선형성</em> 을 이용해 알고리즘의 평균적인 성능을 구할 수 있다는 뜻이다.</p>

<p><code>sigma i &lt;- 1 to n-1, sigma j &lt;- i+1 to n P(X_ij = 1)</code> 다시 이 식으로 돌아오자. 여기에 적용할 수 있는 퀵소트의 특징이 있다. 여기서 <code>z_i</code> 를 정렬된 배열의 <code>i</code> 번쨰 원소라 했을때 <em>pivot</em> 이 될 수 있는 것은 <code>z_i, z_i+1, ... z_j-1, z_j</code> 다. 이때</p>

<p>(1) <code>z_i</code> 또는 <code>z_j</code> 가 <em>pivot</em> 이 되면, 즉 가장 작은 수나 가장 큰 수가 <em>pivot</em> 이 되면 <code>z_i</code> 와 <code>z_j</code> 는 한번만 비교된다. (이후에는 다른 재귀로 넘어가 둘 중 하나의 수만 남음) <br />
(2) <code>z_i+1</code>, ..., <code>z_j-1</code> 이 <em>pivot</em> 이 되면 <code>z_i</code> 와 <code>z_j</code> 는 절대로 비교되지 않는다. <em>pivot</em> 기준으로 큰 수와 작은수는 서로 비교되지 않으며 둘 다 피벗과만 비교된다. 이후에도 다른 파티션으로 나누어져 비교되지 않는다.</p>

<p>따라서 각 <em>sub-problem</em> 에서 일어나는 비교가 일어날 확률은 <code>2 / (j - i + 1)</code> 이다. 다시 말해서 전체 원소 중에서 <code>z_i</code> 와 <code>z_j</code> 를 피벗으로 삼는 경우에만 비교가 일어난다.</p>

<p>따라서 평균 연산 수 <code>E(C)</code> 는 <code>sigma i &lt;- 1 to n-1, sigma j &lt;- i+1 to n [2 / (j -i + 1)]</code> 이다.</p>

<p>이때 <code>j = i +1</code> 부터 시작하므로 내부 시그마는 <code>1/2 + 1/3 + ... 1/n</code> 이다. 그리고 내부 시그마에서 <code>i</code> 가 사라졌으므로 외부 시그마 <code>i &lt;- 1 to n-1</code> 을 <code>n-1</code> 대신 대략 <code>n</code> 이라고 놓으면,</p>

<p><code>E(C) &lt;= 2 * n * [sigma k &lt;- 2 to n (1/k)]</code> 다. </p>

<p>이때 <code>sigma k &lt;- 2 to n (1/k)</code> &lt;= <code>ln n</code> 인데, 본래 식의 <code>k</code> 1 부터의 시그마보다 작으므로 이걸 적분으로 넓이를 구하면 <code>ln n - ln 1 =  ln n</code> 이다. </p>

<p>따라서 <code>E(C) &lt;= 2 * n * ln n</code></p>

<h3 id="notes">Notes</h3>

<p>이하는 필기 노트입니다. </p>

<h4 id="matrixmultiplication">matrix multiplication</h4>

<p>단순히 brute force 로 3 for-loop 로 구현하면 당연히 o(n^3) -_-;</p>

<p>스트라센 매트릭스 곱셈으로 구현하면 놀랍게도 n^2 </p>

<h4 id="multiplication">Multiplication</h4>

<ol>
<li>define Input, output  </li>
<li>assess performance</li>
</ol>

<p>can we do better strait forard?</p>

<p>일반적인 곱셈(초등3학년)은 2n * n</p>

<h4 id="karatsubamultiplication">Karatsuba Multiplication</h4>

<p>a * c <br />
b * d = 2652 <br />
(a + b)(c + d) = 6164
(a+b)(c+d) - a*c - b * d = 2840</p>

<p>ad bc </p>

<p>6164 + * 10000 <br />
+ 2652
+ 2840 * 100</p>

<p>x = 10^n/2 a + b <br />
y = 10^n/2 c + d</p>

<p>x * y => 10^n ac + 10 n/2 (ad+bc) + bd <br />
따라서 <em>Karatsuba multiplication</em> 은 <em>product</em> 문제를 ac, ad, bc, bd 의 곱으로 쪼갬.</p>

<p>여기서도, ac, ad, bc, bd 를 모두 구하는 대신에</p>

<p>(a+b)(c+d) - ac bd 를 빼면,  ac bd (a+b)(c+d) 3개만 구하면 된다.</p>

<p>따라서 3개의 recursive multiplication 만 필요</p>

<h4 id="closestpairs">Closest Pairs</h4>

<p>brute force 는 n^2 인데, </p>

<p>1D 의 closest pair 에서 sorting 하면 n^2 가 아니라 nlogn 이다.</p>

<p>로직은 다음과 같다.</p>

<p>문제를 반으로 잘라가면서 왼쪽에서 거리가 가장 짧은것 좌표 쌍, 오른쪽에서 가장 짧은것을 찾고, 각 영역에 좌표가 하나씩 있는 쌍도 검사 한다.</p>

<p>(1) 주어진 배열을 P 라 하고 반으로 각각 좌우 Q, R 자른다. O(n) Q를 x 정렬한것을 Qx, y 축 기준으로 Qy, R도 Rx, Ry. 이건 전체 인풋 n 에 대해서 n logn <br />
(2) ClosestPair(Qx, Qy), Closest(Rx, Ry) 해서 각각 좌 우에서 가장 짧은 거리를 가진 pair 쌍을 찾는다.  이걸 (p1, q1), (p2, q2)  라 하면 <br />
(3) (p1, q1), (p2, q2) 의 거리를 구해 최소값인 d 를 찾는다 <br />
(4) Closest(Px, Py, d) 해서 (p3 , q3) 가 있으면 찾아낸다. 여기서 찾은건 하나는 Q 하나는 R 에 있는 d 보다 작은 거리를 가진 점의 쌍 <br />
(5) p1, p2, p3 쌍중 가장 작은 d 를 가진 것을 리턴 </p>

<p>ClosestSplitPair</p>

<p>(1) Px 의 가운데 점을 xBar 라 하면 이것 기준으로 -d, +d 의 x 값을 가진 점들을 Py 에서 찾아낸다. 정의에 의해서 x1 - x2 &lt;= d 이기 때문에 아무리 커봐야 xBar 기준으로 좌우 d 까지밖에 존재하지 못함. 이걸 Sy 라 부르자. 이건 Py 가 이미 정렬되어 있기 때문에 O(n) 시간. <br />
(2) Sy 는 y 축 기준으로 이미 정렬되어 있는데, 여기서 Sy 의 원소를 루프로 돌면서 이것 기준으로 +7개 원소를 검사하면서 거리가 d 보다 작은것이 있는지 검사. 이것 또한 마찬가지로 d 의 정의와 두 점이 Q, R 에 있다는 점을 이용해서 증명이 가능함. </p>

<p>y1 - y2 도 d 보다 작거나 같이 때문에 y 기준으로 정렬된 점을 기준으로 잡았을때, </p>

<p>p 와 같은 왼편에 있는 것들은 p와의 거리가 d 보다 작을 수 없다. 왜냐하면 d 자체가 같은 사이드에 있는 것들의 최소 거리이기 때문. <br />
이런점들을 아무리 많이 왼쪽에 구겨 넣어도 3개. p 포함하면 4개다. 마찬가지로 q 와 같은 편에 있는것들도 3개.</p>

<p>따라서 운이 나쁠 경우 Sy 에서 p, q + 6개를 더 검사해야. </p>

<p>직사각형을 그려보면 이해가 쉬움.</p>

<p>Input 은 (x1, y1) ... (xn, yn) 의 pair n개 편의상 p1, p2, ... pn</p>

<p>d(p<em>i, p</em>j) 는 두 point 사이 거리</p>

<p>(1) 모든 점들을 x 기준으로 정렬했을때 가운데에 있는 점을 xBar 라 하면 S<em>y 는 xBard - d, xBar + d 사이에 있는 모든 점이다. 만약에 왼쪽에 있는 p, 오른쪽에 있는 q 가 존재한다면 이 둘은 S</em>y 사이에 있고 아래 증명에 에해서 x1, x2 사이 거리는 d 보다 작다.</p>

<p>왜냐하면, p(x1, y1), q(x2, y2) 사이의 거리가 d 보다 작기 때문에 x1 - x2 &lt;= d 이다. </p>

<p>(2) S_y 에서 p, q 가 존재한다면 그건 y 기준으로 7 원소 이내에 인접해 있다. </p>

<h3 id="references">References</h3>

<p>(1) <a href="https://acrocontext.wordpress.com">https://acrocontext.wordpress.com</a> <br />
(2) <a href="http://sadakurapati.wordpress.com/2013/10/25/quicksort-a-practical-and-efficient-sorting-algorithm/">http://sadakurapati.wordpress.com</a> <br />
(3) <a href="http://www.opendatastructures.org/ods-java/1_3_Mathematical_Background.html">http://www.opendatastructures.org</a></p>
    </section>

    <footer>
      
      <section class="author_info margin_top_big">
        <div class="alignleft border rad_circle" style="height: 87px; width: 87px; background-image: url(http://www.gravatar.com/avatar/aa2032ba2302419e3c2ede54f1fbf687?d=404&amp;s=250); background-size: cover;"></div>
        <p class="margin_left_medium text small">Author</p>
        <p class="margin_left_medium text bold"><a href="http://language.is">1ambda</a></p>
        <p class="margin_left_medium text small">Lisp, Emacs, FP</p>
      </section>
      
    </footer>

    

    
    <div id="disqus_thread" class="margin_top_big"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = '1ambda'; // required: replace example with your forum shortname
  var disqus_identifier = '42';
  var disqus_url = 'http://1ambda.github.io/divide-and-conquer/';

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

    </article>
</main>


  
  <script src="../assets/fitvids/jquery.fitvids.js"></script>
<script>
$(document).ready(function(){
  // Target your .container, .wrapper, .post, etc.
  $("section").fitVids();
});
</script>


  <footer class="blog_info margin_top_big padding_medium text center">
    <h5 class="text book small">&copy; 2014 <a href="..">Old Lisper</a>. All rights reserved.</h5>
    <h5 class="text book small"><a href="https://github.com/dreyacosta/velox" target="_blank" class="text bold">Velox theme</a> by <a href="http://dreyacosta.com/">David Rey</a></h5>
    <h5 class="text book small">Proudly published with <a href="http://ghost.org"><span>Ghost</span></a></h5>

  </footer>

  
  <script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = '1ambda'; // required: replace example with your forum shortname

/* * * DON'T EDIT BELOW THIS LINE * * */
(function () {
 var s = document.createElement('script'); s.async = true;
 s.type = 'text/javascript';
 s.src = '//' + disqus_shortname + '.disqus.com/count.js';
 (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
 }());
</script>



  </body>
  </html>
