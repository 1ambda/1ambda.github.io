<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>92s on Old Lisper</title>
    <link>https://1ambda.github.io/92/</link>
    <description>Recent content in 92s on Old Lisper</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Sat, 25 Jun 2016 10:05:26 +0900</lastBuildDate>
    <atom:link href="https://1ambda.github.io/92/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Data Analysis</title>
      <link>https://1ambda.github.io/92/data-analysis/</link>
      <pubDate>Sat, 25 Jun 2016 10:05:26 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/</guid>
      <description>

&lt;h2 id=&#34;machine-learning&#34;&gt;Machine Learning&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-1&#34;&gt;Chapter 01&lt;/a&gt; - Linear Regression&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-2&#34;&gt;Chapter 02&lt;/a&gt; - Gradient Descent&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-3&#34;&gt;Chapter 03&lt;/a&gt; - Logistic Regression&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-4&#34;&gt;Chapter 04&lt;/a&gt; - Neural Network&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-5&#34;&gt;Chapter 05&lt;/a&gt; - Back Propagation&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-6&#34;&gt;Chapter 06&lt;/a&gt; - Practical Advices&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-7&#34;&gt;Chapter 07&lt;/a&gt; - Support Vector Machine&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-8&#34;&gt;Chapter 08&lt;/a&gt; - K-means, PCA Details&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-9&#34;&gt;Chapter 09&lt;/a&gt; - Anomaly Detection, Recommender System&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;machine-learning-week-10&#34;&gt;Chapter 10&lt;/a&gt; - Stochastic Gradient, Synthetic Data, Ceiling Analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;analytics-edge&#34;&gt;Analytics Edge&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week1&#34;&gt;Week 1 (external)&lt;/a&gt; - Intro&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week2&#34;&gt;Week 2 (external)&lt;/a&gt; - Linear Regression&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week3&#34;&gt;Week 3 (external)&lt;/a&gt; - Logistic Regression&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week4&#34;&gt;Week 4 (external)&lt;/a&gt; - CART, Random Forest&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week5&#34;&gt;Week 5 (external)&lt;/a&gt; - Text Analytics&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week6&#34;&gt;Week 6 (external)&lt;/a&gt; - Clustering, Recommendation&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week7&#34;&gt;Week 7 (external)&lt;/a&gt; - Visualization: Heat Map, Social Network, Wordcloud&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week8&#34;&gt;Week 8 (external)&lt;/a&gt; - Linear Optimization&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/week9&#34;&gt;Week 9 (external)&lt;/a&gt; - Integer Optimization&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/kaggle&#34;&gt;Kaggle Competition (external)&lt;/a&gt; - &lt;a href=&#34;https://www.kaggle.com/c/15-071x-the-analytics-edge-competition-spring-2015/&#34;&gt;Predicting which NY Times Blog Articles Will Be Most Popular&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/1ambda/data-analysis/tree/master/analytics-edge/final&#34;&gt;Final Exam (external)&lt;/a&gt; - Final Exam: Regression, Clustering, Text Mining&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;intro-to-computational-thinking-and-data-science&#34;&gt;Intro to Computational Thinking and Data Science&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;intro-to-data-science-1&#34;&gt;Chapter 1&lt;/a&gt; - Modeling&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;intro-to-data-science-2&#34;&gt;Chapter 2&lt;/a&gt; - Monte Carlo Simulation&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;intro-to-data-science-3&#34;&gt;Chapter 3&lt;/a&gt; - Optimization Problem&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;intro-to-data-science-4&#34;&gt;Chapter 4&lt;/a&gt; - State Modeling, Hierarchical Clustering&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;process-mining&#34;&gt;Process Mining&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;process-mining-1&#34;&gt;Week 1&lt;/a&gt; - Process Mining Intro&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;process-mining-2&#34;&gt;Week 2&lt;/a&gt; - Alpha Algorithm&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;process-mining-3&#34;&gt;Week 3&lt;/a&gt; - Metric, C-nets&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;process-mining-4&#34;&gt;Week 4&lt;/a&gt; - Conformance Checking, Dotted Chart&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;process-mining-5&#34;&gt;Week 5&lt;/a&gt; - Decision, Social, Organization Mining&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;pattern-discovery&#34;&gt;Pattern Discovery&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;pattern-discovery-1&#34;&gt;Chapter 1&lt;/a&gt; - Apriori, FP Growth&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;pattern-discovery-2&#34;&gt;Chapter 2&lt;/a&gt; - Null-invariant, Pattern-Fusion, Constaint&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;pattern-discovery-3&#34;&gt;Chapter 3&lt;/a&gt; - Sequential Pattern Mining&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ML 01: Linear Regression</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-1/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:15 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-1/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Machine Learning&lt;/strong&gt; by Andrew Ng, &lt;em&gt;Coursera&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;what-is-machine-learning&#34;&gt;What is Machine Learning?&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;Field of study that gies computers the abiliry to learn without being explicitly programmed. (1959, Arthur Samuel)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Well-posed Learning Problem:&lt;/strong&gt; A computer program is said to &lt;em&gt;learn&lt;/em&gt; from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E (1998, Tom Michell)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;체크메이트를 예로 들면, 수천번의 체스 게임은 &lt;em&gt;E&lt;/em&gt; 에 해당하고 게임 속에서 체크메이트는 &lt;em&gt;T&lt;/em&gt; 에, &lt;em&gt;P&lt;/em&gt; 는 다음 게임에서 이길 확률로 볼 수 있다.&lt;/p&gt;

&lt;p&gt;다른 예로, 이메일을 분류하는 스팸검사기가 있다고 할때&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;E&lt;/em&gt;: Wathing you label emails as spam or not spam.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;T&lt;/em&gt;: Classifying emails as spam or not spam.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;P&lt;/em&gt;: The number(or fraction) of emails correctly classified as spam/not spam.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;supervised-learning&#34;&gt;Supervised Learning&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Given the rihgt answer&lt;/strong&gt; for each example in the data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;즉, 주어진 정답이 있을때 사용할 수 있다. 이런 문제들은 많은데, &lt;em&gt;Regression&lt;/em&gt; 이나 &lt;em&gt;Classification&lt;/em&gt; 등이 있다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Regression:&lt;/strong&gt; Predict continuous valued output&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Classification:&lt;/strong&gt; Discrete valued output (0 or 1)&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;단순히 1개 혹은 2개의 attribute 를 사용할 수 있지만, infinite number of features(attribute) 를 사용하는 &lt;em&gt;Support Vector Machine&lt;/em&gt; 같은 알고리즘도 있다.&lt;/p&gt;

&lt;h3 id=&#34;unsupervised-learning&#34;&gt;Unsupervised Learning&lt;/h3&gt;

&lt;p&gt;즉 모든 데이터에 attribute 는 있지만 주어진 정답이 없을때 사용한다. 다시 말해서, 여러 집단으로 분류될때 미리 컴퓨터에게 이건 &lt;code&gt;type1&lt;/code&gt; 이야 등의 정보를 제공하지 않는다.&lt;/p&gt;

&lt;p&gt;예를 들어서, 다음의 두가지 예는 &lt;em&gt;Unsupervised leanring&lt;/em&gt; 이 아니라 &lt;em&gt;Supervised learning&lt;/em&gt; 이다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;(1) &lt;strong&gt;Given email labeled as spam/not spam&lt;/strong&gt;, learn a spam filter&lt;br/&gt;&lt;br/&gt;
(2) &lt;strong&gt;Given a dataset of patients diagnosed as either having diabetes or not&lt;/strong&gt;, learn to classify new patients as having diabetes or not&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Clustering&lt;/strong&gt; 이라 불리는데, DNS Clustering, Social network analysis, market segmentation 등에 쓰인다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cocktail party problem&lt;/strong&gt; 은 2명이 동시에 말하고, 이걸 서로 다른 위치에 있는 마이크가 녹음한다고 할 때 이 소리를 구분할 수 있는가 하는 문제다. 이것 또한 &lt;em&gt;Unsupervised lerning&lt;/em&gt; 으로 해결할 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;model-representation&#34;&gt;Model Representation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://mercris.files.wordpress.com/2012/07/genericmlatwork.png&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://mercris.files.wordpress.com/2012/07/genericmlatwork.png&#34;&gt;http://mercris.files.wordpress.com/2012/07/genericmlatwork.png&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Traning Set&lt;/em&gt; 을 넣고 &lt;em&gt;Learning Algorithm&lt;/em&gt; 을 돌리면 &lt;em&gt;Hypothesis&lt;/em&gt; 가 나오는데, 이건 사실 함수라 보면 된다. 여기에 새로운 &lt;em&gt;Input X&lt;/em&gt; 를 넣으면 &lt;em&gt;Estimated Y&lt;/em&gt; 가 나온다.&lt;/p&gt;

&lt;p&gt;참고로, 변수가 하나인 &lt;em&gt;Linear regression&lt;/em&gt; 은 &lt;strong&gt;Univariate linear regression&lt;/strong&gt; 이라 부른다.&lt;/p&gt;

&lt;h3 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h3&gt;

&lt;p&gt;예를 들어서 다음과 같은 데이터셋이 있을때,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;http://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584&#34;&gt;http://mercris.files.wordpress.com/2012/07/screen-shot-2012-07-17-at-2-12-05-pm.png?w=584&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;H(hypothesis)&lt;/em&gt; 가 다음처럼 나온다면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://s0.wp.com/latex.php?latex=h_%7B%5Ctheta%7Dx+%3D+%5Ctheta_%7B0%7D+%2B+%5Ctheta_%7B1%7Dx&amp;bg=ffffff&amp;fg=333333&amp;s=0&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;0 (Theta)&lt;/code&gt; 는 &lt;em&gt;parameter&lt;/em&gt; 라고 부른다.
문제는, 상수를 어떻게 찾느냐인데, 아이디어는 간단하다. training set &lt;code&gt;(x, y)&lt;/code&gt; 에 가까운 &lt;code&gt;h(x)&lt;/code&gt; 를 찾으면 된다.&lt;/p&gt;

&lt;p&gt;따라서 다음과 같은 식을 만들 수 있고,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://s0.wp.com/latex.php?latex=J%28%5Ctheta_%7B0%7D%2C+%5Ctheta_%7B1%7D%29+%3D+%5Cdfrac+%7B1%7D%7B2m%7D+%5Csum+%5Climits_%7Bi%3D1%7D%5E%7Bm%7D+%28h_%7B%5Ctheta%7D+%28x%5E%7B%28i%29%7D%29+-+y%5E%7B%28i%29%7D%29%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;J(01, 02)&lt;/code&gt; 를 최소화 하는 &lt;code&gt;(01, 02)&lt;/code&gt; 를 찾으면 된다. 이 식을 &lt;strong&gt;cost function&lt;/strong&gt; 또는 &lt;strong&gt;squred error function&lt;/strong&gt; 이라 부른다. 여기서 &lt;code&gt;1/2m&lt;/code&gt; 으로 나누는 이유에 대해 좀 궁금해서 구글링 해봤는데, &lt;code&gt;1/m&lt;/code&gt; 으로 나누는 이유는 &lt;em&gt;squared error&lt;/em&gt; 에 대해 &lt;em&gt;mean&lt;/em&gt; 을 얻기 위한거고, &lt;code&gt;1/2&lt;/code&gt; 로 다시 나누는 이유는 미분했을때 나오는 &lt;code&gt;2&lt;/code&gt; 를 제거하기 위해서다. &lt;a href=&#34;http://stackoverflow.com/questions/21099289/cant-understand-the-cost-function-for-linear-regression&#34;&gt;SO 답변&lt;/a&gt; 을 첨부하면,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The cost function is&lt;/p&gt;

&lt;p&gt;J(theta_0, theta&lt;em&gt;1) = 1/(2m) * sum&lt;/em&gt;(i=1)^m [ h_theta(x^i) - y^i ]^2
By h_theta(x^i) we denote what model outputs for x^i, so h_theta(x^i) - y^i is its error (assuming, that y^i is a correct output).&lt;/p&gt;

&lt;p&gt;Now, we calculate the square of this error [ h_theta(x^i) - y^i ]^2 (which removes the sign, as this error could be both positive and negative) and sum it over all samples, and to &lt;strong&gt;bound it somehow we normalize it - simply by dividing by m,&lt;/strong&gt; so we have mean (because we devide by number of samples) squared (because we square) error (because we compute an error):&lt;/p&gt;

&lt;p&gt;1/m * sum_(i=1)^m [ h_theta(x^i) - y^i ]^2
&lt;strong&gt;This 2 which appears in the front is used only for simplification of the derivative&lt;/strong&gt;, because when you will try to minimize it, you will use the steepest descent method, which is based on the derivative of this function. Derivative of a^2 is 2a, and our function is a square of something, so this 2 will cancel out. This is the only reason of its existance.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 &lt;em&gt;cost function&lt;/em&gt; 은 &lt;em&gt;regression&lt;/em&gt; 문제를 위해 자주 쓰이는 기법이다.&lt;/p&gt;

&lt;h3 id=&#34;cost-function-intuition-1&#34;&gt;Cost Function: Intuition 1&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Cost function&lt;/em&gt; 에서 만약에 &lt;code&gt;0_0&lt;/code&gt; 이 제로라면 &lt;code&gt;0_1&lt;/code&gt; 만 찾으면 된다. 따라서 다음과 같은 실제 데이터에서&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://cfile3.uf.tistory.com/image/2275174452D612AE06C75B&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://mapository.tistory.com/59&#34;&gt;http://mapository.tistory.com/59&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;J(0_1)&lt;/code&gt; 을 찾아보면, 다음과 같은 이차함수가 나온다.&lt;/p&gt;

&lt;p&gt;&lt;img align=&#34;center&#34; src=&#34;http://cfile29.uf.tistory.com/image/234E894A52D6113D1F8267&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://mapository.tistory.com/59&#34;&gt;http://mapository.tistory.com/59&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;당연히 이차함수이므로, 기울기가 0이 되는 지점은 &lt;code&gt;J(0_1)&lt;/code&gt; 을 미분해서 찾으면 된다. (이래서 아까 1/2가 있던 것)&lt;/p&gt;

&lt;h3 id=&#34;cost-function-intuition-2&#34;&gt;Cost Function: Intuition 2&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Parameter&lt;/em&gt; 가 &lt;code&gt;0_1&lt;/code&gt; 만 있었을때는, (&lt;code&gt;0_0&lt;/code&gt; = 0) &lt;code&gt;J(0_1)&lt;/code&gt; 이 이차함수였지만, &lt;code&gt;J(0_0, 0_1)&lt;/code&gt; 일때는 다음과 같은 모양을 보여준다.&lt;/p&gt;

&lt;p&gt;&lt;img align=&#34;center&#34; src=&#34;http://cfile2.uf.tistory.com/image/2232CA4C52D611111DDFCD&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://mapository.tistory.com/59&#34;&gt;http://mapository.tistory.com/59&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;J(0_0, 0_1)&lt;/code&gt; 값을 제외하고 &lt;code&gt;(0_0, 0_1)&lt;/code&gt; 을 평면으로 나타내면 아래 사진에서 우측과 같은 여러 궤도가 나온다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://cfile24.uf.tistory.com/original/2107074652D6134E0ECB0F&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://mapository.tistory.com/59&#34;&gt;http://mapository.tistory.com/59&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;여기서 같은 궤도에 있는 &lt;code&gt;(0_0, 0_1)&lt;/code&gt; 쌍은, 같은 &lt;code&gt;J&lt;/code&gt; 함수를 만든다. 그리고 재밌는 사실은 궤도가 가장 좁은 타원의 중심에 있는 &lt;code&gt;(0_0, 0_1)&lt;/code&gt; 가 가장 작은 &lt;code&gt;J(0_0, 0_1)&lt;/code&gt; 를 만들어 낸다.&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent&#34;&gt;Gradient Descent&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Gradient Descent&lt;/em&gt; 알고리즘은 &lt;em&gt;Linear Regression&lt;/em&gt; 에만 쓸 수 있는건 아니고, 범용적인 알고리즘이다. &lt;em&gt;cost function&lt;/em&gt; 의 최소값을 찾기 위해 사용할 수 있는데, 다음과 같은 &lt;code&gt;J&lt;/code&gt; 가 있을때,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://cfile28.uf.tistory.com/image/2401353E52D618322EDFB5&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://mapository.tistory.com/59&#34;&gt;http://mapository.tistory.com/59&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;높이를 비교해 가며 점점 낮은쪽으로 이동해 가면서 &lt;code&gt;J&lt;/code&gt; 의 최소값을 찾을 수 있다. 식은 다음과 같은데,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://2.bp.blogspot.com/-AdV-O-MoZHE/TtLibFTaf9I/AAAAAAAAAVM/aOxUGP7zl98/s1600/gradient+descent+algorithm+OLS.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://econometricsense.blogspot.kr/2011_11_01_archive.html&#34;&gt;http://econometricsense.blogspot.kr/2011_11_01_archive.html&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;:=&lt;/code&gt; 는 &lt;em&gt;assignment&lt;/em&gt; 다. &lt;code&gt;a(alpha)&lt;/code&gt; 는 &lt;em&gt;learning rate&lt;/em&gt; 라 부른다. 이때 &lt;code&gt;(0_0, 0_1)&lt;/code&gt; 은 동시에 업데이트 되야한다. &lt;strong&gt;(Simultaneous update)&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-intuition&#34;&gt;Gradient Descent: Intuition&lt;/h3&gt;

&lt;p&gt;이제 저 식을 분해하기 위해 &lt;code&gt;J(0_1)&lt;/code&gt; 처럼 &lt;em&gt;parameter&lt;/em&gt; 하나만 놓고 보면, 이차원 함수가 나올테다. 만약 현재 &lt;code&gt;0_1&lt;/code&gt; 이 이차함수의 최저점 우측에 있다면, &lt;code&gt;J(0_1)&lt;/code&gt; 을 미분한 값&lt;strong&gt;(Slope, 기울기)&lt;/strong&gt; 에 양수 &lt;code&gt;a&lt;/code&gt; 를 곱한 값을 &lt;code&gt;0_1&lt;/code&gt; 에서 뻬면서 갱신하면 &lt;code&gt;0_1&lt;/code&gt; 은 점점 최저점 쪽으로 간다,&lt;/p&gt;

&lt;p&gt;반대로 &lt;code&gt;0_1&lt;/code&gt; 이 &lt;code&gt;J(0_1)&lt;/code&gt; 의 좌측에 위치한다면 우측으로 이동하고, 아래는 그걸 요약한 그림이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.ytimg.com/vi/ud4o8AYe9tI/hqdefault.jpg&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;따라서 &lt;em&gt;learning late&lt;/em&gt; &lt;code&gt;a&lt;/code&gt; 가 너무 작으면 &lt;em&gt;Gradient descent&lt;/em&gt; 가 너무 느려진다. 왜냐하면 &lt;code&gt;0&lt;/code&gt; 의 차이가 점점 작이지기 때문에 최저점에 도착할때 까지 너무 많은 step 이 필요하다.&lt;/p&gt;

&lt;p&gt;반대로 너무 크면 최저점을 넘어갈 수 있다. 심지어 최저점에서 점점 더 멀어질 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;if &lt;code&gt;a&lt;/code&gt; is too small, &lt;em&gt;gradient descent&lt;/em&gt; can be slow &lt;br/&gt;&lt;br/&gt;
if &lt;code&gt;a&lt;/code&gt; is too large, &lt;em&gt;gradient desscent&lt;/em&gt; can overshoot the minimum, It may fail to converge, or even diverge&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그런데 이 &lt;em&gt;gradient descent&lt;/em&gt; 알고리즘의 문제는 &lt;strong&gt;local optimum&lt;/strong&gt; 수 있다는 점이다. 왜냐하면 &lt;strong&gt;local optimum&lt;/strong&gt; 에서도 &lt;code&gt;J&lt;/code&gt; 의 derivative 가 &lt;code&gt;0&lt;/code&gt; 이기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Extrema_example.svg/2000px-Extrema_example.svg.png&#34; align=&#34;center&#34; /&gt;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Backpropagation&#34;&gt;http://en.wikipedia.org/wiki/Backpropagation&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-for-linear-regression&#34;&gt;Gradient Descent For Linear Regression&lt;/h3&gt;

&lt;p&gt;이제 &lt;em&gt;cost function&lt;/em&gt; 을 &lt;em&gt;gradient descent&lt;/em&gt; 에 집어넣고, 정리하자. &lt;code&gt;0_0(Theta zero)&lt;/code&gt;, 과 &lt;code&gt;0_1(Theta one)&lt;/code&gt; 대해서 시그마 내부 제곱을 각각 미분해서 정리하면,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://pingax.com/wp-content/uploads/2013/11/Convergence-300x107.png&#34;  align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://pingax.com/linear-regression-with-r-step-by-step-implementation-part-1/&#34;&gt;http://pingax.com/linear-regression-with-r-step-by-step-implementation-part-1/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;참고로 &lt;strong&gt;Convex function&lt;/strong&gt; 은 &lt;em&gt;Bowl shaped&lt;/em&gt; 처럼 &lt;em&gt;local optima&lt;/em&gt; 가 없는 &lt;code&gt;h&lt;/code&gt;(Hypothesis) 를 말한다. 따라서 &lt;em&gt;convex function&lt;/em&gt; 을 선택할 수 있다면, 하는편이 낫다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Batch&lt;/strong&gt; &lt;em&gt;gradient descent&lt;/em&gt; 는 모든 training example 을 사용하는 &lt;em&gt;gradient descent&lt;/em&gt; 를 말한다. (시그마에서)&lt;/p&gt;

&lt;p&gt;어떤 경우에는 &lt;em&gt;gradient descent&lt;/em&gt; 같은 interative algorithm 없이도 &lt;code&gt;min J(0_0, 0_1)&lt;/code&gt; 를 풀 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;a href=&#34;http://mercris.wordpress.com/&#34;&gt;http://mercris.wordpress.com/&lt;/a&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://mapository.tistory.com/&#34;&gt;http://mapository.tistory.com/&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://econometricsense.blogspot.kr&#34;&gt;http://econometricsense.blogspot.kr&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://pingax.com/&#34;&gt;http://pingax.com/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 02: Gradient Descent</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-2/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:17 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-2/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Machine Learning&lt;/strong&gt; by Andrew Ng, &lt;em&gt;Coursera&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;linear-regression-with-multiple-variables&#34;&gt;Linear Regression with Multiple Variables&lt;/h2&gt;

&lt;h3 id=&#34;mutiple-features&#34;&gt;Mutiple Features&lt;/h3&gt;

&lt;p&gt;변수가 적을때는 &lt;em&gt;Hypothesis&lt;/em&gt; 가 간단하다. 많으면 어떻게 될까? &lt;em&gt;Feature&lt;/em&gt; 가 &lt;code&gt;N+1&lt;/code&gt; 개라면,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://bt22dr.files.wordpress.com/2013/05/04_2.png?w=300&amp;h=19&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;http://bt22dr.wordpress.com&#34;&gt;http://bt22dr.wordpress.com&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;편의상 &lt;code&gt;x_0 = 1&lt;/code&gt; 이라 두면, &lt;em&gt;Hypothesis&lt;/em&gt; 는 &lt;em&gt;Zero-based index&lt;/em&gt; 인 &lt;code&gt;n+1&lt;/code&gt; 벡터 &lt;code&gt;h&lt;/code&gt; 와 &lt;code&gt;x&lt;/code&gt; 의 곱이다. 따라서 &lt;code&gt;h(x) = h_t * x&lt;/code&gt; 로 표기할 수 있다. 이걸 &lt;strong&gt;Mutivariate linear regression&lt;/strong&gt; 이라 부른다.&lt;/p&gt;

&lt;h3 id=&#34;gradient-descent-for-multiple-variables&#34;&gt;Gradient Descent for Multiple Variables&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Cost function&lt;/em&gt; 은 다음과 같다. 변수의 subscript 는 &lt;code&gt;j&lt;/code&gt; 번째 &lt;em&gt;Feature&lt;/em&gt; 를, superscript 는 &lt;code&gt;i&lt;/code&gt; 번째 데이터임을 말한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://bt22dr.files.wordpress.com/2013/05/04_6.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://bt22dr.wordpress.com/&#34;&gt;http://bt22dr.wordpress.com/&lt;/a&gt;)&lt;/p&gt;
&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;다음은 &lt;em&gt;Gradient Descent&lt;/em&gt; 알고리즘을 구하는 정의다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://bt22dr.files.wordpress.com/2013/05/04_7.png?w=300&amp;h=104&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://bt22dr.wordpress.com/&#34;&gt;http://bt22dr.wordpress.com/&lt;/a&gt;)&lt;/p&gt;
&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;따라서&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://bt22dr.files.wordpress.com/2013/05/04_8.png?w=630&amp;h=354&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://bt22dr.wordpress.com/&#34;&gt;http://bt22dr.wordpress.com/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;feature-scaling&#34;&gt;Feature Scaling&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Feature&lt;/em&gt; 간 데이터 크기가 많이 차이가 나면, &lt;em&gt;Gradient Descent&lt;/em&gt; 에서 등고선 간 간격이 좁으므로, &lt;em&gt;Global optima&lt;/em&gt; 를 찾는데 오래걸릴 수 있다. 따라서 &lt;em&gt;Feature&lt;/em&gt; 값을 &lt;code&gt;m&lt;/code&gt; 으로 나누거나  -1 과 1 사이로 &lt;em&gt;scaliing&lt;/em&gt; 할 수 있다. 거꾸로 말하면, &lt;em&gt;Feature scaling&lt;/em&gt; 을 이용하면 &lt;em&gt;Gradient descent&lt;/em&gt; 가 결과값을 더 빠르게 찾는다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.stack.imgur.com/4RBjR.png&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;또한 &lt;strong&gt;Mean normalization&lt;/strong&gt; 을 이용할 수 있는데, 모든 &lt;em&gt;feature&lt;/em&gt; 에서 평균을 빼서, 평균을 0 으로 만드는 방법이다.&lt;/p&gt;

&lt;p&gt;더 일반적인 방법은 &lt;em&gt;mean normalization&lt;/em&gt; 을 하고, 거기에 &lt;code&gt;max-min&lt;/code&gt; 또는 &lt;em&gt;standard deviation&lt;/em&gt; 으로 나누는 방법이다.&lt;/p&gt;

&lt;h3 id=&#34;learning-rate&#34;&gt;Learning Rate&lt;/h3&gt;

&lt;p&gt;디버깅 팁 중 하나는, 우리가 작성한 &lt;em&gt;Gradient descent&lt;/em&gt; 알고리즘이 매 &lt;em&gt;interation&lt;/em&gt; 마다 줄어들어야 한다는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://d37rcl8t6g8sj5.cloudfront.net/wp-content/uploads/gradient_descent_error_by_iteration.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://spin.atomicobject.com&#34;&gt;http://spin.atomicobject.com&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;그리고, 어느 지점에선가 &lt;em&gt;converged&lt;/em&gt; 되는지 검사하기 위해 &lt;em&gt;automatic convergence test&lt;/em&gt; 를 사용할 수 있다. 예를 들어 한 이터레이션에서, 10^-3 보다 적게 줄어드는지 검사한다거나.&lt;/p&gt;

&lt;p&gt;만약에 &lt;em&gt;gradient descent&lt;/em&gt; 값이 증가하면, 더 작은 &lt;em&gt;learning rate&lt;/em&gt; 를 사용해라. 그렇다고 너무 작은 값을 사용하면 &lt;em&gt;gradient descent&lt;/em&gt; 가 느리게 수렴할 수 있다. &lt;em&gt;learning rate&lt;/em&gt; 가 너무 크면, 심지어 수렴하지 않을 수도 있다.&lt;/p&gt;

&lt;p&gt;따라서 &lt;em&gt;learning rate&lt;/em&gt; 를 &lt;code&gt;0.001&lt;/code&gt;, &lt;code&gt;0.003&lt;/code&gt;, &lt;code&gt;0.01&lt;/code&gt;, &lt;code&gt;0.03&lt;/code&gt;, &lt;code&gt;0.1&lt;/code&gt;, &lt;code&gt;0.3&lt;/code&gt;, &lt;code&gt;1&lt;/code&gt; 처럼 작은 것부터 선택하되, 천천히 늘려가는 것이 좋다.&lt;/p&gt;

&lt;h3 id=&#34;polynomial-regression&#34;&gt;Polynomial Regression&lt;/h3&gt;

&lt;p&gt;집값을 예측하기 위해 두개의 &lt;em&gt;feature&lt;/em&gt;, &lt;code&gt;frontage&lt;/code&gt; 와 &lt;code&gt;depth&lt;/code&gt; 가 있다고 하자. 두 값을 곱해 &lt;code&gt;area&lt;/code&gt; 라는 새로운 &lt;em&gt;feature&lt;/em&gt; 를 만들면, &lt;em&gt;Hypothesis&lt;/em&gt; 가 간단해진다. 따라서 기존의 &lt;em&gt;feature&lt;/em&gt; 를 이용 할 수 있는지도 잘 알아보는 게 좋다.&lt;/p&gt;

&lt;p&gt;자 이제, 집 값(Housing prices) 을 예측하기 위해 &lt;em&gt;Size(Area)&lt;/em&gt; 라는 &lt;em&gt;feature&lt;/em&gt; 를 이용한다 하자. &lt;em&gt;training set&lt;/em&gt; 이 다음과 같을때,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/01_02_Introduction_regression_analysis_and_gr_files/Image.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.holehouse.org/mlclass&#34;&gt;http://www.holehouse.org/mlclass&lt;/a&gt;&lt;/p&gt;
&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;hypothesis&lt;/em&gt; 를 &lt;em&gt;quadratic&lt;/em&gt; 로 세우면 어느 지점부터는 예측된 값이 감소하므로 &lt;em&gt;traning set&lt;/em&gt; 과 일치하지 않는다. 따라서 &lt;em&gt;cubic&lt;/em&gt; 다항식을 이용해 볼 수 있겠는데, &lt;em&gt;feature&lt;/em&gt; 가 &lt;code&gt;size&lt;/code&gt; 하나 뿐이므로, &lt;em&gt;hypothesis&lt;/em&gt; 는 &lt;code&gt;size&lt;/code&gt; 를 이용한 삼차식이 되겠다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/04_Linear_Regression_with_multiple_variables_files/Image%20[10].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;http://www.holehouse.org/mlclass&#34;&gt;http://www.holehouse.org/mlclass&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 경우 &lt;code&gt;size&lt;/code&gt; 하나로 3개의 &lt;em&gt;feature&lt;/em&gt; 를 만들었으니, &lt;em&gt;scaling&lt;/em&gt; 이 문제가 될 수 있다.&lt;/p&gt;

&lt;p&gt;이 전에 앞서서 &lt;em&gt;feature&lt;/em&gt; 가 두개인 &lt;em&gt;hypothesis&lt;/em&gt; (quadratic) 은 말이 안된다고 했는데, 두개지만 &lt;em&gt;square&lt;/em&gt; 모델을 사용하면 우리가 가진 &lt;em&gt;training set&lt;/em&gt; 과 얼추 맞아 떨어지는 모델을 찾을 수 있다. 그림이 없어서 대충 식을 첨부하면,&lt;/p&gt;

&lt;p&gt;&lt;code&gt;h(x) = y0 + y1(size) + y2 * square(size)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;y&lt;/code&gt; 는 강의에서 말하는 &lt;code&gt;0(theta)&lt;/code&gt; 라 보면 된다.&lt;/p&gt;

&lt;h3 id=&#34;nomal-equation&#34;&gt;Nomal Equation&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;gradient descent&lt;/em&gt; 는 반복하면서 특정 값에 수렴해 가는 알고리즘 이었지만 &lt;strong&gt;normal equation&lt;/strong&gt; 은 그냥 &lt;code&gt;J(0)&lt;/code&gt; 식을 풀어버려 값을 찾아낸다.&lt;/p&gt;

&lt;p&gt;예를 들어서 &lt;code&gt;J(0)&lt;/code&gt; 가 &lt;code&gt;0(theta)&lt;/code&gt; 에 대해  &lt;em&gt;quadratic&lt;/em&gt; 이면, &lt;code&gt;0&lt;/code&gt; 에 대해 미분해서 최저점을 찾아내면 된다. 문제는, &lt;code&gt;0&lt;/code&gt; 가 여러개 일때, 모든 &lt;code&gt;0_j&lt;/code&gt; 에 대해 &lt;em&gt;cost function&lt;/em&gt; 을 풀어야 한다는 것이다. &lt;em&gt;partial derivative&lt;/em&gt; 를 이용해서 해를 찾으면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.longhaiqiang.com/wp-content/uploads/2013/08/Snip20130817_44.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.longhaiqiang.com/&#34;&gt;http://www.longhaiqiang.com/&lt;/a&gt;)&lt;/p&gt;
&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;행렬을 이용할 수도 있다. 자세한 건 강의 내용을 보자, &lt;em&gt;design matrix&lt;/em&gt; 라고 부르는 &lt;code&gt;X&lt;/code&gt; 를 만들어서 아래의 식을 구하면 된다. 사실 &lt;code&gt;X&lt;/code&gt; 는 그냥 &lt;em&gt;feature&lt;/em&gt; 들을 있는 그대로 행렬로 만들면 된다. 맨 앞에 &lt;code&gt;x0&lt;/code&gt; 만 추가해서.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.longhaiqiang.com/wp-content/uploads/2013/08/Snip20130817_41.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.longhaiqiang.com/&#34;&gt;http://www.longhaiqiang.com/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;참고로, 저 식을 &lt;em&gt;Octave&lt;/em&gt; 에서는 다음과 같이 계산한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-octave&#34;&gt;pinv(X`*X)*X`*y
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;normal equation&lt;/em&gt; 을 이용할때는 &lt;em&gt;feature scaling&lt;/em&gt; 을 하지 않아도 괜찮다. &lt;em&gt;gradient descent&lt;/em&gt; 와 비교해 보자면,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Gradient Descent:&lt;/strong&gt; &lt;br/&gt;
(1) &lt;em&gt;learning rate&lt;/em&gt; 를 골라야 한다.
(2) &lt;em&gt;feature scaling&lt;/em&gt; 을 해야할 필요가 있다.&lt;br /&gt;
(3) &lt;em&gt;interation&lt;/em&gt; 을 해야하므로 알고리즘이 제대로 돌아가는지 체크해야할 필요가 있다.&lt;br /&gt;
(4) 대신 &lt;code&gt;n&lt;/code&gt; 이 커도 잘 돌아간다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Normal Equation:&lt;/strong&gt; &lt;br/&gt;
(1) &lt;em&gt;learning rate&lt;/em&gt; 를 고를 필요가 없다.&lt;br /&gt;
(2) &lt;em&gt;feature scaling&lt;/em&gt; 을 해야할 필요가 없다.&lt;br /&gt;
(3) &lt;em&gt;interation&lt;/em&gt; 을 하지 않는다.&lt;br /&gt;
(4) &lt;code&gt;n&lt;/code&gt; 이 커질경우 굉장히 느려지고 &lt;code&gt;(X^TX)^-1)&lt;/code&gt; 을 계산해야 한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;따라서 &lt;code&gt;n&lt;/code&gt; 이 너무 크지 않으면, 100~1000 정도까지는, &lt;em&gt;normal equation&lt;/em&gt; 을 쓰는편이 낫다.&lt;/p&gt;

&lt;h3 id=&#34;nomal-equation-noninvertibility&#34;&gt;Nomal Equation Noninvertibility&lt;/h3&gt;

&lt;p&gt;만약에, 우리가 가진 &lt;code&gt;X&lt;/code&gt; 가 &lt;em&gt;non-invertible&lt;/em&gt; 하다면 어떻게 될까? &lt;em&gt;invertible matrix&lt;/em&gt; 란, 아래를 만족시키는 &lt;code&gt;B&lt;/code&gt; 가 존재하는 행렬이다. &lt;code&gt;I&lt;/code&gt; 는 &lt;em&gt;identity matrix&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/math/7/3/3/7334597613ae1773c19e1ed1289349db.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://en.wikipedia.org/wiki/Invertible_matrix&#34;&gt;http://en.wikipedia.org/wiki/Invertible_matrix&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;만약 저런 &lt;code&gt;B&lt;/code&gt; 가 존재하지 않아 &lt;em&gt;non-invertible&lt;/em&gt; 한 행렬을 &lt;strong&gt;sigular matrix&lt;/strong&gt;, &lt;strong&gt;degenerate matrix&lt;/strong&gt; 라 부른다.&lt;/p&gt;

&lt;p&gt;우리가 계산해야 할 행렬이 &lt;em&gt;non-invertible&lt;/em&gt; 이라면, 두 가지 경우가 있을 수 있는데,&lt;/p&gt;

&lt;p&gt;(1) Redundant features(linearly dependent) e.g &lt;code&gt;x1 = (3.28) * x2&lt;/code&gt;&lt;br /&gt;
(2) too many features e.g &lt;code&gt;m &amp;lt;= n&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;이럴 때는 몇몇 &lt;em&gt;feature&lt;/em&gt; 를 삭제하고, &lt;em&gt;regulaization&lt;/em&gt; 을 하면 된다.&lt;/p&gt;

&lt;h3 id=&#34;cost-function-octave&#34;&gt;Cost Function: Octave&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;cost function&lt;/em&gt; 을 구현 해 보면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-matlab&#34;&gt;function J = costFunctionJ(X, y, theta)

m = size(X, 1) % number of training examples
predictions= X * theta; % predictions of hypothesis on all m examples
sqrErros = (predictions-y).^2;

J = 1 / (2*m) * sum(sqrErros);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;R&lt;/em&gt; 이나 이런것들은 행렬연산이 참 쉬운것 같다.&lt;/p&gt;

&lt;h3 id=&#34;vectorization&#34;&gt;Vectorization&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Vectorization&lt;/em&gt; 을 이용하면, &lt;code&gt;for loop&lt;/code&gt; 을 제거할 수 있는데, 예를 들어&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.ytimg.com/vi/jRr2XuZOWB8/hqdefault.jpg&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이건 행렬 곱셈이 한번에 이루어진다는 것을 이용한 방법이다. 따라서 &lt;em&gt;gradient descent&lt;/em&gt; 알고리즘에서 &lt;code&gt;theta&lt;/code&gt; 를 &lt;code&gt;for-loop&lt;/code&gt; 으로 구하는 것이 아니라, &lt;em&gt;vectorization&lt;/em&gt; 을 이용하면 한번에 계산할 수 있다.&lt;/p&gt;

&lt;p&gt;이게 그림을 구하기가 어려운데, 아래첨자(sub-script) 를 이렇게 기술한다고 하자. &lt;code&gt;x_0&lt;/code&gt; 그럼, &lt;em&gt;grandient descent&lt;/em&gt; 알고리즘 식에서 &lt;em&gt;learning rate&lt;/em&gt; 뒷부분이 &lt;em&gt;vector&lt;/em&gt; 가 되는데 그 이유는 &lt;code&gt;theta&lt;/code&gt; 와 마찬가지로 &lt;code&gt;j&lt;/code&gt; 에 대한 나열이기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://2.bp.blogspot.com/-ZxJ87cWjPJ8/TtLtwqv0hCI/AAAAAAAAAV0/9FYqcxJ6dNY/s1600/gradient+descent+algorithm+OLS.png&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;구글에 검색하니까 1번으로 뜨는게 &lt;em&gt;vectorization(parallel computing)&lt;/em&gt; 이더라. 병렬 연산에 많이 사용되나보다.&lt;/p&gt;

&lt;h3 id=&#34;refenrences&#34;&gt;Refenrences&lt;/h3&gt;

&lt;p&gt;(1) &lt;a href=&#34;http://stats.stackexchange.com/questions/111467/is-it-necessary-to-scale-the-target-value-in-addition-to-scaling-features-for-re&#34;&gt;StackExchange&lt;/a&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://bt22dr.wordpress.com/&#34;&gt;http://bt22dr.wordpress.com/&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/&#34;&gt;http://spin.atomicobject.com&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://www.holehouse.org/mlclass/01_02_Introduction_regression_analysis_and_gr.html&#34;&gt;http://www.holehouse.org/mlclass/&lt;/a&gt;&lt;br /&gt;
(5) &lt;a href=&#34;http://www.longhaiqiang.com/&#34;&gt;http://www.longhaiqiang.com/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 03: Logistic Regression</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-3/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:21 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-3/</guid>
      <description>

&lt;p&gt;지난 시간엔 &lt;em&gt;Regression&lt;/em&gt; 을 해결하기 위해 &lt;em&gt;graident descent&lt;/em&gt; 알고리즘을 도입했었다. &lt;em&gt;learning rate&lt;/em&gt;, &lt;em&gt;vectorization&lt;/em&gt; 등에 대해서 알아 보기도 했고. 이번시간엔 &lt;em&gt;classification&lt;/em&gt; 과 &lt;em&gt;regulrzation&lt;/em&gt; 에 대해서 배워 본다.&lt;/p&gt;

&lt;p&gt;이 수업이 재밌는 이유는 수식을 증명하는 것보다 수식속에 숨겨진 내용들을 직관적으로 이해할 수 있게 설명하기 때문이다. &lt;del&gt;그러나 교수님 과제는 제발 그만&lt;/del&gt;&lt;/p&gt;

&lt;h3 id=&#34;classification&#34;&gt;Classification&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;regression&lt;/em&gt; 이 &lt;em&gt;continuous value&lt;/em&gt; 를 다룬다면 &lt;strong&gt;Classification&lt;/strong&gt; 은 &lt;strong&gt;discrete value&lt;/strong&gt; 를 다룬다. 따라서 &lt;em&gt;Classification (분류)&lt;/em&gt; 의 예는,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;이메일이 스팸인지 / 아닌지&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;온라인 거래가 사기인지 / 아닌지 (Online Transaction: Fraudulent)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;악성 종양인지 / 아닌지&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://i.stack.imgur.com/VVtRW.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://stats.stackexchange.com&#34;&gt;http://stats.stackexchange.com&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위와 같은 경우, &lt;em&gt;Regression&lt;/em&gt; 으로 문제를 풀면 당장은 맞아 보이나, 종양이 이상한 위치에 생겼을 경우 아래와 같이 직선이 크게 변한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.stack.imgur.com/nEC4H.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://stats.stackexchange.com&#34;&gt;http://stats.stackexchange.com&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;따라서 이렇게 &lt;em&gt;discrete value&lt;/em&gt; 에 대해서는 &lt;em&gt;Regression&lt;/em&gt; 보다는 &lt;em&gt;Threshold&lt;/em&gt; 에 기반을 두어, &lt;code&gt;h(x)&lt;/code&gt; 가 일정 값 이상이면 &lt;code&gt;y=1&lt;/code&gt; 로 예측하는 편이 더 정확도가 높아진다. 게다가 &lt;em&gt;regression&lt;/em&gt; 은 직선이기 때문에, &lt;code&gt;0 &amp;lt;= y &amp;lt;= 1&lt;/code&gt; 인 &lt;code&gt;y&lt;/code&gt; 에 대해서 0보다 작거나, 1보다 더 큰 &lt;code&gt;y&lt;/code&gt; 를 만들어낼 수 있다.&lt;/p&gt;

&lt;p&gt;이런 이유 때문에 &lt;em&gt;Classification&lt;/em&gt; 문제에 &lt;em&gt;Regression&lt;/em&gt; 을 잘 사용하지 않는다. 그러나 &lt;code&gt;y&lt;/code&gt; 의 범위가 &lt;code&gt;0 &amp;lt;= h(x) &amp;lt;= 1&lt;/code&gt; 을 가지는 &lt;em&gt;Logistic Regression&lt;/em&gt; 도 있다. 이건 &lt;em&gt;Classification&lt;/em&gt; 에 사용되기도 한다.&lt;/p&gt;

&lt;h3 id=&#34;logistic-regression&#34;&gt;Logistic Regression&lt;/h3&gt;

&lt;p&gt;이전에 언급했듯이 &lt;em&gt;classification&lt;/em&gt; 에선 예측된 값, 즉 &lt;code&gt;h(x)&lt;/code&gt; 값이 0 과 1사이에 있길 바란다. 이를 위해 &lt;em&gt;logistic function&lt;/em&gt;, 혹은 &lt;strong&gt;sigmoid function&lt;/strong&gt; 이라 불리는 아래 식을 &lt;em&gt;hypothesis&lt;/em&gt; &lt;code&gt;h(x)&lt;/code&gt; 에 적용하면 아래와 같은 그림이 나온다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.saedsayad.com/images/ANN_Sigmoid.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.saedsayad.com&#34;&gt;http://www.saedsayad.com&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 때 &lt;em&gt;sigmoid function&lt;/em&gt; 이 적용된 &lt;code&gt;h(x)&lt;/code&gt; 는 최대값이 1이므로, 이건 입력값 &lt;code&gt;x&lt;/code&gt; 에 대해서 &lt;code&gt;y&lt;/code&gt; 가 1이 나올 확률이라 보아도 된다. 따라서&lt;/p&gt;

&lt;p&gt;&lt;code&gt;h(x) = P(y = 1 | x ; 0)&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Probability that &lt;code&gt;y = 1&lt;/code&gt;, given &lt;code&gt;x&lt;/code&gt;, parameterized by &lt;code&gt;0(theta)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 때 &lt;em&gt;sigmoid function&lt;/em&gt; 을 보면, X 축이 0보다 큰 점에선 &lt;code&gt;y&lt;/code&gt; 값이 0.5 보다 크므로, 이 점 이후부터는 &lt;code&gt;y&lt;/code&gt; 를 1 이라 &lt;em&gt;예측 (predict)&lt;/em&gt; 하고, 반대로 X 축 값이 0보다 작은 지점에선 &lt;code&gt;y&lt;/code&gt; 를 0이라 예측할 수 있다.&lt;/p&gt;

&lt;p&gt;그런데 &lt;code&gt;h(x) = g(0^T * x)&lt;/code&gt; 이므로, 본래의 &lt;em&gt;hypothesis&lt;/em&gt; &lt;code&gt;0^T * x&lt;/code&gt; 가 0이 되는 지점을 찾으면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/04/1341403634_5914.jpg&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer/&#34;&gt;http://blog.csdn.net/abcjennifer/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;decision-boundary&#34;&gt;Decision Boundary&lt;/h3&gt;

&lt;p&gt;이제 실제로 문제에 적용해 보자. 다음과 같이 두개의 집단이 있을때, 이 두 집단을 가르는 식을 찾기 위한 &lt;code&gt;h(x) = g(01 + 01x1 + 02x2)&lt;/code&gt; 가 있다고 해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/05/1341470683_7505.jpg&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer/&#34;&gt;http://blog.csdn.net/abcjennifer/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이때 &lt;code&gt;0(theta)&lt;/code&gt; 를 &lt;code&gt;[-3; 1; 1]&lt;/code&gt; 로 잡으면 &lt;code&gt;y&lt;/code&gt; 가 &lt;code&gt;1&lt;/code&gt; 이 되는 지점은 &lt;code&gt;0^T * x &amp;gt;= 0&lt;/code&gt; 인 지점, 즉 &lt;code&gt;-3 + x1 + x2 &amp;gt;= 0&lt;/code&gt; 인지점을 찾으면 된다. 이 식을 풀어서 쓰면&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x1 + x2 =&amp;gt; 3&lt;/code&gt; 이므로, 위 그림에서 분홍색 선을 찾을 수 있다. 이 선을 &lt;strong&gt;Decision Boundary&lt;/strong&gt; 라 부른다. 그리고 이 &lt;em&gt;Decision Boundary&lt;/em&gt; 는 &lt;code&gt;g(z) = 0&lt;/code&gt; 즉,  &lt;code&gt;h(x) = 0.5&lt;/code&gt; 인 지점이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Non-linear dicision boundary&lt;/em&gt; 는 어떨까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/05/1341471338_7289.jpg&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer/&#34;&gt;http://blog.csdn.net/abcjennifer/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 경우  &lt;code&gt;x1^2&lt;/code&gt;, &lt;code&gt;x2^2&lt;/code&gt; 이라는 새로운 &lt;em&gt;feature&lt;/em&gt; 를 도입하고, &lt;em&gt;parameter&lt;/em&gt; 인 &lt;code&gt;theta&lt;/code&gt; 를 &lt;code&gt;[-1; 0; 0; 1; 1;]&lt;/code&gt; 로 잡았다. 식을 풀면, 위와 같은 원 형태의 &lt;em&gt;Decision Boundary&lt;/em&gt; 가 나온다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;feature&lt;/em&gt; 만 잘 조합하면, 즉 &lt;em&gt;polynomial&lt;/em&gt; 만 잘 만들면 땅콩이나 하트모양 등의 &lt;em&gt;Decision boundary&lt;/em&gt; 도 만들 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h3&gt;

&lt;p&gt;이제 문제는 &lt;code&gt;theta&lt;/code&gt; 를 어떻게 고르느냐 하는건데, 식을 좀 다시 살펴보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[9].png&#34; align=&#34;center&#34; /&gt;
&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[11].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Linear regression&lt;/em&gt; 에서 사용하는 &lt;em&gt;cost function&lt;/em&gt; 에 지금의 &lt;code&gt;h(x)&lt;/code&gt;, 즉 &lt;em&gt;sigmoid function&lt;/em&gt; 이 적용된 &lt;code&gt;h(x)&lt;/code&gt; 를 제곱한 &lt;code&gt;J(0)&lt;/code&gt; 는 &lt;em&gt;non-convex&lt;/em&gt; 형태가 된다. 따라서 &lt;em&gt;global optimum&lt;/em&gt; 보다는 &lt;em&gt;local optimum&lt;/em&gt; 을 찾게 된다.&lt;/p&gt;

&lt;p&gt;이를 방지하기 위해서, &lt;em&gt;convex&lt;/em&gt; 형태의 &lt;em&gt;cost function&lt;/em&gt; 을 사용해야 하는데,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[12].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 &lt;em&gt;cost function&lt;/em&gt; 을 사용하면, &lt;code&gt;y = 1&lt;/code&gt; 일때 다음과 같은 그래프를 얻게 된다. &lt;code&gt;0 &amp;lt;= h(x) &amp;lt;= 1&lt;/code&gt; 임을 참고하자. &lt;code&gt;y = 1&lt;/code&gt; 일때, &lt;code&gt;h(x) = 0&lt;/code&gt; 으로 가면, &lt;em&gt;cost function&lt;/em&gt; 의 값, 즉 &lt;em&gt;cost&lt;/em&gt; 자체가 높아지므로, &lt;em&gt;Cost&lt;/em&gt; 를 낮추는 반대 방향으로 움직이게 된다.&lt;/p&gt;

&lt;p&gt;직관적으로 보면, &lt;code&gt;h(x)&lt;/code&gt; 자체는 &lt;code&gt;y = 1&lt;/code&gt; 일 확률인데, &lt;code&gt;y = 1&lt;/code&gt; 일때, &lt;code&gt;h(x) = 0&lt;/code&gt; 이라는 것은 말이 안 되므로 비용이 무한대로 증가하는 것이 말이 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[13].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;반대로 &lt;code&gt;y = 0&lt;/code&gt; 일때의 그래프를 보면 &lt;code&gt;h(x) = 0&lt;/code&gt; 즉, &lt;code&gt;y = 0&lt;/code&gt; 일 확률이 &lt;code&gt;0&lt;/code&gt; 으로 갈때 &lt;em&gt;cost&lt;/em&gt; 가 감소한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[14].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;결국 아래의 새로운 &lt;em&gt;logistric regression cost function&lt;/em&gt; 을 이용하면, &lt;code&gt;J(0)&lt;/code&gt; 를 &lt;em&gt;convex function&lt;/em&gt; 으로 만들 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[12].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;simplified-cost-function-and-gradient-descent&#34;&gt;Simplified Cost Function and Gradient Descent&lt;/h3&gt;

&lt;p&gt;이제 &lt;code&gt;y = 0&lt;/code&gt;, &lt;code&gt;y = 1&lt;/code&gt; 로 나누어져 있던 &lt;em&gt;cost function&lt;/em&gt; 을 좀 더 간단히 표현해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[15].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;다음과 동일하다. &lt;code&gt;y = 0&lt;/code&gt;, &lt;code&gt;y = 1&lt;/code&gt; 을 직접 넣어보면 금방 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cost(hθ(x),y) = -y * log(hθ(x)) - (1-y) * log(1 - hθ(x))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;
자 이제 다시 본론으로 돌아와서, 우리는 처음에 &lt;code&gt;theta&lt;/code&gt; 를 찾길 원했고, 그래서 &lt;em&gt;gradient descent&lt;/em&gt; 를 쓰려고 했는데, 마침 보니 &lt;code&gt;h(x)&lt;/code&gt; 가 &lt;em&gt;sigmoid function&lt;/em&gt; 이 적용된 형태라서 &lt;em&gt;non-convex function&lt;/em&gt; 이므로, &lt;code&gt;h(x)&lt;/code&gt; 를 포함한 &lt;em&gt;cost-function&lt;/em&gt; 이 &lt;em&gt;convex function&lt;/em&gt; 이 되는 식을 찾아냈다. 이제 그 식을 &lt;em&gt;gradient descent&lt;/em&gt; 에 적용하면,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[16].png&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이고, 이제 이걸 &lt;em&gt;batch gradient descent&lt;/em&gt; 에 적용하면 아래와 같은데, 여기에 &lt;em&gt;partial derivative&lt;/em&gt; 를 적용하면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[20].png&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;놀랍게도 &lt;em&gt;linear regression&lt;/em&gt; 과 같은 식이 나온다. &lt;del&gt;오오 머신러닝 오오&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[18].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;다만 다른점은 &lt;em&gt;hypothesis&lt;/em&gt; 가 &lt;em&gt;sigmoid function&lt;/em&gt; 을 적용한 형태라는 것,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[17].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;advanced-optimization&#34;&gt;Advanced Optimization&lt;/h3&gt;

&lt;p&gt;위에서 보았겠지만, &lt;code&gt;J(0)&lt;/code&gt; 의 최소값을 찾기 위해서는 아래 두개의 값을 구해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[19].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 값들을 이용해서 &lt;em&gt;gradient descent&lt;/em&gt; 대신 다음의 알고리즘을 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;(1) Conjugate gradient&lt;br /&gt;
(2) BFGS&lt;br /&gt;
(3) L-BFGS&lt;/p&gt;

&lt;p&gt;이 알고리즘들의 장점은, &lt;em&gt;leanring rate&lt;/em&gt; 를 고를 필요가 없고, 대부분 &lt;em&gt;gradient decsent&lt;/em&gt; 보다 빠르다.&lt;/p&gt;

&lt;p&gt;그러나 더 복잡하고, 라이브러리마다 구현이 다를 수 있으며, 디버깅이 힘들수 있다. 자 이제 &lt;em&gt;advanced optimization&lt;/em&gt; 을 이용해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[21].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위와 같은 식에 대해서 &lt;em&gt;cost function&lt;/em&gt; 을 &lt;code&gt;octave&lt;/code&gt; 에서 이렇게 만들 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[22].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;
&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;이제, &lt;code&gt;octave&lt;/code&gt; 에서 제공해 주는 &lt;code&gt;fminunc&lt;/code&gt; 에 우리가 만든 &lt;code&gt;costFunction&lt;/code&gt; 과 초기 &lt;code&gt;theta&lt;/code&gt; 값, 그리고 옵션을 집어 넣으면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-matlab&#34;&gt;% define the options data structure
options= optimset(&#39;GradObj&#39;, &#39;on&#39;, &#39;MaxIter&#39;, &#39;100&#39;); 

% set the initial dimensions for theta % initialize the theta values
initialTheta= zeros(2,1); 

% run the algorithm
[optTheta, funtionVal, exitFlag]= fminunc(@costFunction, initialTheta, options); 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;optTheta&lt;/code&gt; 는 우리 찾길 원했던 &lt;code&gt;theta&lt;/code&gt; 값이고, &lt;code&gt;functionVal&lt;/code&gt; 은 최종 &lt;em&gt;cost&lt;/em&gt; 를 돌려준다. &lt;code&gt;exstFlag&lt;/code&gt; 는 알고리즘이 수렴했는지, 아닌지 알려준다.&lt;/p&gt;

&lt;p&gt;만약 &lt;em&gt;logistic regression&lt;/em&gt; 에 대한 &lt;code&gt;theta&lt;/code&gt; 값을 찾고 싶으면, &lt;em&gt;cost function&lt;/em&gt; 을 &lt;em&gt;logistic regression&lt;/em&gt; 에 맞게 작성하면 된다.&lt;/p&gt;

&lt;h3 id=&#34;multiclass-classification&#34;&gt;Multiclass Classification&lt;/h3&gt;

&lt;p&gt;이제 단순히 &lt;code&gt;y = 0 or 1&lt;/code&gt;(&lt;em&gt;binary classification&lt;/em&gt;) 이 아닌, 다양한 &lt;em&gt;class&lt;/em&gt; 가 있는 &lt;em&gt;classification&lt;/em&gt; 을 고려해보자, 예를 들면 날씨는 &lt;code&gt;sunny&lt;/code&gt;, &lt;code&gt;cloudy&lt;/code&gt;, &lt;code&gt;hot&lt;/code&gt;, &lt;code&gt;cold&lt;/code&gt; 등으로 분류될 수 있다.&lt;/p&gt;

&lt;h4 id=&#34;one-vs-all-one-vs-rest&#34;&gt;one-vs-all (One-vs-rest)&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;multi class&lt;/em&gt; 를 분류할 수 있는 한가지 방법은, 하나를 정하고, 그 나머지와 분류하는것이다. 이걸 &lt;em&gt;class&lt;/em&gt; 갯수만큼 진행하면,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[23].png&#34; align=&#34;center&#34; /&gt;
&lt;img src=&#34;http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[24].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 그림과 같은 경우, &lt;em&gt;class&lt;/em&gt; 가 3개기 때문에 &lt;code&gt;(i = 1, 2, 3)&lt;/code&gt; 으로 놓으면 &lt;code&gt;i&lt;/code&gt; 마다 각각의 &lt;code&gt;hθ^(i)(x)&lt;/code&gt; 값, 즉 예측 값을 얻을 수 있다. 따라서 새로운 무언가가 input 으로 들어왔을때, &lt;code&gt;hθ^(i)(x)&lt;/code&gt; 값을 최대로 해주는 &lt;code&gt;i&lt;/code&gt; 을 선택하면 분류가 된다. &lt;del&gt;참 쉽죠?&lt;/del&gt;&lt;/p&gt;

&lt;h3 id=&#34;overfitting&#34;&gt;Overfitting&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Overfitting&lt;/strong&gt; 은 너무나 많은 &lt;em&gt;feature&lt;/em&gt; 가 있을 때는 &lt;em&gt;cost function&lt;/em&gt; 이 트레이닝 셋에 잘 맞아 &lt;code&gt;0&lt;/code&gt; 에 수렴 하지만, 새로운 데이터가 들어왔을때는 예측을 잘 하지 못하는 경우를 말한다. 다시 말해 &lt;em&gt;hypothesis&lt;/em&gt; 가 너무 고차원의 다항식이어서 그렇다. &lt;em&gt;(too many parameters)&lt;/em&gt; 즉 아래 그림에서 좌측은 경향을 나타내긴 하지만 모든 트레이닝셋을 경유하는 직선은 만들어내지 못했다. (&lt;em&gt;under fit&lt;/em&gt;) 반면 가장 우측은, 트레이닝셋을 모두 경유하는 &lt;em&gt;hypothesis&lt;/em&gt; 를 만들어 냈지만, 다항식의 차수가 너무 높아 새로운 데이터가 들어왔을 때 예측하지 못할 수가 있다. &lt;em&gt;can&amp;rsquo;t apply, unable to generalize&lt;/em&gt; 교수님은 다음과 같이 슬라이드에 적으셨다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It makes accurate predictions for examples in the training set, but it does not generalize well to make accurate prediction on new, previously unseen examples&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;logistic regression&lt;/em&gt; 에서도 &lt;em&gt;Overfitting&lt;/em&gt; 이 발생할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[1].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;주로 &lt;em&gt;training set&lt;/em&gt; 이 부족하고 &lt;em&gt;feature&lt;/em&gt; 가 많을때 발생하는데 해결책은&lt;/p&gt;

&lt;p&gt;(1) &lt;em&gt;feature&lt;/em&gt; 를 줄일 수 있다. 수동으로 사용할 &lt;em&gt;feature&lt;/em&gt; 를 선택하는 방법과 &lt;em&gt;Model selection algorithm&lt;/em&gt; 을 사용할 수도 있다.&lt;br /&gt;
(2)  &lt;em&gt;regularization&lt;/em&gt; 을 이용한다. 모든 &lt;em&gt;feature&lt;/em&gt; 를 유지하지만, 얼마나 각 &lt;em&gt;feature&lt;/em&gt; 가 &lt;em&gt;prediction&lt;/em&gt; 에 기여할지를 변경한다.&lt;/p&gt;

&lt;h3 id=&#34;regularization-cost-function&#34;&gt;Regularization, Cost function&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Regularization&lt;/em&gt; 은 원하는 파라미터가 &lt;em&gt;hypothesis&lt;/em&gt; 에 기여하는 바를 조절하는 것이다. 우리가 만약에 &lt;code&gt;0_3&lt;/code&gt; 과 &lt;code&gt;0_4&lt;/code&gt; 를 최소화 하고 싶다고 하자.  그럼 다음과 같은 식을 만들면 된다. 전체 식의 최소값을 찾는 것이기 때문에, 상수가 &lt;code&gt;1000&lt;/code&gt; 인 &lt;code&gt;0_3&lt;/code&gt;, &lt;code&gt;0_4&lt;/code&gt; 는 &lt;em&gt;0(zero)&lt;/em&gt; 에 가까운 수가 나온다. 다시 말해서 이들 두 파라미터가 기여하는 바를 줄인 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[2].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;parameters&lt;/em&gt; 가 작은 값을 가질수록 간단한 &lt;em&gt;hypothesis&lt;/em&gt; 가 나오고, &lt;em&gt;overfitting&lt;/em&gt; 하지 않는다. 이를 위해 &lt;code&gt;λ&lt;/code&gt; 라는 &lt;em&gt;regularization parameter&lt;/em&gt; 를 가진 식을 &lt;em&gt;cost function&lt;/em&gt; 에 더 붙여 &lt;em&gt;parameter&lt;/em&gt; 가 기여하는 바를 조절하면, 아래와 같은 식을 구할 수 있다. 참고로 뒷 부분의 식은  &lt;em&gt;regularization term&lt;/em&gt; 이라 부르는데, &lt;code&gt;j&lt;/code&gt; 가 1부터 시작하는 것에 주목하자. 이는 &lt;code&gt;0_0&lt;/code&gt; 은 &lt;em&gt;regularization&lt;/em&gt; 하지 않는다는 의미이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[5].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;λ&lt;/code&gt; 가 매우 크면 어떻게 될까? &lt;code&gt;0_0&lt;/code&gt; 이외의 다른 파라미터는 0에 수렴 하므로, &lt;em&gt;hypothesis&lt;/em&gt; 는 상수가 되어 트레이닝 셋에 &lt;em&gt;under fit&lt;/em&gt; 할 것이다.&lt;/p&gt;

&lt;h3 id=&#34;regularized-linear-regression&#34;&gt;Regularized Linear Regression&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;regularization term&lt;/em&gt; 으 &lt;code&gt;j&lt;/code&gt; 가 1부터 시작하므로, &lt;em&gt;cost function&lt;/em&gt; 을 쉽게 계산하기 위해 분리하면 &lt;em&gt;gradient descent&lt;/em&gt; 식은 다음과 같이 적을 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[6].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이제 위 두 식에서 아래 식을 정리하면, 다음과 같고&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[8].png&#34; align=&#34;center&#34; /&gt;
&amp;lt;면 된다. 이때 이 매트릭스의 &lt;code&gt;(0, 0)&lt;/code&gt;
위 식에서 앞부분은 아래와 같다. 보통 &lt;code&gt;m&lt;/code&gt; 이 매우 크고, &lt;code&gt;a&lt;/code&gt; 가 매우 작으므로 위 값은 1보다 작다. 예를 들면 &lt;code&gt;0.99 * 0_j&lt;/code&gt; 처럼.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[9].png&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이제 &lt;em&gt;Normal equation&lt;/em&gt; 에 어떻게 적용할지 고려해 보자, 본래 &lt;em&gt;normal equation&lt;/em&gt; 식은 아래와 같은데,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/04_Linear_Regression_with_multiple_variables_files/Image%20[13].png&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;X^T * X&lt;/code&gt; 부분에 &lt;code&gt;λ&lt;/code&gt; 가 곱해지는 &lt;code&gt;n+1 * n+1&lt;/code&gt; 의 &lt;em&gt;matrix&lt;/em&gt; 를 곱하면 된다. 이때 이 매트릭스의 &lt;code&gt;(0, 0)&lt;/code&gt; 부분이 &lt;code&gt;0&lt;/code&gt; 인 것은 &lt;code&gt;0_0&lt;/code&gt; 에 &lt;em&gt;regularization&lt;/em&gt; 을 적용하지 않기 위한 것.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[10].png&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;그럼 만약에 &lt;code&gt;X^T * X&lt;/code&gt; 가 &lt;em&gt;non-invertible&lt;/em&gt; 이라면 어떻게 될까? 이건 지난 시간에 언급했듯이 &lt;em&gt;redundant feature&lt;/em&gt; 가 너무 많거나, &lt;code&gt;m &amp;lt;= n&lt;/code&gt;, 즉 트레이닝 셋에 비해 &lt;em&gt;feature&lt;/em&gt; 가 너무 많을 때 발생한다고 말했다.&lt;/p&gt;

&lt;p&gt;놀랍게도, &lt;code&gt;λ &amp;gt; 0&lt;/code&gt; 이면, 아래 식에서 &lt;code&gt;X^T * X + λ&lt;/code&gt; (λ&amp;rsquo;s (0, 0) = 0) 은 제대로 &lt;em&gt;invertible&lt;/em&gt; 함을 증명할 수 있다. 다시 말해서 &lt;em&gt;regularzation&lt;/em&gt; 을 통해서 &lt;em&gt;non-invertible&lt;/em&gt; 문제도 해결할 수 있다는 것.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[10].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;regularized-logistic-regression&#34;&gt;Regularized Logistic Regression&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;linear regression&lt;/em&gt; 과 마찬가지로 &lt;code&gt;0(theta)&lt;/code&gt; 를 0과 1로 분리해 &lt;em&gt;regularization term&lt;/em&gt; 을 추가하면 된다. 다른점은 &lt;code&gt;h(x)&lt;/code&gt; 가 &lt;em&gt;sigmoid function&lt;/em&gt; 의 형태라는 것.&lt;/p&gt;

&lt;p&gt;그리고 &lt;em&gt;gradient descent&lt;/em&gt; 를 풀기 위해 &lt;em&gt;octave&lt;/em&gt; 에서 제공하는 알고리즘들을(&lt;em&gt;conjugate&lt;/em&gt;, &lt;em&gt;BFGS&lt;/em&gt;, &lt;em&gt;L-BFGS&lt;/em&gt; 등) 을 &lt;code&gt;fminunc&lt;/code&gt; 이용해서 사용할 수 있다. 이를 위해 언급 했듯이 &lt;code&gt;jval&lt;/code&gt; 과 &lt;code&gt;0(theta)&lt;/code&gt; 에 대한 &lt;code&gt;graident&lt;/code&gt; 를 돌려주는 &lt;em&gt;cost function&lt;/em&gt; 을 만들어야 하는데, &lt;em&gt;regularzation term&lt;/em&gt; 이 추가되었으므로 해당하는 값을 더해서 각 &lt;code&gt;0&lt;/code&gt; 에 대한 &lt;em&gt;gradient&lt;/em&gt; 를 계산하는 식을 만들어주면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[16].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;
&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;3주째에는 &lt;em&gt;Classification&lt;/em&gt; 과 &lt;em&gt;Regularization&lt;/em&gt; 에 대해서 배웠다. 수업은 어렵지 않다. 과제가 문제지 ㅠㅠ 교수님. 파이썬으로 과제를 내주셨으면 좀 더 배우는 맛이 있었을텐데요!&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;a href=&#34;http://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression&#34;&gt;why-not-approach-classification-through-regression&lt;/a&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://www.saedsayad.com/artificial_neural_network.htm&#34;&gt;http://www.saedsayad.com&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://blog.csdn.net/abcjennifer/&#34;&gt;http://blog.csdn.net/abcjennifer/&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Machine Learning&lt;/strong&gt; by Andrew Ng, &lt;em&gt;Coursera&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 04: Neural Network</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-4/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:25 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-4/</guid>
      <description>

&lt;p&gt;지난 시간에는 실리콘 밸리의 머신러닝 개발자들이 귀한대접을 받는다는 훈훈한 덕담으로 강의가 끝났다. 이번시간에는 뜬금없이 &lt;em&gt;Neural Network (신경망)&lt;/em&gt; 을 건들다가 놀랍게도 그것이 &lt;em&gt;logistic regression&lt;/em&gt; 과 연관이 있으며 &lt;code&gt;n&lt;/code&gt; 이 매우 클 경우의 &lt;em&gt;classification&lt;/em&gt; 문제를 해결할 수 있다는 것을 배운다.&lt;/p&gt;

&lt;h3 id=&#34;non-linear-hypotheses&#34;&gt;Non-Linear Hypotheses&lt;/h3&gt;

&lt;p&gt;다음과 같은 트레이닝 셋이 있을때, 두 집단을 &lt;em&gt;classification&lt;/em&gt; 하는 &lt;em&gt;hypothesis&lt;/em&gt; 를 찾는다고 하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/08_Neural_Networks_Representation_files/Image.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org&#34;&gt;http://www.holehouse.org&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x1&lt;/code&gt; 과 &lt;code&gt;x2&lt;/code&gt; 만으로는 찾을 수 없으니, 더 많은 &lt;em&gt;feature&lt;/em&gt;  &lt;code&gt;x1^2, x1x2, x2^2&lt;/code&gt; 를 도입한다 하자. 트레이닝 셋에 적합한 가설을 찾을수는 있겠지만, 항상 좋은건 아니다.&lt;/p&gt;

&lt;p&gt;(1) 우선 지난 시간에 언급했듯이 &lt;em&gt;Overfitting&lt;/em&gt; 이 발생할 수 있고&lt;br /&gt;
(2) &lt;em&gt;feature&lt;/em&gt; 수가 &lt;code&gt;n&lt;/code&gt; 이라 할때, 모든 &lt;em&gt;quadratic feature&lt;/em&gt; 를 도입하면 &lt;em&gt;feature&lt;/em&gt; 수가 &lt;code&gt;O(n^2)&lt;/code&gt; (&lt;code&gt;n^2/2&lt;/code&gt;)만큼 늘어난다. (아래 그림 참조) 다시 말해서 계산 비용이 엄청나게 비싸진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20140507021224421&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/feliciafay&#34;&gt;http://blog.csdn.net/feliciafay&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;그리고 &lt;em&gt;feature&lt;/em&gt; 수를 줄이기 위해 &lt;code&gt;x1^2, x2^2, x3^2 ...&lt;/code&gt; 등 &lt;em&gt;quadratic feature&lt;/em&gt; 만을 도입하고 나머지 &lt;em&gt;parameter&lt;/em&gt; 를 버리면, &lt;em&gt;hypothesis&lt;/em&gt; 가 &lt;em&gt;underfit&lt;/em&gt; 할 수 있다.&lt;/p&gt;

&lt;p&gt;만약 &lt;em&gt;feature&lt;/em&gt; 를 &lt;em&gt;cubic&lt;/em&gt; 까지 도입하면 &lt;em&gt;feature&lt;/em&gt; 수가 &lt;code&gt;O(n^3)&lt;/code&gt; 으로 늘어나 계산시간은 어마어마하게 걸린다. 따라서 차수를 늘려 문제를 해결하려는 방법은 &lt;code&gt;n&lt;/code&gt; 이 클때 좋은 방법이 아니다. 게다가 일반적으로 대부분의 문제들은 &lt;code&gt;n&lt;/code&gt; 이 큰편이다.&lt;/p&gt;

&lt;p&gt;자동차 이미지 인식 문제를 고려해 보자. 이미지는 픽셀이므로, 50 * 50 픽셀로 구성된 경우 &lt;code&gt;n = 2500&lt;/code&gt; 이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20140507021231812&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/feliciafay&#34;&gt;http://blog.csdn.net/feliciafay&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이건 그레이스케일의 경우고 만약 RGB 라면 여기에 3을 곱해서 &lt;code&gt;n = 7500&lt;/code&gt; 이 된다. &lt;em&gt;quadratic&lt;/em&gt; 이면 &lt;code&gt;7500^2 / 2&lt;/code&gt;, 대략 3 millions 개의 &lt;em&gt;feature&lt;/em&gt; 를 가지게 된다. 이쯤되면 답이 없다. &lt;code&gt;n&lt;/code&gt; 이 큰 &lt;em&gt;classification&lt;/em&gt; 에 대해 사용할 수 있는 다른 방법은 없을까?&lt;/p&gt;

&lt;h3 id=&#34;model-representation&#34;&gt;Model Representation&lt;/h3&gt;

&lt;p&gt;잠깐 눈을 돌려 &lt;em&gt;Neural Networks&lt;/em&gt; 에 대해 이야기 해 보자. 다양한 알고리즘을 개발하는 대신  스스로 학습하는 뇌를 모방한 알고리즘을 개발할 수 있다면 진짜 AI 를 구현할 수 있지 않을까? 라는 질문에서 &lt;em&gt;Neural networks&lt;/em&gt; 는 출발한다.&lt;/p&gt;

&lt;p&gt;뇌를 모방한 알고리즘을 만들려면, 인간의 뇌가 어떻게 작동하는지 알아야한다. 뇌는 &lt;em&gt;Neuron&lt;/em&gt; 이라는 단위의 집합으로 구성되었는데, 요로코롬 생겼다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://home.agh.edu.pl/~vlsi/AI/intro/neuron.png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://home.agh.edu.pl/~vlsi/AI/intro/&#34;&gt;http://home.agh.edu.pl/~vlsi/AI/intro/&lt;/a&gt;)&lt;/p&gt;
&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;em&gt;Dendrite&lt;/em&gt; 라는 부분이 &lt;strong&gt;input&lt;/strong&gt; 이고, &lt;em&gt;Axon&lt;/em&gt; 이 &lt;strong&gt;output&lt;/strong&gt; 이다. 이걸 모델링하면,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20140507021238515&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/feliciafay&#34;&gt;http://blog.csdn.net/feliciafay&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 좌측에 있는 &lt;code&gt;x1, x2, x3&lt;/code&gt; 가 &lt;em&gt;input&lt;/em&gt; 이라 보면 되고, &lt;code&gt;h0(x)&lt;/code&gt; 는 이전처럼 &lt;code&gt;0^T * x&lt;/code&gt; 에 &lt;em&gt;sigmoid function&lt;/em&gt; 을 적용한 것이다. 그리고 &lt;em&gt;neural network&lt;/em&gt; 에서 &lt;em&gt;parameter&lt;/em&gt; 대신 &lt;code&gt;0(theta)&lt;/code&gt; 를 &lt;strong&gt;weights&lt;/strong&gt; 라 부르기도 한다. &lt;code&gt;x0&lt;/code&gt; 은 값이 &lt;code&gt;1&lt;/code&gt; 이고, &lt;em&gt;bias unit&lt;/em&gt; 이라 부르는데 편의상 그리기도 하고 안그리기도 한다. &lt;del&gt;교수님 뜻대로 하소서&lt;/del&gt;
&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;여기까지는 단일 &lt;em&gt;neuron&lt;/em&gt; 을 모델링 한것이고, &lt;em&gt;neural network&lt;/em&gt; 는 여러개의 &lt;em&gt;neuron&lt;/em&gt; 들이 합쳐진 것이다. 간단히 그려보면,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20140507021247656&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/feliciafay&#34;&gt;http://blog.csdn.net/feliciafay&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;em&gt;layer 1&lt;/em&gt; 은 &lt;em&gt;input layer&lt;/em&gt;, 마지막인 *layer 3*은 &lt;em&gt;output layer&lt;/em&gt; 다. 그리고 가운데 있는 레이어들, 여기서는 &lt;em&gt;layer2&lt;/em&gt;, &lt;strong&gt;hidden layer&lt;/strong&gt; 라 부른다. 디버깅이 아니라면 &lt;em&gt;hidden layer&lt;/em&gt; 에서 산출되는 값들을 관측하려고 할 필요는 없다. &lt;em&gt;hidden layer&lt;/em&gt; 는 하나 이상일 수 있다. 실제 계산 과정을 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20140507021254640&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/feliciafay&#34;&gt;http://blog.csdn.net/feliciafay&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ai^j&lt;/code&gt; 는, &lt;code&gt;j&lt;/code&gt; 번째 &lt;em&gt;hidden layer&lt;/em&gt; 에서 &lt;code&gt;i&lt;/code&gt; 번째 &lt;em&gt;unit&lt;/em&gt; 이다. &lt;code&gt;0(theta)^j&lt;/code&gt; 는 &lt;em&gt;layer j&lt;/em&gt; 와 &lt;em&gt;layer j+1&lt;/em&gt; 사이에서 사용되는 &lt;em&gt;weights&lt;/em&gt; 다. 이때 &lt;em&gt;hidden layer&lt;/em&gt; 의 각 &lt;em&gt;unit&lt;/em&gt; 마다 &lt;em&gt;input&lt;/em&gt; 을 위한 &lt;em&gt;weight&lt;/em&gt; 를 가지고 있다고 하면 위의 그림에서 &lt;code&gt;0&lt;/code&gt; 의 &lt;em&gt;dimension&lt;/em&gt; 은 &lt;code&gt;3 * 4&lt;/code&gt; 다. (&lt;em&gt;bias unit&lt;/em&gt; &lt;code&gt;x0&lt;/code&gt; 포함)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If network has &lt;code&gt;s_j&lt;/code&gt; units in layer &lt;code&gt;j&lt;/code&gt;, &lt;code&gt;s_j+1&lt;/code&gt; units in layer &lt;code&gt;j+1&lt;/code&gt;, then &lt;code&gt;0^j&lt;/code&gt; will be dimension &lt;code&gt;s_j+1 * (s_j + 1)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이제 &lt;em&gt;output layer&lt;/em&gt; 를 잘 보면 이 레이어의 &lt;em&gt;input&lt;/em&gt; 은 &lt;code&gt;a^(2)&lt;/code&gt; 고, &lt;em&gt;weight&lt;/em&gt; 로 &lt;code&gt;0^2&lt;/code&gt; 를 가지고 있다. 따라서 &lt;code&gt;h0(x)&lt;/code&gt; 는 위의 식처럼 된다.&lt;/p&gt;

&lt;h3 id=&#34;forward-propagation&#34;&gt;Forward Propagation&lt;/h3&gt;

&lt;p&gt;위 그림처럼 &lt;code&gt;x&lt;/code&gt; 를 받아, &lt;code&gt;h0(x)&lt;/code&gt; 를 계산하는 방법을 &lt;em&gt;forward propagation&lt;/em&gt; 이라 부르는데 &lt;em&gt;vectorization&lt;/em&gt; 을 이용해서 간단히 해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.try2go.com/wp-content/uploads/2014/08/forward-propogation.jpg&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.try2go.com/201408/neural-networks-1/&#34;&gt;http://www.try2go.com/201408/neural-networks-1/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;sigmoid fucntion&lt;/em&gt; &lt;code&gt;g&lt;/code&gt; 내부의 수식을 &lt;code&gt;z&lt;/code&gt; 라 부르고 &lt;code&gt;a^(1) = x&lt;/code&gt; 라 두면, 우측처럼 수식이 심플해진다. &lt;code&gt;z^(2) = 0^(1) * a^(1)&lt;/code&gt; 이고, 여기에 &lt;em&gt;sigmoid function&lt;/em&gt; 을 적용하면 &lt;code&gt;a^(2)&lt;/code&gt; 가 나온다. 여기에 &lt;em&gt;bias unit&lt;/em&gt; &lt;code&gt;a_0^(2) = 1&lt;/code&gt; 을 더해 &lt;code&gt;a^(2)&lt;/code&gt; 를 4차원 벡터로 만들면 다시 &lt;code&gt;z^(3)&lt;/code&gt; 를 계산할 수 있다.
&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;자, 이제 왜 &lt;em&gt;neural network&lt;/em&gt; 를 뜬금없이 공부하다가 &lt;em&gt;forward propagation&lt;/em&gt; 의 &lt;em&gt;vectorization&lt;/em&gt; 까지 고려했는지를 밝힐 시간이다! 위 그림에서 &lt;code&gt;a^(1)&lt;/code&gt; 즉, &lt;em&gt;layer 1&lt;/em&gt; 을 가려버리면 아래와 같은데&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.try2go.com/wp-content/uploads/2014/08/learn-features.jpg&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.try2go.com/201408/neural-networks-1/&#34;&gt;http://www.try2go.com/201408/neural-networks-1/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이때 &lt;code&gt;h0(x)&lt;/code&gt; 를 계산하는 식을 구해보면, &lt;em&gt;logistic regression&lt;/em&gt; 과 똑같다. &lt;del&gt;오오 머신러닝 오오&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;결국, &lt;em&gt;neural network&lt;/em&gt; 가 하는 일은 &lt;em&gt;logistic regression&lt;/em&gt; 이다.&lt;/strong&gt; 단지  &lt;em&gt;hidden layer&lt;/em&gt; 에서 &lt;code&gt;x1, x2, x3&lt;/code&gt; 를 적당한 &lt;em&gt;weight&lt;/em&gt; 로 훈련시켜 새로운 &lt;em&gt;feature&lt;/em&gt; &lt;code&gt;a1^(2),  a2^(2), a3^(2)&lt;/code&gt; 를 만들어 내고, 그걸로 &lt;em&gt;logistic regression&lt;/em&gt; 을 할 뿐이다.&lt;/p&gt;

&lt;p&gt;다시 한번 정리하자면 &lt;em&gt;neural network&lt;/em&gt; 는 &lt;em&gt;feature&lt;/em&gt; 를 훈련시켜 다른 값을 가진  &lt;em&gt;feature&lt;/em&gt; 로 바꾸는 과정을 통해 &lt;em&gt;hypothesis&lt;/em&gt; 를 매우 고차의 다항식으로 만들지 않고도 &lt;code&gt;n&lt;/code&gt; 이 매우 큰 경우의 &lt;em&gt;classification&lt;/em&gt; 을 풀 수 있도록 한다. 항상 같은 개수의 &lt;em&gt;feature&lt;/em&gt; 만 나오는건 아니고, 더 줄이거나 좀 더 늘릴 수도 있다. 아래의 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://alphaism.files.wordpress.com/2012/11/selection_001.png?w=630&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://alphaism.wordpress.com/&#34;&gt;http://alphaism.wordpress.com/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;p&gt;먼저 간단히 &lt;em&gt;AND&lt;/em&gt; 연산을 &lt;em&gt;neural network&lt;/em&gt; 로 구현한다 하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.try2go.com/wp-content/uploads/2014/08/and.jpg&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.try2go.com/201408/neural-networks-1/&#34;&gt;http://www.try2go.com/201408/neural-networks-1/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 그림처럼 &lt;code&gt;z^(2) = -30 + 20x1 + 20x2&lt;/code&gt; 라면, 우측 표 처럼 각각 &lt;code&gt;h0(x)&lt;/code&gt; 값이 나오고, &lt;em&gt;sigmoid function&lt;/em&gt; 은 &lt;code&gt;4.6&lt;/code&gt; 정도일때 &lt;code&gt;y ~= 0.99&lt;/code&gt; 이므로 &lt;code&gt;g(+10)&lt;/code&gt; 은 거의 &lt;code&gt;1&lt;/code&gt;, &lt;code&gt;g(-10)&lt;/code&gt; 은 거의 &lt;code&gt;0&lt;/code&gt; 이라 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;XNOR&lt;/em&gt; 은 &lt;em&gt;AND&lt;/em&gt; &lt;em&gt;~ AND ~&lt;/em&gt; 그리고 &lt;em&gt;OR&lt;/em&gt; 을 조합하면 만들 수 있다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/08_Neural_Networks_Representation_files/Image%20[17].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org&#34;&gt;http://www.holehouse.org&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;결국 &lt;em&gt;neural network&lt;/em&gt; 는 각 &lt;em&gt;hidden layer&lt;/em&gt; 에서 함수를 이용해 이전 단계의 결과에 어떤 처리를 가해 복잡한 일들을 해낼 수 있는 것이다.&lt;/p&gt;

&lt;h3 id=&#34;multiclass-classification&#34;&gt;Multiclass Classification&lt;/h3&gt;

&lt;p&gt;이제 &lt;em&gt;multi-class&lt;/em&gt; 를 고려해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.try2go.com/wp-content/uploads/2014/08/one-vs-all.jpg&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.try2go.com/201408/neural-networks-1/&#34;&gt;http://www.try2go.com/201408/neural-networks-1/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 그림처럼 4개의 클래스가 있을 때, &lt;em&gt;output&lt;/em&gt; 인 &lt;code&gt;h(x)&lt;/code&gt; 를 &lt;code&gt;4 * 1&lt;/code&gt; vector 로 만들도록 하고, 각 클래스에 대해서 &lt;code&gt;[1; 0; 0; 0], [0; 1; 0; 0], [0; 0; 1; 0], [0; 0; 0; 1]&lt;/code&gt; 이 되도록 훈련시키면 된다. 기본적인 아이디어는 &lt;em&gt;one vs all method&lt;/em&gt; 와 같다.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;a href=&#34;http://blog.csdn.net/feliciafay/article/details/25171147&#34;&gt;http://blog.csdn.net/feliciafay&lt;/a&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://www.holehouse.org/mlclass/08_Neural_Networks_Representation.html&#34;&gt;http://www.holehouse.org&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://home.agh.edu.pl/~vlsi/AI/intro/&#34;&gt;http://home.agh.edu.pl/~vlsi/AI/intro/&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://www.try2go.com/201408/neural-networks-1/&#34;&gt;http://www.try2go.com/201408/neural-networks-1/&lt;/a&gt;&lt;br /&gt;
(5) &lt;a href=&#34;http://alphaism.wordpress.com/2012/11/13/neural-network-algorithm/&#34;&gt;http://alphaism.wordpress.com/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 05: Back Propagation</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-5/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:28 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-5/</guid>
      <description>

&lt;p&gt;지난시간엔 왜 &lt;em&gt;neural network&lt;/em&gt; 를 사용하는지 알아보았다. 데이터의 차수가 매우 클 때 &lt;em&gt;logistic regression&lt;/em&gt; 으로는 성능이 떨어지거나 &lt;em&gt;overfitting&lt;/em&gt; 의 문제가 발생할 수 있다는 사실을 알게 되었고, 마지막엔 &lt;em&gt;multi class&lt;/em&gt; 문제를 어떻게 해결할지도 잠깐 논의 해봤다.&lt;/p&gt;

&lt;p&gt;이번에는 &lt;em&gt;back propagation&lt;/em&gt;, &lt;em&gt;gradient checking&lt;/em&gt; 에 대해서 배워보자.&lt;/p&gt;

&lt;h3 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h3&gt;

&lt;p&gt;시작하기 전에 몇 가지 표기법을 정의하자.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;L&lt;/code&gt; 을 레이어의 수, &lt;code&gt;s_l&lt;/code&gt; 을 해당 레이어의 유닛 수라 하자. 그러면 &lt;em&gt;bianry classification&lt;/em&gt; 에서 &lt;code&gt;S_L = 1&lt;/code&gt; 이다. 아웃풋 레이어의 유닛 수를 더 간단히 &lt;code&gt;K&lt;/code&gt; 라 하자.&lt;/p&gt;

&lt;p&gt;이제 &lt;em&gt;neural network&lt;/em&gt; 에 대한 &lt;em&gt;cost function&lt;/em&gt; 을 볼건데 먼저 &lt;em&gt;binary classification&lt;/em&gt; 의 &lt;em&gt;regularized cost function&lt;/em&gt; 식을 다시 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://3.bp.blogspot.com/-qNym-oCdMIg/Trd03YeslWI/AAAAAAAAApQ/GUfXiJ3vpUE/s400/Screen+shot+2011-11-07+at+3.03.55+AM.png&#34; alt=&#34;http://aimotion.blogspot.kr/&#34; /&gt;&lt;/p&gt;

&lt;p&gt;지난 시간에 언급했듯이 신경망에서 각 단계는 &lt;em&gt;logistic regression&lt;/em&gt; 과 같이 때문에 &lt;code&gt;L&lt;/code&gt; 의 신경망은 &lt;code&gt;L-1&lt;/code&gt; 의 &lt;em&gt;logistic regression&lt;/em&gt; 의 식으로 변환할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20[3].png&#34; align=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;이 식의 가장 큰 문제점은 이 식을 보면 당황스럽다는 것이다.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;뒷 부분 &lt;em&gt;regularization term&lt;/em&gt; 은 이해하기 어렵지 않다. 신경망에선 &lt;code&gt;weight&lt;/code&gt; (&lt;em&gt;theta&lt;/em&gt;) 의 행렬이 이전 레이어와 다음 레이어의 유닛 수로 구성되므로 &lt;code&gt;(theta_ji^l)^2&lt;/code&gt; 으로 모든 &lt;code&gt;theta^2&lt;/code&gt; 를 구할 수 있다.&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;i = 1&lt;/code&gt; 부터 시작하는 이유는 &lt;em&gt;logistic regression&lt;/em&gt; 의 &lt;em&gt;regularization term&lt;/em&gt; 에서 &lt;code&gt;theta_0&lt;/code&gt; 을 포함하지 않는것과 같다.&lt;/p&gt;

&lt;p&gt;문제는 시그마 &lt;code&gt;K&lt;/code&gt; 부분인데, &lt;code&gt;K&lt;/code&gt; 가 이 신경망에서 클래스의 개수 라는 점을 고려하면 &lt;code&gt;y_k&lt;/code&gt; 는 &lt;code&gt;[0; 0; 1; 0; ...]&lt;/code&gt; 에서 &lt;code&gt;k&lt;/code&gt; 번째 값, &lt;code&gt;(h0)_k&lt;/code&gt; 또한 &lt;code&gt;k&lt;/code&gt; 번째 &lt;em&gt;output unit&lt;/em&gt; 의 값 이라 보면 된다.&lt;/p&gt;

&lt;p&gt;원래 &lt;em&gt;cost function&lt;/em&gt; 정의 자체가 우리가 가진 &lt;em&gt;hypothesis&lt;/em&gt; 로 구한 값과 본래의 값 &lt;code&gt;y&lt;/code&gt; 와의 차이를 알려주는 것이므로 &lt;code&gt;K&lt;/code&gt; 개의 클래스가 있을때는 각 클래스 위치의 값과 본래의 &lt;em&gt;k-dimensional vector&lt;/em&gt; &lt;code&gt;y&lt;/code&gt; 값의 해당 포지션의 차이를 모두 합한 값을 구하는 것이라 &lt;em&gt;neural network&lt;/em&gt; 의 &lt;em&gt;cost function&lt;/em&gt;  정의할 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;backpropagation-algorithm&#34;&gt;Backpropagation: Algorithm&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;gradient computation&lt;/em&gt; 을 위해서는 &lt;em&gt;cost function&lt;/em&gt; 과 각 &lt;code&gt;l&lt;/code&gt; 의 &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;j&lt;/code&gt; 위치의 &lt;code&gt;theta&lt;/code&gt; 에 대해서 &lt;em&gt;cost function&lt;/em&gt; 의 &lt;em&gt;partial derivative&lt;/em&gt; 를 구해야 한다. &lt;del&gt;네?&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20[7].png&#34; align=&#34;center&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20[8].png&#34; alt=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20[8].png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;다음과 같은 신경망이 있다고 하자, 그리고 &lt;em&gt;training set&lt;/em&gt; 이 &lt;code&gt;(x, y)&lt;/code&gt; 만 있다고 한다면 &lt;em&gt;cost function&lt;/em&gt; 을 얻기 위해 다음의 &lt;em&gt;forward propagation&lt;/em&gt; 을 진행하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20[9].png&#34; alt=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20[9].png&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;그럼 &lt;code&gt;i, j, l&lt;/code&gt; 에 대한 &lt;em&gt;cost function&lt;/em&gt; 의 &lt;em&gt;partial derivative&lt;/em&gt; 는 어떻게 구할까?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;back propagation&lt;/strong&gt; 을 이용하면 된다. 개요는 이렇다. 마지막 단계에서 신경망을 이용해 얻은 값 &lt;code&gt;a4&lt;/code&gt; 와 실제 값인 &lt;code&gt;y&lt;/code&gt; 의 차이를 &lt;code&gt;d4&lt;/code&gt;(&lt;em&gt;delta&lt;/em&gt;) 라 하자. 보면 알겠지만 이건 &lt;em&gt;error&lt;/em&gt; 다. 이 에러값을 이용해 &lt;code&gt;d3&lt;/code&gt; 즉 레이어 3 에서의 에러값을 구하고, 반복하면서 &lt;code&gt;d2&lt;/code&gt; 까지 구한다. (&lt;code&gt;d1&lt;/code&gt; 은 없다. &lt;code&gt;a1&lt;/code&gt; 이 &lt;em&gt;input&lt;/em&gt; 이기때문)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;forward propagation&lt;/em&gt; 과 다르게 뒤에서 앞쪽으로 &lt;em&gt;error&lt;/em&gt; 가 전파되기 때문에 &lt;em&gt;back propagation, BP&lt;/em&gt; 라 부른다. BP 로 찾은 &lt;code&gt;d&lt;/code&gt; 값을 이용하면 &lt;em&gt;partial derivative&lt;/em&gt; 를 쉽게 구할 수 있다. &lt;code&gt;d3, d2&lt;/code&gt; 를 구하는 방법은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20[10].png&#34; alt=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning_files/Image%20[10].png&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.holehouse.org/&#34;&gt;http://www.holehouse.org/&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;식에 대한 &lt;em&gt;intuition&lt;/em&gt; 은 이전 레이어의 유닛의 &lt;code&gt;d&lt;/code&gt; 를 얻기 위해서 다음 레이어의 모든 &lt;code&gt;d&lt;/code&gt; 와 &lt;code&gt;theta&lt;/code&gt; 의 곱을 이용한다는 사실이다. 이건 &lt;em&gt;FP&lt;/em&gt; 에서 다음 단계의 유닛 &lt;code&gt;a&lt;/code&gt; 를 얻기 위해 이전 단계의 모든 유닛과 &lt;code&gt;theta&lt;/code&gt; 를 이용한다는 사실을 거꾸로 생각해보면 이해할 수 있다.&lt;/p&gt;

&lt;p&gt;이때 &lt;em&gt;sigmoid function&lt;/em&gt; &lt;code&gt;g&lt;/code&gt; 의 미분은 &lt;code&gt;g&#39; = g(1-g)&lt;/code&gt; 이고, &lt;code&gt;g&#39;(z3)&lt;/code&gt; 는 &lt;code&gt;a3 * (1 - a3)&lt;/code&gt; 으로 고쳐쓸 수 있다.&lt;/p&gt;

&lt;p&gt;만약에 &lt;em&gt;regularization term&lt;/em&gt; 을 무시한다면 다시 말해 &lt;code&gt;lambda = 0&lt;/code&gt; 이면, &lt;em&gt;partial derivative&lt;/em&gt; 는 &lt;code&gt;d&lt;/code&gt; 를 이용해 쉽게 작성할 수 있다.&lt;/p&gt;

&lt;p&gt;알고리즘을 좀 자세히 살펴보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/18/1342599882_9006.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;지금까지의 설명과 같이 먼저 &lt;em&gt;FP&lt;/em&gt; 를 진행해서 각 레이어의 유닛 &lt;code&gt;a&lt;/code&gt; 을 구하고, &lt;em&gt;BP&lt;/em&gt; 를 진행한다.&lt;/p&gt;

&lt;p&gt;이 때 마지막 단계에서 삼각형(&lt;em&gt;large delta&lt;/em&gt;, &lt;code&gt;Delta&lt;/code&gt;) 에 이전 단계의 &lt;code&gt;DELTA&lt;/code&gt; 와 &lt;code&gt;aj^(l)di(l+1)&lt;/code&gt; 를 더하는데, 사실 &lt;code&gt;aj^(l)di(l+1)&lt;/code&gt; 가 바로 &lt;em&gt;reulgarization term&lt;/em&gt; 을 무시했을 때의 &lt;em&gt;partial derivative&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;이렇게 모든 &lt;code&gt;DELTA&lt;/code&gt; 를 구하고 나서 이제 &lt;code&gt;D&lt;/code&gt; 에 &lt;em&gt;regularization term&lt;/em&gt; 을 추가한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/19/1342669084_1797.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이제 &lt;em&gt;regularization term&lt;/em&gt; 까지 더한 &lt;code&gt;D&lt;/code&gt; 가 바로 &lt;em&gt;partial derivative&lt;/em&gt; 다. &lt;del&gt;너무 난해하다&lt;/del&gt;&lt;/p&gt;

&lt;h3 id=&#34;back-propagation-intuition&#34;&gt;Back propagation: Intuition&lt;/h3&gt;

&lt;p&gt;조금 더 &lt;em&gt;Back propagation, BP&lt;/em&gt; 를 살펴보자. &lt;code&gt;dj^(l-1)&lt;/code&gt; 를 얻기 위해 &lt;code&gt;d^(l)&lt;/code&gt; 과 &lt;code&gt;theta&lt;/code&gt; 를 이용한다는 사실은 알겠다. 근데 &lt;code&gt;g&#39;&lt;/code&gt; 이라던지 이런건 도대체 어디서 나온걸까?&lt;/p&gt;

&lt;p&gt;처음으로 다시 돌아가면 &lt;em&gt;cost function&lt;/em&gt; 에서 &lt;em&gt;training set&lt;/em&gt; 이 1개라면 다시 말해 &lt;code&gt;m=1&lt;/code&gt; 이고, &lt;code&gt;lambda=0&lt;/code&gt; 이라면 &lt;em&gt;cost function&lt;/em&gt; 은 &lt;code&gt;h(x), y&lt;/code&gt; 에 의해 좌우된다. 결국 &lt;em&gt;squared error&lt;/em&gt; 와 다를바 없다는 소리다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360304035_3064.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;결국 &lt;code&gt;dj^(l)&lt;/code&gt; 은 &lt;code&gt;aj^(l)&lt;/code&gt; 의 &lt;em&gt;error of cost&lt;/em&gt; 다. 더 엄밀히 수학적으로 말하자면 &lt;code&gt;dj^(l)&lt;/code&gt; 은 &lt;code&gt;cost(i)&lt;/code&gt; 에 대한 &lt;code&gt;zj^(l)&lt;/code&gt; 의 &lt;em&gt;partial derivative&lt;/em&gt; 다. &lt;code&gt;zj^(l)&lt;/code&gt; 이 변할때 &lt;code&gt;i&lt;/code&gt; 에 대한 &lt;em&gt;cost&lt;/em&gt; 가 얼마나 변하는지가 바로 &lt;code&gt;d&lt;/code&gt; 란 이야기다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360304589_4715.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;d&lt;/code&gt; 에 대한 더 엄밀한 수학적 증명은&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?delta_k%20=%20frac{partial%20J(Theta)}{partial%20z_k}%20=%20frac{partial%20J(Theta)}{partial%20a_k}frac{partial%20a_k}{partial%20z_k}%20=%20Theta_{k}delta_{k+1}cdot%20g%27(z_k)%20\%20Delta%20w_{ij}%20=%20Delta%20w_{ij}%20+%20frac{partial%20J(Theta)}{partial%20w_{ij}}%20=%20Delta%20w_{ij}%20+%20a_j^l%20cdot%20delta_k^(l+1)\%20frac{partial%20J(Theta)}{partial%20w_{ij}}%20=%20frac{partial%20J(Theta)}{partial%20z_k}%20cdot%20frac{partial%20z_k}{partial%20w_{ij}}&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;unrolling-parameters&#34;&gt;Unrolling Parameters&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;octave&lt;/em&gt; 에서 &lt;code&gt;reshape&lt;/code&gt; 함수를 이용해서 벡터를 매트릭스로 변환하는 방법을 알려준다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360306972_1270.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360307271_1026.png&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;gradient-checking&#34;&gt;Gradient Checking&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;BP&lt;/em&gt; 를 이용해서 &lt;em&gt;neural network&lt;/em&gt; 의 &lt;em&gt;cost function&lt;/em&gt; 을 위한 &lt;em&gt;partial derivative&lt;/em&gt; 를 구하는 방법을 배웠는데, 안타깝게도 이게 쉽게 구현할 수 있는것이 아니라서 버그가 생길 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;gradient checking&lt;/em&gt; 이란 방법을 이용하면 &lt;em&gt;FP, BP&lt;/em&gt; 의 구현이 완벽함을 보일 수 있다. 배워보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360308451_8919.png&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;말 그대로 기울기에 대한 근사치를 구해서 비교하여 검증하는 방법이다. &lt;code&gt;e&lt;/code&gt;(엡실론) 이 매우 작다 하고, &lt;code&gt;0-e&lt;/code&gt; 와 &lt;code&gt;0+e&lt;/code&gt; 두 점 사이의 기울기를 구해 &lt;em&gt;gradient&lt;/em&gt; 와 근사한 값을 구한다.&lt;/p&gt;

&lt;p&gt;우리는 &lt;code&gt;0&lt;/code&gt; 가 하나가 아니기 때문에, 각각의 &lt;code&gt;0&lt;/code&gt;(&lt;code&gt;theta&lt;/code&gt;) 에 대해 모두 &lt;em&gt;gradient&lt;/em&gt; 의 근사치를 구해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360308632_9597.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360308843_4503.png&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;마지막에서 &lt;em&gt;gradient checking&lt;/em&gt; 을 이용해 구한 &lt;code&gt;gradApprox&lt;/code&gt; 와 실제 *BP 를 이용해 구한 &lt;em&gt;graident&lt;/em&gt; 인 &lt;code&gt;Dvec&lt;/code&gt; 과 비슷한지 검사한다.&lt;/p&gt;

&lt;p&gt;그러나, 한가지 알아야할 사실이 있다. &lt;em&gt;gradient checking&lt;/em&gt; 은 굉장히 비싸기 때문에 &lt;code&gt;Dvec&lt;/code&gt; 과 비슷한 값을 구했는지 검사한 후에는 &lt;em&gt;gradient checking&lt;/em&gt; 를 꺼야한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360310625_8308.png&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;random-initialization&#34;&gt;Random Initialization&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;gradient desecnt&lt;/em&gt; 를 위한 함수를 사용할때 &lt;code&gt;initialTheta&lt;/code&gt; 를 줘야한다. 그냥 &lt;code&gt;zeros&lt;/code&gt; 로 만들까? &lt;em&gt;neural network&lt;/em&gt; 에서 모든 &lt;code&gt;theta&lt;/code&gt; 가 &lt;code&gt;0&lt;/code&gt; 으로 시작하면 모든 유닛의 값이 같아진다. 오류(&lt;code&gt;d&lt;/code&gt;) 도 같고, &lt;em&gt;partial derivative&lt;/em&gt; 의 값도 같으므로  다음 이터레이션에서도 같은 유닛은 같은 값을 가지고 이게 반복된다.&lt;/p&gt;

&lt;p&gt;결국 내가 가진 모든 히든 유닛이 같은 계산을 해 내고 있으므로, 하나의 &lt;em&gt;feature&lt;/em&gt; 에 대한 극도로 중복된 연산을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/08/1360312970_4725.png&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;theta&lt;/code&gt; 가 대칭이기 때문에 발생하는 문제인데 &lt;em&gt;symmetry breaking&lt;/em&gt; 을 위해 &lt;code&gt;[-e, e]&lt;/code&gt; 사이의 &lt;code&gt;theta&lt;/code&gt; 를 랜덤으로 골라보자. 물론 이 &lt;code&gt;e&lt;/code&gt; 는 &lt;em&gt;gradient checking&lt;/em&gt; 에서의 &lt;code&gt;e&lt;/code&gt; 와 관련이 없다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/20/1342765672_2379.jpg&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;putting-it-toghther&#34;&gt;Putting It Toghther&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;neural network&lt;/em&gt; 를 훈련시킬 때 먼저 해야 할 일은 아키텍쳐를 고르는 일이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;output unit&lt;/em&gt; 과 &lt;em&gt;input unit&lt;/em&gt; 은 &lt;em&gt;class&lt;/em&gt; 와 &lt;em&gt;feature&lt;/em&gt; 수로 결정된다. 문제는 &lt;em&gt;hidden unit&lt;/em&gt; 과 &lt;em&gt;hidden layer&lt;/em&gt; 의 수다.&lt;/p&gt;

&lt;p&gt;기본적으로는 1개의 히든 레이어를 사용하거나, 1개 이상을 사용한다면 같은 수의 히든 유닛을 모든 히든 레이어에서 사용하는것이 대부분 계산 비용 면에서 낫다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/09/1360373142_6515.png&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;(2) &lt;em&gt;weights&lt;/em&gt; 를 랜덤하게 초기화 한다.&lt;br /&gt;
(3) &lt;em&gt;forward propagation&lt;/em&gt;&lt;br /&gt;
(4) &lt;em&gt;cost function&lt;/em&gt; 을 구한다.&lt;br /&gt;
(5)  &lt;em&gt;partial derivatives&lt;/em&gt; 구하기 위해 &lt;em&gt;back propagation&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;BP&lt;/em&gt; 를 할때는 &lt;em&gt;traning set&lt;/em&gt; 의 수 &lt;code&gt;m&lt;/code&gt; 번 만큼 루프를 돌면서 각 &lt;code&gt;(xi, yi)&lt;/code&gt; 를 이용해 &lt;em&gt;FP&lt;/em&gt;, &lt;em&gt;BP&lt;/em&gt; 를 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/09/1360373729_4414.png&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;(6) &lt;em&gt;gradient checking&lt;/em&gt; 을 이용해 얻은 근사치와 &lt;em&gt;partial derivatives&lt;/em&gt; 를 비교한다. 값이 적당히 비슷하면 &lt;em&gt;gradient checking&lt;/em&gt; 코드를 제거한다.&lt;br /&gt;
(7) &lt;em&gt;cost function&lt;/em&gt; 을 최소화 하기 위해 &lt;em&gt;gradient descent&lt;/em&gt; 나 &lt;em&gt;advanced optimization method&lt;/em&gt; 를 사용한다.&lt;/p&gt;

&lt;p&gt;한 가지 알아야 할 사실은 &lt;em&gt;neural network&lt;/em&gt; 의 &lt;em&gt;cost function&lt;/em&gt; 은 &lt;em&gt;non-convex&lt;/em&gt; 이기 때문에 &lt;em&gt;local optimum&lt;/em&gt; 에서 멈출 수 있다.&lt;/p&gt;

&lt;p&gt;그런덷 문제가 굉장히 크다면 &lt;em&gt;gradient descent&lt;/em&gt; 로 찾은 &lt;em&gt;local optimum&lt;/em&gt; 도 충분히 좋은 값이라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/09/1360374039_7863.png&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;처음에 1장에서 봤던 언덕 그림이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://cfile28.uf.tistory.com/image/2401353E52D618322EDFB5&#34; alt=&#34;&#34; /&gt;&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://mapository.tistory.com/59&#34;&gt;http://mapository.tistory.com/59&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;em&gt;gradient descent&lt;/em&gt; 가 하는 일은 언덕을 내려가는거고, &lt;em&gt;back propagation&lt;/em&gt; 이 하는 일은 방향을 잡아주는 일이다.(&lt;code&gt;z&lt;/code&gt; 가 변했을 때 &lt;em&gt;cost function&lt;/em&gt; 값이 변하는 양인 오차 &lt;code&gt;d&lt;/code&gt; 의 값이 적어지도록 방향을 잡아줌)&lt;/p&gt;

&lt;p&gt;그래서 신경망에서 &lt;em&gt;gradient descent&lt;/em&gt; 를 사용한다 하더라도 적당히 좋은 로컬 옵티멈을 찾아준다는 훈훈한 이야기&lt;/p&gt;

&lt;h3 id=&#34;autonomous-driving&#34;&gt;Autonomous Driving&lt;/h3&gt;

&lt;p&gt;무인 운전을 신경망으로 어떻게 해결하는지를 보여준다. 미리 사람이 한번 운전한 경로(&lt;code&gt;y&lt;/code&gt;) 를 바탕으로 학습하는데, 생각도 못해본 분야들에 이미  이런 기술들이 적용되어 있구나 싶다. &lt;del&gt;무려 1992년에 했던 실험이다&lt;/del&gt;&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;a href=&#34;http://aimotion.blogspot.kr/&#34;&gt;http://aimotion.blogspot.kr/&lt;/a&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://www.holehouse.org/mlclass/09_Neural_Networks_Learning.html&#34;&gt;http://www.holehouse.org/mlclass/&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://blog.csdn.net/abcjennifer/article/details/7758797&#34;&gt;http://blog.csdn.net/abcjennifer/&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 06: Practical Advices</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-6/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:29 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-6/</guid>
      <description>

&lt;p&gt;지난시간엔 &lt;em&gt;back propagation&lt;/em&gt; 구현해 보고 여기에 적용할 수 있는 소소한 것들 &lt;em&gt;random initialization&lt;/em&gt; 과 &lt;em&gt;gradient checking&lt;/em&gt; 등도 알아 보았다.&lt;/p&gt;

&lt;p&gt;머신러닝을 단순히 아는것과, 실전에서 사용할 수 있다는 건 큰 차이가 있다. 이번 시간에는 실전에서 필요한 여러가지 팁들에 대해 설명한다. 후반부에서는 스팸 분류기를 통해 간단한 머신러닝 시스템을 설계해 본다.&lt;/p&gt;

&lt;h3 id=&#34;diagnostics&#34;&gt;Diagnostics&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://chart.apis.google.com/chart?cht=tx&amp;amp;chl=J(%5Ctheta)%20%3D%20%7B1%20%5Cover%202m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20(h_%5Ctheta(x%5E%7B(i)%7D%20-%20y%5E%7B(i)%7D)%5E2%20%2B%20%5Clambda%5Csum_%7Bj%3D1%7D%5Em%20%5C%20%5Ctheta_j%5E2%5D&#34;&gt;http://chart.apis.google.com/chart?cht=tx&amp;amp;chl=J(%5Ctheta)%20%3D%20%7B1%20%5Cover%202m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20(h_%5Ctheta(x%5E%7B(i)%7D%20-%20y%5E%7B(i)%7D)%5E2%20%2B%20%5Clambda%5Csum_%7Bj%3D1%7D%5Em%20%5C%20%5Ctheta_j%5E2%5D&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;집 가격에 대한 &lt;em&gt;linear regression&lt;/em&gt; 가설을 세웠는데 &lt;em&gt;error&lt;/em&gt; 가 좀 큰 것을 발견했다. 어떻게 해야할까?&lt;/p&gt;

&lt;p&gt;(1) Get more training examples&lt;br /&gt;
(2) Try smaller sets of features&lt;br /&gt;
(3) Try getting additional features&lt;br /&gt;
(4) Try adding polynomial features&lt;br /&gt;
(5) Try decreasing &lt;em&gt;lambda&lt;/em&gt;&lt;br /&gt;
(5) Try increasing &lt;em&gt;lambda&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이중에서 더 많은 트레이닝 셋을 추가하는 것은 별로 도움이 안 될 수도 있다. (이유는 뒷 부분에서 논의한다.)&lt;/p&gt;

&lt;p&gt;알고리즘의 정상 동작여부를 파악할 수 있는 몇 가지 판별법을 알아보자. &lt;em&gt;gradient checking&lt;/em&gt; 이 그랬던 것처럼, 구현하는데는 좀 시간이 걸려도 디버깅에 드는 시간을 많이 줄여준다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A diagnostic can sometimes rule out certain courses of action (changes to your learning algorithm) as being unlikely to improve its performance significantly&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;evaluating-a-hypothesis&#34;&gt;Evaluating a hypothesis&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;low training error&lt;/em&gt; 를 갖는 &lt;em&gt;hypothesis (가설)&lt;/em&gt; 이 항상 좋은 건 아니다. &lt;em&gt;overfitting&lt;/em&gt; 이 발생할 수 있기 때문이다.&lt;/p&gt;

&lt;p&gt;그리고 &lt;em&gt;feature&lt;/em&gt; 가 많을 수록 &lt;em&gt;plotting&lt;/em&gt; 하기 힘들기 가설을 평가할 다른 방법을 찾아야 한다. 단순히 그리는 것 만으로 모든 가설을 평가하긴 어렵다.&lt;/p&gt;

&lt;p&gt;한가지 평가 방법으로 전체 &lt;em&gt;training set&lt;/em&gt; 을 &lt;code&gt;70% / 30%&lt;/code&gt; 로 분리해 &lt;code&gt;70%&lt;/code&gt; 은 &lt;em&gt;training set&lt;/em&gt; 으로 나머지 &lt;code&gt;30%&lt;/code&gt; 는 &lt;em&gt;test set&lt;/em&gt; 으로 활용할 수 있다. (&lt;em&gt;참고로 테스트셋과 트레이닝셋은 랜덤하게 분리하는 편이 좋다.&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/09/1360378105_8286.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;linear regressoin&lt;/em&gt; 에 트레이닝 셋과 테스트셋을 분리하는 과정을 알아 보면&lt;/p&gt;

&lt;p&gt;(1) &lt;code&gt;0(theta)&lt;/code&gt; 를 트레이닝 셋에 대해 학습시켜 트레이닝 에러를 최소화 하는 &lt;code&gt;J(0)&lt;/code&gt; 를 찾는다.&lt;br /&gt;
(2) 학습된 &lt;code&gt;0(theta)&lt;/code&gt; 에 대해 테스트 셋을 돌려 &lt;em&gt;test error&lt;/em&gt; 를 찾는다.&lt;/p&gt;

&lt;p&gt;그럼 &lt;em&gt;linear regression&lt;/em&gt; 말고 &lt;em&gt;classification&lt;/em&gt; 에는 어떻게 적용할까?&lt;/p&gt;

&lt;p&gt;마찬가지로 &lt;code&gt;0(theta)&lt;/code&gt; 에 대해 &lt;code&gt;J(0)&lt;/code&gt; 를 찾고, 여기에 &lt;code&gt;J_test(0)&lt;/code&gt; 를 돌려 테스트 에러를 찾는다.&lt;/p&gt;

&lt;p&gt;아니면 아래 그림에서 볼 수 있듯이 &lt;em&gt;misclassification error&lt;/em&gt; 를 이용해도 된다. 보면 알겠지만 같은 정의다. &lt;code&gt;y = 0&lt;/code&gt; 일때 &lt;code&gt;h(x) &amp;lt; 0.5&lt;/code&gt; 이어야 하고, &lt;code&gt;y = 1&lt;/code&gt; 일때 &lt;code&gt;h(x) =&amp;gt; 0.5&lt;/code&gt; 이어야 하기 때문에 엇갈리게 나온 경우 &lt;code&gt;err&lt;/code&gt; 함수에서 &lt;code&gt;1&lt;/code&gt; 을 리턴해, 이 값을 모두 합한 뒤 전체 테스트 셋의 숫자로 나누면 테스트 에러값을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/09/1360378588_2059.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;model-selection&#34;&gt;Model Selection&lt;/h3&gt;

&lt;p&gt;당연한 이야기지만 &lt;em&gt;training set&lt;/em&gt; 에 가설이 &lt;em&gt;well fit&lt;/em&gt; 되어있기 때문에 트레이닝셋에 포함되지 않은 새로운 경향의 데이터를 만나면 에러가 많이 생길 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Once parameters were fir to some set of data (training set), the error of the parameters as measured on that data (the training error &lt;code&gt;J(0)&lt;/code&gt;) is likely to be lower than the actual generalization error.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;d&lt;/code&gt; 를 &lt;em&gt;degree of polynomial (가설의 다항식 차수)&lt;/em&gt; 이라 하자. 그럼 &lt;code&gt;d = 1, 2, .. , 10&lt;/code&gt; 중에 어떤 걸 택하는 게 좋을까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/09/1360380082_1392.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;각각에서 나오는 파라미터 벡터를 &lt;code&gt;0^(1), 0^(2), ...&lt;/code&gt; 이라 하자. 그리고 여기서 나오는 테스트 셋의 에러를 &lt;code&gt;J_test(0^(1))&lt;/code&gt;, &lt;code&gt;J_test(0^(2))&lt;/code&gt; 등이라 하면 이 값을 모두 조사해 최소로 나오는 &lt;code&gt;d&lt;/code&gt; 를 가진 모델을 택한다.&lt;/p&gt;

&lt;p&gt;그러나 문제는 이렇게 선택한 모델이 &lt;em&gt;optimistic estimate of generalization error&lt;/em&gt; 라는 점이다. 테스트 셋에 대해서 가장 적은 에러를 모델이 보여준다 해도 실제 데이터에 대해 똑같이 적은 에러를 보여주리라고 확신할 수 없다.&lt;/p&gt;

&lt;h3 id=&#34;train-validation-test-sets&#34;&gt;Train / Validation / Test Sets&lt;/h3&gt;

&lt;p&gt;이 문제를 해결하기 위해 &lt;em&gt;training set&lt;/em&gt; 을 &lt;em&gt;60%/20%/20%&lt;/em&gt; 로 나누어 각각을 &lt;em&gt;training set&lt;/em&gt;, &lt;em&gt;cross validation set (CV)&lt;/em&gt;, &lt;em&gt;test set&lt;/em&gt; 이라 하자. 그리하여 각각의 에러를 구할 수 있다.&lt;/p&gt;

&lt;p&gt;여기서 &lt;em&gt;CV&lt;/em&gt; 에 대한 &lt;em&gt;error&lt;/em&gt; 가 최저인 모델을 택하면 이 모델은 &lt;em&gt;test set&lt;/em&gt; 에 대해서는 &lt;em&gt;fit&lt;/em&gt; 되어 있지 않기 때문에 &lt;em&gt;test error&lt;/em&gt; 가 &lt;em&gt;estimate generalization error&lt;/em&gt; 라 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/10/1360459807_7333.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;다시 정리해 보면 먼저 &lt;code&gt;0&lt;/code&gt; 를 &lt;em&gt;training set&lt;/em&gt; 에 대해 학습 시켜 &lt;code&gt;0&lt;/code&gt; 값을 얻은 뒤, &lt;em&gt;cross validation (CV)&lt;/em&gt; 에 대해 &lt;em&gt;error&lt;/em&gt; 를 구해 가장 작은 값을 갖는 모델을 고른다.&lt;/p&gt;

&lt;p&gt;이제 이 모델에 대해서 &lt;em&gt;test error&lt;/em&gt; 를 구하면 이 모델은 테스트 셋에 대해서 &lt;em&gt;fit&lt;/em&gt; 되지도, 가장 적은 에러를 가지는지 검사되지도 않은 데이터이므로 일반적인 에러값에 대한 추정치라 볼 수 있다.&lt;/p&gt;

&lt;p&gt;일반적으로 &lt;em&gt;CV error&lt;/em&gt; 는 &lt;em&gt;test error&lt;/em&gt; 보다 더 작은 값을 가지는데, 이는 선택한 모델의 &lt;code&gt;0&lt;/code&gt; 가 &lt;em&gt;CV set&lt;/em&gt; 에 대해 최저치를 갖도록 &lt;em&gt;fit&lt;/em&gt; 되어있기 때문이다.&lt;/p&gt;

&lt;h3 id=&#34;diagnosing-bias-vs-variance&#34;&gt;Diagnosing Bias vs Variance&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/10/1360461366_4352.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;그림에서 볼 수 있듯이 &lt;code&gt;d=1&lt;/code&gt; 인 경우엔 &lt;em&gt;underfit&lt;/em&gt;, &lt;code&gt;d=4&lt;/code&gt; 인 경우엔 &lt;em&gt;overfit&lt;/em&gt; 이 발생한다. 다른말로 각각 &lt;em&gt;high bias&lt;/em&gt;, &lt;em&gt;high variance&lt;/em&gt; 라 부른다.&lt;/p&gt;

&lt;p&gt;아래와 같이 가로 축을 &lt;code&gt;d&lt;/code&gt;, 세로 축을 &lt;code&gt;error&lt;/code&gt; 라 하면 &lt;code&gt;d&lt;/code&gt; 가 증가할 수록 &lt;em&gt;training error&lt;/em&gt; 는 0 에 가까워진다. 반면 &lt;em&gt;CV set&lt;/em&gt; 에 대해서는 하나의 &lt;code&gt;d&lt;/code&gt; 만 최저치를 가지고 나머지는 그 보다 높기 때문에 아래와 같은 그래프를 그릴 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/28/1343484056_3257.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 그래프가 시사하는 바는,&lt;/p&gt;

&lt;p&gt;(1) &lt;em&gt;underfit&lt;/em&gt; 할 경우 &lt;code&gt;d&lt;/code&gt; 가 작으므로 &lt;code&gt;J_train(0)&lt;/code&gt; 는 매우 크고, &lt;code&gt;J_cv(0)&lt;/code&gt; 는 그의 거의 비슷한 값을 가지게 된다. (&lt;em&gt;bias problem&lt;/em&gt;)&lt;br /&gt;
(2) &lt;em&gt;overfit&lt;/em&gt; 할 경우 &lt;code&gt;d&lt;/code&gt; 가 크므로 &lt;code&gt;J_train(0)&lt;/code&gt; 는 매우 작고, &lt;code&gt;J_cv(0)&lt;/code&gt; 는 그보다는 훨씬 크다. (&lt;em&gt;variance problem&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;따라서 &lt;code&gt;J_train(0)&lt;/code&gt; 값이 &lt;code&gt;J_cv(0)&lt;/code&gt; 과 얼마나 비슷한지 비교함으로써 &lt;em&gt;overfit&lt;/em&gt; 혹은 &lt;em&gt;underfit&lt;/em&gt; 되는지 판단할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/28/1343484595_6134.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.4four.us/article/2010/11/bias-variance-tradeoff&#34;&gt;여기&lt;/a&gt; 서 &lt;em&gt;bias vs varance&lt;/em&gt; 의 이해를 위해 인용을 좀 하자면,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Bias, 즉 선입관이 크면, (좋게 말해서) 줏대가 있고 (나쁘게 말해서) 고집이 세기 때문에 새로운 경험을 해도 거기에 크게 휘둘리지 않는다. 평소 믿음과 다른 결과가 관찰되더라도 한두 번 갖고는 콧방귀도 안 뀌며 생각의 일관성을 중시한다. (High Bias, Low Variance) 반대로 선입관이 작으면, (좋게 말하면) 사고가 유연하고 (나쁘게 말하면) 귀가 얇기 때문에 개별 경험이나 관찰 결과에 크게 의존한다. 새로운 사실이 발견되면 최대한 그걸 받아들이려고 하는 것이다. 그래서 어떤 경험을 했느냐에 따라서 최종 형태가 왔다갔다한다. (High Variance, Low Bias)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;regularization-and-bias-variance&#34;&gt;Regularization and Bias / Variance&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;regularization&lt;/em&gt; 이 끼어들면 &lt;code&gt;lambda&lt;/code&gt; 를 &lt;em&gt;bias vs variance&lt;/em&gt; 문제에서 고려해야 한다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201207/28/1343485336_9809.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;lambda&lt;/em&gt; 가 크면 당연히 &lt;em&gt;high bias&lt;/em&gt;, 매우 작으면 &lt;em&gt;high variance&lt;/em&gt; 다. 그러면 중간 값을 찾아야 한다는건 알겠는데, 어느정도가 적당한 값일까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/10/1360461577_6101.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 전과 비교했을때 &lt;code&gt;J(0)&lt;/code&gt; 에 &lt;em&gt;regularization term&lt;/em&gt; 이 추가되었지만 &lt;code&gt;J_train(0)&lt;/code&gt; 이나 &lt;code&gt;J_cv(0)&lt;/code&gt;, &lt;code&gt;J_test(0)&lt;/code&gt; 에는 &lt;em&gt;regularization term&lt;/em&gt; 이 없다는 점에 유의하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/10/1360461899_5163.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;모델을 선택했다면 &lt;em&gt;lambda&lt;/em&gt; 를 천천히 증가시켜가면서 각각에 대해 &lt;code&gt;0(theta)&lt;/code&gt; 를 구한다. 그리고 이 값을 이용해 구한 &lt;code&gt;J_cv(0)&lt;/code&gt; 가 가장 적은 에러 값을 가지는 &lt;em&gt;lambda&lt;/em&gt; 를 구하면 된다. &lt;em&gt;model selection&lt;/em&gt; 과 비슷하다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;lambda&lt;/em&gt; 과 &lt;em&gt;CV error&lt;/em&gt;, &lt;em&gt;training error&lt;/em&gt; 간 관계를 알아보자면 아래와 같다. 위에서 언급 했듯이 &lt;em&gt;lambda&lt;/em&gt; 가 크면 &lt;em&gt;bias&lt;/em&gt;, 0 에 가까우면 &lt;em&gt;variance&lt;/em&gt; 임을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/10/1360462458_2256.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;bias&lt;/em&gt; 와 &lt;em&gt;variance&lt;/em&gt;, 그리고 &lt;em&gt;lambda&lt;/em&gt; 의 관계는 아래 그래프에서도 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201210/12/1350026192_9384.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;learning-curves&#34;&gt;Learning Curves&lt;/h3&gt;

&lt;p&gt;전체 트레이닝 셋의 사이즈 &lt;code&gt;m&lt;/code&gt; 이 커질때 에러는 어떻게 되는가 그래프로 한번 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/11/1360552101_5795.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;간단히 생각해 보면 &lt;code&gt;m&lt;/code&gt; 의 사이즈가 클수록 &lt;em&gt;training set&lt;/em&gt; 의 에러는 점점 늘어나고, &lt;code&gt;m&lt;/code&gt; 이 커지면 커질수록 &lt;em&gt;generalize&lt;/em&gt; 가 가능하므로 &lt;em&gt;CV error&lt;/em&gt; 는 점점 줄어든다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;high bias&lt;/em&gt; 인 경우 처음엔 &lt;em&gt;training error&lt;/em&gt; 이 매우 크다가, &lt;code&gt;m&lt;/code&gt; 이 클수록 &lt;em&gt;training error&lt;/em&gt; 의 증가율이 작아지므로&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/11/1360552417_8655.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 그림이 시사하는 바는&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;high bias&lt;/em&gt; 알고리즘이라면 &lt;code&gt;m&lt;/code&gt; 이 을 많이 수집한다 해도 &lt;code&gt;J_cv(0)&lt;/code&gt; 의 감소율이 적기 때문에 별 도움이 되지 못한다. 다시 말해 &lt;code&gt;m&lt;/code&gt; 을 많이 투입해도 얻어지는 &lt;em&gt;training error&lt;/em&gt; 와 &lt;em&gt;CV error&lt;/em&gt; 의 차이는 미미하다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;반면 &lt;em&gt;high variance&lt;/em&gt; 의 경우에는 &lt;code&gt;m&lt;/code&gt; 이 크면 클수록 &lt;em&gt;training error&lt;/em&gt; 의 증가율이 점점 줄어들고, &lt;em&gt;overfit&lt;/em&gt; 이기 때문에 &lt;em&gt;CV error&lt;/em&gt; 는 &lt;em&gt;training set&lt;/em&gt; 과 차이가 많이 난다. 그래프는&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/11/1360552431_2697.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;결국&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;high variance&lt;/em&gt; 일 경우 &lt;code&gt;m&lt;/code&gt; 을 많이 투입하면 할수록 낮은 &lt;em&gt;CV error&lt;/em&gt; 를 얻는데 도움이 된다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;다시 말해 이 두가지 경우는 &lt;em&gt;training error&lt;/em&gt; 와 &lt;em&gt;CV error&lt;/em&gt; 의 차이가 꽤 클때는 &lt;code&gt;m&lt;/code&gt; 을 높이면 낮은 &lt;em&gt;CV error&lt;/em&gt; 를 적은 비용으로 얻을 수 있다는 뜻이다.&lt;/p&gt;

&lt;h3 id=&#34;applying-to-neural-network&#34;&gt;Applying to Neural Network&lt;/h3&gt;

&lt;p&gt;이제 처음에 나왔던 6가지 경우를 고려해 보자.&lt;/p&gt;

&lt;p&gt;(1) Get more training examples -&amp;gt; &lt;em&gt;fixing high variance&lt;/em&gt;&lt;br /&gt;
(2) Try smaller sets of features -&amp;gt; &lt;em&gt;fixing high variance&lt;/em&gt;&lt;br /&gt;
(3) Try getting additional features -&amp;gt; &lt;em&gt;fixing high bias&lt;/em&gt;&lt;br /&gt;
(4) Try adding polynomial features -&amp;gt; &lt;em&gt;fixing high bias&lt;/em&gt;&lt;br /&gt;
(5) Try decreasing &lt;em&gt;lambda&lt;/em&gt; -&amp;gt; &lt;em&gt;fixing high bias&lt;/em&gt;&lt;br /&gt;
(5) Try increasing &lt;em&gt;lambda&lt;/em&gt; -&amp;gt; &lt;em&gt;fixing high variance&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/11/1360552523_3279.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;bias vs variance&lt;/em&gt; 문제를 &lt;em&gt;neural network&lt;/em&gt; 에 적용시켜보자.&lt;/p&gt;

&lt;p&gt;(1) 작은 사이즈의 신경망이라면 계산 비용은 저렴한 대신 &lt;em&gt;underfit&lt;/em&gt; 할 수 있다.&lt;br /&gt;
(2) 큰 사이즈의 신경망이라면 계산 비용은 비싸고 &lt;em&gt;overfit&lt;/em&gt; 할 수 있다. 따라서 &lt;em&gt;regurarization&lt;/em&gt; 을 이용해 &lt;em&gt;overfit&lt;/em&gt; 되는 정도를 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/11/1360552606_9371.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;machine-learning-system-design&#34;&gt;Machine Learning System Design&lt;/h3&gt;

&lt;p&gt;간단한 스팸 분류기를 작성한다고 하자. &lt;em&gt;supervised learning&lt;/em&gt; 을 위해서&lt;/p&gt;

&lt;p&gt;(1) &lt;code&gt;x&lt;/code&gt; = features of email (&lt;em&gt;choose 100 words indicative of spam or not&lt;/em&gt;)&lt;br /&gt;
(2) &lt;code&gt;y&lt;/code&gt; = spam &lt;code&gt;1&lt;/code&gt; or not spam &lt;code&gt;0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360804751_1943.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;각 단어가 이메일 본문에 등장했는지 아닌지를 각 &lt;em&gt;feature&lt;/em&gt; 의 값으로 사용한다. (&lt;code&gt;1&lt;/code&gt; or &lt;code&gt;0&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;일반적으로는 100개를 수동으로 고르는게 아니라, 스팸에서 많이 사용된 단어를 &lt;code&gt;n&lt;/code&gt; 개 골라 사용한다.&lt;/p&gt;

&lt;p&gt;그럼 &lt;em&gt;low error&lt;/em&gt; 를 얻기 위해서는 무엇을 해야할까?&lt;/p&gt;

&lt;p&gt;(1) Collect lots of data : 항상 도움이 되진 않는다.&lt;br /&gt;
(2) Develop sophisticated features based on email routing information&lt;br /&gt;
(3) Develop sophisticated features for message body. e.g should &amp;ldquo;discount&amp;rdquo; and &amp;ldquo;discounts&amp;rdquo; be treated as the same word?&lt;br /&gt;
(4) Develop sophisticated algorithm to detect misspelings e.g m0rtgage&lt;/p&gt;

&lt;p&gt;등등 의 다양한 방법을 고안할 수 있다. 이 중 무엇을 선택해야 할까? 좀 더 체계적인 방법은 없을까? 여기 몇 가지 가이드라인이 있다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;Start with a simple algorithm that can implement quickly. Implement it and test it on your corss-validation data.&lt;/li&gt;
&lt;li&gt;Plot learning curves to decide if more data, more features, etc. are likely to help.&lt;/li&gt;
&lt;li&gt;Error analysis: manually examine the examples (in corss validation set) that your algorithm made errors on. See if you spot any systematic trend in what type of examples it is making errors on.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;error-analysis&#34;&gt;Error Analysis&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;error analysis&lt;/em&gt; 하는 방법은 &lt;em&gt;CV error&lt;/em&gt; 를 발견했을 때, 각각의 에러를 수동으로 검사하면서 분류하는 것이다.&lt;/p&gt;

&lt;p&gt;이메일의 타입이 무엇인지, 혹은 어떤 &lt;em&gt;feature&lt;/em&gt; 가 알고리즘에서 이 이메일을 분류하는데 도움이 될만한지 생각해 본다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360804909_5716.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;error analysis&lt;/em&gt; 가 에러가 나타난 이유에 대한 어떤 경향을 제공할 수 있기 때문에 간단히 먼저 구현해 보고 분석 해 보는것도 나쁘지 않다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;error analysis&lt;/em&gt; 는 실제로 분석 결과를 새로운 알고리즘에 적용했을때 &lt;em&gt;performace&lt;/em&gt; 가 더 좋을지 알려주지 않는다. 따라서 해보고 &lt;em&gt;numerical evaluation&lt;/em&gt; 을 비교해 본다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360804976_1060.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;skewed-classes&#34;&gt;Skewed Classes&lt;/h3&gt;

&lt;p&gt;암을 진단한다고 하자. &lt;em&gt;logistic regression&lt;/em&gt; 을 구현했고, 놀랍게도 &lt;em&gt;test error&lt;/em&gt; 가 &lt;code&gt;1%&lt;/code&gt; 라고 하자.&lt;/p&gt;

&lt;p&gt;근데, 만약에 환자중에 &lt;code&gt;0.5%&lt;/code&gt; 만 암환자라면, 차라리 모두 암이 아니라고 진단하는 다음의 함수가 더 에러가 낮다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-matlab&#34;&gt;function y = predictCancer(x)
  y = 0; 
return
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이렇게 확률이 희박한 &lt;em&gt;class&lt;/em&gt; 를 &lt;strong&gt;skewed class&lt;/strong&gt; 라 부른다. 또 한가지 사실을 알 수 있는데, &lt;em&gt;error&lt;/em&gt; 가 낮다고 해서 항상 좋은 알고리즘이 아니라는 사실이다. &lt;code&gt;y = 0&lt;/code&gt; 은 &lt;code&gt;99.5&lt;/code&gt; 의 정확도를 보여주지만 알고리즘이 아니다. 에러값 말고 다른 평가방법이 필요하다!&lt;/p&gt;

&lt;h3 id=&#34;precision-recall&#34;&gt;Precision / Recall&lt;/h3&gt;

&lt;p&gt;그림을 먼저 보자. 예측 여부와 실제 값에 따라서 &lt;code&gt;2 x 2&lt;/code&gt; 매트릭스를 붙일 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201208/06/1344228190_4576.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;em&gt;precision&lt;/em&gt; 과 &lt;em&gt;recall&lt;/em&gt; 이란 개념을 끌어낼 수 있는데&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;**Precision: ** Of All patients where we predicted y = 1, what fraction actually has cancer?&lt;/p&gt;

&lt;p&gt;**Recall: ** Of all patients that actually have cancer, what fraction did we correctly detect as having cancer?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;다시 말해 &lt;em&gt;precision&lt;/em&gt; 은 우리가 암이 있다고 진단한 환자중 실제 암이 있는 환자의 비율이고, &lt;em&gt;recall&lt;/em&gt; 은 실제 암이 있는 환자 중 우리가 암이 있다고 진단한 환자의 비율이다.&lt;/p&gt;

&lt;p&gt;위의 함수처럼 &lt;code&gt;y = 0&lt;/code&gt; 으로 진단하는 경우 &lt;em&gt;true positive&lt;/em&gt; = &lt;code&gt;0&lt;/code&gt; 이므로 &lt;em&gt;recall&lt;/em&gt; = &lt;code&gt;0&lt;/code&gt; 이다.&lt;/p&gt;

&lt;p&gt;단순히 &lt;em&gt;error&lt;/em&gt; 만으로 판단하는 것은 위의 예처럼 잘못된 판단일 수 있다. 따라서 &lt;em&gt;skewed class&lt;/em&gt; 가 있더라도 &lt;em&gt;precision&lt;/em&gt; 과 &lt;em&gt;recall&lt;/em&gt; 을 보면 알고리즘에 속임수가 있는지, 없는지를 파악할 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;trading-off-precision-and-recall&#34;&gt;Trading off Precision and Recall&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360805261_5122.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 &lt;code&gt;h(x) &amp;gt;= 0.5&lt;/code&gt; 일경우에 &lt;code&gt;1&lt;/code&gt; 을, &lt;code&gt;h(x) &amp;lt; 0.5&lt;/code&gt; 일 경우에 &lt;code&gt;0&lt;/code&gt; 을 예측하는데, 이 수치를 좀 더 올려 &lt;code&gt;0.7&lt;/code&gt; 이상 또는 미만으로 예측한다 해 보자.&lt;/p&gt;

&lt;p&gt;이 경우 좀 더 확실한 환자만 암이라 진단하므로 &lt;em&gt;precision&lt;/em&gt; 은 올라가는 반면 &lt;em&gt;recall&lt;/em&gt; 은 내려간다.&lt;/p&gt;

&lt;p&gt;거꾸로 수치를 &lt;code&gt;0.3&lt;/code&gt; 으로 낮추면 덜 확실해도 그냥 암이라 우기므로 &lt;em&gt;recall&lt;/em&gt; 은 높아지겠지만 예측한 것중 실제 환자를 의미하는 &lt;em&gt;precision&lt;/em&gt; 값은 떨어진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360805315_5777.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 그림을 보면 &lt;em&gt;threshold&lt;/em&gt; 에 따라서 &lt;em&gt;recall&lt;/em&gt; 과 &lt;em&gt;precision&lt;/em&gt; 값이 얼추 반비례하는 걸 볼 수 있다. 디테일에 따라서 구체적인 그래프의 모양은 다를 수 있다.&lt;/p&gt;

&lt;p&gt;그럼 이제 문제는, &lt;em&gt;threshold&lt;/em&gt; 를 고를 수 있느냐, 다시 말해 어느 &lt;em&gt;(precision, recall)&lt;/em&gt; 쌍이 더 좋은가 하는 문제다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360805419_2578.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;단순히 평균을 쓰면 &lt;code&gt;y = 1&lt;/code&gt; 로 예측하는 것과 같은 알고리즘들이 높은 값을 얻을 수 있다. 예를 들어 위 그림에서 &lt;em&gt;algorithm 3&lt;/em&gt; 가 그렇듯이.&lt;/p&gt;

&lt;p&gt;따라서 단순히 평균을 하기 보다는 &lt;em&gt;F1 score&lt;/em&gt; 를 많이 쓴다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201208/06/1344234475_3823.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;따라서 &lt;em&gt;CV set&lt;/em&gt; 에 대해 높은 &lt;em&gt;F1 score&lt;/em&gt; 를 가지는 &lt;em&gt;threshold&lt;/em&gt; 를 택함으로써 좋은 알고리즘을 고를 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;data-for-machine-learning&#34;&gt;Data for Machine Learning&lt;/h3&gt;

&lt;p&gt;지금까지는 &lt;em&gt;evaluation&lt;/em&gt; 에 대한 논의었고, &lt;em&gt;data&lt;/em&gt; 에 대한 이야기를 좀 더 해 보자. 앞에서는 단순히 데이터가 많다고 해서 좋다는 뉘앙스로 이야기를 했지만 실제 특정 상황에서, 특정 알고리즘은 다량의 데이터를 이용하면 좋은 성능을 내기도 한다. 실제 그런가 보자. 4개의 서로 다른 알고리즘을 트레이닝 셋 사이즈를 늘려가며 정확도를 비교한 결과다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360806606_8278.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;It&amp;rsquo;s not who has the best algorithm that wins, It&amp;rsquo;s who has the most data.&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;항상 그렇지는 않다. 집 값을 예측 할 때 &lt;em&gt;feature&lt;/em&gt; 로 사이즈 하나만 준다면 정확하게 예측하기란 불가능하다. 양이 문제가 아니고 집 값을 예측하기에 충분한 정보가 필요하다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360807112_1041.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;많은 수의 &lt;em&gt;parameter&lt;/em&gt; 가 있다. 하자. &lt;em&gt;low bias&lt;/em&gt; 기 때문에 &lt;code&gt;J_train(0)&lt;/code&gt; 는 작을 것이다. (&lt;em&gt;not underfit&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;그리고 여기에 &lt;em&gt;parameter&lt;/em&gt; 보다 훨씬 많은 &lt;em&gt;training set&lt;/em&gt; 을 사용한다면, &lt;em&gt;overfit&lt;/em&gt; 하지 않는다 볼 수 있다. 따라서 &lt;em&gt;underfit&lt;/em&gt; 도 아니고 &lt;em&gt;overfit&lt;/em&gt; 도 아니므로&lt;/p&gt;

&lt;p&gt;&lt;code&gt;J_test(0)&lt;/code&gt; 는 &lt;code&gt;J_train(0)&lt;/code&gt; 에 근사한 값을 가진다 볼 수 있다. 결국 작은 &lt;code&gt;J_test(0)&lt;/code&gt; 을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;정리하자면, 충분한 양의 정보를 가지고 있고 (&lt;em&gt;large parameters&lt;/em&gt;), 큰 사이즈의 데이터를 대상으로 알고리즘을 훈련 시킨다면 상당히 좋은 성능을 뽑아낼 수 있다는 훈훈한 이야기. (거꾸로 말하면, 반복하지만, 데이터만 많다고, 혹은 파라미터만 많다고 좋은 결과를 얻을 수 없다는 이야기)&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;Machine Learning&lt;/em&gt; by &lt;strong&gt;Andrew NG&lt;/strong&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://www.4four.us/article/2010/11/bias-variance-tradeoff&#34;&gt;http://www.4four.us&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 07: Support Vector Machine</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-7/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:31 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-7/</guid>
      <description>

&lt;p&gt;이번시간에 &lt;em&gt;Support Vector Machine, SVM&lt;/em&gt; 을 배운다.&lt;/p&gt;

&lt;h3 id=&#34;optimization-objective&#34;&gt;Optimization Objective&lt;/h3&gt;

&lt;p&gt;먼저 직관을 얻기 위해 &lt;em&gt;logistic regression&lt;/em&gt; 의 &lt;em&gt;sigmoid function&lt;/em&gt; 을 좀 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201208/09/1344525027_7041.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;y = 1&lt;/code&gt; 이면 &lt;code&gt;0^Tx &amp;gt;&amp;gt; 0&lt;/code&gt; 이어야 &lt;code&gt;h(x)&lt;/code&gt; 가 &lt;code&gt;1&lt;/code&gt; 에 가까워 진다.&lt;/p&gt;

&lt;p&gt;이제 &lt;em&gt;cost function&lt;/em&gt; 에 &lt;code&gt;h(x)&lt;/code&gt; 를 넣자. 그리고 &lt;code&gt;m = 1&lt;/code&gt; 인 트레이닝 셋에 대해서 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360809698_1212.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;파란 그래프에서 볼 수 있듯이 &lt;code&gt;y = 1&lt;/code&gt; 일때 &lt;code&gt;0^Tx &amp;gt;&amp;gt; 0&lt;/code&gt; 이면 &lt;em&gt;cost&lt;/em&gt; 가 상당히 낮아지는걸 볼 수 있다. 이 그래프를 좀 단순화 해서 &lt;em&gt;자주색&lt;/em&gt; 그래프를 만들어 보자. 두개의 직선으로 만들었는데, 이 &lt;em&gt;cost function&lt;/em&gt; 을 계산하면 상당히 근접한 값을 얻을 수 있고, 동시에 그래프가 단순해져 &lt;em&gt;computational advantage&lt;/em&gt; 를 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;각각 좌측, 우측에 있는 &lt;em&gt;cost function&lt;/em&gt; 을 이렇게 쓴다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5C%20%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;logistic regression&lt;/em&gt; 식 에서 &lt;code&gt;-log h(x)&lt;/code&gt; 를 &lt;code&gt;cost_1(z)&lt;/code&gt; 로, &lt;code&gt;-log(1 - h(x)))&lt;/code&gt; 를 &lt;code&gt;cost_0(z)&lt;/code&gt; 로 바꾸면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%20m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7D%28-log%5C%20h_%5Ctheta%28x%5E%7B%28i%29%7D%29%29%5C%20&amp;amp;plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28-log%281%5C%20-%5C%20h_%7B%5Ctheta%7D%28x%5E%7B%28i%29%7D%29%29%29%5D%5C%20&amp;amp;plus;%20%5C%20%7B%5Clambda%20%5Cover%202m%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2%20%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5C%5Ccost_1%28z%29%5C%20%28y%20%3D%201%29%20%5C%5Ccost_0%28z%29%5C%20%28y%20%3D%200%29%20%5C%5C%20min_%5Ctheta%20%5C%20%7B1%20%5Cover%20m%7D%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&amp;amp;plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29%5D%5C%20&amp;amp;plus;%20%5C%20%7B%5Clambda%20%5Cover%202m%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이 때, &lt;code&gt;1/m&lt;/code&gt; 은 상수이므로 제거해도 어차피 똑같은 &lt;code&gt;0(theta)&lt;/code&gt; 를 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;그리고 식을 좀 간략히 적어보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20A%20&amp;amp;plus;%20%5Clambda%20B&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;lambda&lt;/code&gt; 가 하는 일은 &lt;em&gt;low cost (&amp;lsquo;A&amp;rsquo;)&lt;/em&gt; 와 &lt;em&gt;small parameter (&amp;lsquo;B&amp;rsquo;)&lt;/em&gt; 를 조절하는 일이다. 식을 좀 변경하면 이렇게도 볼 수 있다. 여기서 &lt;code&gt;C&lt;/code&gt; 는 &lt;code&gt;1 / lambda&lt;/code&gt; 과 같은 역할이라 보면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20&amp;amp;plus;%20%5Clambda%20B&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;아주 작은 수의 &lt;code&gt;lambda&lt;/code&gt; 를 사용하면 파라미터 &lt;code&gt;B&lt;/code&gt; 가 커지는데, 이것은 &lt;code&gt;C&lt;/code&gt; 가 커져 &lt;code&gt;A&lt;/code&gt; 를 낮추고 &lt;code&gt;B&lt;/code&gt; 를 높이는 것과 똑같다. 반대로 &lt;code&gt;C&lt;/code&gt; 가 작으면 &lt;code&gt;A&lt;/code&gt; 가 커지고, &lt;code&gt;B&lt;/code&gt; 가 작아진다.&lt;/p&gt;

&lt;p&gt;결국 &lt;code&gt;C&lt;/code&gt; 를 쓰느냐 &lt;code&gt;lambda&lt;/code&gt; 를 쓰느냐는, 어떤 항을 옵티마이제이션의 중심으로 두느냐다. 최적화된 파라미터를 찾는건 똑같다.&lt;/p&gt;

&lt;p&gt;식을 마지막으로 정리하면,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20%5C%20%5B%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&amp;amp;plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29%5D%5C%20&amp;amp;plus;%20%5C%20%7B1%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;결국 위 식 (&lt;em&gt;cost&lt;/em&gt;) 를 최소화 하면, &lt;code&gt;y = 1&lt;/code&gt; 일때 &lt;code&gt;0^Tx &amp;gt;&amp;gt; 0&lt;/code&gt; 이 되므로 &lt;code&gt;h(x) == 1&lt;/code&gt; 이란 뜻이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360809865_3224.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;large-mingin-intuition&#34;&gt;Large Mingin Intuition&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;SVM&lt;/em&gt; 은 &lt;em&gt;large margin classifier&lt;/em&gt; 라 부르도 한다. 왜 그런게 한번 살펴보자.&lt;/p&gt;

&lt;p&gt;두 집단을 구분하는 초록색, 자주색, 검은색 직선을 생각해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360811170_6003.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;검은색 선이 가장 낫고, 자주색과 초록색은 두 집단을 분리하긴 하는데 썩 만족할만하게는 아니다. 검은 선과 평행하고 각 점까지의 거리가 최소인 파란선을 그리자. 이걸 &lt;em&gt;margin&lt;/em&gt; 이라 부른다. 다시 말해서 &lt;em&gt;margin&lt;/em&gt; 이 클수록 좋은 &lt;em&gt;classification&lt;/em&gt; 이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;large margin&lt;/em&gt; 하고 &lt;em&gt;SVM&lt;/em&gt; 하고 무슨 상관일까? 그 전에 먼저 &lt;code&gt;C&lt;/code&gt; 를 좀 살펴보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360811018_1834.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;z == 0^T x&lt;/code&gt;, 의 범위를 생각해 보면 &lt;code&gt;y = 1&lt;/code&gt; 일때 &lt;code&gt;z &amp;gt;= 1&lt;/code&gt; 이길 바란다. 반대로 &lt;code&gt;y = 0&lt;/code&gt; 이면 &lt;code&gt;z &amp;lt;= -1&lt;/code&gt; 이면 &lt;code&gt;h(x)&lt;/code&gt; 로 충분히 만족할 만한 값을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;이 때 &lt;code&gt;C&lt;/code&gt; 가 매우 크면 &lt;code&gt;A&lt;/code&gt; 즉, 아래의 식은 굉장히 작아진다. 거의 0 에 가깝게&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Csum_%7Bi%3D1%7D%5Em%20y%5E%7B%28i%29%7Dcost_1%28%5Ctheta%5ETx%29%5C%20&amp;amp;plus;%20%5C%20%281%20-%20y%5E%7B%28i%29%7D%29%5C%20%28cost_0%28%5Ctheta%5ETx%29%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/14/1360811206_9816.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;두 집단에 대해서 &lt;code&gt;C&lt;/code&gt; 가 매우 크면, 다시 말해 &lt;code&gt;A&lt;/code&gt; 가 &lt;code&gt;0&lt;/code&gt; 에 가까우면 &lt;em&gt;overfitting&lt;/em&gt; 된다 볼 수 있으므로 자주색과 비슷한 라인을 찾아낸다. 자주색 선은 모든 샘플에 대해 &lt;em&gt;large margin&lt;/em&gt; 을 가지고 있지만 그렇게 썩 좋은 &lt;em&gt;classification&lt;/em&gt; 이라 볼 수는 없다.&lt;/p&gt;

&lt;p&gt;그러나 &lt;code&gt;C&lt;/code&gt; 가 그렇게 크지 않으면 비 정상적인 샘플들은 조금 무시하고 검은색 선을 찾아낸다. 이게 &lt;em&gt;SVM&lt;/em&gt; 이 작동하는 방식이다.&lt;/p&gt;

&lt;h3 id=&#34;mathematics-behind-large-margin-classification&#34;&gt;Mathematics Behind Large Margin Classification&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360893984_1771.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360893988_7434.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;결국 &lt;code&gt;C&lt;/code&gt; 가 아주 클 때 &lt;code&gt;A = 0&lt;/code&gt; 이므로 &lt;em&gt;SVM&lt;/em&gt; &lt;em&gt;cost fucntion&lt;/em&gt; 을 최소화 하는 것은 아래 식과 동일하다. 그런데 이 식을 풀어 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%20%5Cleft%20%5C%7C%20%5Ctheta%20%5Cright%20%5C%7C%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 &lt;code&gt;0(theta)&lt;/code&gt; 와 &lt;code&gt;x&lt;/code&gt; 를 벡터이므로 &lt;code&gt;0^T x^(i) = p^(i) * ||0||&lt;/code&gt; 라 볼 수 있다. (여기서 &lt;code&gt;p^(i)&lt;/code&gt; 는 &lt;code&gt;x&lt;/code&gt; 의 &lt;code&gt;0&lt;/code&gt; 로의 &lt;em&gt;projection&lt;/em&gt; 된 선의 길이)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Ctheta%5ETx%20%5C%5C%20%5C%5C%20%3D%20p%5E%7B%28i%29%7D%20%5Cleft%20%5C%7C%20%5Ctheta%20%5Cright%20%5C%7C&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이제 이 식을 좀 활용해 보자. &lt;code&gt;C&lt;/code&gt; 가 매우 클때는 &lt;code&gt;B&lt;/code&gt; 만 최소화 하면 되는데&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이 식 자체가 &lt;em&gt;large margin&lt;/em&gt; 을 찾아낸다. 왜 그런가 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360893992_3213.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;왼쪽 그래프의 계산 과정을 보면 &lt;code&gt;x1&lt;/code&gt; 을 &lt;code&gt;0&lt;/code&gt; 에 &lt;em&gt;projection&lt;/em&gt; 해서 얻은 &lt;code&gt;p1&lt;/code&gt; 이 매우 작다. 따라서 &lt;code&gt;p1 * ||0|| &amp;gt;= 1&lt;/code&gt; 에서 &lt;code&gt;||0||&lt;/code&gt; 가 커야 전체 식이 1보다 커지는데, 이러면 식 &lt;code&gt;B&lt;/code&gt; 를 최소화 할 수 없다. 마찬가지로 &lt;code&gt;p2&lt;/code&gt; 는 매우 작은 음수고, &lt;code&gt;p2 * ||0|| &amp;lt;= -1&lt;/code&gt; 에서, &lt;code&gt;||0||&lt;/code&gt; 가 매우 큰 음수여야 한다. 이 또한 &lt;code&gt;0&lt;/code&gt; 를 크게 만드므로 식 &lt;code&gt;B&lt;/code&gt; 가 작아지는 &lt;code&gt;0&lt;/code&gt; 를 찾지 못한다.&lt;/p&gt;

&lt;p&gt;결국 &lt;code&gt;p&lt;/code&gt; 가 커야만 &lt;code&gt;0&lt;/code&gt; 가 작아지기 때문에 &lt;code&gt;p&lt;/code&gt; 를 크게 하는 &lt;code&gt;0&lt;/code&gt; 만 찾고, 이것은 &lt;em&gt;large margin&lt;/em&gt; 이다. 따라서 초록색 같은 &lt;em&gt;low margin&lt;/em&gt; 의 &lt;code&gt;0&lt;/code&gt; 는 선택되지 않는다.&lt;/p&gt;

&lt;p&gt;정리하자면 &lt;code&gt;C&lt;/code&gt; 가 매우 클때 &lt;em&gt;SVM&lt;/em&gt; 은 &lt;em&gt;large magin&lt;/em&gt; 을 찾고, 여기서 &lt;code&gt;C&lt;/code&gt; 를 낮춤으로써 적당한 수준의 &lt;em&gt;classification&lt;/em&gt; 을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5En%20%5Ctheta_j%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;kernels&#34;&gt;Kernels&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360895849_6087.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;SVM&lt;/em&gt; 으로 &lt;em&gt;non-linear decision boundary&lt;/em&gt; 를 어떻게 찾아낼까? 단순히 &lt;em&gt;high polynomial features&lt;/em&gt; 를 사용하는 것보다 더 나은 방법은 없을까? 고차 다항식은 이미지 처리 예제에서도 봤지만, 계산 비용이 너무 비싸다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;kernel&lt;/em&gt; 이란 개념이 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360895854_4557.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;수동으로 몇몇 &lt;em&gt;landmark&lt;/em&gt; &lt;code&gt;l1, l2, ...&lt;/code&gt; 을 고른후 이 &lt;em&gt;landmark&lt;/em&gt; 사이와의 거리로 새로운 &lt;em&gt;feature&lt;/em&gt; &lt;code&gt;f&lt;/code&gt; 를 만든다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?f_1%20%3D%20similarity%28x%2C%20l%5E%7B%281%29%7D%29%20%3D%20exp%20%28-%20%7B%7C%7Cx-l%5E%7B%281%29%7D%7C%7C%5E2%20%5Cover%202%5Csigma%5E2%7D%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;dl &lt;em&gt;similarity function&lt;/em&gt; 을 &lt;em&gt;kernel function&lt;/em&gt; 특히 여기서 사용한 수식은 &lt;em&gt;gaussian kernel&lt;/em&gt; 이라 부른다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360895859_5163.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x&lt;/code&gt; 와 &lt;code&gt;l&lt;/code&gt; 이 상당히 가까우면 &lt;code&gt;f&lt;/code&gt; 는 &lt;code&gt;1&lt;/code&gt; 에 근접하고, 상당히 멀면 &lt;code&gt;0&lt;/code&gt; 에 가까워진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360895862_8544.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 시그마에 따른 &lt;code&gt;f&lt;/code&gt; 값의 변화를 보여주는데, 시그마가 작으면 작을수록 조금만 멀어도 &lt;code&gt;f&lt;/code&gt; 값은 &lt;code&gt;0&lt;/code&gt; 에 가까워진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360895867_6739.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;데이터가 &lt;em&gt;landmark&lt;/em&gt; 중 하나에 라도 가까우면 적어도 하나의 &lt;code&gt;f&lt;/code&gt; 가 1이 되어, &lt;code&gt;h(x)&lt;/code&gt; 가 1 이되고 반면 모든 &lt;em&gt;landmark&lt;/em&gt; 에 멀면 모든 &lt;code&gt;f&lt;/code&gt; 가 0 이 되어 &lt;code&gt;h(x)&lt;/code&gt; 가 0 이된다.&lt;/p&gt;

&lt;p&gt;그럼 이제, 문제는 어떻게 &lt;em&gt;landmark&lt;/em&gt; 를 정할 것인가?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360899128_1431.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360899133_9301.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;l1, ..., lm&lt;/code&gt; 을 &lt;code&gt;x1, ..., xm&lt;/code&gt; 라 하자. 즉 각 &lt;em&gt;training example&lt;/em&gt; 이 &lt;em&gt;landmark&lt;/em&gt; 가 된다. 이를 이용해 구한 &lt;em&gt;feature vector&lt;/em&gt; &lt;code&gt;f^(i)&lt;/code&gt; 중 하나는 &lt;code&gt;sim(x^i, l^i)&lt;/code&gt; 이므로 1이 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360899136_2691.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;따라서 주어진 &lt;code&gt;x&lt;/code&gt; 에 대해 &lt;code&gt;m + 1&lt;/code&gt; 의 벡터 &lt;code&gt;f&lt;/code&gt; 를 구해 &lt;code&gt;0^Tf &amp;gt;= 0&lt;/code&gt; 이면 &lt;code&gt;y = 1&lt;/code&gt; 이다. 그리고 이 때 &lt;em&gt;feature&lt;/em&gt; 수가 &lt;code&gt;m&lt;/code&gt; 이 되므로&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%5Ctheta%20%5C%20C%20%5C%20%5Csum_%7By%3D1%7D%5Emcost_1%28%5Ctheta%5ETf%5E%7B%28i%29%7D%29%20&amp;amp;plus;%20%281-y%5E%7B%28i%29%7D%29cost_0%28%5Ctheta%5ETf%5E%7B%28i%29%7D%29%29%20&amp;amp;plus;%20%7B1%20%5Cover%202%7D%20%5Csum_%7Bj%3D1%7D%5Em%5Ctheta_j%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;마지막 항을 좀 자세히 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Csum_%7Bj%3D1%7D%5Ctheta_j%5E2%20%5C%5C%20%5C%5C%20%3D%20%5Ctheta%5ET%20%5Ctheta&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;인데 &lt;em&gt;SVM&lt;/em&gt; 실제 구현에서는 가운데 &lt;code&gt;M&lt;/code&gt; 매트릭스를 삽입해 좀더 효율적으로 돌아가도록 한다. 이 &lt;code&gt;M&lt;/code&gt; 은 어떤 &lt;em&gt;kernel&lt;/em&gt; 을 사용하는지에 따라 다르다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Ctheta%5ET%20M%20%5C%20%5Ctheta&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;logistic regression&lt;/em&gt; 에 &lt;em&gt;kernel&lt;/em&gt; 을 사용할 수도 있겠지만, 상당히 느리다. 반면 &lt;em&gt;SVM&lt;/em&gt; 에서는 마지막 항을 위 처럼 수정할 수 있기에 빠르게 동작한다.&lt;/p&gt;

&lt;h3 id=&#34;bias-vs-variance-in-svm&#34;&gt;Bias vs Variance in SVM&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360899140_2255.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;(1) &lt;code&gt;C&lt;/code&gt; 가 크면 &lt;em&gt;low bias&lt;/em&gt;, &lt;em&gt;high variance&lt;/em&gt;  (== &lt;em&gt;small &lt;code&gt;lambda&lt;/code&gt;&lt;/em&gt;)&lt;br /&gt;
(2) &lt;code&gt;C&lt;/code&gt; 가 작으면 &lt;em&gt;high bias&lt;/em&gt;, &lt;em&gt;low variance&lt;/em&gt;  (== &lt;em&gt;large &lt;code&gt;lambda&lt;/code&gt;&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sigma&lt;/code&gt; 가 크면 &lt;code&gt;f&lt;/code&gt; 가 적게 변하기 때문에 인풋 &lt;code&gt;x&lt;/code&gt; 에 대해서도 &lt;em&gt;high bias&lt;/em&gt;, &lt;em&gt;low variance&lt;/em&gt; 다.&lt;/p&gt;

&lt;h3 id=&#34;using-an-svm&#34;&gt;Using an SVM&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360901245_9359.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;라이브러리를 사용하더라도 &lt;code&gt;C&lt;/code&gt; 와 어떤 &lt;em&gt;kernel&lt;/em&gt; 을 사용할지는 골라야 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;feature&lt;/em&gt; 가 크고, 트레이닝셋이 작을때는 &lt;em&gt;overfitting&lt;/em&gt; 될 수 있으므로 &lt;em&gt;linear kernel&lt;/em&gt; 을 사용하는 편이 낫다.&lt;/p&gt;

&lt;p&gt;반면 &lt;code&gt;n&lt;/code&gt; 이 작고, &lt;code&gt;m&lt;/code&gt; 이 클 경우에는 &lt;em&gt;non-linear&lt;/em&gt; 가설일 수 있으므로 &lt;em&gt;gaussian kernel&lt;/em&gt; 을 사용할 수 있다. 그러면 &lt;code&gt;sigma&lt;/code&gt; 를 골라야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360901242_6422.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;SVM&lt;/em&gt; 라이브러리를 이용할때는 &lt;code&gt;kernel function&lt;/code&gt; 을 직접 구현해야 한다. 이걸 이용해서 라이브러리는 &lt;code&gt;x&lt;/code&gt; 에 대해 &lt;code&gt;f1, ..., fl&lt;/code&gt; 을 계산한다.&lt;/p&gt;

&lt;p&gt;만약에 &lt;em&gt;feature&lt;/em&gt; 의 스케일이 다르면, &lt;code&gt;x1 = 10000, x2 = 5, ...&lt;/code&gt; &lt;code&gt;||x-l||^2&lt;/code&gt; 값이 숫자가 큰 항에 의해 좌우될 수 있으므로 &lt;em&gt;feature scailing&lt;/em&gt; 을 하는편이 좋다.&lt;/p&gt;

&lt;h4 id=&#34;other-choices-of-kernel&#34;&gt;Other choices of kernel&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360901245_9359.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;SVM&lt;/em&gt; 구현들이 계산을 최적화 하기위해 다양한 트릭을 이용한다. 이로 인해 모든 &lt;em&gt;similarity function&lt;/em&gt; 유효한 커널이 되는건 아니고, &lt;em&gt;&amp;ldquo;Mercer&amp;rsquo;s Theorem&amp;rdquo;&lt;/em&gt; 을 만족해야만 한다. &lt;del&gt;인용하려 했는데 무슨말인지 모르겠음&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;그렇다고 커널이 &lt;em&gt;linear&lt;/em&gt; 와 &lt;em&gt;gaussian&lt;/em&gt; 만 있는건 아니고 다양한 커널이 있다. 그림을 참조하자.&lt;/p&gt;

&lt;h4 id=&#34;multi-class-classification&#34;&gt;Multi-class classification&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/15/1360901253_5022.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;대부분의 &lt;em&gt;SVM&lt;/em&gt; 라이브러리들은 &lt;em&gt;multi-class&lt;/em&gt; 에 대한 함수를 제공한다. 그러나 이것들을 사용하는 대신 &lt;em&gt;one-vs-all&lt;/em&gt; 방법을 사용할 수도 있다. &lt;code&gt;k&lt;/code&gt; 개의 클래스가 있다면 &lt;code&gt;k&lt;/code&gt; 개의 &lt;em&gt;SVM&lt;/em&gt; 훈련시키면 된다.&lt;/p&gt;

&lt;h4 id=&#34;logistic-regression-vs-svm&#34;&gt;Logistic regression vs SVM&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201208/12/1344759226_6088.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;(1) &lt;code&gt;n &amp;gt;= m&lt;/code&gt; 이면 &lt;em&gt;logistic regression&lt;/em&gt; 이나 &lt;em&gt;linear kernel&lt;/em&gt; 이 낫다.&lt;br /&gt;
(2) &lt;code&gt;n&lt;/code&gt; 이 작고, &lt;code&gt;m&lt;/code&gt; 이 중간 사이즈면 &lt;em&gt;gaussian kernel&lt;/em&gt; 을&lt;br /&gt;
(3) &lt;code&gt;n&lt;/code&gt; 이 작고 &lt;code&gt;m&lt;/code&gt; 이 크면 &lt;em&gt;gaussian&lt;/em&gt; 은 상당히 느려진다. &lt;em&gt;feature&lt;/em&gt; 를 좀 수정하고, &lt;em&gt;logistic&lt;/em&gt; 이나 &lt;em&gt;linear kernel&lt;/em&gt; 을 이용한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;SVM&lt;/em&gt; 의 장점은 다양한 &lt;em&gt;kernel&lt;/em&gt; 을 &lt;em&gt;non-linear function&lt;/em&gt; 을 훈련시키기 위해 사용할 수 있다는 점이다.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;Machine Learning&lt;/em&gt; by &lt;strong&gt;Andrew NG&lt;/strong&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 08: K-means, PCA Details</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-8/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:32 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-8/</guid>
      <description>

&lt;p&gt;이번시간에는 &lt;em&gt;PCA&lt;/em&gt; 와 &lt;em&gt;clustering&lt;/em&gt; 을 배운다. &lt;em&gt;PCA&lt;/em&gt; 가 어떻게 돌아가는지 알기위해 &lt;em&gt;covariance matrix&lt;/em&gt;, &lt;em&gt;eigen decomposition&lt;/em&gt;, &lt;em&gt;singular value decomposition&lt;/em&gt; 등의 배경지식도 익혀보자. ~~K-means 는 거들뿐&lt;/p&gt;

&lt;h3 id=&#34;unsupervised-learning-intro&#34;&gt;Unsupervised Learning Intro&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;clustering&lt;/em&gt; 은 다양한 분야에 활용할 수 있다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Market Segmentation&lt;/li&gt;
&lt;li&gt;Social Network Analysis&lt;/li&gt;
&lt;li&gt;Organize Computing Clusters&lt;/li&gt;
&lt;li&gt;Astronomical Data Analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;k-means&#34;&gt;K-Means&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360978231_7390.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360978245_9923.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;랜덤한 위치에 &lt;em&gt;centroid&lt;/em&gt; 를 잡고, 가까운 점들을 색칠 한뒤 그 점들의 중심으로 &lt;em&gt;centroid&lt;/em&gt; 를 옮겨가면서 집단을 만들어 낸다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;k-means&lt;/em&gt; 의 인풋은 &lt;em&gt;centroid&lt;/em&gt; 의 수인 &lt;code&gt;k&lt;/code&gt; 와 &lt;code&gt;x1, x2, ... , xm&lt;/code&gt; 의 트레이닝 셋이다. 구체적인 알고리즘은&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360978315_1086.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;매 이터레이션마다 &lt;code&gt;i to m&lt;/code&gt; 까지 루프를 돌면서 클러스터링된 원소들의 배열인 &lt;code&gt;c^(i)&lt;/code&gt; 에 &lt;code&gt;1 to K&lt;/code&gt; 사이의 값을 넣는다. 이때 &lt;code&gt;c^(i)&lt;/code&gt; 에 삽입될 값은, 해당 원소로부터 가장 가까운 &lt;em&gt;centroid&lt;/em&gt; 의 인덱스다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;c^(i)&lt;/code&gt; is index of cluster &lt;code&gt;(1, ..., K)&lt;/code&gt; to which example &lt;code&gt;x^(i)&lt;/code&gt; is currently assigned&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;따라서 각 원소로부터의 거리를 최소로 하는 &lt;code&gt;k&lt;/code&gt; 에 대해 &lt;code&gt;c^(i) = k&lt;/code&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_k%20%5Cleft%20%7B%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20%5Cmu_k%20%5Cright%20%5C%7C%20%7D%20%5C%5C%20%5C%5C%20%5CRightarrow%20c%5E%7B%28i%29%7D%20%3D%20k&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;optimization-objective&#34;&gt;Optimization Objective&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360979250_8035.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;k-means&lt;/em&gt; 에서 최소화 하려는 &lt;em&gt;cost function&lt;/em&gt; 은&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?J%28c%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%29%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20%5Cmu_%7Bc%5E%7B%28i%29%7D%7D%20%5Cright%20%5C%7C&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;다시 말해서 각 점에서 &lt;em&gt;centroid&lt;/em&gt; 까지의 거리를 최소화 하는 것이 목표다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%7Bc%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%7D%20%5C%20%5C%20J%28c%5E%7B%281%29%7D%2C%20...%2C%20c%5E%7B%28m%29%7D%2C%20%5Cmu_1%2C%20...%2C%20%5Cmu_K%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이 함수 &lt;code&gt;J&lt;/code&gt; 를 다른말로는 &lt;em&gt;distortion function&lt;/em&gt; 이라 부른다. 알고리즘을 다시 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360979289_8146.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;(1) &lt;em&gt;clustering assignment step&lt;/em&gt; 에서는 &lt;code&gt;mu&lt;/code&gt; 를 고정시키고 &lt;code&gt;c^(i)&lt;/code&gt; 에 대해서 &lt;code&gt;J&lt;/code&gt; 를 최소화 한다.&lt;br /&gt;
(2) &lt;em&gt;move centroid step&lt;/em&gt; 에서는 &lt;code&gt;c^(i)&lt;/code&gt; 를 고정시키고 &lt;code&gt;mu&lt;/code&gt; 에 대해서 &lt;code&gt;J&lt;/code&gt; 를 최소화 한다.&lt;/p&gt;

&lt;h3 id=&#34;random-initialization&#34;&gt;Random Initialization&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360980200_9803.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위쪽 예제는 &lt;em&gt;centroid&lt;/em&gt; 의 랜덤 초기화에서 좋게 배치된 경우이고, 아래쪽은 운이 나쁜 경우를 설명하는 그림이다. 이것이 설명하는 바는 &lt;em&gt;centroid&lt;/em&gt; 의 초기화에 따라 결과가 달라질 수 있다는 것이다. 아래 그림을 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360980222_7891.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;따라서 &lt;em&gt;local optima&lt;/em&gt; 를 피가히 위해, 그리고 좋은 &lt;em&gt;clustering&lt;/em&gt; 을 얻기 위해 &lt;em&gt;random initialization&lt;/em&gt; 이용하여 &lt;em&gt;k-mean&lt;/em&gt; 를 여러번 돌릴 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360980246_7140.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;여러번 &lt;em&gt;k-mean&lt;/em&gt; 를 돌려 얻은 &lt;code&gt;J&lt;/code&gt; 에 대해 최소값을 가지는 &lt;code&gt;J&lt;/code&gt; 를 이용해 클러스터링을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;그러나 &lt;code&gt;K&lt;/code&gt; 가 매우 크다면, &lt;em&gt;random initialization&lt;/em&gt; 들어가는 계산 비용에 비해 별로 좋은 결과를 돌려주지 못할 것이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;random initialization&lt;/em&gt; 을 하는 방법으로&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Pick &lt;code&gt;k&lt;/code&gt; distinct random integers &lt;code&gt;i_1, ..., i_k&lt;/code&gt; from &lt;code&gt;{1, ..., m}&lt;/code&gt;.&lt;br /&gt;
Set &lt;code&gt;mu_1 = x^(i_1), ..., mu_k = x^(i_k)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;choosing-the-number-of-cluster&#34;&gt;Choosing the Number of Cluster&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;K&lt;/code&gt; 값을 선택하기 위해 &lt;em&gt;Elbow method&lt;/em&gt; 를 이용할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/16/1360981609_7528.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;K&lt;/code&gt; 값의 변화에 따라 &lt;em&gt;distortion function&lt;/em&gt; &lt;code&gt;J&lt;/code&gt; 값이 급격히 감소하는 지점을 선택하는 방법이다. 그런데 &lt;code&gt;J&lt;/code&gt; 값이 오른쪽 그림처럼 좀 애매하게 감소하면 어떻게 할까?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Sometimes, you are running K-means to get clusters to use for some later / downstream purpose. Evaluate K-means based on a metric for hwo well it perfomrs for that later purpose.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;예를 들어서, 몸무게 / 키 에 따라 집단을 분류해 그에 맞추어 티셔츠를 만든다고 할 때 &lt;code&gt;K = 3 or 5&lt;/code&gt; 에 대해서는 단순히 좋은 클러스터링을 얻는것은 물론  어떤 &lt;code&gt;K&lt;/code&gt; 가 수지타산이 더 맞을지 티셔츠 비즈니스적인 관점에서 생각을 해봐야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://my.csdn.net/uploads/201208/28/1346132804_2121.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;dimensionality-reduction&#34;&gt;Dimensionality Reduction&lt;/h3&gt;

&lt;p&gt;이번엔 &lt;em&gt;unsupervised learning&lt;/em&gt; 의 또 다른 기법인 &lt;em&gt;dimensionality reduction&lt;/em&gt; 을 알아보자. 이 기법의 &lt;em&gt;motivation&lt;/em&gt; 은 2가지다.&lt;/p&gt;

&lt;p&gt;(1) Data Compression&lt;br /&gt;
(2) Data Visualization&lt;/p&gt;

&lt;h3 id=&#34;data-compression&#34;&gt;Data Compression&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361235893_4367.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;두 축을 보면 하나는 인치로, 다른 하나는 센치다. &lt;em&gt;highly redundant data&lt;/em&gt; 이기 때문에 하나의 차원으로 축소할 수 있다.&lt;/p&gt;

&lt;p&gt;중복된 *feature*만 차원을 줄일 수 있는 것은 아니다&lt;/p&gt;

&lt;p&gt;예를 들어 데이터의 한 축을 &lt;em&gt;pilot skill&lt;/em&gt; 다른 축을 &lt;em&gt;pilot enjoyment&lt;/em&gt; 라 하고 두 &lt;em&gt;feature&lt;/em&gt; 간 관계를 거의 직선으로 나타낼 수 있다고 하자. 이 새로운 직선을 &lt;em&gt;pliot aptitude&lt;/em&gt; 라 부르고 두개의 &lt;em&gt;feature&lt;/em&gt; 를 대신하는 새로운 &lt;em&gt;feature&lt;/em&gt; 로 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;feature&lt;/em&gt; 가 한 두개면 중복되는 것을 걸러내거나, 새로운 &lt;em&gt;feature&lt;/em&gt; 로 만들기 쉬운데 만약 수백개라면 이것도 일이다.&lt;/p&gt;

&lt;p&gt;위 그림을 다시 보면 &lt;code&gt;x_1, x_2&lt;/code&gt; 를 &lt;code&gt;z_1&lt;/code&gt; 으로 대신하고 있다. &lt;em&gt;feature&lt;/em&gt; 의 수가 줄어든 것이다.&lt;/p&gt;

&lt;p&gt;이렇게 차원을 줄이면 연산량이 줄어들의 전체 알고리즘의 성능도 빨라진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361235907_7086.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 그림이 &lt;em&gt;dimensionality reduction&lt;/em&gt; 에 대한 &lt;em&gt;intuition&lt;/em&gt; 을 제공한다. 3차원의 데이터를 2차원의 평면으로 투영해 새로운 &lt;em&gt;feature set&lt;/em&gt; 인 &lt;code&gt;z&lt;/code&gt; 를 사용해 데이터를 나타낼 수 있다.&lt;/p&gt;

&lt;p&gt;그림은 3차원 -&amp;gt; 2차원 이지만, 만약 10000 개를 1000 개를 줄일 수 있다면 어마어마한 중복을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;조금 더 이해가 잘되는 3차원 그림을 가져오면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://scipy-lectures.github.io/_images/pca_3d_axis.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://scipy-lectures.github.io/_images/pca_3d_aligned.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://scipy-lectures.github.io&#34;&gt;http://scipy-lectures.github.io&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;data-visualization&#34;&gt;Data Visualization&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;dimensionality reduction&lt;/em&gt; 의 두 번째 &lt;em&gt;motivation&lt;/em&gt; 은 바로 &lt;em&gt;data visualization&lt;/em&gt; 이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GDP&lt;/em&gt;, &lt;em&gt;Country size&lt;/em&gt; 등 다양한 &lt;em&gt;feature&lt;/em&gt; 500개를 2개로 줄여 그래프에 그려보면 데이터에 대한 어떤 &lt;em&gt;intuition&lt;/em&gt; 을 얻을 수도 있다. 즉 데이터가 주로 어떤 종류의 &lt;em&gt;feature&lt;/em&gt; 에 의해 많이 영향을 받는지 파악할수 있다는 것이다.&lt;/p&gt;

&lt;p&gt;강의에 나온 예제에서는 &lt;code&gt;z_1&lt;/code&gt; 은 &lt;em&gt;country size / GDP&lt;/em&gt;, &lt;code&gt;z_2&lt;/code&gt; 는 &lt;em&gt;per person GDP&lt;/em&gt; 였다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;visualization&lt;/em&gt; 을 위한 경우 &lt;code&gt;2, 3&lt;/code&gt; 개 정도로 차원을 줄일 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;principal-component-analysis-problem-formulation&#34;&gt;Principal Component Analysis Problem Formulation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236095_4842.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;2개의 &lt;em&gt;feature&lt;/em&gt; &lt;code&gt;x_1, x_2&lt;/code&gt; 를 하나로 줄인다고 하자. 이 경우 &lt;em&gt;projection error&lt;/em&gt; (파란선의 길이) 를 최소로 하는 선 (빨강)을 찾으려고 할 것이다. 반면 자주색 선의 경우 &lt;em&gt;projection error&lt;/em&gt; 가 가장 큰 선이라 볼 수있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236100_6448.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;따라서 &lt;code&gt;n&lt;/code&gt; 차원을 &lt;code&gt;k&lt;/code&gt; 차원으로 축소할때는 각 데이터를 &lt;code&gt;k&lt;/code&gt; 개의 벡터 &lt;code&gt;u&lt;/code&gt; 에 대해 투영시켰을때의 &lt;em&gt;projection error&lt;/em&gt; 를 최소로 하는 벡터 &lt;code&gt;u&lt;/code&gt; 를 찾으면 된다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Reduce from &lt;code&gt;n&lt;/code&gt;-dimension to &lt;code&gt;k&lt;/code&gt;-dimension, find &lt;code&gt;k&lt;/code&gt; vectors &lt;code&gt;u^1, ..., u^k&lt;/code&gt; onto wihch to project the data, so as to minimized the projection error&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;쉽게 생각하면 &lt;code&gt;k&lt;/code&gt; 개의 &lt;em&gt;direction&lt;/em&gt; 을 찾는다고 생각하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236106_9904.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;왼쪽 그림은 &lt;em&gt;linear regression&lt;/em&gt; 에서 찾아내는 오차, 즉 &lt;code&gt;y&lt;/code&gt; 값과 &lt;em&gt;prediction&lt;/em&gt; 간의 거리이고&lt;/p&gt;

&lt;p&gt;우측 그림은 &lt;em&gt;PCA&lt;/em&gt; 로 찾아낸 선과 각 점사이의 &lt;em&gt;projection error&lt;/em&gt; 를 파란샌으로 나타냈다.&lt;/p&gt;

&lt;p&gt;두 그림에서 볼 수 있듯이 &lt;em&gt;PCA&lt;/em&gt; 는 &lt;em&gt;linear regression&lt;/em&gt; 이 아니다. &lt;em&gt;PCA&lt;/em&gt; 에서는 &lt;code&gt;y&lt;/code&gt; 값이란 개념이 없다.&lt;/p&gt;

&lt;h3 id=&#34;pca-algorithm&#34;&gt;PCA Algorithm&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236182_1422.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PCA&lt;/em&gt; 전에는 &lt;em&gt;preprocessing step&lt;/em&gt; 을 거친다. 이는 다양한 &lt;em&gt;feature&lt;/em&gt; 간 스케일이 다르기 때문에 비교할만한 스케일을 얻기 위함이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;그 후에는 &lt;code&gt;n&lt;/code&gt; 차원으로부터 &lt;em&gt;projection error&lt;/em&gt; 가 최소인 &lt;code&gt;k&lt;/code&gt; 개의 벡터를 얻는 계산을 수행한다.&lt;/p&gt;

&lt;p&gt;(1) 먼저 &lt;code&gt;Sigma&lt;/code&gt; 라 부르는 &lt;em&gt;covariance matrix&lt;/em&gt; 를 계산하고 (작은 시그마)&lt;br /&gt;
(2) 그 후에 &lt;code&gt;Sigma&lt;/code&gt; 의 &lt;em&gt;eigenvectors&lt;/em&gt; 를 계산한다.&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;svd&lt;/code&gt; 는 &lt;em&gt;sigular value decomposition&lt;/em&gt; 을 의미한다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Sigma&lt;/code&gt; 를 얻기 위한 &lt;em&gt;vectorization&lt;/em&gt; 은 &lt;code&gt;(1/m) * X&#39; * X&lt;/code&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236425_3920.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;svd&lt;/code&gt; 함수의 리턴값으로 &lt;code&gt;U&lt;/code&gt; 매트릭스가 나오는데, 이건 &lt;code&gt;n x n&lt;/code&gt; 매트릭스다. 여기서 첫 &lt;code&gt;k&lt;/code&gt; 개의 컬럼을 취한다. 이 매트릭스를 &lt;code&gt;Y&lt;/code&gt; 라 부르면 새로운 &lt;em&gt;feature vector&lt;/em&gt;  &lt;code&gt;z&lt;/code&gt; 는&lt;/p&gt;

&lt;p&gt;&lt;code&gt;z = Y^T * x&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;정리하면 아래 그림과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236428_5117.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;pca-details&#34;&gt;PCA Details&lt;/h3&gt;

&lt;p&gt;넘어가기 전에 잠깐 &lt;em&gt;PCA&lt;/em&gt; 에서 다룬 &lt;em&gt;covariance matrix&lt;/em&gt; 나 &lt;em&gt;eigen vector&lt;/em&gt; 를 좀 보고 넘어가자.&lt;/p&gt;

&lt;h4 id=&#34;covariance&#34;&gt;Covariance&lt;/h4&gt;

&lt;p&gt;두 확률 변수 &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt; 에 대해서 &lt;em&gt;covariance&lt;/em&gt; 는&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Csigma%28X%2C%20Y%29%20%3D%20E%5B%28X%20-%20E%28X%29%29%28Y%20-%20E%28Y%29%29%5D%20%5C%5C%20%5C%5C%20%3D%20E%28XY%29%20-%20E%28X%29E%28Y%29%20%5C%20%7B%5Ccolor%7BBlue%7D%20%28by%5C%20linearity%5C%20of%5C%20expectation%29%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;보면 알겠지만, 독립이면 &lt;em&gt;covariance&lt;/em&gt; 값이 &lt;code&gt;0&lt;/code&gt; 이다. 따라서 두 변수간 상관정도라 보면 된다. 공분산이 양수면 양의 상관관계를, 음수이면 음의 상관관계를 가진다.&lt;/p&gt;

&lt;p&gt;이해를 위해서 &lt;a href=&#34;http://darkpgmr.tistory.com/110&#34;&gt;여기&lt;/a&gt;로 부터 인용을 하자면&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;x의 분산은 x들이 평균을 중심으로 얼마나 흩어져 있는지를 나타내고, x와 y의 공분산은 x, y의 흩어진 정도가 얼마나 서로 상관관계를 가지고 흩어졌는지를 나타낸다. 예를 들어, x와 y 각각의 분산은 일정한데 x가 E(x)보다 클때 y도 E(y)보다 크면 공분산은 최대가 되고, x가 E(x)보다 커질때 y는 E(y)보다 작아지면 공분산은 최소(음수가 됨), 서로 상관관계가 없으면 공분산은 0이 된다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;공분산은 몇 가지 성질이 있는데&lt;/p&gt;

&lt;p&gt;(1) &lt;code&gt;X, Y&lt;/code&gt; 가 독립이면 &lt;em&gt;covariance = &lt;code&gt;0&lt;/code&gt;&lt;/em&gt; 이다. 그러나 역은 &lt;em&gt;gaussian random variable&lt;/em&gt; 일때만 성립한다.&lt;/p&gt;

&lt;p&gt;(2) &lt;img src=&#34;http://upload.wikimedia.org/math/0/6/0/060cda617e0812f174f5f75b6032b3dd.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;(3) &lt;img src=&#34;http://upload.wikimedia.org/math/5/e/9/5e9674eac71398dcb022fc5cb76e2717.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;(4) &lt;img src=&#34;http://upload.wikimedia.org/math/8/2/3/823d4a54cac228efe1658718bfa7707a.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;공분산마다 값이 다르기 때문에 비교를 위해 &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt; 의 표준편차로 나눈 것을 &lt;em&gt;correlation, 상관계수&lt;/em&gt; 라 부른다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/math/0/7/6/076d3820a46afe55ee680f3c85e34c76.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h4 id=&#34;covariance-matrix&#34;&gt;Covariance Matrix&lt;/h4&gt;

&lt;p&gt;이제 &lt;em&gt;covariance matrix&lt;/em&gt; 를 알아보자. 공분산 행렬은 데이터 &lt;code&gt;X&lt;/code&gt; (벡터) 에 대해 &lt;code&gt;X&lt;/code&gt; 의 두 원소 &lt;code&gt;X^(i), X^(j)&lt;/code&gt; 간 공분산을 구한 행렬이다. &lt;code&gt;X&lt;/code&gt; 를 &lt;code&gt;n&lt;/code&gt; 벡터라 하면, &lt;code&gt;X&lt;/code&gt; 의 공분산 행렬은 &lt;code&gt;n x n&lt;/code&gt; 행렬이다. 그리고 &lt;code&gt;Cov(X, Y) = Cov(Y, X)&lt;/code&gt; 이므로 &lt;em&gt;symmetric matrix, 대칭행렬&lt;/em&gt; 이기도 하다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h4 id=&#34;eigen-vector-eigen-value&#34;&gt;Eigen vector, Eigen value&lt;/h4&gt;

&lt;p&gt;아까 슬라이드에서 잠깐 &lt;em&gt;eigen vector&lt;/em&gt; 가 나왔는데, 우리말로 &lt;em&gt;고유벡터&lt;/em&gt; 라 부른다. 고유벡터 &lt;code&gt;v&lt;/code&gt; 는 행렬 &lt;code&gt;A&lt;/code&gt; 곱했을때 상수 &lt;code&gt;λ&lt;/code&gt; 와 다음의 관계를 가진다. (&lt;code&gt;A&lt;/code&gt; 는 &lt;code&gt;n x n&lt;/code&gt; 매트릭스)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?Av%20%3D%20%5Clambda%20v&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이해를 위해 &lt;a href=&#34;http://darkpgmr.tistory.com/105&#34;&gt;여기&lt;/a&gt;서 인용하면&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;square matrix&lt;/em&gt; &lt;code&gt;A&lt;/code&gt; 를 선형변환으로 봤을 때, 선형 변환 &lt;code&gt;A&lt;/code&gt; 에 의한 변환 결과가 자기 자신의 상수배 &lt;code&gt;λ&lt;/code&gt; 가 되는 &lt;code&gt;0&lt;/code&gt; 이 아닌 벡터 &lt;code&gt;v&lt;/code&gt; 를 &lt;em&gt;eigen vector&lt;/em&gt; 라 하고, 이 &lt;code&gt;λ&lt;/code&gt; 를 &lt;em&gt;eigen value&lt;/em&gt; 라 한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;기하학적으로 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Eigenvalue_equation.svg/375px-Eigenvalue_equation.svg.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://en.wikipedia.org&#34;&gt;http://en.wikipedia.org&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h4 id=&#34;diagonalization&#34;&gt;Diagonalization&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;SVD&lt;/em&gt; 에 대해 이야기 하기 전에 &lt;em&gt;matri diagonalizaion, 행렬 대각화&lt;/em&gt; 도 좀 보자.&lt;/p&gt;

&lt;p&gt;대각행렬은 &lt;em&gt;principal diagonal&lt;/em&gt; 원소를 제외한 모든 원소가 0 인 &lt;em&gt;sqaure matrix&lt;/em&gt; 인데, &lt;em&gt;sqaure matrix, 정방행렬&lt;/em&gt; &lt;code&gt;A&lt;/code&gt; 에 대해서&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?P%5E%7B-1%7DAP%20%3D%20D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;인 &lt;code&gt;P&lt;/code&gt; 와 &lt;code&gt;D&lt;/code&gt; 가 존재하면 &lt;code&gt;A&lt;/code&gt; 는 &lt;em&gt;diagonalizable matrix, 대각화 가능 행렬&lt;/em&gt; &lt;code&gt;P&lt;/code&gt; 를 &lt;em&gt;diagonalizing matrix, 대각화하는 행렬&lt;/em&gt; 이라 부른다.&lt;/p&gt;

&lt;p&gt;위 식에서 &lt;code&gt;D&lt;/code&gt; 는 &lt;em&gt;diagonal matrix&lt;/em&gt; 인데,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?D%20%3D%20%5Cbegin%7Bbmatrix%7D%20%5Clambda_1%20%26%200%20%26%20...%20%26%200%5C%5C%200%20%26%20%5Clambda_2%20%26%20...%20%26%200%5C%5C%20%5Cvdots%20%26%20%5Cvdots%20%26%20%5C%20%26%20%5Cvdots%5C%5C%200%20%26%200%20%26%20%5Ccdots%20%26%20%5Clambda_n%20%5Cend%7Bbmatrix%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;저 식에서 &lt;code&gt;A&lt;/code&gt; 위주로 정리하면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?A%20%3D%20PDP%5E%7B-1%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이 때 &lt;code&gt;P&lt;/code&gt; 가 고유벡터를 열벡터로 하는 행렬이고, &lt;code&gt;D&lt;/code&gt; 가 고유값들을 대각 원소로 하는 대각행렬이면 &lt;em&gt;eigen decomposition&lt;/em&gt; 이라 부른다.&lt;/p&gt;

&lt;p&gt;위에서 &lt;em&gt;covariance matrix&lt;/em&gt; 는 대칭행렬이라 말했는데, (&lt;code&gt;A = A^T&lt;/code&gt;) 이 대칭행렬은&lt;/p&gt;

&lt;p&gt;(1) 항상 &lt;em&gt;eigen decomposition&lt;/em&gt; 이 가능하며&lt;br /&gt;
(2) &lt;em&gt;orthogonal matrix&lt;/em&gt; 로 대각화가 가능하다. (&lt;code&gt;P^-1 = P^T)&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;singular-value-decomposition&#34;&gt;Singular Value Decomposition&lt;/h3&gt;

&lt;p&gt;이제, &lt;em&gt;Sigular Value Decomposition, 특이값 분해&lt;/em&gt; 에 대해 이야기 하자. &lt;em&gt;SVD&lt;/em&gt; 도 행렬을 대각화 하는 한 방법인데, &lt;em&gt;eigen decomposition&lt;/em&gt; 과 달리 &lt;code&gt;m x n&lt;/code&gt; 행렬에 적용 가능하다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;m x n&lt;/code&gt; 행렬 &lt;code&gt;A&lt;/code&gt; 에 대해 &lt;em&gt;SVD&lt;/em&gt; 는&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?A%20%3D%20U%20%5CSigma%20V%5ET&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;m x m&lt;/code&gt; 의 &lt;code&gt;U&lt;/code&gt; 는 &lt;code&gt;AA^T&lt;/code&gt; 를 &lt;em&gt;eigen decomposition&lt;/em&gt; 해서 얻은 &lt;em&gt;orthogonal matrix&lt;/em&gt; 고, &lt;code&gt;U&lt;/code&gt; 의 열벡터를 &lt;code&gt;A&lt;/code&gt; 의 &lt;em&gt;left singular vector&lt;/em&gt; 라 부른다.&lt;/p&gt;

&lt;p&gt;이 때 &lt;code&gt;U&lt;/code&gt; &lt;em&gt;eigen decomposition&lt;/em&gt; 해서 나온 &lt;em&gt;diagonalizing matrix&lt;/em&gt; 이므로 &lt;code&gt;U&lt;/code&gt; 의 열벡터는 &lt;code&gt;AA^T&lt;/code&gt; 의 &lt;em&gt;eigen vectors&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?AA%5ET%20%3D%20U%28%5CSigma%20%5CSigma%5ET%29U%5ET&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;n x n&lt;/code&gt; 의 &lt;code&gt;V&lt;/code&gt; 는 &lt;code&gt;A^TA&lt;/code&gt; 를 &lt;em&gt;eigen decomposition&lt;/em&gt; 해서 얻은 &lt;em&gt;orthogonal matrix&lt;/em&gt; 고 &lt;code&gt;V&lt;/code&gt; 의 열벡터를 &lt;code&gt;A&lt;/code&gt; 의 &lt;em&gt;right singular vector&lt;/em&gt; 라 부른다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?A%5ETA%20%3D%20V%28%5CSigma%5ET%20%5CSigma%29V%5ET&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;마찬가지로 &lt;code&gt;V&lt;/code&gt; 도 &lt;em&gt;eigen decomposition&lt;/em&gt; 의 결과로 얻은 &lt;em&gt;diagonalizing matrix&lt;/em&gt; 이므로 &lt;code&gt;V&lt;/code&gt; 의 열벡터는 &lt;code&gt;A^TA&lt;/code&gt; 의 &lt;em&gt;eigen vectors&lt;/em&gt; 다&lt;/p&gt;

&lt;p&gt;&lt;code&gt;\\Sigma&lt;/code&gt; 는 &lt;code&gt;AA^T, A^TA&lt;/code&gt; 를 &lt;em&gt;eigen decomposition&lt;/em&gt; 해서 얻은 &lt;em&gt;eigen value&lt;/em&gt; 의 &lt;em&gt;square root&lt;/em&gt; 를 대각원소로 하는 &lt;code&gt;m x n&lt;/code&gt; 의 직사각 대각행렬이다. 이 때 대각 원소들이 &lt;code&gt;A&lt;/code&gt; 의 &lt;em&gt;singular value, 특이값&lt;/em&gt; 이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://cfile5.uf.tistory.com/image/277E3949525F5A872F520E&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;(관련 그림과 설명은 &lt;a href=&#34;http://darkpgmr.tistory.com/106&#34;&gt;여기&lt;/a&gt;서 참조했습니다.)&lt;/p&gt;

&lt;p&gt;이 때 &lt;code&gt;AA^T&lt;/code&gt; 와 &lt;code&gt;A^TA&lt;/code&gt; 의 고유값 &lt;code&gt;λ&lt;/code&gt; 는 동일하며 0 이상이다. 그렇기 때문에 &lt;em&gt;square root&lt;/em&gt; 를 씌우고, 동일한 행렬 &lt;code&gt;\\Sigma&lt;/code&gt; 로 표현할 수 있다. (자세한 설명은 &lt;a href=&#34;http://darkpgmr.tistory.com/106&#34;&gt;여기&lt;/a&gt; 참조)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;AA^T&lt;/code&gt; 와 &lt;code&gt;A^TA&lt;/code&gt; 의 공통의 고유값에 대해&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Csigma_1%5E2%20%3E%3D%20%5Csigma_2%5E2%20%3E%3D%20%5Ccdots%20%3E%3D%20%5Csigma_s%5E2%20%3E%3D%200%20%5C%20%5C%20%28s%20%3D%20min%28m%2C%20n%29%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이고 여기에 &lt;em&gt;square root&lt;/em&gt; 를 취한 것이 &lt;code&gt;A&lt;/code&gt; 의 &lt;em&gt;singular value, 특이값&lt;/em&gt; 이며, 이 특이값들을 대각원소로 하는 &lt;code&gt;m x n&lt;/code&gt; 행렬이 &lt;code&gt;\\Sigma&lt;/code&gt; 다.&lt;/p&gt;

&lt;p&gt;이 때 &lt;code&gt;A&lt;/code&gt; 의 특이값과 &lt;em&gt;left singular value&lt;/em&gt; &lt;code&gt;u_i&lt;/code&gt;, &lt;em&gt;right singular value&lt;/em&gt; &lt;code&gt;v_i&lt;/code&gt; 에 대해&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?Av_i%20%3D%20%5Csigma_i%20u_i&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;SVD&lt;/em&gt; 의 기하학적 의미는 &lt;a href=&#34;http://darkpgmr.tistory.com/106&#34;&gt;여기&lt;/a&gt;를 인용하면&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;행렬을 x&amp;rsquo; = Ax와 같이 좌표공간에서의 선형변환으로 봤을 때 직교행렬(orthogonal matrix)의 기하학적 의미는 회전변환(rotation transformation) 또는 반전된(reflected) 회전변환, 대각행렬(diagonal maxtrix)의 기하학적 의미는 각 좌표성분으로의 스케일변환(scale transformation)이다.&lt;/p&gt;

&lt;p&gt;행렬 R이 직교행렬(orthogonal matrix)이라면 RRT = E이다. 따라서 det(RRT) = det&amp;reg;det(RT) = det&amp;reg;2 = 1이므로 det&amp;reg;는 항상 +1, 또는 -1이다. 만일 det&amp;reg;=1라면 이 직교행렬은 회전변환을 나타내고 det&amp;reg;=-1라면 뒤집혀진(reflected) 회전변환을 나타낸다.&lt;/p&gt;

&lt;p&gt;따라서 식 (1), A = UΣVT에서 U, V는 직교행렬, Σ는 대각행렬이므로 Ax는 x를 먼저 VT에 의해 회전시킨 후 Σ로 스케일을 변화시키고 다시 U로 회전시키는 것임을 알 수 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://cfile2.uf.tistory.com/image/2725C84C5260AA5F28DFCA&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://darkpgmr.tistory.com/106&#34;&gt;http://darkpgmr.tistory.com/106&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;다시 처음의 슬라이드로 돌아가면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236421_3927.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;svd&lt;/code&gt; 함수의 인자 &lt;code&gt;Sigma&lt;/code&gt; 가 &lt;em&gt;covariant matrix&lt;/em&gt; 고 리턴값 &lt;code&gt;U, S, V&lt;/code&gt; 가 각각 위에서 본 &lt;code&gt;U, \\Sigma, V&lt;/code&gt; 다. &lt;del&gt;변수 이름을 헷갈리게 지으심;&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;마지막 질문이다. &lt;em&gt;PCA&lt;/em&gt; 에서 데이터 매트릭스 &lt;code&gt;X&lt;/code&gt; 에 대해 &lt;em&gt;covariant matrix&lt;/em&gt; &lt;code&gt;XX^T&lt;/code&gt; 로 구한 &lt;em&gt;eigen vector&lt;/em&gt; 의 열벡터가, 왼쪽부터 순서대로 분산을 최대로 하는 벡터(방향)인데, (&lt;a href=&#34;http://darkpgmr.tistory.com/110&#34;&gt;여기&lt;/a&gt;참조)&lt;/p&gt;

&lt;p&gt;왜 우리는 &lt;em&gt;SVD&lt;/em&gt; 의 &lt;code&gt;U&lt;/code&gt; 를 택하는 것일까? 다시 말해 &lt;em&gt;PCA&lt;/em&gt; 와 &lt;em&gt;SVD&lt;/em&gt; 는 무슨 관계일까?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://math.stackexchange.com/questions/3869/what-is-the-intuitive-relationship-between-svd-and-pca&#34;&gt;What is the intuitive relationship between SVD and PCA&lt;/a&gt; 를 참조하면,&lt;/p&gt;

&lt;p&gt;데이터 매트릭스 &lt;code&gt;X&lt;/code&gt; 에 대해서, 공분산 매트릭스 &lt;code&gt;XX^T&lt;/code&gt; 에 대해&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?XX%5ET%20%3D%20WDW%5ET&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이 때 &lt;code&gt;X&lt;/code&gt; 의 &lt;em&gt;SVD&lt;/em&gt; 는&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?X%20%3D%20U%20%5CSigma%20V%5ET&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;U, V&lt;/code&gt; 는 위에서 언급했듯이 &lt;code&gt;XX^T, X^TT&lt;/code&gt; 의 고유값 분해로 얻은 대칭행렬 이므로 &lt;code&gt;VV^T = I, UU^T = I&lt;/code&gt; 이다. 따라서&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?XX%5ET%20%3D%20%28U%20%5CSigma%20V%5ET%29%28U%20%5CSigma%20V%5ET%29%5ET%20%5C%5C%20%5C%5C%20%3D%20%28U%20%5CSigma%20V%5ET%29%28V%20%5CSigma%20U%5ET%29%20%5C%5C%20%5C%5C%20%3D%20U%20%5CSigma%5E2%20U%5ET&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이므로 분산이 큰 순서대로의 벡터를 열벡터로 담고 있는 &lt;code&gt;XX^T = WDW^T&lt;/code&gt; 에서의 &lt;code&gt;W&lt;/code&gt; 가 바로 &lt;em&gt;SVD&lt;/em&gt; 의 결과인 &lt;code&gt;U&lt;/code&gt; 다.&lt;/p&gt;

&lt;p&gt;실제로 &lt;em&gt;PCA&lt;/em&gt; 를 하기 위해 &lt;em&gt;SVD&lt;/em&gt; 를 이용하는건 &lt;em&gt;numerically&lt;/em&gt; 더 낫다고 한다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In fact, using the SVD to perform PCA makes much better sense numerically than forming the covariance matrix to begin with, since the formation of XX⊤ can cause loss of precision. This is detailed in books on numerical linear algebra, but I&amp;rsquo;ll leave you with an example of a matrix that can be stable SVD&amp;rsquo;d, but forming XX⊤ can be disastrous&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;다 정리하고 보니 드는 생각이,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;왜 공분산 행렬을 &lt;em&gt;eigen decomposition&lt;/em&gt; 한 결과 &lt;code&gt;XX^T = WDW^T&lt;/code&gt; 에서 &lt;code&gt;W&lt;/code&gt; 가 공분산 행렬, 즉 데이터간 상관관계, 즉 데이터 그 자체를 설명하는 걸까?&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;http://math.stackexchange.com/questions/23596/why-is-the-eigenvector-of-a-covariance-matrix-equal-to-a-principal-component&#34;&gt;여기&lt;/a&gt; 에서 얻은 답은,&lt;/p&gt;

&lt;p&gt;공분산 매트릭스 자체는 &lt;em&gt;diagonal matrix&lt;/em&gt; 가 아니다. 다시 말해 데이터 &lt;code&gt;X&lt;/code&gt; 의 각 변수간 상관 관계를 담고 있다.&lt;/p&gt;

&lt;p&gt;그런데, 공분산 매트릭스를 대각화 한다면 변수간 상관관계는 사라진다. 다시 말해&lt;/p&gt;

&lt;p&gt;&lt;code&gt;XX^T = WDW^T&lt;/code&gt; 에서 &lt;code&gt;D&lt;/code&gt; 자체에는 본래 데이터 &lt;code&gt;X&lt;/code&gt;의 변수간 상관 관계가 포함되어 있지 않다. 그러면, 그 데이터는 다 &lt;code&gt;W&lt;/code&gt; 와 &lt;code&gt;W^T&lt;/code&gt; 에 들어있다는 소리인데, &lt;code&gt;W^T&lt;/code&gt; 는 &lt;code&gt;W&lt;/code&gt; 로 표현 가능하므로 &lt;code&gt;W&lt;/code&gt; 에 데이터간 상관 관계가 모두 담겨있다는 소리다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Covariance matrix Cy (it is symmetric) encodes the correlations between variables of a vector. In general a covariance matrix is non-diagonal (i.e. have non zero correlations with respect to different variables).&lt;/p&gt;

&lt;p&gt;But it&amp;rsquo;s interesting to ask, is it possible to diagonalize the covariance matrix by changing basis of the vector?. In this case there will be no (i.e. zero) correlations between different variables of the vector.&lt;/p&gt;

&lt;p&gt;Diagonalization of this symmetric matrix is possible with eigen value decomposition.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그러면 마지막 질문, &lt;code&gt;W&lt;/code&gt; 의 좌측열부터가 왜 높은 분산을 가질까?&lt;/p&gt;

&lt;h3 id=&#34;choosing-the-number-of-pca&#34;&gt;Choosing the number of PCA&lt;/h3&gt;

&lt;p&gt;적절한 &lt;code&gt;k&lt;/code&gt; 의 수는 어떻게 구할까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236222_7050.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;cener&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위에서 언급했듯이 &lt;em&gt;PCA&lt;/em&gt; 가 하는 일은 &lt;em&gt;projection error&lt;/em&gt; 를 최소화 하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%7B1/m%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20-%20x_%7Bapprox%7D%5E%7B%28i%29%7D%20%5Cright%20%5C%7C%20%5Cover%201/m%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%5Cleft%20%5C%7C%20x%5E%7B%28i%29%7D%20%5Cright%20%5C%7C%20%7D%20%5Cleq%200.01&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;인 &lt;code&gt;k&lt;/code&gt; 를 구하면 99% 의 &lt;em&gt;variance&lt;/em&gt; 가 유지된다. 적당한 &lt;em&gt;treshold&lt;/em&gt; 값에 해당하는 &lt;code&gt;k&lt;/code&gt; 값을 찾으면 된다.&lt;/p&gt;

&lt;p&gt;알고리즘은 이런데 (좌측),&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236236_2278.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;cener&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;매번 계산하는건 굉장히 비 효율적이다. 따라서 우측처럼 데이터에 대한 &lt;em&gt;singular value&lt;/em&gt; 를 이용하면 더 계산이 쉬워진다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%7B%5Csum_%7Bi%20%3D%201%7D%5Ek%20%5Cover%20%5Csum_%7Bi%20%3D%201%7D%5En%20%7D%20%5Cgeq%200.99&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;reconstruction-from-compressed-representation&#34;&gt;Reconstruction from Compressed Representation&lt;/h3&gt;

&lt;p&gt;잘 보면 &lt;em&gt;PCA&lt;/em&gt; 가 하는 일은 높은 차원의 데이터를 최대한 보존하면서 차수를 줄이는 일이다. 압축 알고리즘과 비슷하다. (실제로 이미지 압축에 쓴다고 한다.)&lt;/p&gt;

&lt;p&gt;그럼 압축된 차원 &lt;code&gt;z&lt;/code&gt; 에서 다시 본래의 데이터 차원 &lt;code&gt;x&lt;/code&gt; 를 복구하려면 어떻게 해야할까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236299_8368.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;cener&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 그림처럼 &lt;code&gt;z = U^T * x&lt;/code&gt; 라 할때 좌변에 &lt;code&gt;U&lt;/code&gt; 를 곱하면 &lt;code&gt;x_app = U * z&lt;/code&gt; 에서 &lt;code&gt;x_app&lt;/code&gt; 는 거의 &lt;code&gt;x&lt;/code&gt; 에 가까워진다.&lt;/p&gt;

&lt;h3 id=&#34;advice-for-apply-pca&#34;&gt;Advice for Apply PCA&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236320_8959.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;cener&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;supervised learning&lt;/em&gt; 의 속도를 올리는데도 쓸 수 있다. 이미지가 &lt;code&gt;100 x 100&lt;/code&gt; 이면 &lt;code&gt;10000&lt;/code&gt; 개의 &lt;em&gt;feature&lt;/em&gt; 인데, 이건 어마어마하다.&lt;/p&gt;

&lt;p&gt;먼저 &lt;em&gt;input&lt;/em&gt; &lt;code&gt;x&lt;/code&gt; 를 뽑아내 여기에 대해 &lt;em&gt;PCA&lt;/em&gt; 를 실행하면 차원을 줄인 &lt;em&gt;training set&lt;/em&gt; 을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;주의할점은 &lt;code&gt;U&lt;/code&gt; 를 찾을때 &lt;em&gt;training set&lt;/em&gt; 에만 하고 &lt;em&gt;cross validation&lt;/em&gt; 이나 &lt;em&gt;test&lt;/em&gt; 까지 포함해서 &lt;code&gt;U&lt;/code&gt; 를 찾으면 안된다. 나중에 &lt;em&gt;training set&lt;/em&gt; 으로만 찾아낸 &lt;code&gt;U&lt;/code&gt; 를 이용해서 &lt;em&gt;CV, test&lt;/em&gt; 에 대해 다시 &lt;em&gt;PCA&lt;/em&gt; 하자.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;다른 &lt;em&gt;PCA&lt;/em&gt; 응용으로는&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Reduce memory, disk needed to store data&lt;/li&gt;
&lt;li&gt;Speed up learning algorithm&lt;/li&gt;
&lt;li&gt;Visualization (&lt;code&gt;k = 2 or 3&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236325_5356.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;cener&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PCA&lt;/em&gt; 를 이용하면 &lt;em&gt;feature&lt;/em&gt; 의 수가 줄기 때문에 &lt;em&gt;overfitting&lt;/em&gt; 을 방지하기 위해 사용할 수 있다고 생각하겠지만, 별로 좋은 생각은 아니다.&lt;/p&gt;

&lt;p&gt;작동은 할지 모르겠지만 &lt;em&gt;regularization&lt;/em&gt; 을 이용하는 편이 낫다.&lt;/p&gt;

&lt;p&gt;왜냐하면 &lt;em&gt;PCA&lt;/em&gt; 는 &lt;code&gt;y&lt;/code&gt; 값이 없는 상태에서 작동하기 때문에 &lt;code&gt;y&lt;/code&gt; 를 고려하지 않은 데이터가 손실이 발생할 수 있다. &lt;code&gt;1%&lt;/code&gt; 만 손실된다 하더라도, 그 &lt;code&gt;1%&lt;/code&gt; 가 &lt;code&gt;y&lt;/code&gt; 와 관련해 굉장히 중요한 정보일 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236329_4045.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;cener&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;또 다른 잘못된 &lt;em&gt;PCA&lt;/em&gt; 의 사용으로는, 그냥 무작정 &lt;em&gt;PCA&lt;/em&gt; 를 사용하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;original data&lt;/em&gt; &lt;code&gt;x&lt;/code&gt; 에 대해 알고리즘을 구현도 안해보고, 바로 &lt;em&gt;PCA&lt;/em&gt; 의 결과인 &lt;code&gt;z&lt;/code&gt; 를 이용하려는건 좋은 생각이 아니다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x&lt;/code&gt; 대해 작업 해보고 결과가 별로일때 &lt;em&gt;PCA&lt;/em&gt; 를 고려하자.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;Machine Learning&lt;/em&gt; by &lt;strong&gt;Andrew NG&lt;/strong&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://scipy-lectures.github.io&#34;&gt;http://scipy-lectures.github.io&lt;/a&gt;&lt;br /&gt;
(5) &lt;a href=&#34;http://en.wikipedia.org/wiki/Correlation_and_dependence&#34;&gt;Wiki: Correlation and dependence&lt;/a&gt;&lt;br /&gt;
(6) &lt;a href=&#34;http://en.wikipedia.org/wiki/Covariance&#34;&gt;http://en.wikipedia.org/wiki/Covariance&lt;/a&gt;&lt;br /&gt;
(7) &lt;a href=&#34;http://darkpgmr.tistory.com/110&#34;&gt;http://darkpgmr.tistory.com/110&lt;/a&gt;&lt;br /&gt;
(8) &lt;a href=&#34;http://darkpgmr.tistory.com/105&#34;&gt;http://darkpgmr.tistory.com/105&lt;/a&gt;&lt;br /&gt;
(9) &lt;a href=&#34;http://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors&#34;&gt;Wiki: Eigenvalues and Eigenvectors&lt;/a&gt;&lt;br /&gt;
(10) &lt;a href=&#34;http://www.ktword.co.kr/abbr_view.php?m_temp1=4695&amp;amp;id=762&#34;&gt;http://www.ktword.co.kr&lt;/a&gt;&lt;br /&gt;
(11) &lt;a href=&#34;http://darkpgmr.tistory.com/106&#34;&gt;http://darkpgmr.tistory.com/106&lt;/a&gt;&lt;br /&gt;
(12) &lt;a href=&#34;http://math.stackexchange.com/questions/3869/what-is-the-intuitive-relationship-between-svd-and-pca&#34;&gt;What is the intuitive relationship between SVD and PCA&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 09: Anomaly Detection, Recommender System</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-9/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:34 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-9/</guid>
      <description>

&lt;p&gt;이번시간엔 &lt;em&gt;anomaly detection&lt;/em&gt; 과 &lt;em&gt;recommender system&lt;/em&gt; 을 배운다.&lt;/p&gt;

&lt;h3 id=&#34;anomaly-dectection&#34;&gt;Anomaly Dectection&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236753_7590.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236757_2205.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;anomaly&lt;/em&gt; 는 정상집단에서 떨어진 데이터라 보면 된다. 공장에서 품질이 떨어지는 제품을 골라낼때 사용할 수 있는데, 위 그림은 비행기 엔진 공장을 예로 들어 설명한다.&lt;/p&gt;

&lt;p&gt;데이터로부터 &lt;code&gt;p(x)&lt;/code&gt; 를 만들어, 검사할 데이터가 &lt;em&gt;threshold&lt;/em&gt; 를 넘는지 안넘는지 검사해 &lt;em&gt;anomaly&lt;/em&gt; 로 판정할 수 있다.&lt;/p&gt;

&lt;p&gt;참고로, &lt;em&gt;anomaly&lt;/em&gt; 가 너무 많으면, &lt;em&gt;false positive&lt;/em&gt; 가 높은 것인데 이 때는  &lt;em&gt;threshold&lt;/em&gt; 를 줄이면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236761_2830.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;anomaly detection&lt;/em&gt; 은 &lt;em&gt;fraud detection&lt;/em&gt; 에 많이 사용된다. 데이터로부터 모델 &lt;code&gt;p(x)&lt;/code&gt; 를 만들고 &lt;em&gt;unusual user&lt;/em&gt; 를 검사하기 위해 &lt;code&gt;p(x) &amp;lt; e&lt;/code&gt; 인지 검사하면 된다.&lt;/p&gt;

&lt;p&gt;이외에도 항공기 엔진 예제처럼 제품의 품질 관리나, 데이터 센터에서의 노드 과부하 탐지등에 사용할 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;gaussian-distribution&#34;&gt;Gaussian Distribution&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236829_8964.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236829_8964.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;gaussian density&lt;/em&gt; 공식은&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?P%28x%3B%20%5Cmu%2C%20%5Csigma%5E2%29%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20%5Cexp%28-%20%7B%28x%20-%20%5Cmu%29%5E2%20%5Cover%202%5Csigma%5E2%7D%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236839_1788.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;평균과 분산은&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Cmu%20%3D%20%7B1%20%5Cover%20m%7D%20%5C%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x%5E%7B%28i%29%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Csigma%5E2%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;anomaly-detection-algorithm&#34;&gt;Anomaly Detection Algorithm&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236899_7015.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;각 &lt;em&gt;feature&lt;/em&gt; 가 가우시안 분포를 따른다고 하면,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?p%28x%29%20%5C%5C%20%5C%5C%20%3D%20p%28x_1%3B%20%5Cmu_1%2C%20%5Csigma_1%5E2%29%5C%20p%28x_2%3B%20%5Cmu_2%2C%20%5Csigma_1%5E2%29%20%5Ccdots%5C%20p%28x_n%3B%20%5Cmu_n%2C%20%5Csigma_1%5En%29%20%5C%5C%20%5C%5C%20%3D%20%5Cprod_%7Bj%20%3D%201%7D%5En%20p%28x_j%3B%20%5Cmu_j%2C%20%5Csigma_j%5E2%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 가정하려면, 각 &lt;em&gt;feature&lt;/em&gt; 가 독립적이어야 하지만 실제로는 독립적이지 않더라도 어느정도 동작한다. 이 때&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Cmu_j%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x_j%5E%7B%28i%29%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Csigma_j%5E2%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%7B%28x_j%5E%7B%28i%29%7D%20-%20%5Cmu_j%29%5E2%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236904_6921.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;따라서 &lt;code&gt;p(x)&lt;/code&gt; 는 아래 식이 된다. &lt;code&gt;p(x)&lt;/code&gt; 는 &lt;em&gt;feature&lt;/em&gt; 가 나올 확률로 이해하면 된다. 이 때 &lt;code&gt;p(x)&lt;/code&gt; 가 상당히 작으면, 평균에 가깝지 않은 &lt;em&gt;feature&lt;/em&gt; 가 많이 나왔다는 뜻이므로 &lt;em&gt;anomaly&lt;/em&gt; 라 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?p%28x%29%20%5C%5C%20%5C%5C%20%3D%20%5Cprod_%7Bj%3D1%7D%5En%20%5C%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma_j%5E2%7D%7D%20%5C%20%5Cexp%28-%7B%28x_j%20-%20%5Cmu_j%29%5E2%20%5Cover%202%5Csigma_j%5E2%7D%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236907_7102.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;두 &lt;em&gt;feature&lt;/em&gt; &lt;code&gt;x1, x2&lt;/code&gt; 의 가우시안 분포를 3차원으로 조합하면 &lt;code&gt;p(x)&lt;/code&gt; 가 좌측 하단 3차원 원뿔의 높이가 된다.&lt;/p&gt;

&lt;h3 id=&#34;evaluating-anomaly-detection&#34;&gt;Evaluating Anomaly Detection&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236992_3664.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361236996_4034.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;anomaly&lt;/em&gt; 를 잘 나타낼거 같은 &lt;em&gt;feature&lt;/em&gt; 를 골라내고, 이를 이용해 모델을 만든다.&lt;/p&gt;

&lt;p&gt;우리가 가진 데이터가 &lt;em&gt;anomaly&lt;/em&gt; 를 알려주는 &lt;code&gt;y&lt;/code&gt; 가 있다면, 위 그림처럼 &lt;em&gt;training set&lt;/em&gt; 으로 &lt;em&gt;non-anomalous&lt;/em&gt; 을 이용하고, &lt;em&gt;CV, Test Set&lt;/em&gt; 으로 나머지를 반반씩 분할하면 된다.&lt;/p&gt;

&lt;p&gt;즉 &lt;em&gt;good example&lt;/em&gt; 로 모델을 만들고, &lt;em&gt;anomaly&lt;/em&gt; 가 섞여있는 &lt;em&gt;cv, test set&lt;/em&gt; 으로 평가한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361237001_5250.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 때 &lt;em&gt;skewed classess&lt;/em&gt; 이기 때문에 (&lt;code&gt;y = 0&lt;/code&gt; 이 대다수, &lt;code&gt;y = 1&lt;/code&gt; 은 희박) 단순히 정확도로 평가하긴 좀 무리가 있다. &lt;em&gt;precision, recall, f1 score&lt;/em&gt; 등을 이용해 평가해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;threshold&lt;/em&gt; 인 &lt;code&gt;e&lt;/code&gt; (엡실론) 를 고르기 위해 &lt;em&gt;cross validation&lt;/em&gt; 을 이용할 수 있다. &lt;em&gt;f1 score&lt;/em&gt; 를 최대화 하는 &lt;code&gt;e&lt;/code&gt; 를 고른다거나.&lt;/p&gt;

&lt;h3 id=&#34;anomaly-dectection-vs-supervised-learning&#34;&gt;Anomaly Dectection vs Supervised Learning&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;y&lt;/code&gt; 값이 있는 데이터라면, 왜 &lt;em&gt;supervised learning&lt;/em&gt; 을 이용하지 않을까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361242897_8389.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h4 id=&#34;anomaly-detection&#34;&gt;Anomaly Detection&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;anomaly detection&lt;/em&gt; &lt;em&gt;skewed class&lt;/em&gt; 가 있을 때 사용한다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Many different &lt;strong&gt;types&lt;/strong&gt; of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like&lt;/p&gt;

&lt;p&gt;Future anomalies may look nothing like any of the anomalous examples we&amp;rsquo;ve seen so far&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;보면 알겠지만 &lt;em&gt;anomaly&lt;/em&gt; 가 굉장히 다양할 수 있기 때문에 &lt;em&gt;anomaly&lt;/em&gt; 를 특정 형태로 구분짓는 알고리즘을 쓰긴 좀 힘들다.&lt;/p&gt;

&lt;p&gt;게다가, 가지고 있는 데이터 셋에서 보지 못했던 새로운 종류의 &lt;em&gt;anomaly&lt;/em&gt; 가 나올 수도 있다.&lt;/p&gt;

&lt;h4 id=&#34;supervised-learning&#34;&gt;Supervised Learning&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;positive, negative example&lt;/em&gt; 이 많을 때 사용한다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Enough positive examples for algorithms to get a sense of what positive examples are like, futre positive example likly to be similar to ones in training set&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;supervised learning&lt;/em&gt; 에서 &lt;em&gt;positive example&lt;/em&gt; 은 어떤 특정 형태기 때문에, 미래에 발견할 &lt;em&gt;positive example&lt;/em&gt; 도 비슷한 형태라 생각될 때 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;SPAM filtering&lt;/em&gt; 에서는 다양한 타입의 &lt;em&gt;positive example&lt;/em&gt; 이 있어도, 우리가 충분한 양의 &lt;em&gt;positive example&lt;/em&gt; 이 있기 때문에 커버할 수 있어 &lt;em&gt;supervised learning&lt;/em&gt; 을 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361243087_2169.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;choosing-what-features-to-use&#34;&gt;Choosing What Features to Use&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361244210_3429.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;feature&lt;/em&gt; 의 분포가 가우시안이면 고맙지만, 아닐경우 변환이 필요하다. 왼쪽 아래 분포에 로그를 씌우면, 가우시안 분포 비슷하게 보인다.&lt;/p&gt;

&lt;p&gt;다른 방법으로는 &lt;code&gt;log(x_2 + c)&lt;/code&gt;, &lt;code&gt;sqrt(x_3)&lt;/code&gt; 등등이 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361245473_5316.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;흔한 에러는 &lt;code&gt;p(x)&lt;/code&gt; 가 &lt;em&gt;normal, anomalous&lt;/em&gt; 에 대해서 모두 높은 경우인데, 슬라이드의 아래쪽에서 볼 수 있듯이 &lt;code&gt;x2&lt;/code&gt; 라는 &lt;em&gt;feature&lt;/em&gt; 를 만들어서 &lt;em&gt;anomaly&lt;/em&gt; 를 발견하는 알고리즘을 만들 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361246077_9679.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;anomaly&lt;/em&gt; 를 위한 &lt;em&gt;feature&lt;/em&gt; 를 고를 때 특이하게 높거나, 낮을 수 있는 것을 고르면 된다. 데이터 센터 예제에서는 &lt;em&gt;CPU load / network traffic&lt;/em&gt; 등이 있을 수 있다. 네트워크 트래픽이 낮은데 &lt;em&gt;CPU load&lt;/em&gt; 가 높다면 확실히 &lt;em&gt;anomaly&lt;/em&gt; 기 때문이다.&lt;/p&gt;

&lt;h3 id=&#34;multivariate-gaussian-distribution&#34;&gt;Multivariate Gaussian Distribution&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361257865_7961.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;feature&lt;/em&gt; 를 &lt;em&gt;CPU laod, memory use&lt;/em&gt; 로 했을 때 낮은 CPU 부하에도 메모리 사용량이 높으면 &lt;em&gt;anomaly&lt;/em&gt; 라 볼 수 있다.&lt;/p&gt;

&lt;p&gt;그런데, 슬라이드의 왼쪽 그림에서 녹색으로 표시한 &lt;em&gt;anomaly&lt;/em&gt; 는 지금까지 설명했던 알고리즘으로 찾기가 힘들다. 적당한 수준의 &lt;em&gt;memory use&lt;/em&gt; 와 그리 낮지 않은 &lt;em&gt;cpu load&lt;/em&gt; 를 가지기 때문이다.&lt;/p&gt;

&lt;p&gt;실제 &lt;em&gt;normal example&lt;/em&gt; 이 타원형이기 때문에, 원으로 &lt;em&gt;anomaly&lt;/em&gt; 를 찾기는 어렵다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361258533_5107.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;따라서 &lt;code&gt;p(x_1)p(x_2)...&lt;/code&gt; 을 이용한 모델 말고 다른 방법으로 모델을 만들어야 한다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;u&lt;/code&gt; 를 &lt;code&gt;n&lt;/code&gt; 벡터라 하고, &lt;code&gt;Sigma&lt;/code&gt; 를 &lt;code&gt;u&lt;/code&gt; 의 &lt;em&gt;convariance matrix&lt;/em&gt; 라 하자. 그러면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?p%28x%3B%20%5Cmu%2C%20%5CSigma%29%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%20%282%5Cpi%29%5E%7Bn/2%7D%20%5C%20%7C%5CSigma%7C%5E%7B1/2%7D%7D%20%5C%20%5Cexp%28-%7B1%5Cover%202%7D%28x%20-%20%5Cmu%29%5ET%20%5C%20%5CSigma%5E%7B-1%7D%28x%20-%20%5Cmu%29%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;|Sigma|&lt;/code&gt; 는 &lt;code&gt;Sigma&lt;/code&gt; 의 행렬식인데, 여기를 참고하자.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ghebook.blogspot.com/2011/06/matrix.html&#34;&gt;행렬&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ghebook.blogspot.com/2011/06/determinant.html&#34;&gt;행렬식&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ghebook.blogspot.kr/2011/06/geometric-meaning-of-determinant.html&#34;&gt;행렬식의 기하학적 의미&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://darkpgmr.tistory.com/104&#34;&gt;행렬식과 기하학적 활용&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 위 식을 이용해서 나온 &lt;code&gt;p(x)&lt;/code&gt; 를 3차원, 2차원으로 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361259228_7695.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361259243_2967.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361259236_1052.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361259583_5151.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Cmu%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x%5E%7B%28i%29%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5CSigma%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%20%5C%20%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29%5ET&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361259728_6035.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;u, Sigma&lt;/code&gt; 를 찾아 &lt;code&gt;p(x)&lt;/code&gt; 를 만들고, 테스트 데이터에 대해 &lt;code&gt;p(x) &amp;lt; e&lt;/code&gt; 인지 비교한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361260300_1768.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;original model&lt;/em&gt; 은 &lt;em&gt;multivariate model&lt;/em&gt; 에서 각 &lt;em&gt;feature&lt;/em&gt; 간 상관 관계가 없는 (독립), 즉 &lt;em&gt;covariance matrix&lt;/em&gt; 가 &lt;em&gt;diagonal matrix&lt;/em&gt; 인 경우다. (&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/19/1361260755_3407.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Original model&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;수동으로 &lt;em&gt;feature&lt;/em&gt; 를 만들때 사용할 수 있다. 또는 적은 연산을 원할때, 다시 말해서 &lt;code&gt;n&lt;/code&gt; 이 커서 연산이 무지막지하게 클 때 좋다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;m&lt;/code&gt; 이 작아도 쓸 수 있다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multivariate Gaussian&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;계산 비용이 비싸지만, 자동으로 &lt;em&gt;feature&lt;/em&gt; 간 상관관계를 모델에 포함시킨다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Sigma&lt;/code&gt; 가 &lt;em&gt;invertible&lt;/em&gt; 이기 위해서는 &lt;code&gt;m &amp;gt; n&lt;/code&gt; 이어야 한다. 실제로는 &lt;code&gt;m&lt;/code&gt; 이 &lt;code&gt;n&lt;/code&gt; 보다 훨씬 클 때 사용하는 경우가 많다. (e.g. &lt;code&gt;m &amp;gt;= 10n&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;만약에 &lt;code&gt;m &amp;gt; n&lt;/code&gt; 인데, &lt;code&gt;Sigma&lt;/code&gt; 가 &lt;em&gt;non-invertible&lt;/em&gt; 이면 &lt;em&gt;redundant feature&lt;/em&gt; 가 있는 경우니 확인해 보자. (흔한 오류라고 함)&lt;/p&gt;

&lt;h3 id=&#34;recommender-system&#34;&gt;Recommender System&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/20/1361324993_7588.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;content-based-recommendations&#34;&gt;Content Based Recommendations&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/20/1361325560_4034.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 슬라이드는 유저 &lt;code&gt;j&lt;/code&gt; 로 부터 &lt;code&gt;theta^(j)&lt;/code&gt; 를 얻어, &lt;em&gt;feature&lt;/em&gt; &lt;code&gt;x&lt;/code&gt; 와 곱함으로써 &lt;em&gt;linear regression&lt;/em&gt; 문제로 변경했다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/20/1361326084_2070.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;theta^(j)&lt;/code&gt; 는 어떻게 훈련시킬까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%7D%20%5C%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%7B1%20%5Cover%202m%5E%7B%28j%29%7D%7D%5C%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;amp;plus;%20%7B%5Clambda%20%5Cover%202m%5E%7B%28j%29%7D%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 &lt;code&gt;m^(j)&lt;/code&gt; 는 유저 &lt;code&gt;j&lt;/code&gt; 에 의해 점수를 받은 영화의 수인데, 어차피 상수이므로 제거하면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%7D%20%5C%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%7B1%20%5Cover%202%7D%5C%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/20/1361326247_4648.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 때 각 유저마다의 &lt;code&gt;theta(j)&lt;/code&gt; 를 합 해 최소화 시키는 방식으로 전체 &lt;code&gt;theta&lt;/code&gt; 를 훈련시킬 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%2C%20%5Ccdots%20%5Ctheta%5E%7B%28n_u%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/20/1361326573_9477.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;gradient descent&lt;/em&gt; 는&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28j%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28j%29%7D%20-%20%5Calpha%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%20%28%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%29x_k%5E%7B%28i%29%7D%20%5C%20%28for%5C%20k%20%3D%200%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28j%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28j%29%7D%20-%20%5Calpha%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%20%28%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%29x_k%5E%7B%28i%29%7D%20&amp;amp;plus;%20%5Clambda%5Ctheta_k%5E%7B%28j%29%7D%5C%20%28for%5C%20k%20%5Cneq%200%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;collaborative-filtering&#34;&gt;Collaborative Filtering&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/20/1361327928_4438.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;content-based recommendation&lt;/em&gt; 에서 &lt;em&gt;feature&lt;/em&gt; 를 구하긴 사실 어려운 일이다. 누가 이 영화가 얼마만큼 로맨스고, 아닌지를 판별해줄까?&lt;/p&gt;

&lt;p&gt;문제를 좀 변경해서, 만약에 유저로부터 &lt;code&gt;theta(j)&lt;/code&gt; 를 얻어낼 수 있다면 그 정보로 부터 &lt;em&gt;feature&lt;/em&gt; &lt;code&gt;x(i)&lt;/code&gt; 를 추출할 수 있다. 왜냐하면 &lt;code&gt;(\theta^(j))^T * x^(i) ~ y^(i, j)&lt;/code&gt; 이기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/20/1361328443_4320.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;x^(i)&lt;/code&gt; 를 얻기 위해,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min_%7Bx%5E%7B%28j%29%7D%2C%20%5Ccdots%20x%5E%7B%28n_m%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%20%5Csum_%7Bi%3A%20%5C%20r%28i%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%5Csum_%7Bk%3D1%7D%5En%28x_k%5E%7B%28i%29%7D%29%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/20/1361330430_7394.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;theta&lt;/code&gt; 가 주어지면 &lt;code&gt;x&lt;/code&gt; 를 훈련할 수 있고&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x&lt;/code&gt; 가 주어지면 &lt;code&gt;theta&lt;/code&gt; 를 훈련할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서 최초의 랜덤 &lt;code&gt;theta&lt;/code&gt; 에 대해 &lt;code&gt;x&lt;/code&gt; 를 훈련하고, 다시 &lt;code&gt;theta&lt;/code&gt; 를 훈련하고, 반복하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361495687_3476.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;theta&lt;/code&gt; 와 &lt;code&gt;x&lt;/code&gt; 를 반복해서 훈련시키는 것보다, 동시에 훈련시키는 것이 좀 더 효율적이다. 따라서&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?J%28%7Bx%5E%7B%28j%29%7D%2C%20%5Ccdots%20x%5E%7B%28n_m%29%7D%2C%20%5Ctheta%5E%7B%28i%29%7D%2C%20%5Ccdots%20%5Ctheta%5E%7B%28n_u%29%7D%7D%29%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7B%28i%2C%20j%29%3A%20%5C%20r%28i%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%5Csum_%7Bk%3D1%7D%5En%28x_k%5E%7B%28i%29%7D%29%5E2%20&amp;amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;를 최소화 시키면 된다. 참고로 &lt;code&gt;x_0&lt;/code&gt; 은 &lt;em&gt;collaborative filtering&lt;/em&gt; 에서 필요가 없다. 알고리즘 자체가 &lt;em&gt;feature&lt;/em&gt; 를 직접 찾아내니 &lt;em&gt;hard coded&lt;/em&gt; 된 &lt;em&gt;feature&lt;/em&gt; 는 사용하지 않는다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361495692_7530.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;(1) &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;theta&lt;/code&gt; 를 작은 값으로 초기화 한다.&lt;/p&gt;

&lt;p&gt;이는 &lt;em&gt;symmetry breaking&lt;/em&gt; 을 하기 위함이다. 작은 랜덤값들로 초기화 하여 &lt;code&gt;x^(i)&lt;/code&gt; 가 서로 다른 값들을 가지도록 도와준다.&lt;/p&gt;

&lt;p&gt;(2) &lt;em&gt;cost function&lt;/em&gt; &lt;code&gt;J&lt;/code&gt; 를 &lt;em&gt;gradient descent&lt;/em&gt; 등으로 최소화 시킨다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?x_k%5E%7B%28i%29%7D%20%3A%3D%20x_k%5E%7B%28i%29%7D%20-%20%5Calpha%20%5Csum_%7Bj%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5Ctheta_k%5E%7B%28j%29%7D%20&amp;amp;plus;%20%5Clambda%20x_k%5E%7B%28i%29%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28i%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28i%29%7D%20-%20%5Calpha%20%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5Cx_k%5E%7B%28i%29%7D%20&amp;amp;plus;%20%5Clambda%20%5Ctheta_k%5E%7B%28j%29%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;(3) 유저의 &lt;em&gt;parameter&lt;/em&gt; &lt;code&gt;theta&lt;/code&gt; 와 영화의 &lt;em&gt;feature&lt;/em&gt; &lt;code&gt;x&lt;/code&gt; 에 대해 &lt;code&gt;theta^T * x&lt;/code&gt; 를 이용해 예측하면 된다.&lt;/p&gt;

&lt;h3 id=&#34;vectorization-low-rank-matrix-factorization&#34;&gt;Vectorization: Low Rank Matrix Factorization&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361496844_8727.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361496849_5252.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;collaborative filtering&lt;/em&gt; 은 &lt;em&gt;low rank matrix factoriazation&lt;/em&gt; 이라 부르기도 한다. 위 슬라이드처럼 &lt;code&gt;X, THETA&lt;/code&gt; 를 구성하고 &lt;code&gt;X * THETA^T&lt;/code&gt; 를 구하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361496854_2443.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;low rank matrix factorization&lt;/em&gt; 을 이용해서 &lt;em&gt;feature&lt;/em&gt; 를 찾으면, 두 영화 &lt;code&gt;i, j&lt;/code&gt; 가 얼마나 유사한지 &lt;code&gt;||x^(i) - x^(j)||&lt;/code&gt; 으로 판단할 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;implementation-detail-mean-normalization&#34;&gt;Implementation Detail: Mean Normalization&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361497832_3797.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;만약 위 슬라이드의 &lt;code&gt;Eve&lt;/code&gt; 처럼 아무 영화도 평가 안한 사람에게는, &lt;code&gt;theta&lt;/code&gt; 가 &lt;code&gt;0&lt;/code&gt; 으로 나온다. (첫번째 &lt;em&gt;term&lt;/em&gt; 이 &lt;code&gt;0&lt;/code&gt; 이고, &lt;em&gt;regularization term&lt;/em&gt; 은 &lt;code&gt;theta&lt;/code&gt; 를 최소화한다.)&lt;/p&gt;

&lt;p&gt;그렇게 되면, 어떤 영화도 높은 &lt;em&gt;rating&lt;/em&gt; 을 받을 수 없으므로 (&lt;code&gt;theta^T * x&lt;/code&gt;). 추천할 거리가 없다. 이건 별로 좋은 상황이 아닌데, &lt;em&gt;mean normalization&lt;/em&gt; 을 이용하면 이 문제를 해결할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361497813_3878.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt1&#34;&gt;http://blog.csdn.net/linuxcumt1&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;mean normalized&lt;/em&gt; 데이터를 이용하면, 추천 안한 사람이 &lt;code&gt;theta = 0&lt;/code&gt; 을 갖더라도, 남들이 추천한 선호도 &lt;code&gt;u&lt;/code&gt; 에 따라서 영화를 추천받을 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20&amp;amp;plus;%20%5Cmu_i&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;잘보면 &lt;em&gt;feature scaling&lt;/em&gt; 과는 다르게 특정 &lt;em&gt;range&lt;/em&gt; 로 나누질 않는데, 이건 이미 &lt;em&gt;rating&lt;/em&gt; 자체가 일정 범위 &lt;code&gt;1-5&lt;/code&gt; 를 갖기 때문이다.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;Machine Learning&lt;/em&gt; by &lt;strong&gt;Andrew NG&lt;/strong&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://ghebook.blogspot.com/2011/06/matrix.html&#34;&gt;http://ghebook.blogspot.com&lt;/a&gt;&lt;br /&gt;
(5) &lt;a href=&#34;http://darkpgmr.tistory.com/104&#34;&gt;http://darkpgmr.tistory.com&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ML 10: Stochastic Gradient, Synthetic Data, Ceiling Analysis</title>
      <link>https://1ambda.github.io/92/data-analysis/machine-learning-week-10/</link>
      <pubDate>Sat, 25 Jun 2016 14:25:35 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/machine-learning-week-10/</guid>
      <description>

&lt;p&gt;이번 주에는 &lt;em&gt;mini-batch, stochastic graident descent&lt;/em&gt;, &lt;em&gt;online learning&lt;/em&gt;, &lt;em&gt;map-reduce&lt;/em&gt; 등의 개념에 대해 배운다.&lt;/p&gt;

&lt;h3 id=&#34;learning-with-large-datasets&#34;&gt;Learning With Large Datasets&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361499744_2717.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;왜 그렇게 큰 데이터 셋이 필요할까? 좋은 퍼포먼스를 얻기 위한 한 가지 방법이, &lt;em&gt;low bias&lt;/em&gt; 알고리즘에 &lt;em&gt;massive data&lt;/em&gt; 를 활용해 훈련하는 것이기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361499747_9327.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;그러나 커다란 데이터 셋을 연산하기 위해서는 연산비용이 정말 비싸다. 예를 들어
&lt;code&gt;m = 100,000,000&lt;/code&gt; 이라 하면 &lt;em&gt;gradient&lt;/em&gt; 를 계산하기 위해 매번 &lt;code&gt;k * m&lt;/code&gt; 의 연산이 필요하다.&lt;/p&gt;

&lt;p&gt;따라서 모든 데이터를 이용해 알고리즘을 훈련하기 보다는, 랜덤하게 고른 작은 서브셋에 대해서 알고리즘을 개발하고, 이후에 전체 데이터에 대해서 훈련하는 방법을 쓰기도 한다.&lt;/p&gt;

&lt;p&gt;그러면 &lt;code&gt;m&lt;/code&gt; 이 작아도 알고리즘이 충분히 잘 훈련된다는 것을 어떻게 보장할까? 이는 &lt;em&gt;learning curve&lt;/em&gt; 를 그려보면 된다.&lt;/p&gt;

&lt;p&gt;위 슬라이드에서 우측 하단은 &lt;em&gt;high bias&lt;/em&gt; 알고리즘인데 &lt;code&gt;m&lt;/code&gt; 을 많이 투입해도 별다른 이득이 없으므로 적당한 수준에서 &lt;code&gt;m&lt;/code&gt; 을 정하면 된다.&lt;/p&gt;

&lt;p&gt;물론 만든 알고리즘이 우측처럼 &lt;em&gt;high bias&lt;/em&gt; 로 나오면, 좀 더 자연스러운 생각은 &lt;em&gt;hidden layer&lt;/em&gt; 를 추가한다거나, 새로운 &lt;em&gt;feature&lt;/em&gt; 를 도입해서 &lt;em&gt;bias&lt;/em&gt; 를 낮추는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;stochstic-gradient-descent&#34;&gt;Stochstic Gradient Descent&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361500908_4667.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;gradient descent&lt;/em&gt; 를 이용하는 &lt;em&gt;linear regression&lt;/em&gt; 에서&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?h_%5Ctheta%28x%29%20%3D%20%5Csum_%7Bj%3D0%7D%5En%20%5C%20%5Ctheta_jx_j&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?J_%7Btrain%7D%28%5Ctheta%29%20%3D%20%7B1%20%5Cover%202m%7D%20%5Csum_%7Bi%3D1%7D%5Em%5C%20%28h_%5Ctheta%28x%29%5E%7B%28i%29%7D%20-%20y%5E%7B%28i%29%7D%29%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이미 언급했듯이 &lt;em&gt;batch gradient descent&lt;/em&gt; 의 문제는, &lt;code&gt;m&lt;/code&gt; 이 크면 &lt;code&gt;J&lt;/code&gt; 의 연산이 어마어마하게 많아진다는 것이다. 매 스텝마다 &lt;code&gt;m&lt;/code&gt; 을 읽고, 계산값을 저장하기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361501694_2445.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;이 문제를 해결하기 위해 &lt;em&gt;stochastic gradient descent&lt;/em&gt; 에서는 한 턴에 한 쌍의 &lt;code&gt;x, y&lt;/code&gt; 에 대해서만 &lt;em&gt;gradient&lt;/em&gt; 를 계산한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;batch gradient decsent&lt;/em&gt; 에서는 한 턴마다 모든 모든 쌍의 &lt;code&gt;x, y&lt;/code&gt; 에 대해  &lt;em&gt;gradient&lt;/em&gt; (= &lt;code&gt;theta_j&lt;/code&gt;) 를 계산 했었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?cost%28%5Ctheta%2C%20%28x%5E%7B%28i%29%7D%2C%20y%5E%7B%28i%29%7D%29%29%20%3D%20%7B1%20%5Cover%202%7D%5C%20%28h_%5Ctheta%28x%5E%7B%28i%29%7D%20-%20y%5E%7B%28i%29%7D%29%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?J_%7Btrain%7D%28%5Ctheta%29%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%20cost%28%5Ctheta%2C%20%28x%5E%7B%28i%29%7D%2C%20y%5E%7B%28i%29%7D%29%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;라고 하면&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- Randomly shuffle dataset  
- Repeat for i = 1 to m
  - 0_j := 0_j - a * derivative of cost(0, (xi, yi)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;즉 &lt;code&gt;J_train&lt;/code&gt; 의 미분 대신에 &lt;code&gt;cost&lt;/code&gt; 의 미분값을 이용해서 연산을 줄이는 방법이다. 이 때 데이터가 이미 랜덤하게 섞였다는 점을 기억하자. 기하학적으로 보면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361502040_9252.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;batch&lt;/em&gt; 에서는 올바른 방향을 향해 가지만, 보폭이 좀 좁다. &lt;em&gt;stochastic&lt;/em&gt; 은 이리 갔다, 저리 갔다 하지만 결국에는 최저점을 향해 간다. 다만 &lt;em&gt;global optima&lt;/em&gt; 에 도달하지 못하고 그 근처에 도착할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;m&lt;/code&gt; 이 굉장히 크면, &lt;em&gt;repeat&lt;/em&gt; 부분의 루프를 1번만 돌려도 될 테지만, 작으면 여러번 돌려서 최대한 좋은 퍼포먼스를 내도록 훈련시킬 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;min-batch-gradient-descent&#34;&gt;Min-Batch Gradient Descent&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361503946_9357.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Batch gradient descent:&lt;/strong&gt; Use all &lt;code&gt;m&lt;/code&gt; examples in each iteration&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stochastic gradient descent:&lt;/strong&gt; Use &lt;code&gt;1&lt;/code&gt; example in each iteration&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Batch gradient descent:&lt;/strong&gt; Use &lt;code&gt;b&lt;/code&gt; examples in each iteration&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Ctheta_j%20%3A%3D%20%5Ctheta-j%20-%20%7B%5Calpha%20%5Cover%20b%7D%20%5Csum_%7Bk%20%3D%20i%7D%5E%7Bi%20&amp;amp;plus;%20b%20-%201%7D%20%28h_%5Ctheta%28x%5E%7B%28k%29%7D%29%20-%20y%5E%7B%28k%29%7D%29%20x_j%5E%7B%28k%29%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361504164_4561.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;b&lt;/code&gt; 는 보통 &lt;code&gt;2 - 100&lt;/code&gt; 사이의 값이기 때문에 &lt;em&gt;batch&lt;/em&gt; 보다 훨씬 빠르다. 또한 &lt;em&gt;vectorization&lt;/em&gt; 을 이용하면 &lt;em&gt;gradient computation&lt;/em&gt; 을 &lt;em&gt;partially parallelize&lt;/em&gt; 할 수 있기 때문에 &lt;em&gt;stochastic&lt;/em&gt; 보다 더 빠를 수 있다. &lt;del&gt;병렬화의 미덕&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;단점으로는 추가적인 파라미터 &lt;code&gt;b&lt;/code&gt; 가 필요하다는 점이다. 그러나 &lt;em&gt;vectorization&lt;/em&gt; 을 잘 이용하면 더 빨라지므로 문제 없다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;stochastic-gradient-descent-convergence&#34;&gt;Stochastic Gradient Descent Convergence&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361519060_5993.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;convergence&lt;/em&gt; 를 검증하는 방법으로, 훈련시키는 동안 얻은 &lt;code&gt;cost(0, (xi yi)&lt;/code&gt; 평균값을 이용해 플롯을 그릴 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361519096_5186.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;stochastic&lt;/em&gt; 은 &lt;em&gt;global optimum&lt;/em&gt; 을 찾아내지 못할 수도 있기 때문에, 그 주변에서 알짱거릴 수도 있다.&lt;/p&gt;

&lt;p&gt;더 많은 &lt;code&gt;m&lt;/code&gt; 을 투입하면, 까끌거리는 선보다 좀 매끄러운 곡선을 얻을 수도 있다.&lt;/p&gt;

&lt;p&gt;때때로 알고리즘이 전혀 학습하지 못하는 것 처럼 보일수도 있는데, 그럴 경우 &lt;code&gt;m&lt;/code&gt; 을 더 투입하면 좀 경사가 낮은 커브로 조금씩 &lt;em&gt;decreasing&lt;/em&gt; 할 수 있다. 이를 보면 결국 훈련되긴 하는데, 평균값을 플랏으로 그리니 들쭉날쭉 해 보이는 것이다. (물론 학습하지 못하는 경우도 있다. &lt;code&gt;m&lt;/code&gt; 을 더 늘려서 확인해 보자.)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;cost&lt;/code&gt; 값이 증가한다면 더 작은 &lt;em&gt;learning late&lt;/em&gt; 값을 이용하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361519184_7199.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;learning rate&lt;/em&gt; 와 관련해서 위 슬라이드처럼 식을 만들면, 이터레이션 넘버가 천천히 증가하면서 &lt;code&gt;alpha&lt;/code&gt; 가 감소해 &lt;em&gt;converge&lt;/em&gt; 하는 결과를 얻을 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If we reduce learning rate &lt;code&gt;alpha&lt;/code&gt; (and run stochastic gradient descent long enough), it&amp;rsquo;s possible that we may find a set of better parameters than with large &lt;code&gt;alpha&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;online-learning&#34;&gt;Online Learning&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361520551_7175.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;online learning&lt;/em&gt; 에서는 데이터를 얻어 &lt;code&gt;theta&lt;/code&gt; 를 업데이트하는데 사용하고, 버린다. 큰 사이트라면 데이터가 지속적으로 들어오기 때문에, &lt;em&gt;trianing data&lt;/em&gt; 를 볼 필요가 없다. 다시 말해 같은 데이터를 두번 이상 쓰지 않는다는 말이다.&lt;/p&gt;

&lt;p&gt;또 다른 장점으로는 사용자의 취향 변화를 빠르게 반영할 수 있다는 점이다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Can adopt to changing user preference&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361520594_9988.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;product search&lt;/em&gt; 에 &lt;em&gt;predicted CTR&lt;/em&gt; 를 이용해, 검색어와 잘 매칭되는 상품을 결과로 돌려수 있다. 이때 매 검색마다 돌려주는 검색결과는 일종의 &lt;em&gt;training set&lt;/em&gt; 이 된다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;special offers&lt;/li&gt;
&lt;li&gt;customized selection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;등에도 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;map-reduce-and-data-parallelism&#34;&gt;Map Reduce and Data Parallelism&lt;/h3&gt;

&lt;p&gt;데이터가 어마어마하게 많으면, 하나의 컴퓨터에서 머신러닝 알고리즘을 돌리기가 좀 힘들다. 어떻게 해결할까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361522176_1942.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361522180_7521.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;쉽게 말하면, 분산해서 처리할 수 있는 결과는 &lt;code&gt;map&lt;/code&gt; 으로 해결하고, 이 결과들을 이용해 전체적인 결과는 &lt;code&gt;reduce&lt;/code&gt; 가 계산한다. (실제로는 &lt;code&gt;reduce&lt;/code&gt; 도 여러개 일 수 있다)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361522184_5033.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Many lenaring algorithms can be expressed as computing sums of functions over the training set&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이렇기 때문에 &lt;em&gt;map-reduce&lt;/em&gt; 가 큰 데이터셋에 대한 계산 처리 방법으로 좋은 해결책이 될 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/22/1361522188_9650.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;요즘엔 대부분의 프로세서가 멀티코어이기 때문에, 하나의 컴퓨터에서도 병렬화를 이용해 계산을 빠르게 해 낼 수 있다. 이 경우는 &lt;em&gt;network latency&lt;/em&gt; 등에 대해 생각을 안해도 된다. 참고로 좋은 라이브러리들은 자동으로 연산을 병렬화한다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;photo-ocr-and-pipeline&#34;&gt;Photo OCR and Pipeline&lt;/h3&gt;

&lt;p&gt;머신러닝 예제로 &lt;em&gt;Photo OCR&lt;/em&gt; 을 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361935712_3407.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Photo OCR pipeline&lt;/em&gt; 은&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Image&lt;/li&gt;
&lt;li&gt;Text detection&lt;/li&gt;
&lt;li&gt;Character segmentation&lt;/li&gt;
&lt;li&gt;Character recognition&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;의 단계를 거친다. 각 단계마다 머신러닝을 적용할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;sliding-windows&#34;&gt;Sliding Windows&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361936303_5994.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361936307_1350.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361937647_2708.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;텍스트나, 보행자등 특정 패턴을 검색하기 위해 이동하는 &lt;em&gt;rectangle&lt;/em&gt; 의 단위를 &lt;em&gt;step-size, slide&lt;/em&gt; 라 부른다. &lt;em&gt;slide&lt;/em&gt; 의 사이즈를 변경해 가면서 패턴을 파악하는 방법을 &lt;em&gt;sliding window&lt;/em&gt; 라 부른다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361937654_3410.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361937664_2466.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;텍스트를 인식해서, 근처의 텍스트와 묶는 &lt;em&gt;expansion&lt;/em&gt; 작업을 하고 &lt;em&gt;character segmentation&lt;/em&gt; 단계로 넘어간다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361937671_6657.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361937676_4874.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;artificial-data&#34;&gt;Artificial Data&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;low bias&lt;/em&gt; 에 &lt;em&gt;massive data set&lt;/em&gt; 을 조합하면 좋은 퍼포먼스가 나오긴 하는데, 어디서 커다란 데이터셋을 구할까? 작은 데이터 셋으로 커다란 데이터셋을 인위적으로 만들 수 있을까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361948453_3756.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361948457_9107.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361948462_1113.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;스케일링, 로테이션, 디스토션, 백그라운드 수정 등 다양한 조합을 통해 진짜처럼 보이는 &lt;em&gt;synthetic data&lt;/em&gt; 를 얻을 수 있다. 마찬가지로, &lt;em&gt;speech recognition&lt;/em&gt; 에도 &lt;em&gt;synthetic data&lt;/em&gt; 를 만들어 퍼포먼스를 높일 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361948466_5032.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;synthetic data&lt;/em&gt; 를 만들기 전에 &lt;em&gt;low bias classifier&lt;/em&gt; 인지 확인하자.&lt;/li&gt;
&lt;li&gt;데이터를 조합하는데 들어가는 노력이 얼마나 들까 생각해보자&lt;/li&gt;
&lt;li&gt;&lt;em&gt;crowd source&lt;/em&gt; 를 고려하자. (e.g. Amazon Mechanical Turk)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;10 초당 1개의 &lt;em&gt;example&lt;/em&gt; 을 수동으로 얻는다면, 10000 개를 얻는데 대략 3.5일의 시간이 걸린다.&lt;/p&gt;

&lt;h3 id=&#34;ceiling-analysis&#34;&gt;Ceiling Analysis&lt;/h3&gt;

&lt;p&gt;이전의 &lt;em&gt;Photo OCR&lt;/em&gt; 문제에서 퍼포먼스를 높이려면 파이프라인의 각 단계 중 어느 부분에 가장 많은 노력을 들여야할까?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361952527_2269.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;각 단계에서 수동으로 정확도 100% 를 만들었을때와, 전체적인 정확도를 비교해서 어느 부분을 향상 시켰을때 가장 효율적일지를 파악할수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361952535_9451.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361952540_1528.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361952938_3624.jpg&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;supervised learning&lt;/strong&gt; 의 종류로&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;linear regresison&lt;/li&gt;
&lt;li&gt;logistic regression&lt;/li&gt;
&lt;li&gt;neural networks&lt;/li&gt;
&lt;li&gt;SVM&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;unsupervised learning&lt;/strong&gt; 으로&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;k-means&lt;/li&gt;
&lt;li&gt;PCA&lt;/li&gt;
&lt;li&gt;anomaly detection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한 머신 러닝의 응용으로&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;recommender system&lt;/li&gt;
&lt;li&gt;large scale ML&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;마지막으로 머신러닝에 도움이 되는 주제로&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;bias vs variance&lt;/li&gt;
&lt;li&gt;regularization&lt;/li&gt;
&lt;li&gt;evaluation technique&lt;/li&gt;
&lt;li&gt;learning curve&lt;/li&gt;
&lt;li&gt;error analysis&lt;/li&gt;
&lt;li&gt;ceiling analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;등을 배웠다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.my.csdn.net/uploads/201302/27/1361953290_6926.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;Machine Learning&lt;/em&gt; by &lt;strong&gt;Andrew NG&lt;/strong&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://blog.csdn.net/linuxcumt&#34;&gt;http://blog.csdn.net/linuxcumt&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://blog.csdn.net/abcjennifer&#34;&gt;http://blog.csdn.net/abcjennifer&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Data Science 1</title>
      <link>https://1ambda.github.io/92/data-analysis/intro-to-data-science-1/</link>
      <pubDate>Sat, 25 Jun 2016 14:20:42 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/intro-to-data-science-1/</guid>
      <description>

&lt;h3 id=&#34;simulation-models&#34;&gt;Simulation Models&lt;/h3&gt;

&lt;p&gt;Simulation attempts to build an &lt;strong&gt;experimental device&lt;/strong&gt; called &lt;em&gt;model&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Simulation model is &lt;em&gt;descriptive, not prescriptive&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;직역하자면 시뮬레이션은 실험가능한 도구인 모델을 만들어낸다. 모든 모델이 정확하진 않지만, 다시 말해 현상을 완벽하게 설명하진 못하지만, 어떤 모델들은 대략 비슷하게 사실을 예측해 낸다. 그런점에서 모델은 유용하다.&lt;/p&gt;

&lt;p&gt;(1) &lt;strong&gt;Deterministic simulations&lt;/strong&gt; are completely defined by the model &lt;em&gt;rerunning the simulation will not change the result&lt;/em&gt;&lt;br /&gt;
(2) &lt;strong&gt;Stochastic simulations&lt;/strong&gt; include randomness. &lt;em&gt;Difference runs can generate different results&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;nondeterminism&#34;&gt;Nondeterminism&lt;/h3&gt;

&lt;p&gt;*Casual nondeterminism: * Not every event is caused by previous events&lt;/p&gt;

&lt;p&gt;*Predictive nondeterminism: * Lack of knowledge about the world makes it impossible make accurate predictions about future states&lt;/p&gt;

&lt;p&gt;*Stachastic Processes: * An ongoing process where the next state might depend on both the previous states and &lt;strong&gt;some random element&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def rollDie():
   &amp;quot;&amp;quot;&amp;quot;returns an int between 1 and 6&amp;quot;&amp;quot;&amp;quot;
   
def rollDie():
   &amp;quot;&amp;quot;&amp;quot;returns a random int between 1 and 6 &amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위쪽 &lt;code&gt;rollDie&lt;/code&gt; 는 &lt;em&gt;underdetermined&lt;/em&gt; 인 반면 아래쪽은 &lt;em&gt;non-deterministric&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;hash-table&#34;&gt;Hash Table&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Many to One&lt;/em&gt; 이기 때문에 &lt;em&gt;Collision&lt;/em&gt; 이 생긴다. &lt;strong&gt;bucket&lt;/strong&gt; 을 이용해서 같은 키값을 가진 것들을 같은 버켓에 저장하도록 하면 충돌을 어느정도는 예방할 수 있다.&lt;/p&gt;

&lt;p&gt;물론, 테이블이 커지면 충돌이 적어지고 탐색시간이 빨라지지만 메모리가 많이 들고, 테이블이 작아지면 충돌이 많아지고 탐색시간이 &lt;em&gt;linear search&lt;/em&gt; 에 가깝게 느려지지만 메모리는 적게든다. &lt;em&gt;Time / Space trade off&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;그리고 좋은 해쉬 함수는 &lt;em&gt;uniform distribution&lt;/em&gt; 을 생성한다. 다시 말해서 모든 버킷은 같은 수의 데이터를 담고 있어야 한다.&lt;/p&gt;

&lt;p&gt;해시 테이블은 &lt;em&gt;time / space trade off&lt;/em&gt; 를 극명하게 보여주는데, &lt;em&gt;collision&lt;/em&gt; 이 하나도 없을 때 개당 &lt;em&gt;1 byte&lt;/em&gt; 인 10^9 개의 원소를 담고자 한다면, 1GB 가 필요하다.&lt;/p&gt;

&lt;p&gt;그래서 해시 테이블을 만들 때는 가능한한 메모리가 허락하는 한도 내에서 최적화 할 필요가 있다. 다시 말하면 &lt;em&gt;table size&lt;/em&gt; 와 &lt;em&gt;lookup time&lt;/em&gt; 을 동시에 고려해야 한다는 뜻이다.&lt;/p&gt;

&lt;p&gt;버킷 내부에 &lt;code&gt;a&lt;/code&gt; 개를 저장하면 원소를 검색하는데 &lt;code&gt;O(a)&lt;/code&gt; 시간이 걸리지만 메모리는 &lt;code&gt;1/a&lt;/code&gt; 배 만큼 줄어든다.&lt;/p&gt;

&lt;p&gt;이제 해쉬 함수의 성능을 &lt;em&gt;적어도 한번 충돌이 일어날 수 있는 확률&lt;/em&gt; 로 표현해 보자. 한번도 충돌이 나지 않을 경우를 1 에서 빼면 된다.&lt;/p&gt;

&lt;p&gt;입력 원소 &lt;code&gt;K&lt;/code&gt; 개에 대해, 해쉬함수가 &lt;code&gt;range(n)&lt;/code&gt; 의 &lt;em&gt;uniform distribution&lt;/em&gt; 을 만들때 &lt;code&gt;hash(k) = 1/n&lt;/code&gt; 이다. 이 때 충돌이 한번도 일어나지 않을 확률은 &lt;code&gt;1 * (n-1)/n * (n-2)/n  * .. (n-(k-1))/n&lt;/code&gt; 이다. 이 값을 1에서 빼면 *적어도 한번 충돌이 일어날 수 있는 확률*을 구할수 있다.&lt;/p&gt;

&lt;h3 id=&#34;birthday-attack&#34;&gt;Birthday Attack&lt;/h3&gt;

&lt;p&gt;일년이 365일 이라 하면, 얼핏 생각하기에 365명 정도는 모여야 생일이 같은 사람 있을 것 같은데 사실 그렇지 않다. 실제로는 23명만 모여도 생일이 같은 두사람이 있을 확률이 50%를 넘고, 57명이 모이면 99%를 넘는다.&lt;/p&gt;

&lt;p&gt;생일이 같은 두 사람을 찾는 것과 비슷하게, 암호학적 해시 결과가 같은 두 입력값을 자는 것 역시 모든 입력값을 계산하지 않앋 충분히 높은 확률로 해시 충돌을 찾을 수 있다. 이러한 암호 공격을 &lt;em&gt;birthday attack&lt;/em&gt; 이라 부른다.&lt;/p&gt;

&lt;p&gt;바꿔 말하면 &lt;em&gt;birth day problem&lt;/em&gt; 은 해시 버켓이 365개인 해시 테이블이라 봐도 무방하다.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;atLeastTwoSameBirthday&lt;/code&gt; 함수는 &lt;code&gt;n + 1&lt;/code&gt; 명이 있는 방 안에서 적어도 두명은 생일이 같을 확률을, &lt;code&gt;minNumOfPeopleProb&lt;/code&gt; 는 인자로 받은 &lt;code&gt;p&lt;/code&gt; 보다 큰, 생일이 같을 확률을 얻기 위한 최소한의 인원을 돌려준다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import operator


def atLeastTwoSameBirthday(n):
    xs = range(365 - n, 365)
    ys = map((lambda x: float(x) / 365), xs)
    return 1 - reduce(operator.mul, ys)


def minNumOfPeopleProb(p):
    for n in range(1, 365):
        if atLeastTwoSameBirthday(n) &amp;gt;= p:
            return n

    return n


print atLeastTwoSameBirthday(29)
print atLeastTwoSameBirthday(249)
print minNumOfPeopleProb(0.99)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;low-of-large-numbers&#34;&gt;Low of Large Numbers&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;In repeated &lt;strong&gt;independent tests&lt;/strong&gt; with the same actual probabilty &lt;em&gt;p&lt;/em&gt; of a particular outcome in each test, the chance of that the &lt;em&gt;fraction of times&lt;/em&gt; that outcome occurs differs from p converges to zero as the number of trials goes to infinity&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;low of large numbers&lt;/em&gt; 는 &lt;strong&gt;&lt;code&gt;|head - tail|&lt;/code&gt; 이 0에 수렴한다&lt;/strong&gt; 를 의미하지 않는다. 오히려 &lt;code&gt;|head - tail|&lt;/code&gt; 는 특정 비율이다(&lt;em&gt;ratio&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;이제 실제로 그러한지 시뮬레이션을 하기 위해 코드를 작성하면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pylab
import random


def flipPlot(minExp, maxExp):
    ratios = []
    diffs = []
    xAxis = []

    for exp in range(minExp, maxExp + 1):
        xAxis.append(2 ** exp)

    for flips in xAxis:
        heads = 0
        for n in range(flips):
            if random.random() &amp;lt; 0.5:
                heads += 1

        tails = flips - heads
        ratios.append(heads / float(tails))
        diffs.append(abs(heads - tails))

    pylab.title(&#39;Diff between Heads and Tails&#39;)
    pylab.xlabel(&amp;quot;# of Flips&amp;quot;)
    pylab.ylabel(&amp;quot;Abs(#Heads - #Tails)&amp;quot;)
    pylab.plot(xAxis, diffs)
    pylab.figure()
    pylab.title(&amp;quot;Heads / Tails Ratios&amp;quot;)
    pylab.xlabel(&amp;quot;# of Flips&amp;quot;)
    pylab.ylabel(&amp;quot;Heads / Tails&amp;quot;)
    pylab.plot(xAxis, ratios)

random.seed(0)
flipPlot(4, 20)
pylab.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;돌려서 나온 &lt;code&gt;|head - tail|&lt;/code&gt; 의 그래프에서 선형 관계가 있다고 느낄 수 있는데 사실이 아니다. 우리는 x 축 값을 지수로 증가시켰기 때문에 우측에는 데이터가 별로 없는 반면 왼쪽에는 압축되어있다.&lt;/p&gt;

&lt;p&gt;선 대신에 점 형태로 그래프를 그리고 축에 로그를 씌우는 코드로 바꾸자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    #...
    
    pylab.title(&#39;Diff between Heads and Tails&#39;)
    pylab.xlabel(&amp;quot;# of Flips&amp;quot;)
    pylab.ylabel(&#39;Abs(#Heads - #Tails)&#39;)
    pylab.plot(xAxis, diffs, &#39;bo&#39;)
    pylab.semilogx()
    pylab.semilogy()
    pylab.figure()
    pylab.title(&#39;Heads / Tails Ratios&#39;)
    pylab.xlabel(&#39;# of Flips&#39;)
    pylab.ylabel(&#39;Heads / Tails&#39;)
    pylab.semilogx()
    pylab.plot(xAxis, ratios, &#39;ro&#39;)
    
    #...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;heads / tails&lt;/code&gt; 는 1에 수렴하는걸 알 수 있다. 반면 &lt;code&gt;|heads - tails|&lt;/code&gt; 는 완벽하진 않지만 선형의 그래프를 그리는걸 알 수 있다.&lt;/p&gt;

&lt;p&gt;여기서 한 가지 사실을 알 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Never possible to be assured of perfec accuracy through samplings, unless you sample the entire population&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그렇다면 &lt;em&gt;sample&lt;/em&gt; 에 대한 경향이 참일때, &lt;em&gt;population&lt;/em&gt; 에 대한 경향이 참임을 증명하기 위해서 얼마나 많은 &lt;em&gt;sample&lt;/em&gt; 을 살펴봐야 할까?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Depends upon the variance in the underlying distribution&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;물론 우리는 &lt;em&gt;distribution&lt;/em&gt; 을 볼 수 없다. 샘플만 가지고 있기 때문에. 그럼 샘플로 &lt;em&gt;variance&lt;/em&gt; 를 얻어보자.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We measure the amount of variance in the outcomes of multiple trials&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;standard deviation&lt;/em&gt; 을 이용하자. 표준편차는 우리가 가진 샘플이 평균에 모여있는지, 아닌지를 알려주는 지표다.&lt;/p&gt;

&lt;p&gt;다시 말해서 &lt;em&gt;standard deviation&lt;/em&gt; 이 작으면, 그래서 샘플의 평균에 샘플들이 대부분 모여있다는걸 알 수 있다면 작은 샘플에 대해서 얻은 어떤 경향이 &lt;em&gt;population&lt;/em&gt; 에도 적용된다는 걸 알 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def flipPlot(minExp, maxExp, trials):
    meanRatios = []
    meanDiffs = []
    sdRatios = []
    sdDiffs = []
    xAxis = []

    for exp in range(minExp, maxExp + 1):
        xAxis.append(2 ** exp)

    for flips in xAxis:
        ratios = []
        diffs = []

        for t in range(trials):
            heads, tails = runTrial(flips)
            ratios.append(heads / float(tails))
            diffs.append(abs(heads - tails))
        meanRatios.append(sum(ratios) / trials)
        meanDiffs.append(sum(diffs) / trials)
        sdRatios.append(stdDev(ratios))
        sdDiffs.append(stdDev(diffs))

    pylab.title(&#39;Mean of Diff bet Heads and Tails (&#39;+str(trials)+&#39; Trials)&#39;)
    pylab.xlabel(&amp;quot;# of Flips&amp;quot;)
    pylab.ylabel(&#39;mean Abs(#Heads - #Tails)&#39;)
    pylab.plot(xAxis, meanDiffs, &#39;bo&#39;)
    pylab.semilogx()
    pylab.semilogy()

    pylab.figure()
    pylab.title(&#39;SD of Diff bet Heads and Tails (&#39;+str(trials)+&#39; Trials)&#39;)
    pylab.xlabel(&#39;# of Flips&#39;)
    pylab.ylabel(&#39;SD Abs(#Heads - #Tails)&#39;)
    pylab.plot(xAxis, sdDiffs, &#39;bo&#39;)
    pylab.semilogx()
    pylab.semilogy()

    pylab.figure()
    pylab.title(&#39;Mean Heads / Tails Ratios&#39;)
    pylab.xlabel(&#39;# of Flips&#39;)
    pylab.ylabel(&#39;mean Heads / Tails&#39;)
    pylab.semilogx()
    pylab.plot(xAxis, meanRatios, &#39;ro&#39;)

    pylab.figure()
    pylab.title(&#39;SD Heads / Tails Ratios&#39;)
    pylab.xlabel(&#39;# of Flips&#39;)
    pylab.ylabel(&#39;SD Heads / Tails&#39;)
    pylab.semilogx()
    pylab.semilogy()
    pylab.plot(xAxis, sdRatios, &#39;ro&#39;)

random.seed(0)
flipPlot(4, 20, 20)
pylab.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이제 코드를 돌려보면, &lt;code&gt;heads / tails&lt;/code&gt; 의 평균은 1로 수렴하는 것을, 표준편차는 &lt;code&gt;n&lt;/code&gt; 이 커질수록 급격히 &lt;code&gt;0&lt;/code&gt; 에 가까워지는걸 알 수 있다.&lt;/p&gt;

&lt;p&gt;반면 &lt;code&gt;|heads - tails|&lt;/code&gt; 의 평균은 &lt;code&gt;n&lt;/code&gt; 이 증가할수록 여전히 커지고, 표준편차도 증가한다.&lt;/p&gt;

&lt;p&gt;그럼, &lt;code&gt;n&lt;/code&gt; 이 클수록 &lt;code&gt;|heads - tails|&lt;/code&gt; 의 표준편차가 증가하므로 우리가 얻은 어떤 경향성이 &lt;code&gt;n&lt;/code&gt; 이 클수록 더 믿지 못한다는 뜻일까?.&lt;/p&gt;

&lt;p&gt;당연히 그렇지 않다! &lt;strong&gt;표준편차는 그 자체로만 보아서는 안되고 평균과 연관지어 생각해야 한다.&lt;/strong&gt; 평균이 100억일때, 표준편차가 100이라면 그건 데이터가 모여있음을 의미한다.&lt;/p&gt;

&lt;p&gt;결국 &lt;em&gt;평균&lt;/em&gt; 이 매우 달라지는 테스트를 할 경우엔 &lt;em&gt;표준편차&lt;/em&gt; 를 사용하는건 적절하지 못하다는 사실을 알 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;coefficient-of-variation&#34;&gt;coefficient of variation&lt;/h3&gt;

&lt;p&gt;그럼 평균이 달라지는경우 표준편차가 의미가 없다면, 어떤 값을 사용해야 &lt;em&gt;population&lt;/em&gt; 의 &lt;em&gt;variance&lt;/em&gt; 를 알 수 있을까? 표준편차를 평균으로 나눈 &lt;em&gt;coefficient of variance&lt;/em&gt; 를 이용하면 된다. 일반적으로 이 값이 1 보다 작은지 아닌지를 기준으로 삼는다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/files_finger_exercises_pythonland.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/files_finger_exercises_montyland.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://courses.edx.org/courses/MITx/600.2_2x&#34;&gt;http://courses.edx.org/courses/MITx/600.2_2x&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;위 두 도시의 스카이라인중 어떤 도시의 &lt;em&gt;coefficient of variance&lt;/em&gt; 가 더 클까?&lt;/p&gt;

&lt;p&gt;한가지 더 생각해볼 문제가 있다. 다음의 두 변수는 CoV 를 계산하는 것이 의미가 있을까?&lt;/p&gt;

&lt;p&gt;(1) &lt;em&gt;Daily Temperature in Celsius for the city of Boston&lt;/em&gt;&lt;br /&gt;
(2) &lt;em&gt;The X coordinate of a drunk in the random walk&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;의미가 없다. &lt;em&gt;CoV&lt;/em&gt; 가 의미있으려면, &lt;em&gt;true zero&lt;/em&gt; 가 있어야 한다. 바꿔 말하면 &lt;em&gt;ratio scale&lt;/em&gt; 에 대해서만 &lt;em&gt;CoV&lt;/em&gt; 가 의미가 있다. 위 두 수치들은 양수 또는 음수값이 있기 때문에 &lt;em&gt;ratio scale&lt;/em&gt; 이 아니다.&lt;/p&gt;

&lt;h3 id=&#34;histogram&#34;&gt;Histogram&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;pylab&lt;/em&gt; 에서는 히스토그램을 어떻게 그릴까?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pylab
import random


def exampleHist(n):
    xs = []
    for x in range(n):
        xs.append(random.random())

    pylab.hist(xs, bins=11)
    pylab.show()

exampleHist(10000)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;a href=&#34;http://ko.wikipedia.org/wiki/%EC%83%9D%EC%9D%BC_%EB%AC%B8%EC%A0%9C&#34;&gt;http://ko.wikipedia.org&lt;/a&gt;&lt;br /&gt;
(2) &lt;em&gt;MIT 6.00.2 2x&lt;/em&gt; in &lt;strong&gt;edx&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Data Science 2</title>
      <link>https://1ambda.github.io/92/data-analysis/intro-to-data-science-2/</link>
      <pubDate>Sat, 25 Jun 2016 14:20:43 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/intro-to-data-science-2/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;Computational systems are so very convenient for modeling behaviors of noisier, uncertain systems, &lt;strong&gt;especially in estimating the values of parameters of those systems&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;monte-carlo-simulation&#34;&gt;Monte Carlo Simulation&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;Monte Carlo simulation is a method of &lt;strong&gt;estimating the value of an unknown quantity using the principles of inferential statistics&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이전에 잠깐 &lt;em&gt;deterministic model&lt;/em&gt; 과 &lt;em&gt;stochastic model&lt;/em&gt; 언급 했었는데, 다시 한번 알아보자면&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In &lt;strong&gt;deterministic models&lt;/strong&gt;, the output of the model is  fully determined by the parameter values and the
initial conditions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stochastic models&lt;/strong&gt; possess some inherent randomness. The same set of parameter values and initial conditions will lead to an ensemble of different outputs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;때때로 사람들이 &lt;em&gt;deterministic model&lt;/em&gt; 은 &lt;em&gt;uncertainty&lt;/em&gt; 를 다루지 않는다고 말하곤 하는데 이건 엄밀히 말하면 틀렸다. &lt;em&gt;deterministic model&lt;/em&gt; 내부적으로는 &lt;em&gt;randomness&lt;/em&gt; 가 없지만, 모델 외부에 &lt;em&gt;uncertainty&lt;/em&gt; 가 있을 수 있다.&lt;/p&gt;

&lt;p&gt;몬테 카를로 시뮬레이션이 바로 &lt;em&gt;deterministic model&lt;/em&gt; 에 대해 &lt;em&gt;random input&lt;/em&gt; 을 이용해 분포를 얻어내는 방법이다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I have heard people say that &amp;ldquo;a stocahstic model handles uncertainty, a deterministic model doesn&amp;rsquo;t&amp;rdquo;. This is not strictly correct. The correct statement should be:
a stochastic model has the capacity to handle then uncertainty in the inputs built into it, for a deterministic model, the uncertainties are extenal to the model. The uncertainties in the inputs to a deterministic model can be handled through use of a Monte Carlo simulation (note that this does not make it a stochastic model). This is computationally inefficient however.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;finding-pi&#34;&gt;Finding PI&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def stdDev(X):
    mean = sum(X) / float(len(X))
    total = 0.0
    for x in X:
        total += (x - mean) ** 2
    return (total / len(X)) ** 0.5


def dropNeedles(num):
    inCircle = 0
    for needles in xrange(1, num + 1, 1):
        x = random.random()
        y = random.random()

        if (x*x + y*y) ** 0.5 &amp;lt;= 1.0:
            inCircle += 1

    return 4 * (inCircle / float(num))


def estimate(numOfNeedles, trials):
    estimates = []
    for i in range(trials):
        pi = dropNeedles(numOfNeedles)
        estimates.append(pi)

    sd = stdDev(estimates)
    est = sum(estimates) / len(estimates)

    return (est, sd)


def simulate(precision, trials):
    numOfNeedles = 1000
    sd = precision

    # 95% of the values lie within precision of the mean
    while sd &amp;gt;= (precision / 2.0):
        est, sd = estimate(numOfNeedles, trials)
        print &#39;PI est =&#39;, est, &amp;quot;sd =&amp;quot;, round(sd, 6), &amp;quot;needles =&amp;quot;, numOfNeedles
        numOfNeedles *= 2

    return est


random.seed(0)
simulate(0.005, 100)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;반지름이 1인 원 안에 바늘을 떨어트려, 해당 원 안에 있을 경우와 직사각형에 있을 경우의 비율에 직사각형의 넓이를 곱하면, 원의 넓이 즉 &lt;code&gt;PI&lt;/code&gt; 값이 나온다.&lt;/p&gt;

&lt;p&gt;실제 돌려보면&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PI est = 3.14844 sd = 0.047886 needles = 1000
PI est = 3.13918 sd = 0.035495 needles = 2000
PI est = 3.14108 sd = 0.02713 needles = 4000
PI est = 3.141435 sd = 0.016805 needles = 8000
PI est = 3.141355 sd = 0.0137 needles = 16000
PI est = 3.14131375 sd = 0.008476 needles = 32000
PI est = 3.141171875 sd = 0.007028 needles = 64000
PI est = 3.1415896875 sd = 0.004035 needles = 128000
PI est = 3.14174140625 sd = 0.003536 needles = 256000
PI est = 3.14155671875 sd = 0.002101 needles = 512000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;32000&lt;/code&gt; 개와 &lt;code&gt;64000&lt;/code&gt; 개의 바늘을 떨어트린 샘플을 보면 실제 샘플도 후자가 많고, 표준편차도 후자가 작음에도 실제 추정값은 더 나쁘게 나왔다.&lt;/p&gt;

&lt;p&gt;표준편차가 작으면 실제 값에 근접한 추정값이 나왔다는 뜻이 아닌가?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Having the small standard deviation doesn&amp;rsquo;t mean we have a good estimate.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그렇지 않다. 표준편차가 작다는 것이, 우리가 얻은 추정값이 실제 값과 같다는 뜻은 아니다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;All this means is that if we were to draw more samples from the same distribution, we can be reasonably confident that we would get a similar value.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;단지 같은 분포에서 더 많은 샘플을 이용하면 &lt;em&gt;현재 값과 비슷한 값 (!= 실제값)&lt;/em&gt; 을 얻을 수 있다는 말이다.&lt;/p&gt;

&lt;p&gt;우리가 구한 값이 실제 &lt;code&gt;PI&lt;/code&gt; 와 근사하다고 믿기 전에 3가지를 먼저 확인해야한다.&lt;/p&gt;

&lt;p&gt;(1) &lt;strong&gt;conceptual model&lt;/strong&gt; (이 경우 &lt;code&gt;PI&lt;/code&gt; 를 위한 계산)&lt;br /&gt;
(2) &lt;strong&gt;implementation&lt;/strong&gt;&lt;br /&gt;
(3) &lt;strong&gt;enough samples&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;만약에 &lt;code&gt;4 * (inCircle / float(num)&lt;/code&gt; 대신에 &lt;code&gt;2 * (inCircle / float(num)&lt;/code&gt; 를 사용해 잘못된 &lt;em&gt;conceptual model&lt;/em&gt; 을 가진다면 (버그라 볼 수도 있겠다.)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PI est = 1.57422 sd = 0.023943 needles = 1000
PI est = 1.56959 sd = 0.017748 needles = 2000
PI est = 1.57054 sd = 0.013565 needles = 4000
PI est = 1.5707175 sd = 0.008402 needles = 8000
PI est = 1.5706775 sd = 0.00685 needles = 16000
PI est = 1.570656875 sd = 0.004238 needles = 32000
PI est = 1.5705859375 sd = 0.003514 needles = 64000
PI est = 1.57079484375 sd = 0.002017 needles = 128000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;보면 알겠지만, 표준편차는 충분히 작음에도 우리가 구한 추정값이 &lt;code&gt;PI&lt;/code&gt; 와는 상당히 다르다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Whenever possible, one should attempt to validate results against realilty&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;normal-distribution&#34;&gt;Normal Distribution&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;Instead of estimating an unknown parameter by a single value, a &lt;strong&gt;confidence interval&lt;/strong&gt; provides a range that is likely to contain the unknown value and a confidence level that the unknown value lays within that range&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;common-pattern-in-science-and-engineering&#34;&gt;Common Pattern in Science and Engineering&lt;/h3&gt;

&lt;p&gt;보통 두 가지 작업이 있는데,&lt;/p&gt;

&lt;p&gt;(1) develop a hypothesis&lt;br /&gt;
(2) design an experiment, take measurements&lt;br /&gt;
(3) use computation to&lt;br /&gt;
- evaluate hypothesis,&lt;br /&gt;
- determin values of unknowns,&lt;br /&gt;
- predict consequences&lt;/p&gt;

&lt;p&gt;두가지는 &lt;code&gt;1 -&amp;gt; 2&lt;/code&gt; 순서일 수 있고, 때때로 뒤 바뀔 수도 있다. 예를 한번 살펴보면&lt;/p&gt;

&lt;p&gt;먼저 16세기에 &lt;em&gt;Hooke&lt;/em&gt; 는 &lt;em&gt;&amp;ldquo;용수철에 가해진 힘은 그 길이에 비례한다는 가설&amp;rdquo;&lt;/em&gt; 을 세웠다. 이를 증명하기 위해 실험을 고안했는데, 천장에 서로 다른 길이의 스프링을 연결하고 거기에 저울 추를 달았다.&lt;/p&gt;

&lt;p&gt;늘어난 길이 &lt;code&gt;x&lt;/code&gt; 에 대해 용수철 상수 &lt;code&gt;k&lt;/code&gt; 를 &lt;code&gt;kx = mg&lt;/code&gt; 를 이용해 계산하면, 얼추 맞는다. 그런데 몇몇 샘플에 대해서는 용수철 상수 &lt;code&gt;k&lt;/code&gt; 가 상당히 다르게 나온다. &lt;code&gt;[11.41, 14.49 ...]&lt;/code&gt; 왜 그럴까? 용수철 상수가 매번 변한다는걸까?&lt;/p&gt;

&lt;p&gt;다음 데이터에 대해 그래프를 그려보면&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Distance (m) Mass (kg)
0.0865 0.1
0.1015 0.15
0.1106 0.2
0.1279 0.25
0.1892 0.3
0.2695 0.35
0.2888 0.4
0.2425 0.45
0.3465 0.5
0.3225 0.55
0.3764 0.6
0.4263 0.65
0.4562 0.7
0.4502 0.75
0.4499 0.8
0.4534 0.85
0.4416 0.9
0.4304 0.95
0.437 1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;distance&lt;/em&gt; 에 대한 예측 &lt;code&gt;ma / k&lt;/code&gt; 와 실제 값이 일치하지 않는다. 이른바 &lt;em&gt;error (오류)&lt;/em&gt; 가 있는 것인데, 이들 오류는 &lt;em&gt;small randomness&lt;/em&gt; 에 대한 축적의 결과로 이루어 진 것이다.&lt;/p&gt;

&lt;p&gt;오류에 대한 &lt;em&gt;probabilty density function&lt;/em&gt; 로 &lt;code&gt;y = x - 1 (-1 &amp;lt;= x &amp;lt; 0)&lt;/code&gt;, &lt;code&gt;y = -x + 1 (0 &amp;lt; x &amp;lt;= 1)&lt;/code&gt; 을 가정했을때 시뮬레이션을 좀 해보자. &lt;code&gt;random.triangular&lt;/code&gt; 를 이용하면 &lt;em&gt;triangle distribution&lt;/em&gt; 을 얻을 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def testErrors(ntrials=10000,npts=100):
    results = [0] * ntrials
    for i in xrange(ntrials):
        s = 0   # sum of random points
        for j in xrange(npts):
            s += random.triangular(-1,1)
        results[i] =s
    # plot results in a histogram
    pylab.hist(results,bins=50)
    pylab.title(&#39;Sum of 100 random points -- Triangular PDF (10,000 trials)&#39;)
    pylab.xlabel(&#39;Sum&#39;)
    pylab.ylabel(&#39;Number of trials&#39;)

testErrors()
pylab.show()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;실행해 보면 에러의 합의 분포가 정규 분포와 비슷하다. 우리가 어떤 에러 분포를 고르든지 간에 &lt;em&gt;finite mean, variance&lt;/em&gt; 를 가지고 있다면 에러의 분포는 정규분포다.&lt;/p&gt;

&lt;p&gt;실제 그런가 &lt;code&gt;random.triangular&lt;/code&gt; 말고 &lt;code&gt;random.uniform&lt;/code&gt; 을 이용해 보면 똑같이 정규분포를 얻는다. 이는 &lt;em&gt;central limit theorem (중심극한정리)&lt;/em&gt; 를 의미하는데 위키에서 인용하면&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;동일한 확률분포를 가진 독립 확률 변수 n개의 평균값은 n이 적당히 크다면 정규분포에 가까워진다는 정리&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;결국 우리가 이전에 스프링을 이용해 봤던 실험에서 발생한 에러는 &lt;em&gt;small random error&lt;/em&gt; 의 &lt;em&gt;accumulation&lt;/em&gt; 이므로, 우리는 이 에러의 분포를 정규분포라 말할 수 있다는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;결국 오차 역시 평균 주변에 몰려있는 값이므로, 참값을 상당히 높은 확률로 추측해 낼 수 있다.&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;정규분포는 19세기의 가장 위대한 수학자인 가우스(C. F. Gauss, 1777-1855)에 의해 새롭게 해석된다. 가우스는 관측에 따른 오차의 정도가 대체로 평균값 주변에서 발생한다는 점에 착안하여 정규분포에 따른 확률 밀도 함수와 똑 같은 식을 얻을 수 있었다. 이것은 &lt;strong&gt;관측 오차 역시 정규분포를 따른다는 것으로, 이후 실험으로 구한 관측값에서 참값을 추정해내는 근본적인 원리&lt;/strong&gt;로 자리잡게 된다. 이런 점에서 위의 종모양 곡선을 오차곡선(error curve)라고도 부른다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;normal distribution&lt;/em&gt; 의 식은&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?f%28x%29%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20e%5E%7B-%28x%20-%20%5Cmu%29%5E2%20%5Cover%20%5Csigma%5E2%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mu = 0, sigma = 1&lt;/code&gt; 인 경우에 &lt;em&gt;standard normal&lt;/em&gt; 혹은 &lt;em&gt;unit normal&lt;/em&gt; 이라 부른다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;So when observation errors are due to the accumlation of many small random perturbations&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?f%28x%29%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20e%5E%7B-%28x%29%5E2%20%5Cover%20%5Csigma%5E2%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;다시 말해 작은 랜덤의 누적으로 발생한 관측 오차의 경우에는 &lt;code&gt;mu = 0&lt;/code&gt; 이다. 그리고 식이 말해주는 바는, 큰 에러의 경우에는 확률이 &lt;em&gt;expnentially less likely&lt;/em&gt; 하다는 것이다.&lt;/p&gt;

&lt;p&gt;이제 각 에러가 일어날 확률 곱을 다음과 같이 구할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Cprod_%7Bi%20%3D%200%7D%5E%7Blen%28obj%29%20-%201%7D%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이때 이 값을 최대화한다는 것은 각 에러가 나올 확률이 가장 높아야 한다. 다시 말해서 가장 평균적인 에러만 나와야 한다는 뜻이다. 이 값의 최대를 구하는 것은 뒤집은 식의 최소값을 찾는 것과 같으므로&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min%20%5C%20%7B1%20%5Cover%20%5Cprod_%7Bi%20%3D%200%7D%5E%7Blen%28obj%29%20-%201%7D%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;여기에 자연 로그를 씌우면 확률 변수의 곱이 덧셈으로 변한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?ln%20%28%7B1%20%5Cover%20%5Cprod%20%5C%20L_%7Berr%7D%20%28obs_i%20-%20pred_i%29%7D%29%20%5C%5C%20%5C%5C%20%5C%5C%20%3D%20-%20%5Csum%20ln%20%28L_%7Berr%7D%28obs_i%20-%20pred_i%29%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이 값을 최소화 하면 된다. 여기서 &lt;em&gt;pdf&lt;/em&gt; 식을 적용하면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min%20-%20%5Csum%20ln%20%28%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20e%5E%7B%28obs_i%20-%20pred_i%29%5E2%20%5Cover%20%5Csigma%5E2%7D%29&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;로그를 씌우면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Csum%20%5Bln%20%7B%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20&amp;amp;plus;%20ln%20%7B%28obs_i%20-%20pred_i%29%5E2%20%5Cover%20%5Csigma%5E2%7D%5D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이 때 다른 상수를 제외하고 실제 최소화 해야 할 부분만 고려하면&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?min%20%5Csum%20%28obs_i%20-%20pred_i%29%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;따라서 이 값을 최소화 하면 &lt;em&gt;most likely observations&lt;/em&gt; 가 된다. 이런 이유에서 오차 제곱의 합의 최소가 되는 파라미터가 바로 가장 신뢰할만한 파라미터가 된다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;
처음부터 정리하자면, 중심 극한 정리에 따라 에러의 분포가 어떠하든 간에 에러가 확률변수라면 이것의 평균은 정규분포다. 따라서 &lt;em&gt;pdf&lt;/em&gt; 식을 적용할 수 있고 이때 &lt;code&gt;mean = 0&lt;/code&gt; 이다.&lt;/p&gt;

&lt;p&gt;에러가 나올 확률의 곱이 최대이면, 모든 에러에 대해 보편적인 에러를 얻었다는 뜻이므로 이에 대해 식을 정리하면,&lt;/p&gt;

&lt;p&gt;&lt;em&gt;sum of squared of erros (SSE, least square)&lt;/em&gt; 를 최소화 하는 파라미터를 선택하면 가장 신뢰할 만한 관측 결과를 얻어낼 수 있다는 결론을 얻게된다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;
파이선에서는 &lt;code&gt;pylab.plotfit&lt;/code&gt; 을 이용해 값을 최소화 하는 파라미터를 뽑아낼 수 있다. 예를 들어서 &lt;code&gt;y = ax + b&lt;/code&gt; 의 합을 최소화 하는 &lt;code&gt;a, b&lt;/code&gt; 를 찾으려면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a, b = pylab.ployfir(xvals, yvals, 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;y = ax^2 + bx + c&lt;/code&gt; 에 대해서는&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a, b, c = pylab.polyfit(xvals, yvals, 2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;firing-arrow&#34;&gt;Firing Arrow&lt;/h3&gt;

&lt;p&gt;이제 위에서 얻은 개념을 다른 예제에 적용해보면서 가설이 얼마나 &lt;em&gt;잘 맞는가&lt;/em&gt; 를 어떻게 측정할건지를 좀 생각해 보자. (&lt;em&gt;Measuring &amp;ldquo;goodness&amp;rdquo; of fit&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;화살이 날라가는 거리에 따른 높이를 측정한 데이터다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Distance (yds) height (ins) height height height
30  0 0 0 0
29 2.25 3.25 4.5 6.5
28 5.25 6.5 6.5 8.75
27 7.5 7.75 8.25 9.25
26 8.75 9.25 9.5 10.5
25 12 12.25 12.5 14.75
24 13.75 16 16 16.5
23 14.75 15.25 15.5 17.5
22 15.5 16 16.6 16.75
21 17 17 17.5 19.25
20 17.5 18.5 18.5 19
15 19.5 20 20.25 20.5
10 18.5 18.5 19 19
5 13 13 13 13
0 0 0 0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
def getTrajectoryData(fileName):
    dataFile = open(fileName, &#39;r&#39;)
    distances = []
    heights1, heights2, heights3, heights4 = [],[],[],[]
    discardHeader = dataFile.readline()
    for line in dataFile:
        d, h1, h2, h3, h4 = line.split()
        distances.append(float(d))
        heights1.append(float(h1))
        heights2.append(float(h2))
        heights3.append(float(h3))
        heights4.append(float(h4))
    dataFile.close()
    return (distances, [heights1, heights2, heights3, heights4])

def tryFits(fName):
    distances, heights = getTrajectoryData(fName)
    distances = pylab.array(distances)*36 # convert yard to
    totHeights = pylab.array([0]*len(distances))
    for h in heights:
        totHeights = totHeights + pylab.array(h)
    pylab.title(&#39;Trajectory of Projectile (Mean of 4 Trials)&#39;)
    pylab.xlabel(&#39;Inches from Launch Point&#39;)
    pylab.ylabel(&#39;Inches Above Launch Point&#39;)
    meanHeights = totHeights/float(len(heights))
    pylab.plot(distances, meanHeights, &#39;bo&#39;)
    a,b = pylab.polyfit(distances, meanHeights, 1)
    altitudes = a*distances + b
    pylab.plot(distances, altitudes, &#39;r&#39;,
               label = &#39;Linear Fit&#39;)
    a,b,c = pylab.polyfit(distances, meanHeights, 2)
    altitudes = a*(distances**2) + b*distances + c
    pylab.plot(distances, altitudes, &#39;g&#39;,
               label = &#39;Quadratic Fit&#39;)
    pylab.legend()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위 코드를 돌려보면 이차함수가 일차함수보다 더 &lt;em&gt;fit&lt;/em&gt; 한 걸 볼 수 있다. 그럼 문제는 매번 그래프로 그릴수도 없고 어떻게 측정할거냐 하는건데, &lt;em&gt;variabilty&lt;/em&gt; 를 이용하는 방법이 있다. 다시 말해 에러가 얼마나 많이 변하냐는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;variability of errors&lt;/em&gt; 는 SEE, 즉 관측 데이터와 예측값 간 차이의 제곱의 합으로 구할 수 있다. 그리고 &lt;em&gt;variability of data&lt;/em&gt; 는 관측값과 관측값의 평균의 차이의 제곱의 합으로 구할 수 있다. 그리고 이 두 변수간 비율로 모델이 얼마나 잘 맞는지를 판단할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?1%20-%20%7B%5Csigma_%7Berr%7D%5E2%20%5Cover%20%5Csigma_%7Bdata%7D%5E2%7D&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;이 값을 &lt;code&gt;R^2&lt;/code&gt; 또는 &lt;em&gt;coefficient of determination&lt;/em&gt; 이라 부른다. 이 값이 &lt;code&gt;1&lt;/code&gt; 에 근접하면 모델이 데이터와 잘 맞고, &lt;code&gt;0&lt;/code&gt; 에 가까우면 거의 안맞는다는 뜻이다.&lt;/p&gt;

&lt;p&gt;그러나 주의해야 할 점이 하나 있다. &lt;code&gt;R^2&lt;/code&gt; 값이 높은 모델이라고 해서 좋은 모델이라는 뜻은 아니다. 지금 현재 가진 데이터에 &lt;em&gt;fit&lt;/em&gt; 된다는 거지, 실제 데이터에 적용하면 어떻게 될지 모른다. &lt;em&gt;overfitting&lt;/em&gt; 할 수도 있다는 이야기다.&lt;/p&gt;

&lt;p&gt;파이썬에서 &lt;code&gt;R^2&lt;/code&gt; 를 구하는 함수를 만들면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def rSquare(measured, estimated):
    &amp;quot;&amp;quot;&amp;quot;measured: one dimensional array of measured values
       estimate: one dimensional array of predicted values&amp;quot;&amp;quot;&amp;quot;
    SEE = ((estimated - measured)**2).sum()
    mMean = measured.sum()/float(len(measured))
    MV = ((mMean - measured)**2).sum()
    return 1 - SEE/MV
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;MIT 6.00.2 2x&lt;/em&gt; in &lt;strong&gt;edx&lt;/strong&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://ko.wikipedia.org/wiki/%EC%A4%91%EC%8B%AC%EA%B7%B9%ED%95%9C%EC%A0%95%EB%A6%AC&#34;&gt;http://ko.wikipedia.org&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://www.financedoctor.co.kr/finance/view.php?f_idx=14587&amp;amp;b_code=8&amp;amp;m_code=0&amp;amp;s_code=0&#34;&gt;http://www.financedoctor.co.kr&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://www.researchgate.net/post/What_is_the_difference_among_Deterministic_model_Stochastic_model_and_Hybrid_model&#34;&gt;www.researchgate.net/&lt;/a&gt;&lt;br /&gt;
(5) &lt;a href=&#34;http://www4.stat.ncsu.edu/~gross/BIO560%20webpage/slides/Jan102013.pdf&#34;&gt;www4.stat.ncsu.edu&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Data Science 3</title>
      <link>https://1ambda.github.io/92/data-analysis/intro-to-data-science-3/</link>
      <pubDate>Sat, 25 Jun 2016 14:20:45 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/intro-to-data-science-3/</guid>
      <description>

&lt;h3 id=&#34;optimization-problems&#34;&gt;Optimization Problems&lt;/h3&gt;

&lt;p&gt;일반적으로 최적화 문제는 크게 두 파트로 구성된다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;An objective funciton that is to be maximized or minimized&lt;/li&gt;
&lt;li&gt;A set of constraint (possibly empty) that must be honored&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;최적화 문제의 예로는&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shortest path&lt;/li&gt;
&lt;li&gt;Traveling salesman&lt;/li&gt;
&lt;li&gt;Bin packaing&lt;/li&gt;
&lt;li&gt;Sequence alignment&lt;/li&gt;
&lt;li&gt;Knapsack&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이런 알려진 문제들을 공부함으로써 &lt;em&gt;problem reduction&lt;/em&gt; 을 이용할 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;knapsack-problem&#34;&gt;Knapsack Problem&lt;/h3&gt;

&lt;p&gt;먼저 &lt;em&gt;greedy approach&lt;/em&gt; 를 사용해 보자. 이 방법을 적용하기 위해서는 무엇이 &lt;em&gt;best&lt;/em&gt; 인지 정해야 한다. &lt;em&gt;value&lt;/em&gt; 가 높은것이나, &lt;em&gt;value/weight&lt;/em&gt; 가 높은것 등 다양한 기준을 세울 수 있다.&lt;/p&gt;

&lt;p&gt;문제를 모델링 해보자. 아이템부터&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Item(object):
    def __init__(self, n, v, w):
        self.name = n
        self.value = v
        self.weight = w

    def getName(self):
        return self.name

    def getValue(self):
        return self.value

    def getWeight(self):
        return self.weight

    def __str__(self):
        result = &#39;&amp;lt;&#39; + self.name + &#39;, &#39; + str(self.value)\
                 + &amp;quot;, &amp;quot; + str(self.weight) + &#39;&amp;gt;&#39;

        return result
        
def buildItems():
    names = [&#39;clock&#39;, &#39;painting&#39;, &#39;radio&#39;,
             &#39;vase&#39;, &#39;book&#39;, &#39;computer&#39;]

    vals = [175, 90, 20, 50, 10, 200]
    weights = [10, 9, 4, 2, 1, 20]

    Items = []

    for i in range(len(vals)):
        Items.append(Item(names[i], vals[i], weights[i]))

    return Items
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;greedy algorithm&lt;/em&gt; 을 구현하면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def greedy(Items, maxWeight, predicate):
    assert type(Items) == list and maxWeight &amp;gt;= 0

    orderedItems = sorted(Items, key=predicate, reverse=True)

    result = []
    totalVal = 0.0
    totalWeight = 0.0
    i = 0

    while totalWeight &amp;lt; maxWeight and i &amp;lt; len(Items):
        if (totalWeight + orderedItems[i].getWeight()) &amp;lt;= maxWeight:
            result.append(orderedItems[i])
            totalWeight += orderedItems[i].getWeight()
            totalVal += orderedItems[i].getValue()

        i += 1

    return (result, totalVal)
   
# predicate
def value(item):
    return item.getValue()


def weightInverse(item):
    return 1.0 / item.getWeight()


def density(item):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;predicate&lt;/em&gt; 를 받아, 이 순서대로 &lt;em&gt;items&lt;/em&gt; 를 정렬 한 뒤 반복문을 돌면서 아이템을 집어넣는다. &lt;code&gt;sorted&lt;/code&gt; 함수는 &lt;em&gt;predicate&lt;/em&gt; 에 따라 정렬 한 뒤 새로운 리스트를 생성한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;orderedItems = sorted(Items, key=predicate, reverse=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이제 테스트 코드를 작성하자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# test
def testGreedy(Items, constraint, pred):
    items, val = greedy(Items, constraint, pred)
    print (&#39;Total value of items taken = &#39; + str(val))
    for item in items:
        print &#39; &#39;, item

def simulation():
    maxWeight = 20
    Items = buildItems()
    print (&#39;Items to choose from&#39;)
    for item in Items:
        print &#39; &#39;, item

    print &#39;by value&#39;
    testGreedy(Items, maxWeight, value)
    print &#39;by 1 / weight&#39;
    testGreedy(Items, maxWeight, weightInverse)
    print &#39;by density&#39;
    testGreedy(Items, maxWeight, density)

simulation()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;결과는&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
Items to choose from
  &amp;lt;clock, 175, 10&amp;gt;
  &amp;lt;painting, 90, 9&amp;gt;
  &amp;lt;radio, 20, 4&amp;gt;
  &amp;lt;vase, 50, 2&amp;gt;
  &amp;lt;book, 10, 1&amp;gt;
  &amp;lt;computer, 200, 20&amp;gt;
  
by value
Total value of items taken = 200.0
  &amp;lt;computer, 200, 20&amp;gt;
  
by 1 / weight
Total value of items taken = 170.0
  &amp;lt;book, 10, 1&amp;gt;
  &amp;lt;vase, 50, 2&amp;gt;
  &amp;lt;radio, 20, 4&amp;gt;
  &amp;lt;painting, 90, 9&amp;gt;

by density
Total value of items taken = 255.0
  &amp;lt;vase, 50, 2&amp;gt;
  &amp;lt;clock, 175, 10&amp;gt;
  &amp;lt;book, 10, 1&amp;gt;
  &amp;lt;radio, 20, 4&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;보면 알겠지만 탐욕적으로 접근했을때 항상 최적의 답안을 찾으리라는 보장이 없다. &lt;del&gt;패가망신&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;전체적인 성능은 &lt;code&gt;sorted&lt;/code&gt; + &lt;code&gt;while&lt;/code&gt; 에서, &lt;code&gt;O(n logn)&lt;/code&gt; 이다. (&lt;code&gt;n&lt;/code&gt; 은 아이템 갯수)&lt;/p&gt;

&lt;h3 id=&#34;0-1-knapsack-problem&#34;&gt;0/1 Knapsack Problem&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;greedy&lt;/em&gt; 는 최적의 답을 제공해 주지 않는다. 어떻게 해야할까? 한가지 방법은,&lt;/p&gt;

&lt;p&gt;벡터 &lt;code&gt;L&lt;/code&gt; 을 각 아이템의 가중치로 채우고, 벡터 &lt;code&gt;V&lt;/code&gt; 를 각 아이템이 선택되었는지, 선택되지 않았는지를 &lt;code&gt;1/0&lt;/code&gt; 으로 표시 한 뒤 &lt;code&gt;V * L&lt;/code&gt; 이 최대가 되는 &lt;code&gt;V&lt;/code&gt; 를 찾으면 된다. 물론 이 값은 무게의 최대치인 &lt;code&gt;W&lt;/code&gt; 를 넘을 수 없다.&lt;/p&gt;

&lt;p&gt;그럼 이제 문제는 다양한 종류의 &lt;code&gt;V&lt;/code&gt; 를 만드는 문제로 치환된다. 일반적으로는 &lt;code&gt;V&lt;/code&gt; 의 수는 &lt;code&gt;2^n&lt;/code&gt; 이겠지만, 여기서는 &lt;code&gt;W&lt;/code&gt; 란 제약조건이 있으므로 그것보다는 작은 수가 될 것이다.&lt;/p&gt;

&lt;p&gt;넘어가기 전에 잠깐! 수의 크기에 대해 감을 잡고 넘어가자. 요즘 &lt;em&gt;CPU&lt;/em&gt; 는 &lt;code&gt;1GHz&lt;/code&gt; 는 그냥 넘으니까, 1초의 10억번이 넘는 연산을 할 수 있다. 한 작업에 대해 수백개의 명령이 필요하므로, 1초에 수백만의 작업을 할 수 있다.&lt;/p&gt;

&lt;p&gt;수백만은 얼마나 큰 수일까? &lt;code&gt;10! = 3628800&lt;/code&gt; 이다. 대략 11 ~ 10 개를 배열해도 백만가지의 순열이 만들어진다. 그리고 &lt;code&gt;2^20 = 1048576&lt;/code&gt; 이므로 원소가 스무개인 집합의 부분집합이 백만개정도라 보면 된다.&lt;/p&gt;

&lt;p&gt;따라서 최적해를 찾고자 할때는 &lt;code&gt;10!&lt;/code&gt;, &lt;code&gt;2^22&lt;/code&gt; 정도가 몇초 내외의 감당할만한 계산시간이라 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;brute-force-approach&#34;&gt;Brute Force Approach&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;power set&lt;/em&gt; 을 만들어 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# brute force
def int2bin(n, digit):
    assert type(n) == int and type(digit) == int
    assert n &amp;gt;= 0 and n &amp;lt; 2 ** digit

    # binary string
    binStr = &#39;&#39;

    while n &amp;gt; 0:
        binStr = str(n % 2) + binStr
        n = n // 2

    while digit - len(binStr) &amp;gt; 0:
        binStr = &#39;0&#39; + binStr

    return binStr


def powerSets(Items):
    count = 2 ** len(Items)
    binStrs = []

    for i in range(count):
        binStrs.append(int2bin(i, len(Items)))

    powerSet = []
    for bs in binStrs:
        elem = []
        for i in range(len(bs)):
            if bs[i] == &#39;1&#39;:
                elem.append(Items[i])
        powerSet.append(elem)

    return powerSet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이제 테스트 함수를 작성하자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def optimalItems(powerSet, constraint, getValue, getWeight):
    optimalSet = None
    optimalValue = 0.0

    for Items in powerSet:
        ItemsValue = 0.0
        ItemsWeight = 0.0

        for item in Items:
            ItemsValue += getValue(item)
            ItemsWeight += getWeight(item)

        if ItemsWeight &amp;lt;= constraint and ItemsValue &amp;gt; optimalValue:
            optimalValue = ItemsValue
            optimalSet = Items

    return (optimalSet, optimalValue)


def bruteForceSolution():
    Items = buildItems()
    pset = buildPowerSet(Items)

    items, value = optimalItems(pset, 20,
                                Item.getValue,
                                Item.getWeight)

    print (&#39;brute force : &#39; + str(value))
    for item in items:
        print &#39; &#39;, item

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;돌려보면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;bruteForceSolution()

brute force : 275.0
  &amp;lt;clock, 175, 10&amp;gt;
  &amp;lt;painting, 90, 9&amp;gt;
  &amp;lt;book, 10, 1&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;다 좋은데, 아이템의 개수가 많아지면 &lt;code&gt;2^n&lt;/code&gt; 으로 숫자가 커지므로 계산 비용이 어마어마하게 커진다. 다른 방법을 찾아보자.&lt;/p&gt;

&lt;h3 id=&#34;decision-tree&#34;&gt;Decision Tree&lt;/h3&gt;

&lt;p&gt;트리의 각 &lt;em&gt;depth&lt;/em&gt; 를 아이템으로 표현하고, &lt;em&gt;left node&lt;/em&gt; 를 &lt;code&gt;1 (selected)&lt;/code&gt;, &lt;em&gt;right node&lt;/em&gt; 를 &lt;code&gt;0 (unselected)&lt;/code&gt; 로 정해 각 노드마다 전체 &lt;em&gt;value, weight&lt;/em&gt; 를 기록하도록 하면 &lt;em&gt;search space&lt;/em&gt; 를 상당히 줄일 수 있다. 왜냐하면 특정 아이템을 선택 한 후 무게를 초과하면, 그 하위 트리는 살펴보지 않아도 되기 때문이다.&lt;/p&gt;

&lt;p&gt;이 트리를 &lt;strong&gt;decision tree&lt;/strong&gt; 라 부른다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# decision tree

def maxVal(items, avail):
    if items == [] or avail == 0:
        result = (0, ())
    elif items[0].getWeight() &amp;gt; avail:
        # do not take
        result = maxVal(items[1:], avail)
    else:
        current = items[0]
        # left branch : take the item
        leftValue, leftItems = maxVal(items[1:],
                                      avail - current.getWeight())
        leftValue += current.getValue()

        # right branch : do not take the item
        rightValue, rightItems = maxVal(items[1:],
                                        avail)

        if leftValue &amp;gt; rightValue:
            result = (leftValue, leftItems + (current,))
        else:
            result = (rightValue, rightItems)

    return result


def decisionTreeSolution():
    Items = buildItems()
    value, selected = maxVal(Items, 20)

    for item in selected:
        print item

    print (&#39;decisition tree value : &#39; + str(value))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;실행하면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# decisionTreeSolution()

&amp;lt;book, 10, 1&amp;gt;
&amp;lt;painting, 90, 9&amp;gt;
&amp;lt;clock, 175, 10&amp;gt;
decisition tree value : 275
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;모든 &lt;em&gt;power set&lt;/em&gt; 을 살펴보지 않는다는 점에서 맘에 들지만, 가방의 용량이 상당히 크다면 &lt;em&gt;power set&lt;/em&gt; 처럼 &lt;code&gt;2^n&lt;/code&gt; 으로 증가할 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;trade-off&#34;&gt;Trade Off&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;greedy&lt;/em&gt; 는 매 선택마다 최선을 택함으로써 &lt;em&gt;locally optimal&lt;/em&gt; 을 찾지만 이게 &lt;em&gt;global optimal&lt;/em&gt; 을 의미하진 않는다. 대신, 상당히 납득할만한 답안을 빠른 시간 안에 줄 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;memoization&#34;&gt;Memoization&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;decision&lt;/em&gt; 트리를 잘 보면 &lt;em&gt;sub-problem&lt;/em&gt; 에서 같은 계산을 여러번 하는걸 볼 수 있다. 예를 들어 &lt;code&gt;{a, b, c, d}&lt;/code&gt; 의 아이템이 있을때 &lt;code&gt;{a, c, d}&lt;/code&gt; 와 &lt;code&gt;{b, c, d}&lt;/code&gt; 는 다른 분기인데, 둘 다 &lt;code&gt;{c, d}&lt;/code&gt; 를 계산하고 있다.&lt;/p&gt;

&lt;p&gt;이 문제는 피보나치에서도 발견할 수 있는데,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def fib(n):
    assert type(n) == int and n &amp;gt;= 0

    if n == 0 or n == 1:
        return 1
    else:
        return fib(n-1) + fib(n-2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;fib(n-1)&lt;/code&gt; 에서 &lt;code&gt;fib(n-2)&lt;/code&gt; 를 계산하니까, &lt;code&gt;fib(n-2)&lt;/code&gt; 를 두번 계산하는 셈이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.cs.cmu.edu/~adamchik/15-121/lectures/Recursions/pix/fib.bmp&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;https://www.cs.cmu.edu/~adamchik&#34;&gt;https://www.cs.cmu.edu/~adamchik&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;한번 계산한 결과는 저장해 놓고 다음에 쓰는 &lt;em&gt;memoization&lt;/em&gt; 을 이용해 보자.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Memoization:&lt;/strong&gt; the first time we compute a function, keep track of the value; any subsequent time, just look up the value&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def fastFib(n, memo):
    assert type(n) == int and n &amp;gt;= 0

    if n == 0 or n == 1:
        return 1

    if n in memo:
        return memo[n]

    result = fastFib(n-1, memo) + fastFib(n-2, memo)
    memo[n] = result
    return result


def testFastFib(n):
    assert type(n) == int and n &amp;gt;= 0

    for i in range(n):
        print (&#39;fast fib of&#39;, i, &#39;=&#39;, fastFib(i, {}))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;memoization&lt;/em&gt; 은 &lt;em&gt;dynamic programming&lt;/em&gt; 등에 사용할 수 있다.&lt;/p&gt;

&lt;h3 id=&#34;graph&#34;&gt;Graph&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;optimization problem&lt;/em&gt; 은 &lt;em&gt;search problem&lt;/em&gt; 이라 볼 수 있다. 다양한 탐색 공간 속에서 최적의 답을 검색해 나가는 문제와 동일하기 때문이다.&lt;/p&gt;

&lt;p&gt;그래프를 모델링 해 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Node(object):
    def __init__(self, name):
        self.name = str(name)

    def getName(self):
        return self.name

    def __str__(self):
        return self.name


class Edge(object):
    def __init__(self, src, dest):
        self.src = src
        self.dest = dest

    def getSrc(self):
        return self.src

    def getDest(self):
        return self.dest

    def __str__(self):
        return str(self.src) + &#39; -&amp;gt; &#39; + str(self.dest)


class WeightedEdge(Edge):
    def __init__(self, src, dest, weight=1.0):
        self.src = src
        self.dest = dest
        self.weight = weight

    def getWeight(self):
        return self.weight

    def __str__(self):
        return str(self.src) + &#39; -&amp;gt; (&#39;\
            + str(self.weight) + &#39;)&#39;\
            + str(self.dest)


class Digraph(object):
    def __init__(self):
        self.nodes = set([])
        self.edges = {}

    def addNode(self, node):
        if node in self.nodes:
            raise ValueError(&#39;duplicated node&#39;)
        else:
            self.nodes.add(node)
            self.edges[node] = []

    def addEdge(self, edge):
        src = edge.getSrc()
        dest = edge.getDest()

        if not(src in self.nodes and dest in self.nodes):
            raise ValueError(&#39;unknown node&#39;)

        self.edges[src].append(dest)

    def childrenOf(self, node):
        return self.edges[node]

    def hasNode(self, node):
        return node in self.nodes

    def __str__(self):
        res = &#39;&#39;

        for src in self.edges:
            for dest in self.edges[src]:
                res = res + str(src) + &#39; -&amp;gt; &#39; + str(dest) + &#39;\n&#39;

        return res[:-1]


# undirected
class Graph(Digraph):
    def addEdge(self, edge):
        Digraph.addEdge(self, edge)
        rev = Edge(edge.getDest(), edge.getSrc())
        Digraph.addEdge(self, rev)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;그래프 최적화 문제의 예는&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shortest path&lt;/li&gt;
&lt;li&gt;Shortest weighted path&lt;/li&gt;
&lt;li&gt;Cliques&lt;/li&gt;
&lt;li&gt;Min cut&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 테스트 그래프를 만들어 보자.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def makeEdge(nodes, src, dest):
    return Edge(nodes[src], nodes[dest])


def testGraph():
    nodes = []

    # index will be the name of each node
    for idx in range(6):
        nodes.append(Node(idx))

    g = Digraph()

    for n in nodes:
        g.addNode(n)

    srcs = [0, 1, 2, 2, 3, 3, 0, 1, 3, 4]
    dests = [1, 2, 3, 4, 4, 5, 2, 0, 1, 0]

    for (s, d) in zip(srcs, dests):
        g.addEdge(makeEdge(nodes, s, d))

    print g
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;실행하면 이런 그래프를 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/L19_graph.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;testGraph()

0 -&amp;gt; 1
0 -&amp;gt; 2
1 -&amp;gt; 2
1 -&amp;gt; 0
2 -&amp;gt; 3
2 -&amp;gt; 4
3 -&amp;gt; 4
3 -&amp;gt; 5
3 -&amp;gt; 1
4 -&amp;gt; 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dfs&#34;&gt;DFS&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# assumes graph is a directed graph
def DFS(graph, start, end, path=[]):
    path = path + [start]

    if start == end:
        return path

    for node in graph.childrenOf(start):
        if node not in path:
            newPath = DFS(graph, node, end, path)

            if newPath is not None:
                return newPath
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;테스트 코드를 돌려보면 알겠지만, 최단경로를 돌려주진 않는다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def makeEdge(nodes, src, dest):
    return Edge(nodes[src], nodes[dest])


def testGraph():
    nodes = []

    # index will be the name of each node
    for idx in range(6):
        nodes.append(Node(str(idx)))

    g = Digraph()

    for n in nodes:
        g.addNode(n)

    srcs = [0, 1, 2, 2, 3, 3, 0, 1, 3, 4]
    dests = [1, 2, 3, 4, 4, 5, 2, 0, 1, 0]

    for (s, d) in zip(srcs, dests):
        g.addEdge(makeEdge(nodes, s, d))

    return g, nodes

def visit():
    g, nodes = testGraph()
    path = DFS(g, nodes[0], nodes[5], [])

    for p in path:
        print p

visit()

0
1
2
3
5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;처음 찾은 목적지까지의 거리보다 더 짧은 목적지까지의 거리만을 탐색하는 알고리즘을 고려해보자. 가장 먼저 찾은 목적지까지거리를 &lt;code&gt;shortest&lt;/code&gt; 에 저장하고, 이것보다 짧은 경로만 탐색한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# assumes graph is a directed graph
def shortestDFS(graph, start, end, path=[], shortest=None):
    path = path + [start]

    if start == end:
        return path

    for node in graph.childrenOf(start):
        if node not in path:
            if shortest is None or len(path) &amp;lt; len(shortest):
                newPath = shortestDFS(graph, node, end, path, shortest)
                if newPath is not None:
                    shortest = newPath

    return shortest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이부분이 핵심이다&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;if shortest is None or len(path) &amp;lt; len(shortest):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;실제로 돌려보면 &lt;code&gt;0, 2, 3, 5&lt;/code&gt; 로 최단경로를 돌려준다.&lt;/p&gt;

&lt;h3 id=&#34;clique&#34;&gt;Clique&lt;/h3&gt;

&lt;p&gt;각 점이 나머지 모든 점과 연결된 그래프를 &lt;em&gt;clique&lt;/em&gt; 라 부르는데, 재미난 특징이 몇 개 있다.&lt;/p&gt;

&lt;p&gt;(1) 모든 &lt;em&gt;edge&lt;/em&gt; 의 수는 &lt;code&gt;n * (n - 1) / 2&lt;/code&gt; 다.&lt;br /&gt;
(2) 임의의 두 점 &lt;code&gt;A, B&lt;/code&gt; 에 대해 길이가 &lt;code&gt;1 &amp;lt;= m &amp;lt;= (n-1)&lt;/code&gt; 인 모든 경로는 &lt;code&gt;(n-2)! / (n-m-1)!&lt;/code&gt; 이다.&lt;br /&gt;
(3) &lt;code&gt;(2)&lt;/code&gt; 를 이용하면, 모든 경로를 탐색할 경우의 퍼포먼스는 &lt;code&gt;O((n-2)!)&lt;/code&gt; 이다. 여기서 &lt;code&gt;1/0! + 1/1! + 1/2! ... + 1/n! &amp;lt;= e&lt;/code&gt;, &lt;code&gt;e&lt;/code&gt; 는 상수&lt;/p&gt;

&lt;h3 id=&#34;bfs&#34;&gt;BFS&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def BFS(graph, start, end, q=[]):
    init = [start]
    q.append(init)

    while len(q) != 0:
        # get a path from q
        current = q.pop(0)
        lastNode = current[len(current) - 1]
        if lastNode == end:
            return current

        for nextNode in graph.childrenOf(lastNode):
            if nextNode not in current:
                path = current + [nextNode]
                q.append(path)

    return None
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;MIT 6.00.2 2x&lt;/em&gt; in &lt;strong&gt;edx&lt;/strong&gt;&lt;br /&gt;
(2) &lt;a href=&#34;https://www.cs.cmu.edu/~adamchik/15-121/lectures/Recursions/recursions.html&#34;&gt;https://www.cs.cmu.edu/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Data Science 4</title>
      <link>https://1ambda.github.io/92/data-analysis/intro-to-data-science-4/</link>
      <pubDate>Sat, 25 Jun 2016 14:20:46 +0900</pubDate>
      
      <guid>https://1ambda.github.io/92/data-analysis/intro-to-data-science-4/</guid>
      <description>

&lt;p&gt;그래프는 네트워크를 표현하는 것 뿐만 아니라, &lt;em&gt;state&lt;/em&gt; 를 표현할 수 있다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Nodes represent states of system&lt;/li&gt;
&lt;li&gt;Edges represent actions that cause a change of state&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러면 그래프 문제는&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Finding sequence of actions to convert system to desired state&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/8puzzle_example.svg/2000px-8puzzle_example.svg.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://en.wikipedia.org&#34;&gt;http://en.wikipedia.org&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;8 puzzle&lt;/em&gt; 도 이렇게 그래프 문제로 변환할 수 있다. 그런데, &lt;code&gt;9! = 362880&lt;/code&gt; 의 &lt;em&gt;node&lt;/em&gt; 와 노드당 &lt;code&gt;2~4&lt;/code&gt; 개의 &lt;em&gt;edge&lt;/em&gt; 를 가지고 있으므로 문제의 사이즈가 어마어마하게 커진다. 거의 백만개의 &lt;em&gt;edge&lt;/em&gt; 를 가진다.&lt;/p&gt;

&lt;h3 id=&#34;an-implicit-graph&#34;&gt;An Implicit Graph&lt;/h3&gt;

&lt;p&gt;그래서, 처음부터 모든 &lt;em&gt;state&lt;/em&gt; 를 만들기 보다는 초기 상태로부터 &lt;em&gt;action&lt;/em&gt; 을 취해가면서 &lt;em&gt;desired state&lt;/em&gt; 를 찾는 방식으로 해결하자.&lt;/p&gt;

&lt;p&gt;퍼즐의 상태를 문자열로 표현하면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class puzzle(object):
    def __init__(self, order):
        self.label = order

        for i in range(9):
            if order[i] == &#39;0&#39;:
                self.spot = i
                return None

    def transition(self, to):
        currentLabel = self.label
        blank = self.spot
        # current slot value which will be filled with blank
        current = str(currentLabel[to]) 
        nextLabel = &#39;&#39;

        for i in range(9):
            if i == to:
                nextLabel += &#39;0&#39;
            elif i == blank:
                nextLabel += current
            else:
                nextLabel += str(currentLabel[i])

        return puzzle(nextLabel)

    def __str__(self):
        return &amp;quot;{0} {1} {2}\n{3} {4} {5}\n{6} {7} {8}\n&amp;quot;.format(self.label[0],
                                                                self.label[1],
                                                                self.label[2],
                                                                self.label[3],
                                                                self.label[4],
                                                                self.label[5],
                                                                self.label[6],
                                                                self.label[7],
                                                                self.label[8])

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;그리고 각 슬롯의 이동 가능한 방향을 딕셔너리로 만들면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;shiftDict = {}
shiftDict[0] = [1, 3]
shiftDict[1] = [0, 2, 4]
shiftDict[2] = [1, 5]
shiftDict[3] = [0, 4, 6]
shiftDict[4] = [1, 3, 5, 7]
shiftDict[5] = [2, 4, 8]
shiftDict[6] = [3, 7]
shiftDict[7] = [4, 6, 8]
shiftDict[8] = [5, 7]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이제 &lt;em&gt;state&lt;/em&gt; 를 변경해 나아가면서 그래프를 만들 수 있다 &lt;em&gt;state&lt;/em&gt;, 즉 &lt;em&gt;node&lt;/em&gt; 를 변경해 나아가면서 그래프를 탐색하는 방법은 2개가 있는데, &lt;em&gt;BFS, DFS&lt;/em&gt; 다. 코드는 거의 유사하다. 스택을 쓰냐 큐를 쓰냐의 차이다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def notInPath(state, path):
    for s in path:
        if s.label == state.label:
            return False

    return True


def BFS(start, end, q=[]):
    initPath = [start]
    q.append(initPath)

    while len(q) != 0:
        currentPath = q.pop(0)
        lastState = currentPath[len(currentPath) - 1]

        if lastState.label == end.label:
            return currentPath

        for s in shifts[lastState.spot]:
            nextState = lastState.transition(s)

            if notInPath(nextState, currentPath):
                nextPath = currentPath + [nextState]
                q.append(nextPath)

    return None


def DFS(start, end, stack=[]):
    initPath = [start]
    stack.insert(0, initPath)

    while len(stack) != 0:
        currentPath = stack.pop(0)
        lastState = currentPath[len(currentPath) - 1]

        if lastState.label == end.label:
            return currentPath

        for s in shifts[lastState.spot]:
            nextState = lastState.transition(s)

            if notInPath(nextState, currentPath):
                nextPath = currentPath + [nextState]
                stack.insert(0, nextPath)

    return None
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;테스트는&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def test():
    goal = puzzle(&#39;012345678&#39;)
    test1 = puzzle(&#39;125638047&#39;)
    answer = BFS(test1, goal)

    for state in answer:
        print state
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;비교해 보면 &lt;em&gt;BFS&lt;/em&gt; 가 훨씬 빠르다.&lt;/p&gt;

&lt;h3 id=&#34;maximum-cliques&#34;&gt;Maximum Cliques&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;For some problems, finding sugraphs of a graph that are complete can be important&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 &lt;em&gt;complete&lt;/em&gt; 란 노드가 다른 노드 모두와 연결되어 있다는 뜻이다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Finding sets of people in a social network that all know each other&lt;/li&gt;
&lt;li&gt;Finin subjects in an infected population that all have had contact with one another&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;두 번째 예제는 &lt;em&gt;complete subgraph&lt;/em&gt; 를 찾는 것의 중요성을 잘 보여준다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;clique&lt;/em&gt; 는 communication networks, gene expression data 등에도 이용할 수 있다.&lt;/p&gt;

&lt;h4 id=&#34;brute-force&#34;&gt;Brute Force&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;maximum clique&lt;/em&gt; 문제를 &lt;em&gt;brute force&lt;/em&gt; 로 풀려면, 가능한 모든 서브 그래프를 찾고, &lt;em&gt;clique&lt;/em&gt; 인지 판별하면서 큰 사이즈의 &lt;em&gt;clique&lt;/em&gt; 를 유지하면 된다.&lt;/p&gt;

&lt;p&gt;모든 서브 그래프를 찾을려면, &lt;a href=&#34;http://1ambda.github.io/edx-600-2x-3/&#34;&gt;지난시간&lt;/a&gt; 에 &lt;em&gt;knapsack problem&lt;/em&gt; 을 풀 때 이용했던 &lt;em&gt;power set&lt;/em&gt; 을 도입하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;knapsack&lt;/em&gt; 문제도 &lt;em&gt;brute force&lt;/em&gt; 로 풀기 위해서 가능한 모든 집합을 구했었다. 후에는 &lt;em&gt;search space&lt;/em&gt; 를 줄이기 위해 &lt;em&gt;decision tree&lt;/em&gt; 를 도입하고, 반복 계산을 피하기 위해 &lt;em&gt;memoization&lt;/em&gt; 이용했었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;clique&lt;/em&gt; 문제도 마찬가지로 각 노드를 숫자로 표현할 수 있으므로 &lt;code&gt;n&lt;/code&gt; 자리의 이진수를 만들어 &lt;em&gt;power set&lt;/em&gt; 을 생성할 수 있다. 지난 시간에 이용했었던 대강의 로직은&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;count = 2 ** len(nodes)

binStrs = []

for i in range(count):
  binStrs.append(int2bin(i, len(nodes))
  
powerSet = []

for bs in binStrs:
  subGraph = []
  
  for i range(len(bs)):
    if bs[i] == &#39;1&#39;:
      subGraph.append(nodes[i])
      
  powerSet.append(subGraph)
  
return powerSet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이번시간엔 재귀를 이용해서 &lt;em&gt;power set&lt;/em&gt; 을 구해보자. 하스켈로 로직을 표현하면,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;powerset [] = [[]]
powerset (x:xs) = xs&#39; ++ map (x:) xs&#39;
  where xs&#39; = powerset xs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;따라서 파이선 코드는&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def powerSet(xs):
    if len(xs) == 0:
        return [[]]

    else:
        # xs = head:tail
        head = xs[0]
        tail = xs[1:]

        prev = powerSet(tail)
        incl = map(lambda sub: sub + [head], prev)
        return prev + incl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이걸 이용해 모든 &lt;em&gt;sub graph&lt;/em&gt; 를 만들고, &lt;em&gt;clique&lt;/em&gt; 인지 검사하는 함수를 만들면&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def powerGraph(graph):
    nodes = []

    for n in graph.nodes:
        nodes.append(n)

    pSet = powerSet(nodes)
    return pSet


def isClique(graph, subGraph):
    for n in subGraph:
        for m in subGraph:
            if not m == n:
                if n not in graph.childrenOf(m):
                    return False

    return True


def maxClique(graph):
    maximum = None
    maxLen = 0
    subGraphs = powerGraph(graph)

    for sub in subGraphs:
        if isClique(graph, sub):
            if len(sub) &amp;gt; maxLen:
                maximum = sub
                maxLen = len(sub)

    return maximum
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/clique.py&#34;&gt;지난시간에 작성했던 Graph 코드&lt;/a&gt; 는 여기로,&lt;/p&gt;

&lt;p&gt;테스트 코드는&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
def testGraph():
    nodes = []
    for name in range(5):
        nodes.append(Node(str(name)))
    g = Graph()
    for n in nodes:
        g.addNode(n)
    g.addEdge(Edge(nodes[0],nodes[1]))
    g.addEdge(Edge(nodes[1],nodes[2]))
    g.addEdge(Edge(nodes[2],nodes[0]))
    g.addEdge(Edge(nodes[2],nodes[4]))
    g.addEdge(Edge(nodes[4],nodes[3]))
    return g


trialGraph = testGraph()
myClique = maxClique(trialGraph)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;myClique&lt;/code&gt; 를 출력하면, &lt;em&gt;node&lt;/em&gt; 가 3개 나와야 한다.&lt;/p&gt;

&lt;h3 id=&#34;machine-learning&#34;&gt;Machine Learning&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Automating automation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Computer programs can automatically follow rules.&lt;br /&gt;
How do we determine these rules automatically?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ML fources on getting computers to program themselves&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let the data do the work.&lt;br /&gt;
Automatically generate programs that create useful outputs from data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;전통적인 프로그래밍에선 &lt;em&gt;data&lt;/em&gt; 와 &lt;em&gt;program&lt;/em&gt; 을 넣고 &lt;em&gt;output&lt;/em&gt; 을 기대했다면,&lt;/p&gt;

&lt;p&gt;&lt;em&gt;machine learning&lt;/em&gt; 에서는 &lt;em&gt;data, output&lt;/em&gt;  을 넣고 &lt;em&gt;program&lt;/em&gt; 을 만든다. 이 프로그램은 다음번에 &lt;em&gt;data&lt;/em&gt; 가 들어왔을 때 &lt;em&gt;output&lt;/em&gt; 을 만들어 낸다. 다시 말해서 머신러닝은 일종의 &lt;em&gt;generalization&lt;/em&gt; 이다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Supervised&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Given a set of feature/label pairs, find a rule that predicts the label associated with a previously unseen input&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Unsupervied&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Given a set of feature vectors (without labels), group them into &amp;ldquo;natural clusters&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;예를 들어 다음은 &lt;em&gt;supervised learning&lt;/em&gt; 이다.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A group of 1000 students are asked for a sample of their handwriting. Researchers make pairs of (handwritten text, typed text). Given a new handwriting sample from a new student, we want to determine what the typed version of the handwriting sample would be.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;clustering&#34;&gt;Clustering&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Low intra-cluster dissimilarity&lt;/li&gt;
&lt;li&gt;High inter-cluster dissimilarity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;간단하긴 한데, 연산 비용이 비싸다. &lt;em&gt;k-means&lt;/em&gt; 와 &lt;em&gt;hierarchical clustering&lt;/em&gt; 을 살펴보자.&lt;/p&gt;

&lt;h4 id=&#34;hierarchical-clustering&#34;&gt;Hierarchical Clustering&lt;/h4&gt;

&lt;p&gt;(1) Start by assigning each item to a cluster, so that if you have &lt;code&gt;N&lt;/code&gt; items, you now have &lt;code&gt;N&lt;/code&gt; clusters, each containing just one item.&lt;/p&gt;

&lt;p&gt;(2) Find the closest (most similar) pair of clusters and merge them into a single cluster, so that now you have one cluster fewer.&lt;/p&gt;

&lt;p&gt;(3) Continue the process until all items are clustered into a single cluster of size &lt;code&gt;N&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.alanfielding.co.uk/multivar/images/dend5.gif&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://www.alanfielding.co.uk&#34;&gt;http://www.alanfielding.co.uk&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Linkage Criteria&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;in &lt;strong&gt;single-linkage&lt;/strong&gt; clustering (also called the &lt;em&gt;connectedness&lt;/em&gt; or &lt;em&gt;minimum&lt;/em&gt; method), we consider the distance between one cluster and another cluster to be equal to the shortest distance from any member of one cluster to any member of th other cluster&lt;/p&gt;

&lt;p&gt;in &lt;strong&gt;complete-linkage&lt;/strong&gt; clustering (also called the &lt;em&gt;diameter&lt;/em&gt; or &lt;em&gt;maximum&lt;/em&gt; method), we consider the distance between one cluster and another cluster to be equal to th greatest distance from any member of one cluster to any member of the other cluster&lt;/p&gt;

&lt;p&gt;in &lt;strong&gt;average-linkage&lt;/strong&gt;, we consider the distance between one cluster and another cluster to be equal to th average distance from any member of one cluster to any member of the other cluster. A slight variant of this uses the median instead of the mean&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;single-linkage&lt;/em&gt; 클러스터 간 거리를 두 클러스터 사이의 최소 거리로, &lt;em&gt;complete-linkage&lt;/em&gt; 는 최대 거리로, &lt;em&gt;average-linkage&lt;/em&gt; 는 평균 거리로 본다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    def singleLinkageDist(self, other):
        &amp;quot;&amp;quot;&amp;quot; Returns the float distance between the points that 
        are closest to each other, where one point is from 
        self and the other point is from other. Uses the 
        Euclidean dist between 2 points, defined in Point.&amp;quot;&amp;quot;&amp;quot;
        minDist = float(&amp;quot;inf&amp;quot;)
        for p1 in self.points:
            for p2 in other.points:
                dist = p1.distance(p2)
                if dist &amp;lt; minDist:
                    minDist = dist

        return minDist

    def maxLinkageDist(self, other):
        &amp;quot;&amp;quot;&amp;quot; Returns the float distance between the points that 
        are farthest from each other, where one point is from 
        self and the other point is from other. Uses the 
        Euclidean dist between 2 points, defined in Point.&amp;quot;&amp;quot;&amp;quot;
        maxDist = float(0)
        for p1 in self.points:
            for p2 in other.points:
                dist = p1.distance(p2)
                if dist &amp;gt; maxDist:
                    maxDist = dist

        return maxDist

    def averageLinkageDist(self, other):
        &amp;quot;&amp;quot;&amp;quot; Returns the float average (mean) distance between all 
        pairs of points, where one point is from self and the 
        other point is from other. Uses the Euclidean dist 
        between 2 points, defined in Point.&amp;quot;&amp;quot;&amp;quot;
        dists = []
        for p1 in self.points:
            for p2 in other.points:
                dists.append(p2.distance(p1))

        return sum(dists) / float(len(dists))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;k-means-clustering&#34;&gt;K-Means Clustering&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://latex.codecogs.com/gif.latex?%5Csum_%7Bc%3D1%7D%5EK%20%5Csum_%7Bx%5C%20%5Cin%5C%20c%7D%20%5Cleft%20%5C%7C%20x%20-%20%5Cmu_c%20%5Cright%20%5C%7C%5E2&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Final result can depend upon initial centroids&lt;/li&gt;
&lt;li&gt;Greedy algorihm can find different local optima&lt;/li&gt;
&lt;li&gt;Choosing the &lt;em&gt;wrong&lt;/em&gt; &lt;code&gt;K&lt;/code&gt; can lead to nonsense&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use priori knowledge about application domain&lt;/li&gt;
&lt;li&gt;Try multiple times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;hierarchical&lt;/em&gt; 과 비교하면&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Hierarchical looks at different numbers of clusters From 1 to n&lt;/p&gt;

&lt;p&gt;K-means looks at many ways of createing k clusters.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;hierarchical&lt;/em&gt; 은 좀 느린편이고 &lt;em&gt;deterministic&lt;/em&gt; 이다. 반면 &lt;em&gt;K-means&lt;/em&gt; 는 비교적 빠르고, &lt;em&gt;stochastic&lt;/em&gt; 이다.&lt;/p&gt;

&lt;p&gt;아래는 &lt;em&gt;K-means&lt;/em&gt; 로 분류하기 어려운 몇 가지 예제들&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/k1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://courses.edx.org/c4x/MITx/6.00.2_2x/asset/k3.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;https://courses.edx.org/c4x/MITx/6.00.2_2x&#34;&gt;https://courses.edx.org/c4x/MITx/6.00.2_2x&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;h3 id=&#34;scaling&#34;&gt;Scaling&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;odd ratio&lt;/em&gt; 는 &lt;em&gt;acutal / expected&lt;/em&gt; 값인데, 1에 가까우면 클러스터링이 랜덤에 비해 별로 나을게 없다는 소리다. (좋은 클러스터링이 아니란 뜻)&lt;/p&gt;

&lt;p&gt;강의에서 나온 환자 예제는 이 값이 1에 근접하는데, 이는 &lt;em&gt;HR, age&lt;/em&gt; 값이 단위가 커서 이 &lt;em&gt;feature&lt;/em&gt; 에 영향을 많이 받기 때문이다.&lt;/p&gt;

&lt;p&gt;따라서 평균 0, 표준편차 1을 가지도록 모든 &lt;em&gt;feature&lt;/em&gt; 를 스케일링 하고 다시 돌리면  &lt;em&gt;odd ratio&lt;/em&gt; &lt;code&gt;0.18, 1.45&lt;/code&gt; 의 두 클러스터를 얻을 수 있다. 하나는 &lt;em&gt;heart attack&lt;/em&gt; 이 잘 안올 환자, 다른 하나는 위험한 환자.&lt;/p&gt;

&lt;p&gt;아래 예제는 스케일링 하면 안되는 경우&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The percent concentration of a virus in a random sampling of healthy and unhealthy people.&lt;/p&gt;

&lt;p&gt;The angle of refraction of light (degree that light bends) observed when entering water vs. glass vs a diamond.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;statistical-fallacies&#34;&gt;Statistical Fallacies&lt;/h3&gt;

&lt;p&gt;세상에는 3 종류의 거짓말이 있다고 한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LIES&lt;/li&gt;
&lt;li&gt;DAMNED LIES&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;STATISTICS&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/638px-Anscombe%27s_quartet_3.svg.png&#34; alt=&#34;&#34; /&gt;
&lt;p align=&#34;center&#34;&gt;(&lt;a href=&#34;http://en.wikipedia.org/wiki/Anscombe&#39;s_quartet&#34;&gt;http://en.wikipedia.org/wiki/Anscombe&#39;s_quartet&lt;/a&gt;)&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;보면 데이터가 정말 다르게 분포해 있지만, &lt;em&gt;mean, variance, correlation, linear regression&lt;/em&gt; 이 동일하다.&lt;/p&gt;

&lt;p&gt;흔한 오류 중 하나로, &lt;em&gt;correlation =&amp;gt; causation&lt;/em&gt; 도 있다.&lt;/p&gt;

&lt;p&gt;학교가 문을 여는 시즌에, 독감이 많이 유행한다고 해서 상관 관계가 있다고 단정짓긴 어렵다. 어쩌면 다른 요인이 있을지도 모른다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;non response bias&lt;/em&gt; 도 생각해봐야 한다. 예를 들어 전화조사에서, 응답자와 비응답자의 정치 성향이 다를 수도 있다는 것이다.&lt;/p&gt;

&lt;h3 id=&#34;data-enhancement&#34;&gt;Data Enhancement&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;texas sharpshotter fallacy (텍사스 명사수의 오류)&lt;/em&gt; 란 것도 있다. &lt;a href=&#34;http://en.wikipedia.org/wiki/Texas_sharpshooter_fallacy&#34;&gt;위키&lt;/a&gt; 에서 인용하면&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The Texas sharpshooter fallacy is an informal fallacy which is committed when differences in data are ignored, but similarities are stressed.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;텍사스의 총잡이가 헛간에 총을 마구마구 쏜 후, 밀집한 지역 중심으로 원을 그리면! 그 총잡이는 명사수처럼 보이게 된다는 것에서 유래한 오류다.&lt;/p&gt;

&lt;p&gt;바꿔 말하면, 우연도 필연으로 해석한다는 것이다. (존재하지도 않는 패턴을 찾으려고 하는것에 비유하기도 함)&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;(1) &lt;em&gt;MIT 6.00.2 2x&lt;/em&gt; in &lt;strong&gt;edx&lt;/strong&gt;&lt;br /&gt;
(2) &lt;a href=&#34;http://en.wikipedia.org/wiki/Heuristic_function&#34;&gt;Wikipedia: Huristic Function&lt;/a&gt;&lt;br /&gt;
(3) &lt;a href=&#34;http://www.alanfielding.co.uk/multivar/dend.htm&#34;&gt;http://www.alanfielding.co.uk&lt;/a&gt;&lt;br /&gt;
(4) &lt;a href=&#34;http://en.wikipedia.org/wiki/Anscombe&#39;s_quartet&#34;&gt;Wikipedia - Anscombe&amp;rsquo;s quartet&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>