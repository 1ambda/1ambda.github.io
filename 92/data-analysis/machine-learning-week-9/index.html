<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="generator" content="Hugo 0.16" />
    <meta name="description" content="hugo content for 1ambda.github.io">
<meta name="author" content="1ambda">

    <link rel="shortcut icon" href="https://1ambda.github.io/images/favicon.png" type="image/x-icon" />

    
    <title>ML 09: Anomaly Detection, Recommender System</title>
    <link href="https://1ambda.github.io/css/nucleus.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/font-awesome.min.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/hybrid.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/featherlight.min.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/perfect-scrollbar.min.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/theme.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/hugo-theme.css" rel="stylesheet">
    <style type="text/css">:root #header + #content > #left > #rlblock_left
    {display:none !important;}</style>
    

  </head>
  <body class="" data-url="/92/data-analysis/machine-learning-week-9/">
    <nav id="sidebar">
  <div id="header-wrapper">
    <div id="header">
      <a id="logo" href="http://getgrav.org">
  <svg id="grav-logo" width="100%" height="100%" viewBox="0 0 504 140" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
    <path d="M235.832,71.564l-7.98,-0.001c-1.213,0.001 -2.197,0.987 -2.197,2.204l0,15.327l-0.158,0.132c-4.696,3.962 -10.634,6.14 -16.719,6.14c-14.356,0 -26.034,-11.68 -26.034,-26.037c0,-14.358 11.678,-26.035 26.034,-26.035c5.582,0 10.919,1.767 15.437,5.113c0.877,0.649 2.093,0.56 2.866,-0.211l5.69,-5.69c0.444,-0.442 0.675,-1.055 0.639,-1.681c-0.034,-0.627 -0.336,-1.206 -0.828,-1.597c-6.76,-5.363 -15.214,-8.314 -23.805,-8.314c-21.18,0 -38.414,17.233 -38.414,38.415c0,21.183 17.234,38.415 38.414,38.415c10.937,0 21.397,-4.705 28.698,-12.914c0.358,-0.403 0.556,-0.921 0.556,-1.46l0,-19.603c0,-1.217 -0.985,-2.203 -2.2,-2.203"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M502.794,34.445c-0.408,-0.616 -1.1,-0.989 -1.838,-0.989l-8.684,0c-0.879,0 -1.673,0.522 -2.022,1.329l-24.483,56.839l-24.92,-56.852c-0.352,-0.799 -1.142,-1.316 -2.012,-1.316l-8.713,0c-0.744,0 -1.44,0.373 -1.843,0.995c-0.408,0.623 -0.476,1.408 -0.174,2.09l30.186,68.858c0.352,0.799 1.143,1.317 2.017,1.317l10.992,0c0.879,0 1.673,-0.527 2.021,-1.329l29.655,-68.861c0.289,-0.68 0.222,-1.461 -0.182,-2.081"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M388.683,34.772c-0.353,-0.798 -1.142,-1.316 -2.017,-1.316l-10.988,0c-0.879,0 -1.673,0.522 -2.021,1.329l-29.655,68.861c-0.294,0.675 -0.226,1.46 0.182,2.077c0.407,0.619 1.096,0.993 1.838,0.993l8.684,0c0.879,0 1.673,-0.526 2.022,-1.329l24.478,-56.842l24.92,56.854c0.353,0.798 1.143,1.317 2.013,1.317l8.717,0c0.744,0 1.44,-0.374 1.843,-0.993c0.408,-0.624 0.471,-1.41 0.174,-2.094l-30.19,-68.857Z"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M309.196,81.525l0.476,-0.229c8.675,-4.191 14.279,-13.087 14.279,-22.667c0,-13.881 -11.295,-25.174 -25.176,-25.174l-31.863,0c-1.214,0 -2.199,0.988 -2.199,2.202l0,68.855c0,1.219 0.985,2.204 2.199,2.204l7.979,0c1.214,0 2.2,-0.985 2.2,-2.204l0,-58.679l21.684,0c7.059,0 12.799,5.739 12.799,12.796c0,5.885 -3.996,10.989 -9.728,12.408c-1.032,0.261 -2.064,0.393 -3.071,0.393l-7.977,0c-0.829,0 -1.585,0.467 -1.959,1.205c-0.378,0.74 -0.305,1.625 0.187,2.296l22.62,30.884c0.412,0.566 1.07,0.901 1.771,0.901l9.915,0c0.827,0 1.587,-0.467 1.96,-1.207c0.378,-0.742 0.302,-1.629 -0.186,-2.296l-15.91,-21.688Z"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M107.191,80.969c-7.255,-4.794 -11.4,-8.845 -15.011,-16.109c-2.47,4.977 -8.236,12.376 -17.962,18.198c-4.856,15.106 -27.954,44.015 -35.43,39.916c-2.213,-1.212 -2.633,-2.808 -2.133,-4.456c0.536,-4.129 9.078,-13.62 9.078,-13.62c0,0 0.18,1.992 2.913,6.187c-3.609,-11.205 5.965,-25.031 8.5,-29.738c3.985,-1.269 4.274,-6.387 4.274,-6.387c0.255,-7.909 -3.278,-13.635 -6.701,-17.059c2.459,3.002 3.255,7.539 3.372,11.694l0,0.023c0.012,0.469 0.012,0.93 0.011,1.39c-0.117,3.439 -1.157,8.19 -3.383,8.19l0.006,0.03c-2.289,-0.098 -5.115,0.391 -7.639,1.18l-5.582,1.334c0,0 2.977,-0.136 4.584,1.252c-1.79,2.915 -5.769,6.533 -10.206,8.588c-6.457,2.995 -8.312,-2.964 -5.034,-6.838c0.805,-0.946 1.618,-1.745 2.387,-2.399c-0.495,-0.513 -0.807,-1.198 -0.889,-2.068c-0.001,-0.005 -0.004,-0.009 -0.005,-0.013c-0.45,-1.977 -0.202,-4.543 2.596,-8.623c0.551,-0.863 1.214,-1.748 2.007,-2.647c0.025,-0.031 0.046,-0.059 0.072,-0.089c0.034,-0.042 0.072,-0.08 0.108,-0.121c0.02,-0.023 0.039,-0.045 0.059,-0.068c0.2,-0.228 0.413,-0.45 0.639,-0.663c3.334,-3.414 8.599,-6.966 16.897,-10.152c9.675,-14.223 13.219,-16.89 13.219,-16.89c1.071,-1.096 2.943,-2.458 3.632,-2.805c-5.053,-8.781 -6.074,-21.158 -4.75,-24.493c-0.107,0.18 -0.206,0.365 -0.287,0.556c0.49,-1.143 0.819,-1.509 1.328,-2.111c1.381,-1.632 6.058,-2.488 7.737,0.971c0.895,1.844 1.063,4.232 1.034,6.023c-3.704,-0.193 -7.063,4.036 -7.063,4.036c0,0 3.067,-1.448 6.879,-1.473c0,0 1.015,0.883 2.283,2.542c-1.712,3.213 -4.524,10.021 -2.488,17.168c0.338,1.408 0.849,2.619 1.483,3.648c0.024,0.045 0.044,0.089 0.069,0.135c0.051,0.066 0.096,0.122 0.144,0.183c3.368,5.072 9.542,5.665 9.542,5.665c-2.906,-1.45 -5.274,-3.76 -6.816,-6.56c-0.8,-1.498 -1.291,-2.762 -1.592,-3.761c-1.636,-6.313 0.771,-9.999 2.149,-12.471c3.17,-4.917 8.944,-7.893 15.151,-7.185c8.712,0.995 14.968,8.862 13.973,17.571c-0.608,5.321 -3.781,9.723 -8.142,12.117c1.049,2.839 -0.073,6.28 -0.073,6.28c2.642,3.323 2.758,5.238 2.667,7.017c-3.357,-0.565 -6.618,1.701 -6.618,1.701c0,0 6.476,-1.546 10.238,1.81c2.446,2.631 4.078,5.009 5.051,6.766c1.393,2.505 7.859,2.683 7.123,7.188c-0.737,4.499 -5.669,4.542 -13.401,-0.56M69.571,0c-38.424,0 -69.571,31.148 -69.571,69.567c0,38.422 31.147,69.573 69.571,69.573c38.42,0 69.568,-31.151 69.568,-69.573c0,-38.42 -31.148,-69.567 -69.568,-69.567"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M73.796,51.693c0.813,-0.814 0.813,-2.134 0,-2.947c-0.815,-0.814 -2.133,-0.814 -2.947,0c-0.815,0.813 -0.815,2.133 0,2.947c0.814,0.813 2.132,0.813 2.947,0" style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M66.445,53.149c-0.814,0.813 -0.814,2.133 0,2.947c0.813,0.814 2.133,0.814 2.947,0c0.813,-0.814 0.813,-2.134 0,-2.947c-0.814,-0.813 -2.134,-0.813 -2.947,0" style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M79.231,54.233c-1.274,-1.274 -3.339,-1.272 -4.611,0l-2.713,2.712c-1.274,1.275 -1.274,3.339 0,4.612l2.978,2.978c1.274,1.275 3.338,1.274 4.611,0l2.712,-2.712c1.274,-1.274 1.274,-3.339 0,-4.612l-2.977,-2.978Z" style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M95.759,41.445c-2.151,-2.578 1.869,-7.257 4.391,-4.463c4.645,5.148 -2.237,7.041 -4.391,4.463M105.004,44.132c3.442,-6.553 -1.427,-10.381 -4.773,-13.523c-5.36,-5.039 -10.706,-7.217 -16.811,-0.241c-6.102,6.977 -2.226,15.068 3.356,19.061c5.584,3.994 14.782,1.255 18.228,-5.297"
      style="fill:#000;fill-rule:nonzero;"></path>
  </svg>
</a>

      
    </div>
</div>


  <div class="highlightable">
    <ul class="topics">
      
      
      
      

      <li class="dd-item  " data-nav-id="/0/home/">
        <a href="https://1ambda.github.io/0/home/">
          <span>
            
              <b>HOME</b>
            
             
            
           </span>
        </a>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/21/scala/">
        <a href="https://1ambda.github.io/21/scala/">
          <span>
            
              <b>-</b>
            
             Scala
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-1/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-1/">
                <span>Easy Scalaz 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-2/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-2/">
                <span>Easy Scalaz 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-3/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-3/">
                <span>Easy Scalaz 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-4/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-4/">
                <span>Easy Scalaz 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-5/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-5/">
                <span>Easy Scalaz 5     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-6/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-6/">
                <span>Easy Scalaz 6     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-1/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-1/">
                <span>Functional Programming 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-2/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-2/">
                <span>Functional Programming 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-3/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-3/">
                <span>Functional Programming 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-4/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-4/">
                <span>Functional Programming 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-5/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-5/">
                <span>Functional Programming 5     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-6/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-6/">
                <span>Functional Programming 6     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-7/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-7/">
                <span>Functional Programming 7     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-1/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-1/">
                <span>Reactive Programming 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-2/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-2/">
                <span>Reactive Programming 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-3/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-3/">
                <span>Reactive Programming 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-4/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-4/">
                <span>Reactive Programming 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-5/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-5/">
                <span>Reactive Programming 5     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/22/haskell/">
        <a href="https://1ambda.github.io/22/haskell/">
          <span>
            
              <b>- </b>
            
             Haskell
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-1/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-1/">
                <span>하스켈로 배우는 함수형 언어 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-2/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-2/">
                <span>하스켈로 배우는 함수형 언어 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-3/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-3/">
                <span>하스켈로 배우는 함수형 언어 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-4/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-4/">
                <span>하스켈로 배우는 함수형 언어 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-5/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-5/">
                <span>하스켈로 배우는 함수형 언어 5     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-6/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-6/">
                <span>하스켈로 배우는 함수형 언어 6     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-7/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-7/">
                <span>하스켈로 배우는 함수형 언어 7     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-8/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-8/">
                <span>하스켈로 배우는 함수형 언어 8     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-9/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-9/">
                <span>하스켈로 배우는 함수형 언어 9     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/poor-mans-concurrency-monad/">
              <a href="https://1ambda.github.io/22/haskell/poor-mans-concurrency-monad/">
                <span>Poor Man&#39;s Concurrency Monad     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/23/javascript/">
        <a href="https://1ambda.github.io/23/javascript/">
          <span>
            
              <b>- </b>
            
             Javascript
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/23/javascript/javascript-inheritance/">
              <a href="https://1ambda.github.io/23/javascript/javascript-inheritance/">
                <span>Javascript Inheritance     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/23/javascript/tips-for-webpack-and-redux/">
              <a href="https://1ambda.github.io/23/javascript/tips-for-webpack-and-redux/">
                <span>Tips for Webpack and Redux     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/23/javascript/rest-api-put-vs-post/">
              <a href="https://1ambda.github.io/23/javascript/rest-api-put-vs-post/">
                <span>REST API: Put vs Post     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/24/java/">
        <a href="https://1ambda.github.io/24/java/">
          <span>
            
              <b>- </b>
            
             Java
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/24/java/interview-questions-collection/">
              <a href="https://1ambda.github.io/24/java/interview-questions-collection/">
                <span>Interview Questions: Collection     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/51/oh-my-github/">
        <a href="https://1ambda.github.io/51/oh-my-github/">
          <span>
            
              <b>- </b>
            
             oh-my-github
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/51/oh-my-github/tutorial/">
              <a href="https://1ambda.github.io/51/oh-my-github/tutorial/">
                <span>10분만에 Github Profile 만들기     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/91/algorithm/">
        <a href="https://1ambda.github.io/91/algorithm/">
          <span>
            
              <b>- </b>
            
             Algorithm
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-1/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-1/">
                <span>Design and Analysis: Divide &amp; Conquer     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-2/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-2/">
                <span>Design and Analysis: Randomized Selection     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-3/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-3/">
                <span>Design and Analysis: Graph Contraction Algorithm     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-4/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-4/">
                <span>Design and Analysis: Graph Search and Connectivity     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-5/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-5/">
                <span>Design and Analysis: Dijkstra, Heap, Red-Black Tree     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-6/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-6/">
                <span>Design and Analysis: Hash Table, Universal Hashing, Bloom filters     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part1-1/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part1-1/">
                <span>Algorithm: Union Find     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part1-2/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part1-2/">
                <span>Algorithm: Analysis     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-1/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-1/">
                <span>Algorithm: Spanning Tree, Shortest Paths     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-2/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-2/">
                <span>Algorithm: Radix Sort, Suffix Sort     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-3/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-3/">
                <span>Algorithm: R-way, Ternary Tries     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-4/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-4/">
                <span>Algorithm: KMP, Boyer-Moore, Rabin-Karp     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-5/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-5/">
                <span>Algorithm: Maximum Flow (Ford-Fulkerson)     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-6/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-6/">
                <span>Algorithm: Data Compression, Huffman, LZW     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-cs188-1/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-cs188-1/">
                <span>AI (CS188): Intro     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-cs188-2/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-cs188-2/">
                <span>AI (CS188): Search     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-planning-1/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-planning-1/">
                <span>AI Planning 1: Intro     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-planning-2/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-planning-2/">
                <span>AI Planning 2: A*. STRIPS     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-planning-3/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-planning-3/">
                <span>AI Planning 3: PSP, PoP     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-planning-4/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-planning-4/">
                <span>AI Planning 4: STN, HTN     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  parent" data-nav-id="/92/data-analysis/">
        <a href="https://1ambda.github.io/92/data-analysis/">
          <span>
            
              <b>- </b>
            
             Data Analysis
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-1/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-1/">
                <span>ML 01: Linear Regression     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-2/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-2/">
                <span>ML 02: Gradient Descent     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-3/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-3/">
                <span>ML 03: Logistic Regression     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-4/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-4/">
                <span>ML 04: Neural Network     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-5/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-5/">
                <span>ML 05: Back Propagation     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-6/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-6/">
                <span>ML 06: Practical Advices     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-7/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-7/">
                <span>ML 07: Support Vector Machine     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-8/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-8/">
                <span>ML 08: K-means, PCA Details     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item active" data-nav-id="/92/data-analysis/machine-learning-week-9/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-9/">
                <span>ML 09: Anomaly Detection, Recommender System     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-10/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-10/">
                <span>ML 10: Stochastic Gradient, Synthetic Data, Ceiling Analysis     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/intro-to-data-science-1/">
              <a href="https://1ambda.github.io/92/data-analysis/intro-to-data-science-1/">
                <span>Intro to Data Science 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/intro-to-data-science-2/">
              <a href="https://1ambda.github.io/92/data-analysis/intro-to-data-science-2/">
                <span>Intro to Data Science 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/intro-to-data-science-3/">
              <a href="https://1ambda.github.io/92/data-analysis/intro-to-data-science-3/">
                <span>Intro to Data Science 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/intro-to-data-science-4/">
              <a href="https://1ambda.github.io/92/data-analysis/intro-to-data-science-4/">
                <span>Intro to Data Science 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-1/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-1/">
                <span>Process Mining 1: Intro     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-2/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-2/">
                <span>Process Mining 2: Alpha Algorithm     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-3/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-3/">
                <span>Process Mining 3: Metric, C-nets     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-4/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-4/">
                <span>Process Mining 4: Conformance Checking, Dotted Chart     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-5/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-5/">
                <span>Process Mining 5: Decision, Social, Organization Mining     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/pattern-discovery-1/">
              <a href="https://1ambda.github.io/92/data-analysis/pattern-discovery-1/">
                <span>Pattern Discovery 1: Apriori, FP Growth     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/pattern-discovery-2/">
              <a href="https://1ambda.github.io/92/data-analysis/pattern-discovery-2/">
                <span>Pattern Discovery 2: Null-invariant, Pattern-Fusion, Constaint     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/pattern-discovery-3/">
              <a href="https://1ambda.github.io/92/data-analysis/pattern-discovery-3/">
                <span>Pattern Discovery 3: Sequential Pattern Mining     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/93/cloud-computing/">
        <a href="https://1ambda.github.io/93/cloud-computing/">
          <span>
            
              <b>- </b>
            
             Cloud Computing
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-1/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-1/">
                <span>CC 01: Map Reduce     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-2/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-2/">
                <span>CC 02: Gossip Protocol     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-3/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-3/">
                <span>CC 03: Membership Protocol     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-4/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-4/">
                <span>CC 04: P2P Systems     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-5/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-5/">
                <span>CC 05: Global Snapshot     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-6/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-6/">
                <span>CC 06: Multicast     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-7/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-7/">
                <span>CC 07: Paxos     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
    </ul>
    <hr>
      
    <section id="footer">
      <p>Built with <a href="https://github.com/matcornic/hugo-theme-learn"><i class="fa fa-heart"></i></a> from <a href="http://getgrav.org">Grav</a> and <a href="http://gohugo.io/">Hugo</a></p>
    </section>
  </div>
</nav>

        <section id="body">
        <div id="overlay"></div>

        <div class="padding highlightable">

            <div id="top-bar">
              
                
                
                
              <div id="top-github-link">
                  <a class="github-link" href="https://github.com/1ambda/1ambda.github.io-hugo/edit/master/content/92/data-analysis/machine-learning-week-9.md" target="blank">
                    <i class="fa fa-code-fork"></i>
                    Edit this page
                  </a>
              </div>
                
              
              <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                  <span id="sidebar-toggle-span">
                      <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                        <i class="fa fa-bars"></i>
                      </a>
                  </span>
                
                <span id="toc-menu"><a href=""><i class="fa fa-list-alt"></i></a></span>
                
                
                
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    
                    
                <a href="https://1ambda.github.io/92/data-analysis/" itemprop="url"><span itemprop="title">Data Analysis</span></a> <i class="fa fa-angle-right"></i>
                    
                  
                
                  
                
                <span itemprop="title"> ML 09: Anomaly Detection, Recommender System</span>
              </div>
              
                  <div class="progress">
    <div class="wrapper">
<nav id="TableOfContents">
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#anomaly-dectection">Anomaly Dectection</a></li>
<li><a href="#gaussian-distribution">Gaussian Distribution</a></li>
<li><a href="#anomaly-detection-algorithm">Anomaly Detection Algorithm</a></li>
<li><a href="#evaluating-anomaly-detection">Evaluating Anomaly Detection</a></li>
<li><a href="#anomaly-dectection-vs-supervised-learning">Anomaly Dectection vs Supervised Learning</a>
<ul>
<li><a href="#anomaly-detection">Anomaly Detection</a></li>
<li><a href="#supervised-learning">Supervised Learning</a></li>
</ul></li>
<li><a href="#choosing-what-features-to-use">Choosing What Features to Use</a></li>
<li><a href="#multivariate-gaussian-distribution">Multivariate Gaussian Distribution</a></li>
<li><a href="#recommender-system">Recommender System</a></li>
<li><a href="#content-based-recommendations">Content Based Recommendations</a></li>
<li><a href="#collaborative-filtering">Collaborative Filtering</a></li>
<li><a href="#vectorization-low-rank-matrix-factorization">Vectorization: Low Rank Matrix Factorization</a></li>
<li><a href="#implementation-detail-mean-normalization">Implementation Detail: Mean Normalization</a></li>
<li><a href="#references">References</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
    </div>
</div>

              

            </div>
            
    	        <div id="body-inner">
                
                <h1>ML 09: Anomaly Detection, Recommender System</h1>
                



<p>이번시간엔 <em>anomaly detection</em> 과 <em>recommender system</em> 을 배운다.</p>

<h3 id="anomaly-dectection">Anomaly Dectection</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236753_7590.png" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236757_2205.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>anomaly</em> 는 정상집단에서 떨어진 데이터라 보면 된다. 공장에서 품질이 떨어지는 제품을 골라낼때 사용할 수 있는데, 위 그림은 비행기 엔진 공장을 예로 들어 설명한다.</p>

<p>데이터로부터 <code>p(x)</code> 를 만들어, 검사할 데이터가 <em>threshold</em> 를 넘는지 안넘는지 검사해 <em>anomaly</em> 로 판정할 수 있다.</p>

<p>참고로, <em>anomaly</em> 가 너무 많으면, <em>false positive</em> 가 높은 것인데 이 때는  <em>threshold</em> 를 줄이면 된다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236761_2830.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>anomaly detection</em> 은 <em>fraud detection</em> 에 많이 사용된다. 데이터로부터 모델 <code>p(x)</code> 를 만들고 <em>unusual user</em> 를 검사하기 위해 <code>p(x) &lt; e</code> 인지 검사하면 된다.</p>

<p>이외에도 항공기 엔진 예제처럼 제품의 품질 관리나, 데이터 센터에서의 노드 과부하 탐지등에 사용할 수 있다.</p>

<h3 id="gaussian-distribution">Gaussian Distribution</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236829_8964.png" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236829_8964.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>gaussian density</em> 공식은</p>

<p><img src="http://latex.codecogs.com/gif.latex?P%28x%3B%20%5Cmu%2C%20%5Csigma%5E2%29%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma%5E2%7D%7D%20%5C%20%5Cexp%28-%20%7B%28x%20-%20%5Cmu%29%5E2%20%5Cover%202%5Csigma%5E2%7D%29" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236839_1788.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p>평균과 분산은</p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Cmu%20%3D%20%7B1%20%5Cover%20m%7D%20%5C%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x%5E%7B%28i%29%7D" alt="" /></p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Csigma%5E2%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29" alt="" /></p>

<p><br/></p>

<h3 id="anomaly-detection-algorithm">Anomaly Detection Algorithm</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236899_7015.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p>각 <em>feature</em> 가 가우시안 분포를 따른다고 하면,</p>

<p><img src="http://latex.codecogs.com/gif.latex?p%28x%29%20%5C%5C%20%5C%5C%20%3D%20p%28x_1%3B%20%5Cmu_1%2C%20%5Csigma_1%5E2%29%5C%20p%28x_2%3B%20%5Cmu_2%2C%20%5Csigma_1%5E2%29%20%5Ccdots%5C%20p%28x_n%3B%20%5Cmu_n%2C%20%5Csigma_1%5En%29%20%5C%5C%20%5C%5C%20%3D%20%5Cprod_%7Bj%20%3D%201%7D%5En%20p%28x_j%3B%20%5Cmu_j%2C%20%5Csigma_j%5E2%29" alt="" /></p>

<p>이렇게 가정하려면, 각 <em>feature</em> 가 독립적이어야 하지만 실제로는 독립적이지 않더라도 어느정도 동작한다. 이 때</p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Cmu_j%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x_j%5E%7B%28i%29%7D" alt="" /></p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Csigma_j%5E2%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20%7B%28x_j%5E%7B%28i%29%7D%20-%20%5Cmu_j%29%5E2%7D" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236904_6921.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p>따라서 <code>p(x)</code> 는 아래 식이 된다. <code>p(x)</code> 는 <em>feature</em> 가 나올 확률로 이해하면 된다. 이 때 <code>p(x)</code> 가 상당히 작으면, 평균에 가깝지 않은 <em>feature</em> 가 많이 나왔다는 뜻이므로 <em>anomaly</em> 라 볼 수 있다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?p%28x%29%20%5C%5C%20%5C%5C%20%3D%20%5Cprod_%7Bj%3D1%7D%5En%20%5C%20%7B1%20%5Cover%20%5Csqrt%7B2%5Cpi%5Csigma_j%5E2%7D%7D%20%5C%20%5Cexp%28-%7B%28x_j%20-%20%5Cmu_j%29%5E2%20%5Cover%202%5Csigma_j%5E2%7D%29" alt="" /></p>

<p><br/></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236907_7102.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p>두 <em>feature</em> <code>x1, x2</code> 의 가우시안 분포를 3차원으로 조합하면 <code>p(x)</code> 가 좌측 하단 3차원 원뿔의 높이가 된다.</p>

<h3 id="evaluating-anomaly-detection">Evaluating Anomaly Detection</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236992_3664.png" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361236996_4034.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>anomaly</em> 를 잘 나타낼거 같은 <em>feature</em> 를 골라내고, 이를 이용해 모델을 만든다.</p>

<p>우리가 가진 데이터가 <em>anomaly</em> 를 알려주는 <code>y</code> 가 있다면, 위 그림처럼 <em>training set</em> 으로 <em>non-anomalous</em> 을 이용하고, <em>CV, Test Set</em> 으로 나머지를 반반씩 분할하면 된다.</p>

<p>즉 <em>good example</em> 로 모델을 만들고, <em>anomaly</em> 가 섞여있는 <em>cv, test set</em> 으로 평가한다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361237001_5250.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p>이 때 <em>skewed classess</em> 이기 때문에 (<code>y = 0</code> 이 대다수, <code>y = 1</code> 은 희박) 단순히 정확도로 평가하긴 좀 무리가 있다. <em>precision, recall, f1 score</em> 등을 이용해 평가해야 한다.</p>

<p><em>threshold</em> 인 <code>e</code> (엡실론) 를 고르기 위해 <em>cross validation</em> 을 이용할 수 있다. <em>f1 score</em> 를 최대화 하는 <code>e</code> 를 고른다거나.</p>

<h3 id="anomaly-dectection-vs-supervised-learning">Anomaly Dectection vs Supervised Learning</h3>

<p><code>y</code> 값이 있는 데이터라면, 왜 <em>supervised learning</em> 을 이용하지 않을까?</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361242897_8389.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<h4 id="anomaly-detection">Anomaly Detection</h4>

<p><em>anomaly detection</em> <em>skewed class</em> 가 있을 때 사용한다.</p>

<blockquote>
<p>Many different <strong>types</strong> of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like</p>

<p>Future anomalies may look nothing like any of the anomalous examples we&rsquo;ve seen so far</p>
</blockquote>

<p>보면 알겠지만 <em>anomaly</em> 가 굉장히 다양할 수 있기 때문에 <em>anomaly</em> 를 특정 형태로 구분짓는 알고리즘을 쓰긴 좀 힘들다.</p>

<p>게다가, 가지고 있는 데이터 셋에서 보지 못했던 새로운 종류의 <em>anomaly</em> 가 나올 수도 있다.</p>

<h4 id="supervised-learning">Supervised Learning</h4>

<p><em>positive, negative example</em> 이 많을 때 사용한다.</p>

<blockquote>
<p>Enough positive examples for algorithms to get a sense of what positive examples are like, futre positive example likly to be similar to ones in training set</p>
</blockquote>

<p><em>supervised learning</em> 에서 <em>positive example</em> 은 어떤 특정 형태기 때문에, 미래에 발견할 <em>positive example</em> 도 비슷한 형태라 생각될 때 사용한다.</p>

<p><em>SPAM filtering</em> 에서는 다양한 타입의 <em>positive example</em> 이 있어도, 우리가 충분한 양의 <em>positive example</em> 이 있기 때문에 커버할 수 있어 <em>supervised learning</em> 을 사용한다.</p>

<p><br/></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361243087_2169.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><br/></p>

<h3 id="choosing-what-features-to-use">Choosing What Features to Use</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361244210_3429.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>feature</em> 의 분포가 가우시안이면 고맙지만, 아닐경우 변환이 필요하다. 왼쪽 아래 분포에 로그를 씌우면, 가우시안 분포 비슷하게 보인다.</p>

<p>다른 방법으로는 <code>log(x_2 + c)</code>, <code>sqrt(x_3)</code> 등등이 있다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361245473_5316.png" alt="" /></p>

<p>흔한 에러는 <code>p(x)</code> 가 <em>normal, anomalous</em> 에 대해서 모두 높은 경우인데, 슬라이드의 아래쪽에서 볼 수 있듯이 <code>x2</code> 라는 <em>feature</em> 를 만들어서 <em>anomaly</em> 를 발견하는 알고리즘을 만들 수 있다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361246077_9679.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>anomaly</em> 를 위한 <em>feature</em> 를 고를 때 특이하게 높거나, 낮을 수 있는 것을 고르면 된다. 데이터 센터 예제에서는 <em>CPU load / network traffic</em> 등이 있을 수 있다. 네트워크 트래픽이 낮은데 <em>CPU load</em> 가 높다면 확실히 <em>anomaly</em> 기 때문이다.</p>

<h3 id="multivariate-gaussian-distribution">Multivariate Gaussian Distribution</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361257865_7961.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>feature</em> 를 <em>CPU laod, memory use</em> 로 했을 때 낮은 CPU 부하에도 메모리 사용량이 높으면 <em>anomaly</em> 라 볼 수 있다.</p>

<p>그런데, 슬라이드의 왼쪽 그림에서 녹색으로 표시한 <em>anomaly</em> 는 지금까지 설명했던 알고리즘으로 찾기가 힘들다. 적당한 수준의 <em>memory use</em> 와 그리 낮지 않은 <em>cpu load</em> 를 가지기 때문이다.</p>

<p>실제 <em>normal example</em> 이 타원형이기 때문에, 원으로 <em>anomaly</em> 를 찾기는 어렵다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361258533_5107.png" alt="" /></p>

<p>따라서 <code>p(x_1)p(x_2)...</code> 을 이용한 모델 말고 다른 방법으로 모델을 만들어야 한다.</p>

<p><code>u</code> 를 <code>n</code> 벡터라 하고, <code>Sigma</code> 를 <code>u</code> 의 <em>convariance matrix</em> 라 하자. 그러면</p>

<p><img src="http://latex.codecogs.com/gif.latex?p%28x%3B%20%5Cmu%2C%20%5CSigma%29%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%20%282%5Cpi%29%5E%7Bn/2%7D%20%5C%20%7C%5CSigma%7C%5E%7B1/2%7D%7D%20%5C%20%5Cexp%28-%7B1%5Cover%202%7D%28x%20-%20%5Cmu%29%5ET%20%5C%20%5CSigma%5E%7B-1%7D%28x%20-%20%5Cmu%29%29" alt="" /></p>

<p>여기서 <code>|Sigma|</code> 는 <code>Sigma</code> 의 행렬식인데, 여기를 참고하자.</p>

<ul>
<li><a href="http://ghebook.blogspot.com/2011/06/matrix.html">행렬</a></li>
<li><a href="http://ghebook.blogspot.com/2011/06/determinant.html">행렬식</a></li>
<li><a href="http://ghebook.blogspot.kr/2011/06/geometric-meaning-of-determinant.html">행렬식의 기하학적 의미</a></li>
<li><a href="http://darkpgmr.tistory.com/104">행렬식과 기하학적 활용</a></li>
</ul>

<p>이제 위 식을 이용해서 나온 <code>p(x)</code> 를 3차원, 2차원으로 보면</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361259228_7695.png" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361259243_2967.png" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361259236_1052.png" alt="" /></p>

<p><br/></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361259583_5151.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Cmu%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%20%3D%201%7D%5Em%20x%5E%7B%28i%29%7D" alt="" /></p>

<p><img src="http://latex.codecogs.com/gif.latex?%5CSigma%20%3D%20%7B1%20%5Cover%20m%7D%20%5Csum_%7Bi%3D1%7D%5Em%20%5C%20%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29%28x%5E%7B%28i%29%7D%20-%20%5Cmu%29%5ET" alt="" /></p>

<p><br/></p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361259728_6035.png" alt="" /></p>

<p><code>u, Sigma</code> 를 찾아 <code>p(x)</code> 를 만들고, 테스트 데이터에 대해 <code>p(x) &lt; e</code> 인지 비교한다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361260300_1768.png" alt="" /></p>

<p><em>original model</em> 은 <em>multivariate model</em> 에서 각 <em>feature</em> 간 상관 관계가 없는 (독립), 즉 <em>covariance matrix</em> 가 <em>diagonal matrix</em> 인 경우다. (</p>

<p><img src="http://img.my.csdn.net/uploads/201302/19/1361260755_3407.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<ul>
<li><strong>Original model</strong></li>
</ul>

<p>수동으로 <em>feature</em> 를 만들때 사용할 수 있다. 또는 적은 연산을 원할때, 다시 말해서 <code>n</code> 이 커서 연산이 무지막지하게 클 때 좋다.</p>

<p><code>m</code> 이 작아도 쓸 수 있다.</p>

<ul>
<li><strong>Multivariate Gaussian</strong></li>
</ul>

<p>계산 비용이 비싸지만, 자동으로 <em>feature</em> 간 상관관계를 모델에 포함시킨다.</p>

<p><code>Sigma</code> 가 <em>invertible</em> 이기 위해서는 <code>m &gt; n</code> 이어야 한다. 실제로는 <code>m</code> 이 <code>n</code> 보다 훨씬 클 때 사용하는 경우가 많다. (e.g. <code>m &gt;= 10n</code>)</p>

<p>만약에 <code>m &gt; n</code> 인데, <code>Sigma</code> 가 <em>non-invertible</em> 이면 <em>redundant feature</em> 가 있는 경우니 확인해 보자. (흔한 오류라고 함)</p>

<h3 id="recommender-system">Recommender System</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/20/1361324993_7588.png" alt="" /></p>

<h3 id="content-based-recommendations">Content Based Recommendations</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/20/1361325560_4034.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p>위 슬라이드는 유저 <code>j</code> 로 부터 <code>theta^(j)</code> 를 얻어, <em>feature</em> <code>x</code> 와 곱함으로써 <em>linear regression</em> 문제로 변경했다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/20/1361326084_2070.png" alt="" /></p>

<p><code>theta^(j)</code> 는 어떻게 훈련시킬까?</p>

<p><img src="http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%7D%20%5C%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%7B1%20%5Cover%202m%5E%7B%28j%29%7D%7D%5C%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;plus;%20%7B%5Clambda%20%5Cover%202m%5E%7B%28j%29%7D%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2" alt="" /></p>

<p>여기서 <code>m^(j)</code> 는 유저 <code>j</code> 에 의해 점수를 받은 영화의 수인데, 어차피 상수이므로 제거하면</p>

<p><img src="http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%7D%20%5C%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%7B1%20%5Cover%202%7D%5C%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/20/1361326247_4648.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p>이 때 각 유저마다의 <code>theta(j)</code> 를 합 해 최소화 시키는 방식으로 전체 <code>theta</code> 를 훈련시킬 수 있다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?min_%7B%5Ctheta%5E%7B%28j%29%7D%2C%20%5Ccdots%20%5Ctheta%5E%7B%28n_u%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%20%5Csum_%7Bi%3A%20%5C%20%28ri%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/20/1361326573_9477.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>gradient descent</em> 는</p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28j%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28j%29%7D%20-%20%5Calpha%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%20%28%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%29x_k%5E%7B%28i%29%7D%20%5C%20%28for%5C%20k%20%3D%200%29" alt="" /></p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28j%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28j%29%7D%20-%20%5Calpha%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%20%28%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%29x_k%5E%7B%28i%29%7D%20&amp;plus;%20%5Clambda%5Ctheta_k%5E%7B%28j%29%7D%5C%20%28for%5C%20k%20%5Cneq%200%29" alt="" /></p>

<h3 id="collaborative-filtering">Collaborative Filtering</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/20/1361327928_4438.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>content-based recommendation</em> 에서 <em>feature</em> 를 구하긴 사실 어려운 일이다. 누가 이 영화가 얼마만큼 로맨스고, 아닌지를 판별해줄까?</p>

<p>문제를 좀 변경해서, 만약에 유저로부터 <code>theta(j)</code> 를 얻어낼 수 있다면 그 정보로 부터 <em>feature</em> <code>x(i)</code> 를 추출할 수 있다. 왜냐하면 <code>(\theta^(j))^T * x^(i) ~ y^(i, j)</code> 이기 때문이다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/20/1361328443_4320.png" alt="" /></p>

<p><code>x^(i)</code> 를 얻기 위해,</p>

<p><img src="http://latex.codecogs.com/gif.latex?min_%7Bx%5E%7B%28j%29%7D%2C%20%5Ccdots%20x%5E%7B%28n_m%29%7D%7D%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%20%5Csum_%7Bi%3A%20%5C%20r%28i%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%5Csum_%7Bk%3D1%7D%5En%28x_k%5E%7B%28i%29%7D%29%5E2" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/20/1361330430_7394.png" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<ul>
<li><code>theta</code> 가 주어지면 <code>x</code> 를 훈련할 수 있고</li>
<li><code>x</code> 가 주어지면 <code>theta</code> 를 훈련할 수 있다.</li>
</ul>

<p>따라서 최초의 랜덤 <code>theta</code> 에 대해 <code>x</code> 를 훈련하고, 다시 <code>theta</code> 를 훈련하고, 반복하면 된다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/22/1361495687_3476.jpg" alt="" /></p>

<p><code>theta</code> 와 <code>x</code> 를 반복해서 훈련시키는 것보다, 동시에 훈련시키는 것이 좀 더 효율적이다. 따라서</p>

<p><img src="http://latex.codecogs.com/gif.latex?J%28%7Bx%5E%7B%28j%29%7D%2C%20%5Ccdots%20x%5E%7B%28n_m%29%7D%2C%20%5Ctheta%5E%7B%28i%29%7D%2C%20%5Ccdots%20%5Ctheta%5E%7B%28n_u%29%7D%7D%29%20%5C%5C%20%5C%5C%20%3D%20%7B1%20%5Cover%202%7D%5Csum_%7B%28i%2C%20j%29%3A%20%5C%20r%28i%2C%20j%29%20%3D%201%20%7D%20%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5E2%20%5C%20&amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bi%3D1%7D%5E%7Bn_m%7D%5Csum_%7Bk%3D1%7D%5En%28x_k%5E%7B%28i%29%7D%29%5E2%20&amp;plus;%20%7B%5Clambda%20%5Cover%202%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_u%7D%5Csum_%7Bk%3D1%7D%5En%28%5Ctheta_k%5E%7B%28j%29%7D%29%5E2" alt="" /></p>

<p>를 최소화 시키면 된다. 참고로 <code>x_0</code> 은 <em>collaborative filtering</em> 에서 필요가 없다. 알고리즘 자체가 <em>feature</em> 를 직접 찾아내니 <em>hard coded</em> 된 <em>feature</em> 는 사용하지 않는다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/22/1361495692_7530.jpg" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p>(1) <code>x</code>, <code>theta</code> 를 작은 값으로 초기화 한다.</p>

<p>이는 <em>symmetry breaking</em> 을 하기 위함이다. 작은 랜덤값들로 초기화 하여 <code>x^(i)</code> 가 서로 다른 값들을 가지도록 도와준다.</p>

<p>(2) <em>cost function</em> <code>J</code> 를 <em>gradient descent</em> 등으로 최소화 시킨다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?x_k%5E%7B%28i%29%7D%20%3A%3D%20x_k%5E%7B%28i%29%7D%20-%20%5Calpha%20%5Csum_%7Bj%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5Ctheta_k%5E%7B%28j%29%7D%20&amp;plus;%20%5Clambda%20x_k%5E%7B%28i%29%7D" alt="" /></p>

<p><img src="http://latex.codecogs.com/gif.latex?%5Ctheta_k%5E%7B%28i%29%7D%20%3A%3D%20%5Ctheta_k%5E%7B%28i%29%7D%20-%20%5Calpha%20%5Csum_%7Bi%3A%5C%20r%28i%2C%20j%29%20%3D%201%7D%5B%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20-%20y%5E%7B%28i%2C%20j%29%7D%5D%5Cx_k%5E%7B%28i%29%7D%20&amp;plus;%20%5Clambda%20%5Ctheta_k%5E%7B%28j%29%7D" alt="" /></p>

<p>(3) 유저의 <em>parameter</em> <code>theta</code> 와 영화의 <em>feature</em> <code>x</code> 에 대해 <code>theta^T * x</code> 를 이용해 예측하면 된다.</p>

<h3 id="vectorization-low-rank-matrix-factorization">Vectorization: Low Rank Matrix Factorization</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/22/1361496844_8727.jpg" alt="" /></p>

<p><img src="http://img.my.csdn.net/uploads/201302/22/1361496849_5252.jpg" alt="" /></p>

<p><em>collaborative filtering</em> 은 <em>low rank matrix factoriazation</em> 이라 부르기도 한다. 위 슬라이드처럼 <code>X, THETA</code> 를 구성하고 <code>X * THETA^T</code> 를 구하면 된다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/22/1361496854_2443.jpg" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>low rank matrix factorization</em> 을 이용해서 <em>feature</em> 를 찾으면, 두 영화 <code>i, j</code> 가 얼마나 유사한지 <code>||x^(i) - x^(j)||</code> 으로 판단할 수 있다.</p>

<h3 id="implementation-detail-mean-normalization">Implementation Detail: Mean Normalization</h3>

<p><img src="http://img.my.csdn.net/uploads/201302/22/1361497832_3797.jpg" alt="" /></p>

<p>만약 위 슬라이드의 <code>Eve</code> 처럼 아무 영화도 평가 안한 사람에게는, <code>theta</code> 가 <code>0</code> 으로 나온다. (첫번째 <em>term</em> 이 <code>0</code> 이고, <em>regularization term</em> 은 <code>theta</code> 를 최소화한다.)</p>

<p>그렇게 되면, 어떤 영화도 높은 <em>rating</em> 을 받을 수 없으므로 (<code>theta^T * x</code>). 추천할 거리가 없다. 이건 별로 좋은 상황이 아닌데, <em>mean normalization</em> 을 이용하면 이 문제를 해결할 수 있다.</p>

<p><img src="http://img.my.csdn.net/uploads/201302/22/1361497813_3878.jpg" alt="" />
<p align="center">(<a href="http://blog.csdn.net/linuxcumt1">http://blog.csdn.net/linuxcumt1</a>)</p></p>

<p><em>mean normalized</em> 데이터를 이용하면, 추천 안한 사람이 <code>theta = 0</code> 을 갖더라도, 남들이 추천한 선호도 <code>u</code> 에 따라서 영화를 추천받을 수 있다.</p>

<p><img src="http://latex.codecogs.com/gif.latex?%28%5Ctheta%5E%7B%28j%29%7D%29%5ET%28x%5E%7B%28i%29%7D%29%20&amp;plus;%20%5Cmu_i" alt="" /></p>

<p>잘보면 <em>feature scaling</em> 과는 다르게 특정 <em>range</em> 로 나누질 않는데, 이건 이미 <em>rating</em> 자체가 일정 범위 <code>1-5</code> 를 갖기 때문이다.</p>

<h3 id="references">References</h3>

<p>(1) <em>Machine Learning</em> by <strong>Andrew NG</strong><br />
(2) <a href="http://blog.csdn.net/linuxcumt">http://blog.csdn.net/linuxcumt</a><br />
(3) <a href="http://blog.csdn.net/abcjennifer">http://blog.csdn.net/abcjennifer</a><br />
(4) <a href="http://ghebook.blogspot.com/2011/06/matrix.html">http://ghebook.blogspot.com</a><br />
(5) <a href="http://darkpgmr.tistory.com/104">http://darkpgmr.tistory.com</a></p>

<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = '1ambda';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


      
      </div>
    </div>

    <div id="navigation">
        <a class="nav nav-prev" href="../machine-learning-week-8"> <i class="fa fa-chevron-left"></i></a>
        <a class="nav nav-next" href="../machine-learning-week-10" style="margin-right: 0px;"><i class="fa fa-chevron-right"></i></a>
    </div>

    </section>
    <div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
      <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
    </div>
    <script src="https://1ambda.github.io/js/jquery-2.x.min.js"></script>
    <script src="https://1ambda.github.io/js/clipboard.min.js"></script>
    <script src="https://1ambda.github.io/js/perfect-scrollbar.min.js"></script>
    <script src="https://1ambda.github.io/js/perfect-scrollbar.jquery.min.js"></script>
    <script src="https://1ambda.github.io/js/jquery.sticky-kit.min.js"></script>
    <script src="https://1ambda.github.io/js/featherlight.min.js"></script>
    <script src="https://1ambda.github.io/js/html5shiv-printshiv.min.js"></script>
    <script src="https://1ambda.github.io/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="https://1ambda.github.io/js/modernizr.custom.71422.js"></script>
    <script src="https://1ambda.github.io/js/learn.js"></script>
    <script src="https://1ambda.github.io/js/hugo-learn.js"></script>
    
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-52181619-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>


  </body>
</html>


