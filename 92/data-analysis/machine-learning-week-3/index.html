<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta name="generator" content="Hugo 0.16" />
    <meta name="description" content="hugo content for 1ambda.github.io">
<meta name="author" content="1ambda">

    <link rel="shortcut icon" href="https://1ambda.github.io/images/favicon.png" type="image/x-icon" />

    
    <title>ML 03: Logistic Regression</title>
    <link href="https://1ambda.github.io/css/nucleus.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/font-awesome.min.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/hybrid.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/featherlight.min.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/perfect-scrollbar.min.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/theme.css" rel="stylesheet">
    <link href="https://1ambda.github.io/css/hugo-theme.css" rel="stylesheet">
    <style type="text/css">:root #header + #content > #left > #rlblock_left
    {display:none !important;}</style>
    

  </head>
  <body class="" data-url="/92/data-analysis/machine-learning-week-3/">
    <nav id="sidebar">
  <div id="header-wrapper">
    <div id="header">
      <a id="logo" href="http://getgrav.org">
  <svg id="grav-logo" width="100%" height="100%" viewBox="0 0 504 140" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
    <path d="M235.832,71.564l-7.98,-0.001c-1.213,0.001 -2.197,0.987 -2.197,2.204l0,15.327l-0.158,0.132c-4.696,3.962 -10.634,6.14 -16.719,6.14c-14.356,0 -26.034,-11.68 -26.034,-26.037c0,-14.358 11.678,-26.035 26.034,-26.035c5.582,0 10.919,1.767 15.437,5.113c0.877,0.649 2.093,0.56 2.866,-0.211l5.69,-5.69c0.444,-0.442 0.675,-1.055 0.639,-1.681c-0.034,-0.627 -0.336,-1.206 -0.828,-1.597c-6.76,-5.363 -15.214,-8.314 -23.805,-8.314c-21.18,0 -38.414,17.233 -38.414,38.415c0,21.183 17.234,38.415 38.414,38.415c10.937,0 21.397,-4.705 28.698,-12.914c0.358,-0.403 0.556,-0.921 0.556,-1.46l0,-19.603c0,-1.217 -0.985,-2.203 -2.2,-2.203"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M502.794,34.445c-0.408,-0.616 -1.1,-0.989 -1.838,-0.989l-8.684,0c-0.879,0 -1.673,0.522 -2.022,1.329l-24.483,56.839l-24.92,-56.852c-0.352,-0.799 -1.142,-1.316 -2.012,-1.316l-8.713,0c-0.744,0 -1.44,0.373 -1.843,0.995c-0.408,0.623 -0.476,1.408 -0.174,2.09l30.186,68.858c0.352,0.799 1.143,1.317 2.017,1.317l10.992,0c0.879,0 1.673,-0.527 2.021,-1.329l29.655,-68.861c0.289,-0.68 0.222,-1.461 -0.182,-2.081"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M388.683,34.772c-0.353,-0.798 -1.142,-1.316 -2.017,-1.316l-10.988,0c-0.879,0 -1.673,0.522 -2.021,1.329l-29.655,68.861c-0.294,0.675 -0.226,1.46 0.182,2.077c0.407,0.619 1.096,0.993 1.838,0.993l8.684,0c0.879,0 1.673,-0.526 2.022,-1.329l24.478,-56.842l24.92,56.854c0.353,0.798 1.143,1.317 2.013,1.317l8.717,0c0.744,0 1.44,-0.374 1.843,-0.993c0.408,-0.624 0.471,-1.41 0.174,-2.094l-30.19,-68.857Z"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M309.196,81.525l0.476,-0.229c8.675,-4.191 14.279,-13.087 14.279,-22.667c0,-13.881 -11.295,-25.174 -25.176,-25.174l-31.863,0c-1.214,0 -2.199,0.988 -2.199,2.202l0,68.855c0,1.219 0.985,2.204 2.199,2.204l7.979,0c1.214,0 2.2,-0.985 2.2,-2.204l0,-58.679l21.684,0c7.059,0 12.799,5.739 12.799,12.796c0,5.885 -3.996,10.989 -9.728,12.408c-1.032,0.261 -2.064,0.393 -3.071,0.393l-7.977,0c-0.829,0 -1.585,0.467 -1.959,1.205c-0.378,0.74 -0.305,1.625 0.187,2.296l22.62,30.884c0.412,0.566 1.07,0.901 1.771,0.901l9.915,0c0.827,0 1.587,-0.467 1.96,-1.207c0.378,-0.742 0.302,-1.629 -0.186,-2.296l-15.91,-21.688Z"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M107.191,80.969c-7.255,-4.794 -11.4,-8.845 -15.011,-16.109c-2.47,4.977 -8.236,12.376 -17.962,18.198c-4.856,15.106 -27.954,44.015 -35.43,39.916c-2.213,-1.212 -2.633,-2.808 -2.133,-4.456c0.536,-4.129 9.078,-13.62 9.078,-13.62c0,0 0.18,1.992 2.913,6.187c-3.609,-11.205 5.965,-25.031 8.5,-29.738c3.985,-1.269 4.274,-6.387 4.274,-6.387c0.255,-7.909 -3.278,-13.635 -6.701,-17.059c2.459,3.002 3.255,7.539 3.372,11.694l0,0.023c0.012,0.469 0.012,0.93 0.011,1.39c-0.117,3.439 -1.157,8.19 -3.383,8.19l0.006,0.03c-2.289,-0.098 -5.115,0.391 -7.639,1.18l-5.582,1.334c0,0 2.977,-0.136 4.584,1.252c-1.79,2.915 -5.769,6.533 -10.206,8.588c-6.457,2.995 -8.312,-2.964 -5.034,-6.838c0.805,-0.946 1.618,-1.745 2.387,-2.399c-0.495,-0.513 -0.807,-1.198 -0.889,-2.068c-0.001,-0.005 -0.004,-0.009 -0.005,-0.013c-0.45,-1.977 -0.202,-4.543 2.596,-8.623c0.551,-0.863 1.214,-1.748 2.007,-2.647c0.025,-0.031 0.046,-0.059 0.072,-0.089c0.034,-0.042 0.072,-0.08 0.108,-0.121c0.02,-0.023 0.039,-0.045 0.059,-0.068c0.2,-0.228 0.413,-0.45 0.639,-0.663c3.334,-3.414 8.599,-6.966 16.897,-10.152c9.675,-14.223 13.219,-16.89 13.219,-16.89c1.071,-1.096 2.943,-2.458 3.632,-2.805c-5.053,-8.781 -6.074,-21.158 -4.75,-24.493c-0.107,0.18 -0.206,0.365 -0.287,0.556c0.49,-1.143 0.819,-1.509 1.328,-2.111c1.381,-1.632 6.058,-2.488 7.737,0.971c0.895,1.844 1.063,4.232 1.034,6.023c-3.704,-0.193 -7.063,4.036 -7.063,4.036c0,0 3.067,-1.448 6.879,-1.473c0,0 1.015,0.883 2.283,2.542c-1.712,3.213 -4.524,10.021 -2.488,17.168c0.338,1.408 0.849,2.619 1.483,3.648c0.024,0.045 0.044,0.089 0.069,0.135c0.051,0.066 0.096,0.122 0.144,0.183c3.368,5.072 9.542,5.665 9.542,5.665c-2.906,-1.45 -5.274,-3.76 -6.816,-6.56c-0.8,-1.498 -1.291,-2.762 -1.592,-3.761c-1.636,-6.313 0.771,-9.999 2.149,-12.471c3.17,-4.917 8.944,-7.893 15.151,-7.185c8.712,0.995 14.968,8.862 13.973,17.571c-0.608,5.321 -3.781,9.723 -8.142,12.117c1.049,2.839 -0.073,6.28 -0.073,6.28c2.642,3.323 2.758,5.238 2.667,7.017c-3.357,-0.565 -6.618,1.701 -6.618,1.701c0,0 6.476,-1.546 10.238,1.81c2.446,2.631 4.078,5.009 5.051,6.766c1.393,2.505 7.859,2.683 7.123,7.188c-0.737,4.499 -5.669,4.542 -13.401,-0.56M69.571,0c-38.424,0 -69.571,31.148 -69.571,69.567c0,38.422 31.147,69.573 69.571,69.573c38.42,0 69.568,-31.151 69.568,-69.573c0,-38.42 -31.148,-69.567 -69.568,-69.567"
      style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M73.796,51.693c0.813,-0.814 0.813,-2.134 0,-2.947c-0.815,-0.814 -2.133,-0.814 -2.947,0c-0.815,0.813 -0.815,2.133 0,2.947c0.814,0.813 2.132,0.813 2.947,0" style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M66.445,53.149c-0.814,0.813 -0.814,2.133 0,2.947c0.813,0.814 2.133,0.814 2.947,0c0.813,-0.814 0.813,-2.134 0,-2.947c-0.814,-0.813 -2.134,-0.813 -2.947,0" style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M79.231,54.233c-1.274,-1.274 -3.339,-1.272 -4.611,0l-2.713,2.712c-1.274,1.275 -1.274,3.339 0,4.612l2.978,2.978c1.274,1.275 3.338,1.274 4.611,0l2.712,-2.712c1.274,-1.274 1.274,-3.339 0,-4.612l-2.977,-2.978Z" style="fill:#000;fill-rule:nonzero;"></path>
    <path d="M95.759,41.445c-2.151,-2.578 1.869,-7.257 4.391,-4.463c4.645,5.148 -2.237,7.041 -4.391,4.463M105.004,44.132c3.442,-6.553 -1.427,-10.381 -4.773,-13.523c-5.36,-5.039 -10.706,-7.217 -16.811,-0.241c-6.102,6.977 -2.226,15.068 3.356,19.061c5.584,3.994 14.782,1.255 18.228,-5.297"
      style="fill:#000;fill-rule:nonzero;"></path>
  </svg>
</a>

      
    </div>
</div>


  <div class="highlightable">
    <ul class="topics">
      
      
      
      

      <li class="dd-item  " data-nav-id="/0/home/">
        <a href="https://1ambda.github.io/0/home/">
          <span>
            
              <b>HOME</b>
            
             
            
           </span>
        </a>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/21/scala/">
        <a href="https://1ambda.github.io/21/scala/">
          <span>
            
              <b>-</b>
            
             Scala
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-1/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-1/">
                <span>Easy Scalaz 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-2/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-2/">
                <span>Easy Scalaz 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-3/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-3/">
                <span>Easy Scalaz 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-4/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-4/">
                <span>Easy Scalaz 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-5/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-5/">
                <span>Easy Scalaz 5     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/easy-scalaz-6/">
              <a href="https://1ambda.github.io/21/scala/easy-scalaz-6/">
                <span>Easy Scalaz 6     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-1/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-1/">
                <span>Functional Programming 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-2/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-2/">
                <span>Functional Programming 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-3/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-3/">
                <span>Functional Programming 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-4/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-4/">
                <span>Functional Programming 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-5/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-5/">
                <span>Functional Programming 5     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-6/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-6/">
                <span>Functional Programming 6     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/functional-programming-7/">
              <a href="https://1ambda.github.io/21/scala/functional-programming-7/">
                <span>Functional Programming 7     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-1/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-1/">
                <span>Reactive Programming 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-2/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-2/">
                <span>Reactive Programming 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-3/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-3/">
                <span>Reactive Programming 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-4/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-4/">
                <span>Reactive Programming 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/21/scala/reactive-programming-5/">
              <a href="https://1ambda.github.io/21/scala/reactive-programming-5/">
                <span>Reactive Programming 5     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/22/haskell/">
        <a href="https://1ambda.github.io/22/haskell/">
          <span>
            
              <b>- </b>
            
             Haskell
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-1/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-1/">
                <span>하스켈로 배우는 함수형 언어 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-2/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-2/">
                <span>하스켈로 배우는 함수형 언어 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-3/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-3/">
                <span>하스켈로 배우는 함수형 언어 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-4/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-4/">
                <span>하스켈로 배우는 함수형 언어 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-5/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-5/">
                <span>하스켈로 배우는 함수형 언어 5     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-6/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-6/">
                <span>하스켈로 배우는 함수형 언어 6     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-7/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-7/">
                <span>하스켈로 배우는 함수형 언어 7     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-8/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-8/">
                <span>하스켈로 배우는 함수형 언어 8     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/intro-to-haskell-9/">
              <a href="https://1ambda.github.io/22/haskell/intro-to-haskell-9/">
                <span>하스켈로 배우는 함수형 언어 9     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/22/haskell/poor-mans-concurrency-monad/">
              <a href="https://1ambda.github.io/22/haskell/poor-mans-concurrency-monad/">
                <span>Poor Man&#39;s Concurrency Monad     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/23/javascript/">
        <a href="https://1ambda.github.io/23/javascript/">
          <span>
            
              <b>- </b>
            
             Javascript
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/23/javascript/javascript-inheritance/">
              <a href="https://1ambda.github.io/23/javascript/javascript-inheritance/">
                <span>Javascript Inheritance     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/23/javascript/tips-for-webpack-and-redux/">
              <a href="https://1ambda.github.io/23/javascript/tips-for-webpack-and-redux/">
                <span>Tips for Webpack and Redux     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/23/javascript/rest-api-put-vs-post/">
              <a href="https://1ambda.github.io/23/javascript/rest-api-put-vs-post/">
                <span>REST API: Put vs Post     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/24/java/">
        <a href="https://1ambda.github.io/24/java/">
          <span>
            
              <b>- </b>
            
             Java
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/24/java/interview-questions-collection/">
              <a href="https://1ambda.github.io/24/java/interview-questions-collection/">
                <span>Interview Questions: Collection     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/51/oh-my-github/">
        <a href="https://1ambda.github.io/51/oh-my-github/">
          <span>
            
              <b>- </b>
            
             oh-my-github
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/51/oh-my-github/tutorial/">
              <a href="https://1ambda.github.io/51/oh-my-github/tutorial/">
                <span>10분만에 Github Profile 만들기     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/91/algorithm/">
        <a href="https://1ambda.github.io/91/algorithm/">
          <span>
            
              <b>- </b>
            
             Algorithm
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-1/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-1/">
                <span>Design and Analysis: Divide &amp; Conquer     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-2/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-2/">
                <span>Design and Analysis: Randomized Selection     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-3/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-3/">
                <span>Design and Analysis: Graph Contraction Algorithm     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-4/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-4/">
                <span>Design and Analysis: Graph Search and Connectivity     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-5/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-5/">
                <span>Design and Analysis: Dijkstra, Heap, Red-Black Tree     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/design-and-analysis-part1-6/">
              <a href="https://1ambda.github.io/91/algorithm/design-and-analysis-part1-6/">
                <span>Design and Analysis: Hash Table, Universal Hashing, Bloom filters     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part1-1/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part1-1/">
                <span>Algorithm: Union Find     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part1-2/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part1-2/">
                <span>Algorithm: Analysis     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-1/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-1/">
                <span>Algorithm: Spanning Tree, Shortest Paths     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-2/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-2/">
                <span>Algorithm: Radix Sort, Suffix Sort     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-3/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-3/">
                <span>Algorithm: R-way, Ternary Tries     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-4/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-4/">
                <span>Algorithm: KMP, Boyer-Moore, Rabin-Karp     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-5/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-5/">
                <span>Algorithm: Maximum Flow (Ford-Fulkerson)     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/algorithm-part2-6/">
              <a href="https://1ambda.github.io/91/algorithm/algorithm-part2-6/">
                <span>Algorithm: Data Compression, Huffman, LZW     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-cs188-1/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-cs188-1/">
                <span>AI (CS188): Intro     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-cs188-2/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-cs188-2/">
                <span>AI (CS188): Search     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-planning-1/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-planning-1/">
                <span>AI Planning 1: Intro     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-planning-2/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-planning-2/">
                <span>AI Planning 2: A*. STRIPS     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-planning-3/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-planning-3/">
                <span>AI Planning 3: PSP, PoP     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/91/algorithm/artificial-intelligence-planning-4/">
              <a href="https://1ambda.github.io/91/algorithm/artificial-intelligence-planning-4/">
                <span>AI Planning 4: STN, HTN     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  parent" data-nav-id="/92/data-analysis/">
        <a href="https://1ambda.github.io/92/data-analysis/">
          <span>
            
              <b>- </b>
            
             Data Analysis
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-1/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-1/">
                <span>ML 01: Linear Regression     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-2/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-2/">
                <span>ML 02: Gradient Descent     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item active" data-nav-id="/92/data-analysis/machine-learning-week-3/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-3/">
                <span>ML 03: Logistic Regression     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-4/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-4/">
                <span>ML 04: Neural Network     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-5/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-5/">
                <span>ML 05: Back Propagation     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-6/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-6/">
                <span>ML 06: Practical Advices     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-7/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-7/">
                <span>ML 07: Support Vector Machine     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-8/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-8/">
                <span>ML 08: K-means, PCA Details     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-9/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-9/">
                <span>ML 09: Anomaly Detection, Recommender System     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/machine-learning-week-10/">
              <a href="https://1ambda.github.io/92/data-analysis/machine-learning-week-10/">
                <span>ML 10: Stochastic Gradient, Synthetic Data, Ceiling Analysis     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/intro-to-data-science-1/">
              <a href="https://1ambda.github.io/92/data-analysis/intro-to-data-science-1/">
                <span>Intro to Data Science 1     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/intro-to-data-science-2/">
              <a href="https://1ambda.github.io/92/data-analysis/intro-to-data-science-2/">
                <span>Intro to Data Science 2     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/intro-to-data-science-3/">
              <a href="https://1ambda.github.io/92/data-analysis/intro-to-data-science-3/">
                <span>Intro to Data Science 3     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/intro-to-data-science-4/">
              <a href="https://1ambda.github.io/92/data-analysis/intro-to-data-science-4/">
                <span>Intro to Data Science 4     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-1/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-1/">
                <span>Process Mining 1: Intro     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-2/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-2/">
                <span>Process Mining 2: Alpha Algorithm     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-3/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-3/">
                <span>Process Mining 3: Metric, C-nets     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-4/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-4/">
                <span>Process Mining 4: Conformance Checking, Dotted Chart     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/process-mining-5/">
              <a href="https://1ambda.github.io/92/data-analysis/process-mining-5/">
                <span>Process Mining 5: Decision, Social, Organization Mining     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/pattern-discovery-1/">
              <a href="https://1ambda.github.io/92/data-analysis/pattern-discovery-1/">
                <span>Pattern Discovery 1: Apriori, FP Growth     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/pattern-discovery-2/">
              <a href="https://1ambda.github.io/92/data-analysis/pattern-discovery-2/">
                <span>Pattern Discovery 2: Null-invariant, Pattern-Fusion, Constaint     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/92/data-analysis/pattern-discovery-3/">
              <a href="https://1ambda.github.io/92/data-analysis/pattern-discovery-3/">
                <span>Pattern Discovery 3: Sequential Pattern Mining     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
      
      

      <li class="dd-item  " data-nav-id="/93/cloud-computing/">
        <a href="https://1ambda.github.io/93/cloud-computing/">
          <span>
            
              <b>- </b>
            
             Cloud Computing
            
           </span>
        </a>
        
        <ul>
          
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-1/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-1/">
                <span>CC 01: Map Reduce     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-2/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-2/">
                <span>CC 02: Gossip Protocol     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-3/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-3/">
                <span>CC 03: Membership Protocol     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-4/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-4/">
                <span>CC 04: P2P Systems     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-5/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-5/">
                <span>CC 05: Global Snapshot     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-6/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-6/">
                <span>CC 06: Multicast     </i></span>
              </a>
            </li>
          
          
          
            <li class="dd-item " data-nav-id="/93/cloud-computing/cloud-computing-7/">
              <a href="https://1ambda.github.io/93/cloud-computing/cloud-computing-7/">
                <span>CC 07: Paxos     </i></span>
              </a>
            </li>
          
          
        </ul>
        
      </li>
      
      
    </ul>
    <hr>
      
    <section id="footer">
      <p>Built with <a href="https://github.com/matcornic/hugo-theme-learn"><i class="fa fa-heart"></i></a> from <a href="http://getgrav.org">Grav</a> and <a href="http://gohugo.io/">Hugo</a></p>
    </section>
  </div>
</nav>

        <section id="body">
        <div id="overlay"></div>

        <div class="padding highlightable">

            <div id="top-bar">
              
                
                
                
              <div id="top-github-link">
                  <a class="github-link" href="https://github.com/1ambda/1ambda.github.io-hugo/edit/master/content/92/data-analysis/machine-learning-week-3.md" target="blank">
                    <i class="fa fa-code-fork"></i>
                    Edit this page
                  </a>
              </div>
                
              
              <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                  <span id="sidebar-toggle-span">
                      <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                        <i class="fa fa-bars"></i>
                      </a>
                  </span>
                
                <span id="toc-menu"><a href=""><i class="fa fa-list-alt"></i></a></span>
                
                
                
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    
                    
                <a href="https://1ambda.github.io/92/data-analysis/" itemprop="url"><span itemprop="title">Data Analysis</span></a> <i class="fa fa-angle-right"></i>
                    
                  
                
                  
                
                <span itemprop="title"> ML 03: Logistic Regression</span>
              </div>
              
                  <div class="progress">
    <div class="wrapper">
<nav id="TableOfContents">
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#classification">Classification</a></li>
<li><a href="#logistic-regression">Logistic Regression</a></li>
<li><a href="#decision-boundary">Decision Boundary</a></li>
<li><a href="#cost-function">Cost Function</a></li>
<li><a href="#simplified-cost-function-and-gradient-descent">Simplified Cost Function and Gradient Descent</a></li>
<li><a href="#advanced-optimization">Advanced Optimization</a></li>
<li><a href="#multiclass-classification">Multiclass Classification</a>
<ul>
<li><a href="#one-vs-all-one-vs-rest">one-vs-all (One-vs-rest)</a></li>
</ul></li>
<li><a href="#overfitting">Overfitting</a></li>
<li><a href="#regularization-cost-function">Regularization, Cost function</a></li>
<li><a href="#regularized-linear-regression">Regularized Linear Regression</a></li>
<li><a href="#regularized-logistic-regression">Regularized Logistic Regression</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#references">References</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
    </div>
</div>

              

            </div>
            
    	        <div id="body-inner">
                
                <h1>ML 03: Logistic Regression</h1>
                



<p>지난 시간엔 <em>Regression</em> 을 해결하기 위해 <em>graident descent</em> 알고리즘을 도입했었다. <em>learning rate</em>, <em>vectorization</em> 등에 대해서 알아 보기도 했고. 이번시간엔 <em>classification</em> 과 <em>regulrzation</em> 에 대해서 배워 본다.</p>

<p>이 수업이 재밌는 이유는 수식을 증명하는 것보다 수식속에 숨겨진 내용들을 직관적으로 이해할 수 있게 설명하기 때문이다. <del>그러나 교수님 과제는 제발 그만</del></p>

<h3 id="classification">Classification</h3>

<p><em>regression</em> 이 <em>continuous value</em> 를 다룬다면 <strong>Classification</strong> 은 <strong>discrete value</strong> 를 다룬다. 따라서 <em>Classification (분류)</em> 의 예는,</p>

<ul>
<li>이메일이 스팸인지 / 아닌지<br /></li>
<li>온라인 거래가 사기인지 / 아닌지 (Online Transaction: Fraudulent)<br /></li>
<li>악성 종양인지 / 아닌지<br /></li>
</ul>

<p><img src="http://i.stack.imgur.com/VVtRW.png" align="center" />
<p align="center">(<a href="http://stats.stackexchange.com">http://stats.stackexchange.com</a>)</p></p>

<p>위와 같은 경우, <em>Regression</em> 으로 문제를 풀면 당장은 맞아 보이나, 종양이 이상한 위치에 생겼을 경우 아래와 같이 직선이 크게 변한다.</p>

<p><img src="http://i.stack.imgur.com/nEC4H.png" align="center" />
<p align="center">(<a href="http://stats.stackexchange.com">http://stats.stackexchange.com</a>)</p></p>

<p>따라서 이렇게 <em>discrete value</em> 에 대해서는 <em>Regression</em> 보다는 <em>Threshold</em> 에 기반을 두어, <code>h(x)</code> 가 일정 값 이상이면 <code>y=1</code> 로 예측하는 편이 더 정확도가 높아진다. 게다가 <em>regression</em> 은 직선이기 때문에, <code>0 &lt;= y &lt;= 1</code> 인 <code>y</code> 에 대해서 0보다 작거나, 1보다 더 큰 <code>y</code> 를 만들어낼 수 있다.</p>

<p>이런 이유 때문에 <em>Classification</em> 문제에 <em>Regression</em> 을 잘 사용하지 않는다. 그러나 <code>y</code> 의 범위가 <code>0 &lt;= h(x) &lt;= 1</code> 을 가지는 <em>Logistic Regression</em> 도 있다. 이건 <em>Classification</em> 에 사용되기도 한다.</p>

<h3 id="logistic-regression">Logistic Regression</h3>

<p>이전에 언급했듯이 <em>classification</em> 에선 예측된 값, 즉 <code>h(x)</code> 값이 0 과 1사이에 있길 바란다. 이를 위해 <em>logistic function</em>, 혹은 <strong>sigmoid function</strong> 이라 불리는 아래 식을 <em>hypothesis</em> <code>h(x)</code> 에 적용하면 아래와 같은 그림이 나온다.</p>

<p><img src="http://www.saedsayad.com/images/ANN_Sigmoid.png" align="center" />
<p align="center">(<a href="http://www.saedsayad.com">http://www.saedsayad.com</a>)</p></p>

<p>이 때 <em>sigmoid function</em> 이 적용된 <code>h(x)</code> 는 최대값이 1이므로, 이건 입력값 <code>x</code> 에 대해서 <code>y</code> 가 1이 나올 확률이라 보아도 된다. 따라서</p>

<p><code>h(x) = P(y = 1 | x ; 0)</code></p>

<blockquote>
<p>Probability that <code>y = 1</code>, given <code>x</code>, parameterized by <code>0(theta)</code></p>
</blockquote>

<p>이 때 <em>sigmoid function</em> 을 보면, X 축이 0보다 큰 점에선 <code>y</code> 값이 0.5 보다 크므로, 이 점 이후부터는 <code>y</code> 를 1 이라 <em>예측 (predict)</em> 하고, 반대로 X 축 값이 0보다 작은 지점에선 <code>y</code> 를 0이라 예측할 수 있다.</p>

<p>그런데 <code>h(x) = g(0^T * x)</code> 이므로, 본래의 <em>hypothesis</em> <code>0^T * x</code> 가 0이 되는 지점을 찾으면 된다.</p>

<p><img src="http://my.csdn.net/uploads/201207/04/1341403634_5914.jpg" align="center" />
<p align="center">(<a href="http://blog.csdn.net/abcjennifer/">http://blog.csdn.net/abcjennifer/</a>)</p></p>

<h3 id="decision-boundary">Decision Boundary</h3>

<p>이제 실제로 문제에 적용해 보자. 다음과 같이 두개의 집단이 있을때, 이 두 집단을 가르는 식을 찾기 위한 <code>h(x) = g(01 + 01x1 + 02x2)</code> 가 있다고 해 보자.</p>

<p><img src="http://my.csdn.net/uploads/201207/05/1341470683_7505.jpg" align="center" />
<p align="center">(<a href="http://blog.csdn.net/abcjennifer/">http://blog.csdn.net/abcjennifer/</a>)</p></p>

<p>이때 <code>0(theta)</code> 를 <code>[-3; 1; 1]</code> 로 잡으면 <code>y</code> 가 <code>1</code> 이 되는 지점은 <code>0^T * x &gt;= 0</code> 인 지점, 즉 <code>-3 + x1 + x2 &gt;= 0</code> 인지점을 찾으면 된다. 이 식을 풀어서 쓰면</p>

<p><code>x1 + x2 =&gt; 3</code> 이므로, 위 그림에서 분홍색 선을 찾을 수 있다. 이 선을 <strong>Decision Boundary</strong> 라 부른다. 그리고 이 <em>Decision Boundary</em> 는 <code>g(z) = 0</code> 즉,  <code>h(x) = 0.5</code> 인 지점이다.</p>

<p><em>Non-linear dicision boundary</em> 는 어떨까?</p>

<p><img src="http://my.csdn.net/uploads/201207/05/1341471338_7289.jpg" align="center" />
<p align="center">(<a href="http://blog.csdn.net/abcjennifer/">http://blog.csdn.net/abcjennifer/</a>)</p></p>

<p>이 경우  <code>x1^2</code>, <code>x2^2</code> 이라는 새로운 <em>feature</em> 를 도입하고, <em>parameter</em> 인 <code>theta</code> 를 <code>[-1; 0; 0; 1; 1;]</code> 로 잡았다. 식을 풀면, 위와 같은 원 형태의 <em>Decision Boundary</em> 가 나온다.</p>

<p><em>feature</em> 만 잘 조합하면, 즉 <em>polynomial</em> 만 잘 만들면 땅콩이나 하트모양 등의 <em>Decision boundary</em> 도 만들 수 있다.</p>

<h3 id="cost-function">Cost Function</h3>

<p>이제 문제는 <code>theta</code> 를 어떻게 고르느냐 하는건데, 식을 좀 다시 살펴보자.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[9].png" align="center" />
<img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[11].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p><em>Linear regression</em> 에서 사용하는 <em>cost function</em> 에 지금의 <code>h(x)</code>, 즉 <em>sigmoid function</em> 이 적용된 <code>h(x)</code> 를 제곱한 <code>J(0)</code> 는 <em>non-convex</em> 형태가 된다. 따라서 <em>global optimum</em> 보다는 <em>local optimum</em> 을 찾게 된다.</p>

<p>이를 방지하기 위해서, <em>convex</em> 형태의 <em>cost function</em> 을 사용해야 하는데,</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[12].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>이 <em>cost function</em> 을 사용하면, <code>y = 1</code> 일때 다음과 같은 그래프를 얻게 된다. <code>0 &lt;= h(x) &lt;= 1</code> 임을 참고하자. <code>y = 1</code> 일때, <code>h(x) = 0</code> 으로 가면, <em>cost function</em> 의 값, 즉 <em>cost</em> 자체가 높아지므로, <em>Cost</em> 를 낮추는 반대 방향으로 움직이게 된다.</p>

<p>직관적으로 보면, <code>h(x)</code> 자체는 <code>y = 1</code> 일 확률인데, <code>y = 1</code> 일때, <code>h(x) = 0</code> 이라는 것은 말이 안 되므로 비용이 무한대로 증가하는 것이 말이 된다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[13].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>반대로 <code>y = 0</code> 일때의 그래프를 보면 <code>h(x) = 0</code> 즉, <code>y = 0</code> 일 확률이 <code>0</code> 으로 갈때 <em>cost</em> 가 감소한다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[14].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>결국 아래의 새로운 <em>logistric regression cost function</em> 을 이용하면, <code>J(0)</code> 를 <em>convex function</em> 으로 만들 수 있다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[12].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<h3 id="simplified-cost-function-and-gradient-descent">Simplified Cost Function and Gradient Descent</h3>

<p>이제 <code>y = 0</code>, <code>y = 1</code> 로 나누어져 있던 <em>cost function</em> 을 좀 더 간단히 표현해 보자.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[15].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>다음과 동일하다. <code>y = 0</code>, <code>y = 1</code> 을 직접 넣어보면 금방 알 수 있다.</p>

<p><code>cost(hθ(x),y) = -y * log(hθ(x)) - (1-y) * log(1 - hθ(x))</code></p>

<p><br/>
자 이제 다시 본론으로 돌아와서, 우리는 처음에 <code>theta</code> 를 찾길 원했고, 그래서 <em>gradient descent</em> 를 쓰려고 했는데, 마침 보니 <code>h(x)</code> 가 <em>sigmoid function</em> 이 적용된 형태라서 <em>non-convex function</em> 이므로, <code>h(x)</code> 를 포함한 <em>cost-function</em> 이 <em>convex function</em> 이 되는 식을 찾아냈다. 이제 그 식을 <em>gradient descent</em> 에 적용하면,</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[16].png" align="center" /></p>

<p>이고, 이제 이걸 <em>batch gradient descent</em> 에 적용하면 아래와 같은데, 여기에 <em>partial derivative</em> 를 적용하면</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[20].png" align="center" /></p>

<p>놀랍게도 <em>linear regression</em> 과 같은 식이 나온다. <del>오오 머신러닝 오오</del></p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[18].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>다만 다른점은 <em>hypothesis</em> 가 <em>sigmoid function</em> 을 적용한 형태라는 것,</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[17].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<h3 id="advanced-optimization">Advanced Optimization</h3>

<p>위에서 보았겠지만, <code>J(0)</code> 의 최소값을 찾기 위해서는 아래 두개의 값을 구해야 한다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[19].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>이 값들을 이용해서 <em>gradient descent</em> 대신 다음의 알고리즘을 사용할 수 있다.</p>

<p>(1) Conjugate gradient<br />
(2) BFGS<br />
(3) L-BFGS</p>

<p>이 알고리즘들의 장점은, <em>leanring rate</em> 를 고를 필요가 없고, 대부분 <em>gradient decsent</em> 보다 빠르다.</p>

<p>그러나 더 복잡하고, 라이브러리마다 구현이 다를 수 있으며, 디버깅이 힘들수 있다. 자 이제 <em>advanced optimization</em> 을 이용해 보자.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[21].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>위와 같은 식에 대해서 <em>cost function</em> 을 <code>octave</code> 에서 이렇게 만들 수 있다.</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[22].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p>
<br/></p>

<p>이제, <code>octave</code> 에서 제공해 주는 <code>fminunc</code> 에 우리가 만든 <code>costFunction</code> 과 초기 <code>theta</code> 값, 그리고 옵션을 집어 넣으면</p>

<pre><code class="language-matlab">% define the options data structure
options= optimset('GradObj', 'on', 'MaxIter', '100'); 

% set the initial dimensions for theta % initialize the theta values
initialTheta= zeros(2,1); 

% run the algorithm
[optTheta, funtionVal, exitFlag]= fminunc(@costFunction, initialTheta, options); 
</code></pre>

<p><code>optTheta</code> 는 우리 찾길 원했던 <code>theta</code> 값이고, <code>functionVal</code> 은 최종 <em>cost</em> 를 돌려준다. <code>exstFlag</code> 는 알고리즘이 수렴했는지, 아닌지 알려준다.</p>

<p>만약 <em>logistic regression</em> 에 대한 <code>theta</code> 값을 찾고 싶으면, <em>cost function</em> 을 <em>logistic regression</em> 에 맞게 작성하면 된다.</p>

<h3 id="multiclass-classification">Multiclass Classification</h3>

<p>이제 단순히 <code>y = 0 or 1</code>(<em>binary classification</em>) 이 아닌, 다양한 <em>class</em> 가 있는 <em>classification</em> 을 고려해보자, 예를 들면 날씨는 <code>sunny</code>, <code>cloudy</code>, <code>hot</code>, <code>cold</code> 등으로 분류될 수 있다.</p>

<h4 id="one-vs-all-one-vs-rest">one-vs-all (One-vs-rest)</h4>

<p><em>multi class</em> 를 분류할 수 있는 한가지 방법은, 하나를 정하고, 그 나머지와 분류하는것이다. 이걸 <em>class</em> 갯수만큼 진행하면,</p>

<p><img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[23].png" align="center" />
<img src="http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[24].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>위 그림과 같은 경우, <em>class</em> 가 3개기 때문에 <code>(i = 1, 2, 3)</code> 으로 놓으면 <code>i</code> 마다 각각의 <code>hθ^(i)(x)</code> 값, 즉 예측 값을 얻을 수 있다. 따라서 새로운 무언가가 input 으로 들어왔을때, <code>hθ^(i)(x)</code> 값을 최대로 해주는 <code>i</code> 을 선택하면 분류가 된다. <del>참 쉽죠?</del></p>

<h3 id="overfitting">Overfitting</h3>

<p><strong>Overfitting</strong> 은 너무나 많은 <em>feature</em> 가 있을 때는 <em>cost function</em> 이 트레이닝 셋에 잘 맞아 <code>0</code> 에 수렴 하지만, 새로운 데이터가 들어왔을때는 예측을 잘 하지 못하는 경우를 말한다. 다시 말해 <em>hypothesis</em> 가 너무 고차원의 다항식이어서 그렇다. <em>(too many parameters)</em> 즉 아래 그림에서 좌측은 경향을 나타내긴 하지만 모든 트레이닝셋을 경유하는 직선은 만들어내지 못했다. (<em>under fit</em>) 반면 가장 우측은, 트레이닝셋을 모두 경유하는 <em>hypothesis</em> 를 만들어 냈지만, 다항식의 차수가 너무 높아 새로운 데이터가 들어왔을 때 예측하지 못할 수가 있다. <em>can&rsquo;t apply, unable to generalize</em> 교수님은 다음과 같이 슬라이드에 적으셨다.</p>

<blockquote>
<p>It makes accurate predictions for examples in the training set, but it does not generalize well to make accurate prediction on new, previously unseen examples</p>
</blockquote>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image.png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p><em>logistic regression</em> 에서도 <em>Overfitting</em> 이 발생할 수 있다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[1].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>주로 <em>training set</em> 이 부족하고 <em>feature</em> 가 많을때 발생하는데 해결책은</p>

<p>(1) <em>feature</em> 를 줄일 수 있다. 수동으로 사용할 <em>feature</em> 를 선택하는 방법과 <em>Model selection algorithm</em> 을 사용할 수도 있다.<br />
(2)  <em>regularization</em> 을 이용한다. 모든 <em>feature</em> 를 유지하지만, 얼마나 각 <em>feature</em> 가 <em>prediction</em> 에 기여할지를 변경한다.</p>

<h3 id="regularization-cost-function">Regularization, Cost function</h3>

<p><em>Regularization</em> 은 원하는 파라미터가 <em>hypothesis</em> 에 기여하는 바를 조절하는 것이다. 우리가 만약에 <code>0_3</code> 과 <code>0_4</code> 를 최소화 하고 싶다고 하자.  그럼 다음과 같은 식을 만들면 된다. 전체 식의 최소값을 찾는 것이기 때문에, 상수가 <code>1000</code> 인 <code>0_3</code>, <code>0_4</code> 는 <em>0(zero)</em> 에 가까운 수가 나온다. 다시 말해서 이들 두 파라미터가 기여하는 바를 줄인 것이다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[2].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p><em>parameters</em> 가 작은 값을 가질수록 간단한 <em>hypothesis</em> 가 나오고, <em>overfitting</em> 하지 않는다. 이를 위해 <code>λ</code> 라는 <em>regularization parameter</em> 를 가진 식을 <em>cost function</em> 에 더 붙여 <em>parameter</em> 가 기여하는 바를 조절하면, 아래와 같은 식을 구할 수 있다. 참고로 뒷 부분의 식은  <em>regularization term</em> 이라 부르는데, <code>j</code> 가 1부터 시작하는 것에 주목하자. 이는 <code>0_0</code> 은 <em>regularization</em> 하지 않는다는 의미이다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[5].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p><code>λ</code> 가 매우 크면 어떻게 될까? <code>0_0</code> 이외의 다른 파라미터는 0에 수렴 하므로, <em>hypothesis</em> 는 상수가 되어 트레이닝 셋에 <em>under fit</em> 할 것이다.</p>

<h3 id="regularized-linear-regression">Regularized Linear Regression</h3>

<p><em>regularization term</em> 으 <code>j</code> 가 1부터 시작하므로, <em>cost function</em> 을 쉽게 계산하기 위해 분리하면 <em>gradient descent</em> 식은 다음과 같이 적을 수 있다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[6].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<p>이제 위 두 식에서 아래 식을 정리하면, 다음과 같고</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[8].png" align="center" />
&lt;면 된다. 이때 이 매트릭스의 <code>(0, 0)</code>
위 식에서 앞부분은 아래와 같다. 보통 <code>m</code> 이 매우 크고, <code>a</code> 가 매우 작으므로 위 값은 1보다 작다. 예를 들면 <code>0.99 * 0_j</code> 처럼.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[9].png" align="center" /></p>

<p>이제 <em>Normal equation</em> 에 어떻게 적용할지 고려해 보자, 본래 <em>normal equation</em> 식은 아래와 같은데,</p>

<p><img src="http://www.holehouse.org/mlclass/04_Linear_Regression_with_multiple_variables_files/Image%20[13].png" align="center" /></p>

<p><code>X^T * X</code> 부분에 <code>λ</code> 가 곱해지는 <code>n+1 * n+1</code> 의 <em>matrix</em> 를 곱하면 된다. 이때 이 매트릭스의 <code>(0, 0)</code> 부분이 <code>0</code> 인 것은 <code>0_0</code> 에 <em>regularization</em> 을 적용하지 않기 위한 것.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[10].png" align="center" /></p>

<p>그럼 만약에 <code>X^T * X</code> 가 <em>non-invertible</em> 이라면 어떻게 될까? 이건 지난 시간에 언급했듯이 <em>redundant feature</em> 가 너무 많거나, <code>m &lt;= n</code>, 즉 트레이닝 셋에 비해 <em>feature</em> 가 너무 많을 때 발생한다고 말했다.</p>

<p>놀랍게도, <code>λ &gt; 0</code> 이면, 아래 식에서 <code>X^T * X + λ</code> (λ&rsquo;s (0, 0) = 0) 은 제대로 <em>invertible</em> 함을 증명할 수 있다. 다시 말해서 <em>regularzation</em> 을 통해서 <em>non-invertible</em> 문제도 해결할 수 있다는 것.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[10].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p></p>

<h3 id="regularized-logistic-regression">Regularized Logistic Regression</h3>

<p><em>linear regression</em> 과 마찬가지로 <code>0(theta)</code> 를 0과 1로 분리해 <em>regularization term</em> 을 추가하면 된다. 다른점은 <code>h(x)</code> 가 <em>sigmoid function</em> 의 형태라는 것.</p>

<p>그리고 <em>gradient descent</em> 를 풀기 위해 <em>octave</em> 에서 제공하는 알고리즘들을(<em>conjugate</em>, <em>BFGS</em>, <em>L-BFGS</em> 등) 을 <code>fminunc</code> 이용해서 사용할 수 있다. 이를 위해 언급 했듯이 <code>jval</code> 과 <code>0(theta)</code> 에 대한 <code>graident</code> 를 돌려주는 <em>cost function</em> 을 만들어야 하는데, <em>regularzation term</em> 이 추가되었으므로 해당하는 값을 더해서 각 <code>0</code> 에 대한 <em>gradient</em> 를 계산하는 식을 만들어주면 된다.</p>

<p><img src="http://www.holehouse.org/mlclass/07_Regularization_files/Image%20[16].png" align="center" />
<p align="center">(<a href="http://www.holehouse.org/">http://www.holehouse.org/</a>)</p>
<br/></p>

<h3 id="summary">Summary</h3>

<p>3주째에는 <em>Classification</em> 과 <em>Regularization</em> 에 대해서 배웠다. 수업은 어렵지 않다. 과제가 문제지 ㅠㅠ 교수님. 파이썬으로 과제를 내주셨으면 좀 더 배우는 맛이 있었을텐데요!</p>

<h3 id="references">References</h3>

<p>(1) <a href="http://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression">why-not-approach-classification-through-regression</a><br />
(2) <a href="http://www.saedsayad.com/artificial_neural_network.htm">http://www.saedsayad.com</a><br />
(3) <a href="http://blog.csdn.net/abcjennifer/">http://blog.csdn.net/abcjennifer/</a><br />
(4) <a href="http://www.holehouse.org/">http://www.holehouse.org/</a></p>

<p><strong>Machine Learning</strong> by Andrew Ng, <em>Coursera</em></p>

<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = '1ambda';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


      
      </div>
    </div>

    <div id="navigation">
        <a class="nav nav-prev" href="../machine-learning-week-2"> <i class="fa fa-chevron-left"></i></a>
        <a class="nav nav-next" href="../machine-learning-week-4" style="margin-right: 0px;"><i class="fa fa-chevron-right"></i></a>
    </div>

    </section>
    <div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
      <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
    </div>
    <script src="https://1ambda.github.io/js/jquery-2.x.min.js"></script>
    <script src="https://1ambda.github.io/js/clipboard.min.js"></script>
    <script src="https://1ambda.github.io/js/perfect-scrollbar.min.js"></script>
    <script src="https://1ambda.github.io/js/perfect-scrollbar.jquery.min.js"></script>
    <script src="https://1ambda.github.io/js/jquery.sticky-kit.min.js"></script>
    <script src="https://1ambda.github.io/js/featherlight.min.js"></script>
    <script src="https://1ambda.github.io/js/html5shiv-printshiv.min.js"></script>
    <script src="https://1ambda.github.io/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="https://1ambda.github.io/js/modernizr.custom.71422.js"></script>
    <script src="https://1ambda.github.io/js/learn.js"></script>
    <script src="https://1ambda.github.io/js/hugo-learn.js"></script>
    
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-52181619-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>


  </body>
</html>


